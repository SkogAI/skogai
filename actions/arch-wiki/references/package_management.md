# Arch-Wiki - Package Management

**Pages:** 180

---

## pacman/Tips and tricks

**URL:** https://wiki.archlinux.org/title/Pacman/Tips_and_tricks

**Contents:**
- Maintenance
  - Listing packages
    - In unused repositories
    - With version
    - With size
      - Individual packages
      - Packages and dependencies
    - By date
    - Not in a specified group, repository or meta package
    - Development packages

For general methods to improve the flexibility of the provided tips or pacman itself, see Core utilities and Bash.

See also System maintenance.

By default, repositories listed in pacman.conf are used for syncing, searching, installing and upgrading from them. This can be changed for more versatility, for example by using some repositories only for searching in them[1]:

See pacman.conf(5) § REPOSITORY SECTIONS.

You may want to get the list of installed packages with their version, which is useful when reporting bugs or discussing installed packages.

Figuring out which packages are largest can be useful when trying to free space on your hard drive. There are two options here: get the size of individual packages, or get the size of packages and their dependencies.

The following command will list all installed packages and their individual sizes:

To list package sizes with their dependencies,

To list the download size of several packages (leave packages blank to list all packages):

To list explicitly installed packages not in the meta package base nor package group xorg with size and description:

To list the packages marked for upgrade with their download size:

To list optional dependencies only:

To list the 20 last installed packages with expac, run:

or, with seconds since the epoch (1970-01-01 UTC):

List explicitly installed packages not in the base meta package:

List explicitly installed packages not in the base meta package or xorg package group:

List all installed packages unrequired by other packages, and which are not in the base meta package or xorg package group:

As above, but with descriptions:

List all installed packages that are not in the specified repository repo_name (multiple repositories can be checked at once):

List all installed packages that are in the repo_name repository (multiple repositories can be checked at once):

List all packages on the Arch Linux ISO that are not in the base meta package:

To list all development/unstable packages, run:

To obtain the list of the dependencies of a package, the simplest solution is reading the output of:

For automation, instead of the error-prone method of parsing pacman output, use expac:

To list explicitly-installed packages with their optional dependencies, run:

Alternatively, with expac:

To list them while omitting optional dependencies you have already installed, run:

To browse all installed packages with an instant preview of each package:

This uses fzf to present a two-pane view listing all packages with package info shown on the right.

Enter letters to filter the list of packages; use arrow keys (or Ctrl-j/Ctrl-k) to navigate; press Enter to see package info under less.

To browse all packages currently known to pacman (both installed and not yet installed) in a similar way, using fzf, use:

The navigational keybindings are the same, although Enter will not work in the same way.

This one might come in handy if you have found that a specific package uses a huge amount of space and you want to find out which files make up the most of that.

If your system has stray files not owned by any package (a common case if you do not use the package manager to install software), you may want to find such files in order to clean them up.

One method is to list all files of interest and check them against pacman:

Most systems will slowly collect several ghost files such as state files, logs, indexes, etc. through the course of usual operation.

pacreport from pacutils can be used to track these files and their associations via /etc/pacreport.conf (see pacreport(1) § FILES).

An example may look something like this (abridged):

Then, when using pacreport --unowned-files as the root user, any unowned files will be listed if the associated package is no longer installed (or if any new files have been created).

Additionally, aconfmgr (aconfmgr-gitAUR) allows tracking modified and orphaned files using a configuration script.

Orphans are packages that were installed as a dependency and are no longer required by any package.

They can accumulate on your system over time either due to uninstalling packages using pacman -R package instead of pacman -Rs package, installing packages as makedepends, or packages removing dependencies in newer versions.

For recursively removing orphans and their configuration files:

If no orphans were found, the output is error: argument '-' specified with empty stdin. This is expected as no arguments were passed to pacman -Rns. The error can be avoided by prefixing the second command with ifne(1) from the moreutils package.

If there is a package listed that you do not want to remove, it can be excluded from the list of orphans by marking it as explicitly installed:

In some cases the method above will not detect all possible unneeded packages. E.g. dependency cycles (also known as "circular dependencies"), excessive dependencies (fulfilled more than once), some non-explicit optionals etc.

To detect such packages:

If you want to remove all packages in the list at once, run the command without --print argument.

Sometimes there may be multiple packages providing same item. For example, there may be multiple packages which provide ttf-font. You may not want all such packages depending your preference.

To detect packages which provide same item:

Check the output and carefully remove redundant package which you do not require.

If it is ever necessary to remove all packages except the essentials packages, one method is to set the installation reason of the non-essential ones as dependency and then remove all unnecessary dependencies.

First, for all the packages "explicitly installed", change their installation reason to "installed as a dependency":

Then, change the installation reason to "explicitly installed" of only the essential packages, those you do not want to remove, in order to avoid targeting them:

Finally, follow the instructions in #Removing unused packages (orphans) to remove all packages that are "installed as a dependency".

Dependencies are alphabetically sorted and doubles are removed.

Alternatively, with expac:

To list configuration files tracked by pacman as susceptible of containing user changes (i.e. files listed in the PKGBUILD backup array) and having received user modifications, use the following command:

Running this command with root permissions will ensure that files readable only by root (such as /etc/sudoers) are included in the output.

This can be used when doing a selective system backup or when trying to replicate a system configuration from one machine to another.

The following command can be used to back up the local pacman database:

Store the backup pacman database file on one or more offline media, such as a USB stick, external hard drive, or CD-R.

The database can be restored by moving the pacman_database.tar.bz2 file into the / directory and executing the following command:

When maintainers update packages, commits are often commented in a useful fashion. Users can quickly check these from the command line by installing pacologAUR. This utility lists recent commit messages for packages from the official repositories or the AUR, by using pacolog package.

Alternative ways of getting and restoring packages.

This article or section is a candidate for merging with #Custom local repository.

To download packages, or groups of packages:

Pacman, which will reference the host installation by default, will not properly resolve and download existing dependencies. In cases where all packages and dependencies are wanted, it is recommended to create a temporary blank DB and reference it with --dbpath:

Then you can burn the "Packages" directory to an optical disc (e.g. CD, DVD) or transfer it to a USB flash drive, external HDD, etc.

For an optical disc drive:

For a USB flash drive, hard disk drive, etc.:

2. Edit pacman.conf and add this repository before the other ones (e.g. extra, core, etc.). This is important. Do not just uncomment the one on the bottom. This way it ensures that the files from the CD/DVD/USB take precedence over those in the standard repositories:

3. Finally, synchronize the pacman database to be able to use the new repository:

Use the repo-add script included with pacman to generate a database for a personal repository. Use repo-add --help for more details on its usage. A package database is a tar file, optionally compressed. Valid extensions are .db or .files followed by an archive extension of .tar, .tar.gz, .tar.bz2, .tar.xz, .tar.zst, or .tar.Z. The file does not need to exist, but all parent directories must exist.

To add a new package to the database, or to replace the old version of an existing package in the database, run:

The database and the packages do not need to be in the same directory when using repo-add, but keep in mind that when using pacman with that database, they should be together. Storing all the built packages to be included in the repository in one directory also allows to use shell glob expansion to add or update multiple packages at once:

If you are looking to support multiple architectures then precautions should be taken to prevent errors from occurring. Each architecture should have its own directory tree:

The repo-add executable checks if the package is appropriate. If this is not the case you will be running into error messages similar to this:

repo-remove is used to remove packages from the package database, except that only package names are specified on the command line.

Once the local repository database has been created, add the repository to pacman.conf for each system that is to use the repository. An example of a custom repository is in pacman.conf. The repository's name is the database filename with the file extension omitted. In the case of the example above the repository's name would simply be repo. Reference the repository's location using a file:// URL, or via HTTP using http://localhost/path/to/directory.

If willing, add the custom repository to the list of unofficial user repositories, so that the community can benefit from it.

See Package proxy cache.

To recreate a package from the file system, use fakepkgAUR. Files from the system are taken as they are, hence any modifications will be present in the assembled package. Distributing the recreated package is therefore discouraged; see ABS and Arch Linux Archive for alternatives.

Keeping a list of all explicitly installed packages can be useful to backup a system or quicken the installation of a new one:

To keep an up-to-date list of explicitly installed packages (e.g. in combination with a versioned /etc/), you can set up a hook. Example:

To install packages from a previously saved list of packages, while not reinstalling previously installed packages that are already up-to-date, run:

However, it is likely foreign packages such as from the AUR or installed locally are present in the list. To filter out from the list the foreign packages, the previous command line can be enriched as follows:

Eventually, to make sure the installed packages of your system match the list and remove all the packages that are not mentioned in it:

If you are suspecting file corruption (e.g. by software/hardware failure), but are unsure if files were corrupted, you might want to compare with the hash sums in the packages. This can be done with pacutils:

For recovery of the database see #Restore pacman's local database. The mtree files can also be extracted as .MTREE from the respective package files.

To reinstall all native packages, use:

Foreign (AUR) packages must be reinstalled separately; you can list them with pacman -Qqm.

Pacman preserves the installation reason by default.

See pacman/Restore local database.

If you have managed to mess up an Arch install with broken packages, it is possible to re-install all the packages and hopefully get it back up and working again (assuming the root of the broken install is mounted in /brokenArch)

paccat is a small utility that finds which package contains a given file, downloads it and then prints the contents. This can be used to read specific files, restore changed files back to their initial state, and extract files without installing the package.

For example, if you want to see the contents of /etc/systemd/logind.conf supplied within the systemd package:

Or if you want to see the contents of archive.h supplied by any package:

bsdtar can also be used to show the contents:

Or you can use vim to browse the archive:

Already running processes do not automatically notice changes caused by updates. Instead, they continue using old library versions. That may be undesirable, due to potential issues related to security vulnerabilities or other bugs, and version incompatibility.

Processes depending on updated libraries may be found using either htop, which highlights the names of the affected programs, or with a snippet based on lsof, which also prints the names of the libraries:

This solution will only detect files, that are normally kept opened by running processes, which basically limits it to shared libraries (.so files). It may miss some dependencies, like those of Java or Python applications.

Many packages install documentation and translations in several languages. Some programs are designed to remove such unnecessary files, such as localepurgeAUR, which runs after a package is installed to delete the unneeded locale files. A more preemptive approach is provided through the NoExtract directive in /etc/pacman.conf, which prevent these files from ever being installed.

To prevent the installation of all translations for help files, except for the C locale, add:

To prevent the installation of all the HTML documentation, add:

To prevent the installation of the various locales, except the required ones, add:

To prevent the installation of the translated man pages, add:

To prevent the installation of the language files in vim-runtime, add:

To prevent the installation of all but English content in Qt applications, add:

To prevent the installation of all but English content in Chromium and Electron applications, add:

To prevent the installation of English help files in LibreOffice, add:

To prevent the installation of all but English content from OnlyOffice, add:

To prevent the installation of all but the English iBus dictionary for emojis, add:

When trying to install a package from a bad connection (e.g. a train using a cell phone), use the --disable-download-timeout option to lessen the chance of receiving errors such as:

When downloading packages pacman uses the mirrors in the order they are in /etc/pacman.d/mirrorlist. The mirror which is at the top of the list by default however may not be the fastest for you. To select a faster mirror, see Mirrors.

Pacman's speed in downloading packages can also be improved by using parallel downloads, a major feature request (FS#20056) added with pacman 6.0.0. It is enabled by default since pacman 7.0.0.

Instead of pacman's built-in file downloader, a separate application can also be used to download packages.

In all cases, make sure you have the latest pacman before doing any modifications.

Powerpill is a pacman wrapper that uses parallel and segmented downloading to try to speed up downloads for pacman.

This is also very handy if you need more powerful proxy settings than pacman's built-in capabilities.

To use wget, first install the wget package then modify /etc/pacman.conf by uncommenting the following line in the [options] section:

Instead of uncommenting the wget parameters in /etc/pacman.conf, you can also modify the wget configuration file directly (the system-wide file is /etc/wgetrc, per user files are $HOME/.wgetrc).

aria2 is a lightweight download utility with support for resumable and segmented HTTP/HTTPS and FTP downloads. aria2 allows for multiple and simultaneous HTTP/HTTPS and FTP connections to an Arch mirror, which should result in an increase in download speeds for both file and package retrieval.

Install aria2, then edit /etc/pacman.conf by adding the following line to the [options] section:

See aria2c(1) § OPTIONS for used aria2c options.

There are other downloading applications that you can use with pacman. Here they are, and their associated XferCommand settings:

**Examples:**

Example 1 (unknown):
```unknown
pacman.conf
```

Example 2 (unknown):
```unknown
/etc/pacman.conf
```

Example 3 (unknown):
```unknown
...
[multilib]
Usage = Sync Search
...
```

Example 4 (unknown):
```unknown
pacman -Sg group
```

---

## Pacserve

**URL:** https://wiki.archlinux.org/title/Pacserve

**Contents:**
- Installation
- Configuration
  - Avahi
- Standalone usage
- Configure Pacman to use Pacserve
- Troubleshooting
  - Problems if using external downloaders in pacman.conf
  - Machines do not see each other
- See also

Pacserve allows to easily share pacman packages between computers. This is very useful if you have a slow internet connection and multiple machines running Arch Linux.

Finally start/enable pacserve.service.

In case you use iptables, you will probably want to start pacserve-ports.service too. For other firewalls open TCP port 15678 and UDP port 15679. The UDP port can be limited to multicast traffic only.

The pacserve.service can configured by editing PACSERVE_ARGS in /etc/pacserve/pacserve.service.conf. Run pacserve --help to see the available options.

To announce and discover Pacserve using mDNS add the option --avahi to PACSERVE_ARGS in /etc/pacserve/pacserve.service.conf.

Instead of pacman, use the pacsrv wrapper to perform an update, install packages and so on. It will automatically download all packages from the LAN, if someone hosts them with pacserve there. Otherwise it will just download them from the internet mirrors, as usually. For example:

If you are always running the pacserve daemon and want pacman to use it without the wrapper, insert the following line (before any other Include lines) in each repository in /etc/pacman.conf.

Here is an example for the Xyne repository:

Alternatively (for official mirrors only), you may insert the Include line at the top of the Pacman mirrorlist file or let pacman.conf-insert_pacserve generate a pacman.conf file for you.

If you are using an external downloader such as wget, pacsrv may return errors when downloading. To work around these errors, simply quote the url and output formatting strings (%u resp. %o) using single quotes:

Peers detection relies on version of python3-threaded_serversAUR. TCP multicast frames coming from a different version of the service are discarded. In this case, running journalctl -u pacserve as root will warn about such unrecognized frames. Upgrade this package first then restart the pacserve.service.

**Examples:**

Example 1 (unknown):
```unknown
pacserve.service
```

Example 2 (unknown):
```unknown
pacserve-ports.service
```

Example 3 (unknown):
```unknown
pacserve.service
```

Example 4 (unknown):
```unknown
PACSERVE_ARGS
```

---

## pacman

**URL:** https://wiki.archlinux.org/title/Pacman_hooks

**Contents:**
- Usage
  - Installing packages
    - Installing specific packages
      - Virtual packages
    - Installing package groups
  - Removing packages
  - Upgrading packages
  - Querying package databases
    - Pactree
    - Database structure

The pacman package manager is one of the major distinguishing features of Arch Linux. It combines a simple binary package format with an easy-to-use Arch build system. The goal of pacman is to make it possible to easily manage packages, whether they are from the official repositories or the user's own builds.

Pacman keeps the system up-to-date by synchronizing package lists with the master server. This server/client model also allows the user to download/install packages with a simple command, complete with all required dependencies.

Pacman is written in the C programming language and uses the bsdtar(1) tar format for packaging.

What follows is just a small sample of the operations that pacman can perform. To read more examples, refer to pacman(8).

A package is an archive containing:

Arch's package manager pacman can install, update, and remove those packages. Using packages instead of compiling and installing programs yourself has various benefits:

To install a single package or list of packages, including dependencies, issue the following command:

To install a list of packages with regex (see this forum thread):

Sometimes there are multiple versions of a package in different repositories (e.g. extra and extra-testing). To install the version from the extra repository in this example, the repository needs to be defined in front of the package name:

To install a number of packages sharing similar patterns in their names, one can use curly brace expansion. For example:

This can be expanded to however many levels needed:

A virtual package is a special package which does not exist by itself, but is provided by one or more other packages. Virtual packages allow other packages to not name a specific package as a dependency, in case there are several candidates. Virtual packages cannot be installed by their name, instead they become installed in your system when you have installed a package providing the virtual package. An example is the dbus-units package.

Some packages belong to a group of packages that can all be installed simultaneously. For example, issuing the command:

will prompt you to select the packages from the gnome group that you wish to install.

Sometimes a package group will contain a large amount of packages, and there may be only a few that you do or do not want to install. Instead of having to enter all the numbers except the ones you do not want, it is sometimes more convenient to select or exclude packages or ranges of packages with the following syntax:

which will select packages 1 through 10 and 15 for installation, or:

which will select all packages except 5 through 8 and 2 for installation.

To see what packages belong to the gnome group, run:

Also visit https://archlinux.org/groups/ to see what package groups are available.

To remove a single package, leaving all of its dependencies installed:

To remove a package and its dependencies which are not required by any other installed package:

The above may sometimes refuse to run when removing a group which contains otherwise needed packages. In this case try:

To remove a package, its dependencies and all the packages that depend on the target package:

To remove a package, which is required by another package, without removing the dependent package:

Pacman saves important configuration files when removing certain applications and names them with the extension: .pacsave. To prevent the creation of these backup files use the -n option:

Pacman can update all packages on the system with just one command. This could take quite a while depending on how up-to-date the system is. The following command synchronizes the repository databases and updates the system's packages, excluding "local" packages that are not in the configured repositories:

Pacman queries the local package database with the -Q flag, the sync database with the -S flag and the files database with the -F flag. See pacman -Q --help, pacman -S --help and pacman -F --help for the respective suboptions of each flag.

Pacman can search for packages in the database, searching both in packages' names and descriptions:

Sometimes, -s's builtin ERE (Extended Regular Expressions) can cause a lot of unwanted results, so it has to be limited to match the package name only; not the description nor any other field:

To search for already installed packages:

To search for package file names in remote packages:

To display extensive information about a given package (e.g. its dependencies):

For locally installed packages:

Passing two -i flags will also display the list of backup files and their modification states:

To retrieve a list of the files installed by a package:

To retrieve a list of the files installed by a remote package:

To verify the presence of the files installed by a package:

Passing the k flag twice will perform a more thorough check.

To query the database to know which package a file in the file system belongs to:

To query the database to know which remote package a file belongs to:

To list all packages no longer required as dependencies (orphans):

To list all packages explicitly installed and not required as dependencies:

See pacman/Tips and tricks for more examples.

For advanced functionality, install pkgfile, which uses a separate database with all files and their associated packages.

To view the dependency tree of a package:

To view the dependent tree of a package, pass the reverse flag -r to pactree.

The pacman databases are normally located at /var/lib/pacman/sync. For each repository specified in /etc/pacman.conf, there will be a corresponding database file located there. Database files are gzipped tar archives containing one directory for each package, for example for the which package:

The desc file contains meta data such as the package description, dependencies, file size and MD5 hash.

Pacman stores its downloaded packages in /var/cache/pacman/pkg/ and does not remove the old or uninstalled versions automatically. This has some advantages:

However, it is necessary to deliberately clean up the cache periodically to prevent the directory to grow indefinitely in size.

The paccache(8) script, provided within the pacman-contrib package, deletes all cached versions of installed and uninstalled packages, except for the most recent three, by default:

Enable and start paccache.timer to discard unused packages weekly. You can configure the arguments for the service in /etc/conf.d/pacman-contrib, e.g with PACCACHE_ARGS='-k1' or PACCACHE_ARGS='-uk0' for the two examples below.

You can also define how many recent versions you want to keep. To retain only one past version use:

Add the -u/--uninstalled switch to limit the action of paccache to uninstalled packages. For example to remove all cached versions of uninstalled packages, use the following:

See paccache -h for more options.

Pacman also has some built-in options to clean the cache and the leftover database files from repositories which are no longer listed in the configuration file /etc/pacman.conf. However pacman does not offer the possibility to keep a number of past versions and is therefore more aggressive than paccache default options.

To remove all the cached packages that are not currently installed, and the unused sync databases, execute:

To remove all files from the cache, use the clean switch twice, this is the most aggressive approach and will leave nothing in the cache directory:

pkgcachecleanAUR and pacleanerAUR are two further alternatives to clean the cache.

Download a package without installing it:

Install a 'local' package that is not from a remote repository (e.g. the package is from the AUR):

To keep a copy of the local package in pacman's cache, use:

Install a 'remote' package (not from a repository stated in pacman's configuration files):

Pacman always lists packages to be installed or removed, and asks for permission before taking any action.

To get a list in a processable format, and to prevent the actions of -S, -U and -R, you can use -p, short for --print.

--print-format can be added to format this list in various ways. --print-format %n will return a list without package versions.

The pacman database organizes installed packages into two groups, according to installation reason:

When installing a package, it is possible to force its installation reason to dependency with:

The command is normally used because explicitly-installed packages may offer optional packages, usually for non-essential features for which the user has discretion.

When reinstalling a package, though, the current installation reason is preserved by default.

The list of explicitly-installed packages can be shown with pacman -Qe, while the complementary list of dependencies can be shown with pacman -Qd.

To change the installation reason of an already installed package, execute:

Use --asexplicit to do the opposite operation.

When successful, the workflow of a transaction follows five high-level steps plus pre/post transaction hooks:

Pacman settings are located in /etc/pacman.conf: this is the place where the user configures the program to work in the desired manner. In-depth information about the configuration file can be found in pacman.conf(5).

General options are in the [options] section. Read pacman.conf(5) or look in the default pacman.conf for information on what can be done here.

To see old and new versions of available packages, uncomment the "VerbosePkgLists" line in /etc/pacman.conf. The output of pacman -Syu will be like this:

The number of packages being downloaded in parallel (at the same time) are configured in /etc/pacman.conf with the ParallelDownloads option under [options]. The /etc/pacman.conf shipped with the pacman package sets it to 5. If the option is unset, packages will be downloaded sequentially.

To have a specific package skipped when upgrading the system, add this line in the [options] section:

For multiple packages use a space-separated list, or use additional IgnorePkg lines. Also, glob patterns can be used. If you want to skip packages just once, you can also use the --ignore option on the command-line - this time with a comma-separated list.

It will still be possible to upgrade the ignored packages using pacman -S: in this case pacman will remind you that the packages have been included in an IgnorePkg statement.

As with packages, skipping a whole package group is also possible:

All files listed with a NoUpgrade directive will never be touched during a package install/upgrade, and the new files will be installed with a .pacnew extension.

Multiple files can be specified like this:

To always skip installation of specific files or directories list them under NoExtract. For example, to avoid installing bash completion scripts, use:

Later rules override previous ones, and you can negate a rule by prepending !.

If you have several configuration files (e.g. main configuration and configuration with testing repository enabled) and would have to share options between configurations you may use Include option declared in the configuration files, e.g.:

where /path/to/common/settings file contains the same options for both configurations.

Pacman can run pre- and post-transaction hooks from the /usr/share/libalpm/hooks/ directory; more directories can be specified with the HookDir option in pacman.conf, which defaults to /etc/pacman.d/hooks. Hook file names must be suffixed with .hook. Pacman hooks are not interactive.

Pacman hooks are used, for example, in combination with systemd-sysusers and systemd-tmpfiles to automatically create system users and files during the installation of packages. For example, tomcat8 specifies that it wants a system user called tomcat8 and certain directories owned by this user. The pacman hooks systemd-sysusers.hook and systemd-tmpfiles.hook invoke systemd-sysusers and systemd-tmpfiles when pacman determines that tomcat8 contains files specifying users and tmp files.

For more information on alpm hooks, see alpm-hooks(5).

Besides the special [options] section, each other [section] in pacman.conf defines a package repository to be used. A repository is a logical collection of packages, which are physically stored on one or more servers: for this reason each server is called a mirror for the repository.

Repositories are distinguished between official and unofficial. The order of repositories in the configuration file matters; repositories listed first will take precedence over those listed later in the file when packages in two repositories have identical names, regardless of version number. In order to use a repository after adding it, you will need to upgrade the whole system first.

Each repository section allows defining the list of its mirrors directly or in a dedicated external file through the Include directive; for example, the mirrors for the official repositories are included from /etc/pacman.d/mirrorlist. See the Mirrors article for mirror configuration.

Pacman stores downloaded package files in cache, in a directory denoted by CacheDir in [options] section of pacman.conf (defaults to /var/cache/pacman/pkg/ if not set).

Cache directory may grow over time, even if keeping just the freshest versions of installed packages.

If you want to move that directory to some more convenient place, do one of the following:

Pacman supports package signatures, which add an extra layer of security to the packages. The default configuration, SigLevel = Required DatabaseOptional, enables signature verification for all the packages on a global level. This can be overridden by per-repository SigLevel lines. For more details on package signing and signature verification, take a look at pacman-key.

If you see the following error: [1]

This is happening because pacman has detected a file conflict, and by design, will not overwrite files for you. This is by design, not a flaw.

The problem is usually trivial to solve (although to be sure, you should try to find out how these files got there in the first place). A safe way is to first check if another package owns the file (pacman -Qo /path/to/file). If the file is owned by another package, file a bug report. If the file is not owned by another package, rename the file which "exists in filesystem" and re-issue the update command. If all goes well, the file may then be removed.

If you had installed a program manually without using pacman, for example through make install, you have to remove/uninstall this program with all of its files. See also Pacman tips#Identify files not owned by any package.

Every installed package provides a /var/lib/pacman/local/package-version/files file that contains metadata about this package. If this file gets corrupted, is empty or goes missing, it results in file exists in filesystem errors when trying to update the package. Such an error usually concerns only one package. Instead of manually renaming and later removing all the files that belong to the package in question, you may explicitly run pacman -S --overwrite glob package to force pacman to overwrite files that match glob.

This article or section is out of date.

Look for .part files (partially downloaded packages) in /var/cache/pacman/pkg/ and remove them (often caused by usage of a custom XferCommand in pacman.conf).

That same error may also appear if archlinux-keyring is out-of-date, preventing pacman from verifying signatures. See Pacman/Package signing#Upgrade system regularly for the fix and how to avoid it in the future.

When pacman is about to alter the package database, for example installing a package, it creates a lock file at /var/lib/pacman/db.lck. This prevents another instance of pacman from trying to alter the package database at the same time.

If pacman is interrupted while changing the database, this stale lock file can remain. If you are certain that no instances of pacman are running then delete the lock file:

This error manifests as Not found in sync db, Target not found or Failed retrieving file.

Firstly, ensure the package actually exists. If certain the package exists, your package list may be out-of-date. Try running pacman -Syu to force a refresh of all package lists and upgrade. Also make sure the selected mirrors are up-to-date and repositories are correctly configured. You can also use Reflector to keep the mirrors up-to-date.

If pacman reports there is nothing to update, but the Failed retrieving file error continues to be printed, consider forcing a database download with pacman -Syyu. This is never needed under normal circumstances, so inspect more closely the status and consistency of the mirror.

It could also be that the repository containing the package is not enabled on your system, e.g. the package could be in the multilib repository, but multilib is not enabled in your pacman.conf.

See also FAQ#Why is there only a single version of each shared library in the official repositories?.

This article or section needs expansion.

Whether due to power loss, kernel panic or hardware failure an update may be interrupted. In most cases, there will not be much damage but the system will likely be unbootable.

Replicating the exact upgrade is needed to ensure the right scriptlets and hooks will run.

In the case that pacman crashes with a "database write" error while removing packages, and reinstalling or upgrading packages fails thereafter, do the following:

If /var/cache/pacman/pkg is a symlink, pacman will try to make a directory instead and thus remove this symlink during self-upgrade. This will cause the update to fail. As a result, /usr/bin/pacman and other contents of the pacman package will be missing.

Never symlink /var/cache/pacman/pkg because it is controlled by pacman. Use the CacheDir option or a bind mount instead; see #Package cache directory.

If you have already encountered this problem and broke your system, you can manually extract /usr contents from the package to restore pacman and then reinstall it properly; see FS#73306 and related forum thread for details.

pacman-staticAUR is a statically compiled version of pacman, so it will be able to run even when the libraries on the system are not working. This can also come in handy when a partial upgrade was performed and pacman can not run anymore.

The pinned comment and the PKGBUILD provides a way to directly download the binary, which can be used to reinstall pacman or to upgrade the entire system in case of partial upgrades.

In some situations, your system may be too broken (e.g., due to missing or incompatible libraries) to run `makepkg` or build the `pacman-static` package from the AUR successfully.

If building from the PKGBUILD fails or `makepkg` cannot be run, you can download a precompiled `pacman-static` binary from a trusted source. This static binary does not depend on system libraries and can be used to restore a working `pacman` on your system.

A reliable source for the binary is:

This will update your system and reinstall `pacman`, fixing broken dependencies related to missing shared libraries.

If even pacman-static does not work, it is possible to recover using an external pacman. One of the easiest methods to do so is by using the archiso and simply using --sysroot or --root to specify the mount point of the system to perform the operation on. See Chroot#Using chroot on how to mount the necessary filesystems required by --sysroot.

Even if pacman is terribly broken, you can fix it manually by downloading the latest packages and extracting them to the correct locations. The rough steps to perform are:

If you have a healthy Arch system on hand, you can see the full list of dependencies with:

But you may only need to update a few of them depending on your issue. An example of extracting a package is

Note the use of the w flag for interactive mode. Running non-interactively is very risky since you might end up overwriting an important file. Also take care to extract packages in the correct order (i.e. dependencies first). This forum post contains an example of this process where only a couple pacman dependencies are broken.

Most likely the initramfs became corrupted during a kernel update (improper use of pacman's --overwrite option can be a cause). There are two options; first, try the Fallback entry.

Once the system starts, run this command (for the stock linux kernel) either from the console or from a terminal to rebuild the initramfs image:

If that does not work, from a current Arch release (CD/DVD or USB stick), mount your root and boot partitions to /mnt and /mnt/boot, respectively. Then chroot using arch-chroot:

Reinstalling the kernel (the linux package) will automatically re-generate the initramfs image with mkinitcpio -p linux. There is no need to do this separately.

Afterwards, it is recommended that you run exit, umount /mnt/{boot,} and reboot.

As the error message says, your locale is not correctly configured. See Locale.

When locale files are intentionally removed by tools such as bleachbit or localepurgeAUR, pacman may issue warnings about missing locales during package updates.

To suppress these warnings, you can comment out the CheckSpace option in pacman.conf. Keep in mind that disabling CheckSpace turns off the space-checking functionality for all package installations, so use this workaround only when you have alternative means to monitor disk space.

Make sure that the relevant environment variables ($http_proxy, $ftp_proxy etc.) are set up. If you use pacman with sudo, you need to configure sudo to pass these environment variables to pacman. Also, ensure the configuration of dirmngr has honor-http-proxy in /etc/pacman.d/gnupg/dirmngr.conf to honor the proxy when refreshing the keys.

To reinstall all the native packages: pacman -Qnq | pacman -S - or pacman -S $(pacman -Qnq) (the -S option preserves the installation reason by default).

You will then need to reinstall all the foreign packages, which can be listed with pacman -Qmq.

It looks like previous pacman transaction removed or corrupted shared libraries needed for pacman itself.

To recover from this situation, you need to unpack required libraries to your filesystem manually. First find what package contains the missed library and then locate it in the pacman cache (/var/cache/pacman/pkg/). Unpack required shared library to the filesystem. This will allow to run pacman.

Now you need to reinstall the broken package. Note that you need to use --overwrite flag as you just unpacked system files and pacman does not know about it. Pacman will correctly replace our shared library file with one from package.

That's it. Update the rest of the system.

Some issues have been reported regarding network problems that prevent pacman from updating/synchronizing repositories. [2] [3] When installing Arch Linux natively, these issues have been resolved by replacing the default pacman file downloader with an alternative (see Improve pacman performance for more details). When installing Arch Linux as a guest OS in VirtualBox, this issue has also been addressed by using Host interface instead of NAT in the machine properties.

If you receive this error message with correct mirrors, try setting a different name server.

If you want to install a package on an sshfs mount using pacman -U and receive this error, move the package to a local directory and try to install again.

Upon executing, e.g., pacman -Syu inside a chroot environment an error is encountered:

This is frequently caused by the chroot directory not being a mountpoint when the chroot is entered. See the note at Install Arch Linux from existing Linux#Downloading basic tools for a solution, and arch-chroot(8) for an explanation and an example of using bind mounting to make the chroot directory a mountpoint.

If you are unable to update packages and receive this error, then try rm -r /var/lib/pacman/sync/ before attempting to update.

If removing sync files doesn't help, check that the sync files are gzip compressed data using file /var/lib/pacman/sync/* before attempting to update. A router or proxy might corrupt the downloads. Corruption could possibly be HTML type.

If sync files are of the correct type, there might be an issue with the mirror server. Look up the mirror server(s) in use with pacman-conf -r core and pacman-conf -r extra. Paste the first returned url in a browser and check that a file listing is returned. In case the mirror returns an error, comment it in /etc/pacman.d/mirrorlist. You may try updating or re-ranking mirrors.

If this error occurs and you're for instance unable to update your system or any package at all, it is possible that you have DISPLAY set to a blank value, which seems to break the GPG-Flow.

In this case, unset DISPLAY or setting it to a arbitrary value will most likely allow to update again, in case any other option above didn't do the trick yet. See this post for further details.

One may use the pacman -Qk $pkg to check if the installed files of the $pkg package match the files from its database version. For several packages, one may use the following loop to reinstall all packages which have missing file(s):

Suppose that your local database located in /var/lib/pacman is more up-to-date compared to installed packages in the / filesystem (e.g., because of a partial rollback), then this method is the appropriate one to re-synchronize the root filesystem with the local database.

**Examples:**

Example 1 (unknown):
```unknown
pacman -Ql pacman pacman-contrib | grep -E 'bin/.+'
```

Example 2 (unknown):
```unknown
pacman -Sy package_name
```

Example 3 (unknown):
```unknown
pacman -Syu package_name
```

Example 4 (unknown):
```unknown
# pacman -S package_name1 package_name2 ...
```

---

## JACK Audio Connection Kit

**URL:** https://wiki.archlinux.org/title/JACK

**Contents:**
- Installation
- Configuration
  - Latency
  - Realtime scheduling and additional resources
  - Realtime kernel and advanced modifications
- Starting the audio graph
  - Jack
  - Jack2
  - Pipewire-jack
- Comparison of JACK implementations

From Wikipedia:JACK Audio Connection Kit:

There are three different implementations of the JACK API: jackAUR, jack2 and pipewire-jack. For an overview, refer to #Comparison of JACK implementations.

Install one of the above packages. For 32-bit application support, also install the lib32-jack2 or lib32-pipewire-jack package (respectively) from the multilib repository.

For the official JACK example-clients and tools install jack-example-tools.

For an alternative ALSA MIDI support in jack2 install a2jmidid.

For dbus support with jack2 install jack2-dbus.

Depending on your use-case and hardware, the system may need further configuration, to allow a JACK implementation to use additional resources or to function properly.

The latency of a running JACK instance (i.e. how much time is spent processing one block of audio) is defined by its frames per period/sample rate ratio.

When looking at jackd(1) § ALSA_BACKEND_OPTIONS as an example, these parameters are defined by the -p and -r flags (respectively).

All JACK implementations may make use of elevated realtime scheduling priority, which allows them to make use of the CPU cycles more often than other applications (see e.g. -P in jackd(1) § OPTIONS).

The realtime-privileges package provides the realtime system group, which is permitted elevated rtprio and unlimited memlock with a sysctl drop-in configuration file and is permitted to alter the system's /dev/cpu_dma_latency file, which may be used by applications to prevent the CPU to use higher C states.

Install the realtime-privileges package and add your user to the realtime group to be able to use realtime scheduling priority that is higher than the default.

A realtime kernel (such as linux-rt or linux-rt-lts) may be used in situations where very low latencies are required. Refer to professional audio for further information and other advanced modifications.

The different JACK implementations have varying ways of starting the audio graph.

Jack1 only supports starting via the jackd(1) executable or by using one of the graphical frontends, that support starting via the library interface.

Jack2 supports starting via the jackd(1) executable, the jack_control script (provided by the jack2-dbus package), the jack@.service systemd user service (refer to /etc/jack/example.conf for configuration documentation) or by using one of the graphical frontends, that support starting via the library or dbus interface.

Pipewire's JACK implementation does not provide the jackd(1) executable or dbus integration. The audio graph is started by the pipewire.service systemd user service.

The following table lists the current implementations of the JACK API and their differing feature sets.

The following table lists control GUIs for JACK and their differing features and levels of support towards the JACK implementations.

This article or section needs expansion.

JACK can handle one soundcard very well, and an arbitrary number of MIDI devices (connected e.g. via USB). If you start JACK and want to use a MIDI keyboard or a synthesizer or some other pure MIDI device, you have to start JACK with a proper soundcard (one that actually outputs or inputs PCM sound). As soon you have done that, you can connect the MIDI device. E.g. with QjackCtl (qjackctl), you click on the connect button and you will find your device listed under JACK-MIDI or ALSA-MIDI, depending on the driver.

For JACK-MIDI, you may want to set the MIDI Driver to seq or raw in QjackCtl Setup > Settings. This should make your MIDI device appear under the MIDI tab. You can also change the name of the client (from a generic "midi_capture_1" to something more descriptive), if you enable Setup > Display > Enable client/port aliases and then Enable client/port aliases editing (rename).

For ALSA-MIDI, make sure to turn on Enable ALSA Sequencer support in QjackCtl Setup > Misc. This will add the ALSA tab in QjackCtl Connect window where your MIDI controller will show up.

For bridging ALSA-MIDI to JACK-MIDI, you may consider using a2jmidid (a2jmidid). The following command will export all available ALSA MIDI ports to JACK MIDI ports:

They will be visible in QjackCtl under the MIDI tab labelled "a2j" client. You can automate starting of a2jmidid by adding to QjackCtl Setup > Options > Execute script after Startup: /usr/bin/a2j_control --ehw && /usr/bin/a2j_control --start

To install some M-Audio MIDI keyboards, you will need the firmware package midisport-firmwareAUR. Also, the snd_usb_audio module has to be available.

See USBMidiDevices article for more information about specific USB MIDI devices.

JACK2 can be directly launched with the jackd executable, or controlled with the D-Bus-based jack_control binary. jack_control makes it easy to start and configure JACK2 via a shell script. Note that you must install the jack2-dbus package to use jack_control. For the a2j_control commands you also need a2jmidid installed (see #Using MIDI devices for more information).

Create a shell script that can be executed at X login:

The above will start a working JACK instance which other programs can then utilize. Details of each line follow. When discovering your own best configuration, it is helpful to do trial and error using QjackCtl's GUI with a non-D-Bus JACK2 version.

Starts JACK if it is not already started.

Sets JACK to use the ALSA driver set.

Sets JACK to use ALSA-compatible sound card named HD2. One can find the names with cat /proc/asound/cards. Most ALSA tutorials and default configurations use card numbers, but this can get confusing when external MIDI devices are in use; names make it easier.

Sets JACK to use 48000 khz sampling. Happens to work very well with this card. Some cards only do 44100, many will go much higher. The higher you go, the lower your latency, but the better your card and your CPU have to be, and software has to support this as well.

Sets JACK to use 2 periods. 2 is right for motherboard, PCI, PCI-X, etc.; 3 for USB.

Sets JACK to use 64 frames per period. Lower is less latency, but the setting in this script gives 2.67 ms latency, which is nicely low without putting too much stress on the particular hardware this example was built for. If a USB sound system were in use it might be good to try 32. Anything less than 3-4 ms should be fine for realtime synthesis and/or FX, 5 ms is the smallest a human being can detect. QjackCtl will tell you how you are doing; at no-load, which means no clients attached, you will want a max of 3-5% CPU usage, and if you cannot get that without xruns (the red numbers which mean the system cannot keep up with the demands), you will have to improve your hardware.

Wait for the above to settle.

Start the ALSA-to-JACK MIDI bridge. Good for mixing in applications which take MIDI input through ALSA but not JACK.

Wait for the above to settle.

Load QjackCtl. GUI configuration tells it to run in the system tray. It will pick up the JACK session started by D-Bus just fine, and very smoothly too. It maintains the patchbay, the connections between these applications and any other JACK-enabled applications to be started manually. The patchbay is set up using manual GUI, but connections pre-configured in the patchbay are automatically created by QjackCtl itself when applications are started.

This example setup utilizes a more GUI focused configuration and management of JACK

If you use JACK for demanding tasks, but every now and then, it is possible to suspend a running PulseAudio session with QjackCtl just when you are using it. On a virgin config, modify the Server prefix option in the Settings > Advanced submenu, so that it states :

The PulseAudio session should resume fine after you close QjackCtl. Tip courtesy of this post.

To allow ALSA programs to play while jack is running you must install the jack plugin for ALSA with alsa-plugins.

And enable it by editing (or creating) /etc/asound.conf (system wide settings) to have these lines if you have a simple 2-channel setup:

If you have a different number of output/input channels or your first two channels are not the ones you wish to route audio to, you cannot use the predefined jack pcm source from /etc/alsa/conf.d/50-jack.conf, but rather something like:

You need not restart your computer or anything. Just edit the ALSA configuration files, start up jack, and there you go...

Remember to start it as a user. If you start it with jackd -d alsa as user X, it will not work for user Y.

For another (more robust but definitely more complex) approach, is to configure and use an ALSA loopback device, by loading the snd-aloop kernel module, as is described in this article. This snd-aloop approach can also be used to bridge Wine's ALSA output to JACK as explained in [3].

GStreamer requires the gst-plugins-good package to work with JACK, which contains the jackaudiosink plugin that adds JACK playback support.

Further information (outdated): https://jackaudio.org/faq/gstreamer_via_jack.html

If you need to keep PulseAudio installed (in the event it is required by other packages, like gnome-settings-daemon), you may want to prevent it from spawning automatically with X and taking over from JACK.

Edit /etc/pulse/client.conf, uncomment "autospawn" and set it to "no":

If you want both to play along, see: PulseAudio/Examples#PulseAudio through JACK

Cadence and other JACK GUI applications are known to write values to ~/.pulse/daemon.conf. These values override any system-wide defaults enabling unexpected behavior (e.g. flat volumes). Refer to PulseAudio#Configuration on how to update these configurations.

In order to prevent ALSA from messing around with your firewire devices you have to blacklist all firewire related kernel modules. This also prevents PulseAudio from using IEEE 1394. Create the following file:

The list of modules is the most recent available at the time of writing at ALSA Firewire Improve Repository.

Now you can unload your loaded firewire modules or reboot.

This article or section is out of date.

JACK can be configured to send audio data over a network to a "master" machine, which then outputs the audio to a physical device. This can be useful to mix audio from a number of "slave" computers without requiring additional cables or hardware mixers, and keeping the audio path digital for as long as possible (as hardware mixers with digital inputs are very rare).

The configuration is very simple, however it requires a network that supports multicast traffic (i.e. IGMP snooping must be enabled on managed network switches), and it requires all machines be running the same JACK major version (JACK1 or JACK2) as the protocols are not interoperable between versions. For JACK2, the netmanager module must be loaded:

The -i -c option tells the netmanager to automatically map any incoming connections to the default audio device. Without this, each incoming connection would have to be manually mapped on each connection. You can use -i -h instead to see all available options, however note that the options are printed in the jackd server output, the jack_load command will not show anything.

On the client, JACK must be started in network mode:

The two machines will connect and on the master the new audio source will be visible:

If you passed the -c option to jack_load as above, then the remote system will now be able to play audio.

See Realtime process management#Configuring PAM and ensure that the user is in the realtime user group.

Still having the "Cannot allocate memory" and/or "Cannot connect to server socket err = No such file or directory" error(s) when pressing qjackctl's start button?

Please delete ~/.jackdrc, ~/.config/jack/conf.xml, ~/.config/rncbc.org/QjackCtl.conf. Kill jackdbus and restart from scratch :) (Thanks to nedko)

and check the resulting PID's with

This will hopefully show the conflicting programs.

Change ALSA input and output channels from 1 to 2

Your CPU or sound card is too weak to handle your settings for JACK. Lower the bitrate, lower the frame size, and raise the frame period in small increments until crackling stops. You can also try changing the sampling rate to 44100 or whatever is natively supported. This allows jack to send audio to the system without having to resample. In jack2 with jack_control, this is accomplished with

If everything appears to be working - you can visually "see" sound in Jack and other things such as PulseAudio can emit sound, check the maximum sample size supported by your sound card. If your card only supports 16 bit samples then you will hear nothing until you tell Jack not to use large samples:

If you install jack-example-tools then you can run jack_simple_client to send a test tone to Jack's output.

Run VLC and change the following menu options:

**Examples:**

Example 1 (unknown):
```unknown
frames per period
```

Example 2 (unknown):
```unknown
sample rate
```

Example 3 (unknown):
```unknown
frames per period
```

Example 4 (unknown):
```unknown
/dev/cpu_dma_latency
```

---

## PHP package guidelines

**URL:** https://wiki.archlinux.org/title/PHP_package_guidelines

**Contents:**
- Package names
- Package file placement
- Architecture

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

This document covers the creation of PKGBUILDs for PHP libraries. The target audience of this document is intended to be packagers of PHP libraries. For PHP Web applications, see Web application package guidelines

For modules the package name should begin with php- and the rest of the name should be constructed from the library name by converting it to lowercase and separate words with hyphens. For example the package name corresponding to File iterator will be php-file-iterator.

PHP packages should install files into /usr/share/php/. This path should be in the php.ini include_path or open_basedir directive in order to be able to include libraries files in PHP web applications.

In most cases, the arch array should contain any because most PHP packages are architecture independent.

**Examples:**

Example 1 (unknown):
```unknown
File iterator
```

Example 2 (unknown):
```unknown
php-file-iterator
```

Example 3 (unknown):
```unknown
/usr/share/php/
```

Example 4 (unknown):
```unknown
include_path
```

---

## getty

**URL:** https://wiki.archlinux.org/title/Automatic_login_to_virtual_console

**Contents:**
- Installation
- Tips and tricks
  - Staircase effect
  - Add additional virtual consoles
  - Automatic login to virtual console
    - Virtual console
    - Serial console
    - Nspawn console
  - Prompt only the password for a default user in virtual console login
  - Have boot messages stay on tty1

A getty is the generic name for a program which manages a terminal line and its connected terminal. Its purpose is to protect the system from unauthorized access. Generally, each getty process is started by systemd and manages a single terminal line.

agetty is the default getty in Arch Linux, as part of the util-linux package.

An alternative is mingettyAUR.

agetty modifies the TTY settings while waiting for a login so that the newlines are not translated to CR-LFs. This tends to cause a "staircase effect" for messages printed to the console.

It is entirely harmless, but in the event it persists once logged, you can fix this behavior with:

See this forums discussion on the subject.

Agetty manages virtual consoles and six of these virtual consoles are provided by default in Arch Linux. They are usually accessible by pressing Ctrl+Alt+F1 through Ctrl+Alt+F6.

Open the file /etc/systemd/logind.conf and set the option NAutoVTs=6 to the number of virtual terminals that you want at boot.

If needed, it is possible to temporarily start a getty@ttyN.service service directly.

Configuration relies on systemd unit drop-in files to override the default parameters passed to agetty.

Configuration differs for virtual versus serial consoles. In most cases, you want to set up automatic login on a virtual console, (whose device name is ttyN, where N is a number). The configuration of automatic login for serial consoles will be slightly different. Device names of the serial consoles look like ttySN, where N is a number.

Create a drop-in file for getty@tty1.service with the following contents:

If you do not want full automatic login, but also do not want to type your username, see #Prompt only the password for a default user in virtual console login.

If you want to use a tty other than tty1, see systemd/FAQ#How do I change the default number of gettys?.

Create a drop-in file:

To configure auto-login for a systemd-nspawn container, override console-getty.service by creating a drop-in file:

If machinectl login my-container method is used to access the container, also adjust the container-getty@.service template that manages pts/[0-9] pseudo ttys:

Getty can be used to login from a virtual console with a default user, typing the password but without needing to insert the username. For instance, to prompt the password for username on tty1:

By default, Arch has the getty@tty1 service enabled. The service file already passes --noclear, which stops agetty from clearing the screen. However systemd clears the screen before starting it. To disable this behavior, create a drop-in file:

This article or section is a candidate for merging with Display Power Management Signaling#Linux console.

When the system is used as a server but has a display connected, the display will be turned on forever. To turn off display after 5 minutes create a drop-in file. On any key press, display will turn back on.

**Examples:**

Example 1 (unknown):
```unknown
$ stty onlcr
```

Example 2 (unknown):
```unknown
Ctrl+Alt+F1
```

Example 3 (unknown):
```unknown
Ctrl+Alt+F6
```

Example 4 (unknown):
```unknown
/etc/systemd/logind.conf
```

---

## Electron package guidelines

**URL:** https://wiki.archlinux.org/title/Electron_package_guidelines

**Contents:**
- Using the system electron
  - Editing version on package.json
  - Building compiled extensions against the system electron
  - Using electron-builder with system electron
- Architecture
- Directory structure
- Getting version of Electron

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

This document covers standards and guidelines on writing PKGBUILDs for Electron.

Arch Linux provides versioned electron* packages and an electron metapackage for the latest version. They can be used to run an electron application via a shell script wrapper:

The appname/ directory, or alternatively a file bundle called appname.asar, can be found in a prebuilt electron application as the resources/app/ folder (or resources/app.asar). Everything else is just a copy of the electron runtime and can be removed from the final package.

It is dangerous to edit version of Electron in package.json or package-lock.json using sed. You can use npm pkg set devDependencies.electron=$(cat /usr/lib/electron*/version) instead.

The factual accuracy of this article or section is disputed.

Some electron applications have compiled native extensions which link to the electron runtime, and must be built using the correct electron version. Since npm/yarn will always build against a private prebuilt copy of electron, patch the electron dependency from package.json to reference the same version as the system electron dependency. The build system will download the prebuilt copy it requires, compile the native extensions, and package everything into a final distribution, but this can be pruned during the package() step as usual.

Alternatively, you can remove the electron dependency from package.json and set the correct environment variables before running npm:

Set HOME to a path inside the $srcdir so the build process does not place any files in your real HOME directory. Make sure to adjust the path for all further commands that make use of the .electron-gyp cache.

(more details in Electron docs).

Many projects use electron-builder to build and package the Javascript file and Electron binaries. By default electron-builder downloads the entire electron version that is defined in the package management file (e.g. package.json). This might not be desired if you want to use the system electron and save the bandwidth since you are going to throw away the electron binaries anyway. The electron-builder provides the configurations electronDist and electronVersion, to specify a custom path of Electron and the version the application is packaged for respectively.

Find the electron-builder configuration file (e.g. electron-builder.json) and add the following settings:

Packages that apply this: rocketchat-desktopAUR ubports-installer-gitAUR

electron-builder configuration

Alternatively you can use the CLI to change/add these settings like this:

Note that you have to specify all these options or it will not work.

The factual accuracy of this article or section is disputed.

The factual accuracy of this article or section is disputed.

An Electron package that contains compiled native extensions is architecture-dependent. Otherwise it is most likely architecture-independent.

If the package contains a prebuilt copy of electron, it is always architecture-dependent.

If the package is architecture-dependent, install the resources/app/ directory to /usr/lib/appname/. Otherwise use /usr/share/appname/.

If the package contains a prebuilt copy of electron, copy the final distribution in its entirety to /opt/appname.

Version of Electron could be given by npm pkg get devDependencies.electron in the directory containing package.json or package-lock.json.

Prebuild or Nonfree application hides version of electron from package.json, package-lock.json, and version files. In such case, you may get version by replacing app or app.asar with /usr/lib/electron/resources/default_app.asar and running pathto/electron-binary --version.

**Examples:**

Example 1 (unknown):
```unknown
#!/bin/sh

exec /usr/bin/electron34 /path/to/appname/ "$@"
```

Example 2 (unknown):
```unknown
appname.asar
```

Example 3 (unknown):
```unknown
resources/app/
```

Example 4 (unknown):
```unknown
resources/app.asar
```

---

## pacman/Restore local database

**URL:** https://wiki.archlinux.org/title/Pacman/Restore_local_database

**Contents:**
- Symptoms
- Prerequisites
- Generating the recovery list
  - Create the recovery script
  - Generate package lists
- Performing the recovery
  - Steps
- See also

The local pacman database may need to be restored if:

This usually indicates corruption or deletion of /var/lib/pacman/local.

Check if the pacman log file is present:

If the log file does not exist, this method cannot be used. Alternatives:

Install pacman-contrib to access paclog-pkglist.

Save the following script as pacrecover and make it executable:

Later operation may result in mismatch between files of older versions of package, still present on machine, and files, found in new version. Such mismatches will have to be fixed manually.

Restrict the second list to packages present in repositories:

Ensure that base packages are included:

Proceed once the contents of both lists are satisfactory, since they will be used to restore pacman's installed package database; /var/lib/pacman/local/.

Define a helper function:

**Examples:**

Example 1 (unknown):
```unknown
pacman -Syu
```

Example 2 (unknown):
```unknown
pacman -S <package>
```

Example 3 (unknown):
```unknown
/var/lib/pacman/local
```

Example 4 (unknown):
```unknown
$ ls /var/log/pacman.log
```

---

## GNOME package guidelines

**URL:** https://wiki.archlinux.org/title/GNOME_package_guidelines

**Contents:**
- Source URL
  - Using released tarball
  - Using a commit from Git repository
- Meson and GNU build systems
- GSettings schemas
- GConf schemas
- ScrollKeeper documentation
- GTK icon cache
- .desktop files
- AppStream and metainfo files

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

The GNOME packages on Arch Linux follow a certain schema.

GNOME packages normally follow two source URL scheme: a released tarball stored in GNOME's FTP server and a specific commit in the software's Git repository

When downloading a released tarball, you can get it from https://download.gnome.org using the following source array:

where ${pkgver%.*} returns the major.minor package version, by removing the suffix of pkgver (which is the micro package version). E.g., if pkgver=3.28.0 then ${pkgver%.*} would return 3.28.

Another common practice is to use as source a specific commit from a GNOME software's source code git repository. It does not classify as a VCS package because Pacman's feature of setting specific commit (see PKGBUILD(5) § USING VCS SOURCES) makes PKGBUILD not follow latest development commits neither update the pkgver field, using the source from the specified commit hash instead.

See a template below:

Replace hash_of_a_commit with the Git commit hash desired, and replace the pkgver() statement to fit the needs of the package you are packaging (see VCS package guidelines#Git).

Please notice that since the source is downloaded with git, then git must be in makedepends and checksums must be set to 'SKIP', just like it would happen with any other VCS package. Using pkgver() function is highly recommended, so it sets pkgver accordingly for the commit hash provided.

Historically GNOME used GNU Build System to build its applications. While there some currently active applications and many inactive applications that still use GNU Build System, most of currently active GNOME applications migrated to Meson Build System.

See Meson package guidelines for instructions that fits the packaging needs of most GNOME applications.

GSettings are the current schemas used by GNOME applications, and can be accessed/read/edited using the GUI tool dconf or the CLI tool gsettings (provided by glib2, which is most likely already installed as dependency). GSettings used to require some attention of the packager, but nowadays no intervention is required.

Most GNOME packages migrated from GConf schemas to #GSettings schemas, but you may cross with an old and obsolete GNOME package to installs these GConf schemas. In these cases, gconfAUR must be added to depends array.

Gconf schemas get installed in the system GConf database, which has to be avoided. Some packages provide a --disable-schemas-install flag for ./configure, which hardly ever works. However, gconftool-2 has a variable called GCONF_DISABLE_MAKEFILE_SCHEMA_INSTALL which you can set to tell gconftool-2 to not update any databases.

When creating packages that install GConf schema files, use

in the PKGBUILD's package() function.

GNOME applications do not use ScrollKeeper nowadays, but you might come across with a GTK2-based application with that documentation.

Since GNOME 2.20 there is no need to run any command for ScrollKeeper, as rarianAUR reads its OMF files directly. scrollkeeper-update is a dummy these days. The only requirement is to include gnome-doc-utilsAUR to makedepends array.

You can disable documentation generation using --disable-scrollkeeper flag from ./configure.

Many graphical GNOME applications install icons in the system, and those icons are included in an icon cache via the gtk-update-icon-cache tool. Every time an icon is added or remove, this tool is used to update the cache.

Many packages install Freedesktop.org-compatible .desktop files and register MimeType entries in them. These information is stored in a database that has to be updated on every addition or removal. This is the function of the update-desktop-database tool.

As many others, most GNOME applications adheres the Freedesktop.org's AppStream specification and provide a metainfo file so that a description of the application is shown in application centers, like gnome-software or Flathub.

GNOME applications usually validate metainfo files if appstream-util tool when meson test is called in check() function. If appstream-glib is not installed, this will simply prevent this particular validation from being executed (i.e. no error will interrupt the build process).

You can identify that appstream-util is used by the application using two methods:

Add appstream-glib to checkdepends array to validate metainfo file.

**Examples:**

Example 1 (unknown):
```unknown
source=("https://download.gnome.org/sources/$pkgname/${pkgver%.*}/$pkgname-$pkgver.tar.xz")
```

Example 2 (unknown):
```unknown
${pkgver%.*}
```

Example 3 (unknown):
```unknown
${pkgver%.*}
```

Example 4 (unknown):
```unknown
url="https://gitlab.gnome.org/GNOME/$pkgname"
makedepends=(git)
_commit=hash_of_a_commit  # tags/X.Y.Z 
source=("git+${url}.git#commit=$_commit")
md5sums=('SKIP')

pkgver() {
  cd $pkgname
  git describe --tags | sed 's/-/+/g'
}
```

---

## KDE package guidelines

**URL:** https://wiki.archlinux.org/title/KDE_package_guidelines

**Contents:**
- Build directory
- Install prefix
- Build type
- Force Qt version
- KF package naming
  - Plasma widgets
  - Runners
  - Service menus
  - Themes
- Icons and .desktop files installation

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

This article or section is out of date.

The KDE packages on Arch Linux follow a certain schema.

A good way of building CMake packages is to make a build directory outside the root of the project and run cmake from that directory. The PKGBUILD should look this way:

Every packages must set the CMAKE_INSTALL_PREFIX variable.

Generally you should not specify the build type; this makes CMake honor environmental variables like such as CFLAGS, CPPFLAGS, etc. [1]

This article or section needs expansion.

Also, some theme-ralated packages possibly may have incorrect names, and needs rechecking: kde theme.

Plasma widgets (formerly Plasmoids) packages should be named plasma6-applets-widgetname so that they are recognizable as Plasma 6-related packages; this also distinguishes them from the official packages. See plasma6-applets examples.

Plasma runners packages should be named plasma6-runners-runnername so that they are recognizable as Plasma 6-related packages; this also distinguishes them from the official packages. See plasma6-runners examples.

Service menus packages should be named kf6-servicemenus-servicename so that they are recognizable as KF6 related packages. See kf6-servicemenus examples.

Plasma themes packages should be named plasma6-themes-themename so that they are recognizable as Plasma 6-related packages. See plasma6-themes examples.

Some KDE software provide icons in the hicolor icon theme and .desktop files, which must be installed via pacman hooks. Refrain from using installation command for these type of files in a .install, as it would result in unnecessary double execution of them.

**Examples:**

Example 1 (unknown):
```unknown
prepare() {
  mkdir -p build
}

build() {
  cd build
  cmake ../${pkgname}-${pkgver}
}
```

Example 2 (unknown):
```unknown
CMAKE_INSTALL_PREFIX
```

Example 3 (unknown):
```unknown
-DCMAKE_INSTALL_PREFIX=/usr
```

Example 4 (unknown):
```unknown
plasma6-applets-widgetname
```

---

## Metasploit Framework

**URL:** https://wiki.archlinux.org/title/Metasploit_Framework

**Contents:**
- Installation
  - Armitage
  - RVM
- Setting up the database
- Usage
  - Module types
  - Searching for exploits
  - Using an exploit
- Tips and tricks
  - Searching from the database

This article or section needs expansion.

From the official site:

Currently, Metasploit requires to setup and configure PostgreSQL on target system to work. This wiki will show how to get Metasploit working with a PostgreSQL database.

Install package metasploit. It is optional to follow the RVM setup instructions below.

Armitage is a GUI front end for Metasploit written in Java; it can be installed with the armitage-gitAUR package.

When running Armitage, #Setting up the database is not optional, and must be followed. It is also mandatory to use a ~/.msf4/database.yml file.

A sample database.yml file is packaged with Armitage as /usr/share/metasploit/database.yml.sample.

Msfconsole requires Ruby and some Ruby#RubyGems to run without error.

Follow the RVM#Installation and RVM#Using RVM articles to install and use Ruby version 3.1.5 (see Metasploit Git Repo) and set it to default.

Once complete, source the newly created RVM installation:

Now cd into /opt/metasploit and use Ruby#Bundler to install all gems necessary to run Msfconsole:

Metasploit can be used without a database, but cache operations like searching would be very slow. This section shows how to set up Metasploit with Postgresql database server.

Follow the PostgreSQL article to setup / start the service. Once the service is started and running, run :

The database should now be properly initialized, and the connection should be automatically established when running msfconsole.

Run db_status to verify that database connection is properly established:

There are several interfaces available for Metasploit. This section will explain how to use msfconsole, the interface that provides the most features available in MSF.

To start it, simply type msfconsole. The prompt will change to msf > to indicate it is waiting for commands.

Everything (scripts, files, programs etc) in Metasploit is a module. There are 6 types of modules:

To discover what operating system and software version a target runs, perform a port scan. With this information, use the search command to search for available exploits.

To search for all exploits targeting Novell on the Linux platform:

To search for all exploits on the Linux platform containing the keyword Apache and filter the results with grep:

To search for specific field, type its name, followed by column and the phrase. The following search fields are available:

See #Searching from the database and #Database search examples for more advanced search queries.

After choosing an appropriate exploit, it is time to start hacking!

First, select an exploit using the use command:

To view information about a module, use the info command:

Running info without arguments will show info about currently selected module.

To view the selected exploit's options, run:

All the required fields must be provided before exploitation. Here, only the RHOST variable must be specified. To assign a value to a variable use the set command:

Now choose the payload:

Choosing a payload (actually, choosing modules in general) will add more options. Run show options again:

Now assign LHOST variable to the address of your computer, where the exploited computer will send connection requests to:

Now launch the attack!

If you are lucky, you will be dropped to a Meterpreter session where you can do anything on the remote computer.

Since everything in Metasploit is stored in a database, it is easy to make powerful search queries without the need of the search frontend command.

To start the database interface, run:

The information about modules is stored in 8 tables:

Almost all tables have 3 columns: id, detail_id and name, except for module_details table which has 16 columns.

The detail_id values are pointers to the rows of module_details table.

To see the all the contents of a table, run:

The module_details table contains multiple columns and viewing them all at once is not convenient. To show only basic information about the modules:

Show some information about available modules, include platform information from module_platforms:

Show all client (aggressive) exploits for Windows platform:

Show all exploits for Windows platform with rank >= 500 disclosed after 2013:

Show all aggressive (client) exploits for Windows platform with rank >= 500 and include additional information about module's target:

To view the possible platform values, and number of available exploits, run from psql:

To disable the banner, run msfconsole with -q/--quiet argument:

If you do not want the variables to reset when selecting another module and when rerunning msfconsole then set it globally via setg, for example:

If you selected VNC viewer as a payload, but are unable to click or do any actions, that means you forgot to set the ViewOnly variable to false. To fix this problem, re-run the exploit with the variable set to false:

If you get an error like this:

This happens because the file robots.rb has incorrect permissions and can be read only by the root user (see the bug report):

To fix this, simply change the permission to be world-readable:

If upon running db_connect you see no output, but later getting a message like this:

that probably means that the postgresql service is not running.

**Examples:**

Example 1 (unknown):
```unknown
~/.msf4/database.yml
```

Example 2 (unknown):
```unknown
database.yml
```

Example 3 (unknown):
```unknown
/usr/share/metasploit/database.yml.sample
```

Example 4 (unknown):
```unknown
$ source ~/.rvm/scripts/rvm
```

---

## Kernel/Arch build system

**URL:** https://wiki.archlinux.org/title/Kernel/Arch_Build_System

**Contents:**
- Getting the ingredients
- Modifying the PKGBUILD
  - Avoid creating the doc
  - Changing prepare()
  - Generate new checksums
- Compiling
- Installing
- Boot loader
- Updating
  - Cleanup

The Arch build system can be used to build a custom kernel based on the official linux package. This compilation method can automate the entire process, and is based on a very well tested package. You can edit the PKGBUILD to use a custom kernel configuration or add additional patches.

Since you will be using makepkg, follow the best practices outlined there first. For example, you cannot run makepkg as the root user. Therefore, create a build directory in your user home first.

Install the devtools and base-devel package.

You need a clean kernel to start your customization from. Retrieve PKGBUILD source and few other files into your build directory by running:

At this point, the directory tree looks like (there may be a few other files):

Then, get any other file you need (e.g. custom configuration files, patches, etc.) from the respective sources.

Edit PKGBUILD and look for the pkgbase parameter. Change this to your custom package name, e.g.:

A large portion of the lengthy compiling effort is devoted to creating the documentation. To avoid creating the documents:

In prepare() function, you can apply needed kernel patches or change kernel build configuration. Since 2018-08-01, the PKGBUILD automatically applies all *.patch files in source.

If you need to change a few configuration options you can edit config in the source.

Or you can use a GUI tool to tweak the options. Comment make olddefconfig in the prepare() function of the PKGBUILD, and add your favorite tool (run make help to list all of the possible configuration targets):

#Changing prepare() suggests a possible modification to $_srcname/.config. Since this path is not where downloading the package files ended, its checksum was not checked by makepkg (which actually checked $_srcname/../../config).

If you replaced the downloaded config with another one before running makepkg, install the pacman-contrib package and generate new checksums by running:

You can now proceed to compile your kernel by the usual command makepkg.

If you have chosen an interactive program for configuring the kernel parameters (like menuconfig), you need to be there during the compilation.

The -s parameter will download any additional dependencies used by recent kernels such as xml and docs.

The compile step will leave two packages in the ~/build/linux folder, one for the kernel and one for the kernel headers. They might have names like:

Best practice is to install both packages together as they might be both needed (e.g. DKMS):

(substitute the actual names of the files you have in the folder)

If you have modified pkgbase in order to have your new kernel installed alongside the default kernel you will need to update your boot loader configuration file and add new entries ('default' and 'fallback') for your custom kernel and the associated initramfs images.

This article or section is out of date.

Assuming one has an arch kernel source that they want to update, one method to do that is with https://github.com/archlinux/linux. In what follows, the top kernel source directory is assumed at ~/build/linux/.

In general, arch sets an arch kernel source with two local git repositories. The one at archlinux-linux/ is a local bare git repository pointing to https://github.com/archlinux/linux.git. The other one is at src/archlinux-linux/, pulling from the bare repository. Possible local patches, and building, are expected at src/archlinux-linux/.

For this example, the HEAD of the locally installed bare git repository source at archlinux-linux/ was initially pointing to

which is somewhere between v5.2.5-arch1 and v5.2.6-arch1.

One can see it fetched v5.2.7-arch1, which was the newest archlinux tag, because it prints what new tags were obtained. If no new tags were obtained then there is no newer archlinux source available.

Now the source can be updated where the actual build will take place.

You can verify you are on track with something like

This shows few specific archlinux patches between Arch Linux kernel v5.2.7-arch1 and Linux 5.2.7.

The up to date PKGBUILD, as well archlinux kernel configuration file, can be pulled in using git in the package directory:

Now you should merge files located in ~/build/linux/linux/* into ~/build/linux/. Merging can also done manually, or with specific utilities. Review #Changing prepare(), and run manually most, if not all, the shell commands of PKGBUILD::prepare().

At this point, makepkg --verifysource should succeed. While #Compiling, make sure to also add --noextract option to the makepkg command, since it should be able to build the packages as if the source was extracted by makepkg --nobuild. And you are back to #Installing.

One will probably want to remove ~/build/linux/linux/ after merging. In addition, ~/build/linux/src/archlinux will accumulate branches in the form of 5.2.7-arch1 if more recent updates are done in this fashion. These can be deleted with

**Examples:**

Example 1 (unknown):
```unknown
$ mkdir ~/build/
$ cd ~/build/
```

Example 2 (unknown):
```unknown
$ pkgctl repo clone --protocol=https linux
```

Example 3 (unknown):
```unknown
~/build/linux/-+
               +--config
               \__PKGBUILD
```

Example 4 (unknown):
```unknown
pkgbase=linux-custom
```

---

## pacman

**URL:** https://wiki.archlinux.org/title/NoExtract

**Contents:**
- Usage
  - Installing packages
    - Installing specific packages
      - Virtual packages
    - Installing package groups
  - Removing packages
  - Upgrading packages
  - Querying package databases
    - Pactree
    - Database structure

The pacman package manager is one of the major distinguishing features of Arch Linux. It combines a simple binary package format with an easy-to-use Arch build system. The goal of pacman is to make it possible to easily manage packages, whether they are from the official repositories or the user's own builds.

Pacman keeps the system up-to-date by synchronizing package lists with the master server. This server/client model also allows the user to download/install packages with a simple command, complete with all required dependencies.

Pacman is written in the C programming language and uses the bsdtar(1) tar format for packaging.

What follows is just a small sample of the operations that pacman can perform. To read more examples, refer to pacman(8).

A package is an archive containing:

Arch's package manager pacman can install, update, and remove those packages. Using packages instead of compiling and installing programs yourself has various benefits:

To install a single package or list of packages, including dependencies, issue the following command:

To install a list of packages with regex (see this forum thread):

Sometimes there are multiple versions of a package in different repositories (e.g. extra and extra-testing). To install the version from the extra repository in this example, the repository needs to be defined in front of the package name:

To install a number of packages sharing similar patterns in their names, one can use curly brace expansion. For example:

This can be expanded to however many levels needed:

A virtual package is a special package which does not exist by itself, but is provided by one or more other packages. Virtual packages allow other packages to not name a specific package as a dependency, in case there are several candidates. Virtual packages cannot be installed by their name, instead they become installed in your system when you have installed a package providing the virtual package. An example is the dbus-units package.

Some packages belong to a group of packages that can all be installed simultaneously. For example, issuing the command:

will prompt you to select the packages from the gnome group that you wish to install.

Sometimes a package group will contain a large amount of packages, and there may be only a few that you do or do not want to install. Instead of having to enter all the numbers except the ones you do not want, it is sometimes more convenient to select or exclude packages or ranges of packages with the following syntax:

which will select packages 1 through 10 and 15 for installation, or:

which will select all packages except 5 through 8 and 2 for installation.

To see what packages belong to the gnome group, run:

Also visit https://archlinux.org/groups/ to see what package groups are available.

To remove a single package, leaving all of its dependencies installed:

To remove a package and its dependencies which are not required by any other installed package:

The above may sometimes refuse to run when removing a group which contains otherwise needed packages. In this case try:

To remove a package, its dependencies and all the packages that depend on the target package:

To remove a package, which is required by another package, without removing the dependent package:

Pacman saves important configuration files when removing certain applications and names them with the extension: .pacsave. To prevent the creation of these backup files use the -n option:

Pacman can update all packages on the system with just one command. This could take quite a while depending on how up-to-date the system is. The following command synchronizes the repository databases and updates the system's packages, excluding "local" packages that are not in the configured repositories:

Pacman queries the local package database with the -Q flag, the sync database with the -S flag and the files database with the -F flag. See pacman -Q --help, pacman -S --help and pacman -F --help for the respective suboptions of each flag.

Pacman can search for packages in the database, searching both in packages' names and descriptions:

Sometimes, -s's builtin ERE (Extended Regular Expressions) can cause a lot of unwanted results, so it has to be limited to match the package name only; not the description nor any other field:

To search for already installed packages:

To search for package file names in remote packages:

To display extensive information about a given package (e.g. its dependencies):

For locally installed packages:

Passing two -i flags will also display the list of backup files and their modification states:

To retrieve a list of the files installed by a package:

To retrieve a list of the files installed by a remote package:

To verify the presence of the files installed by a package:

Passing the k flag twice will perform a more thorough check.

To query the database to know which package a file in the file system belongs to:

To query the database to know which remote package a file belongs to:

To list all packages no longer required as dependencies (orphans):

To list all packages explicitly installed and not required as dependencies:

See pacman/Tips and tricks for more examples.

For advanced functionality, install pkgfile, which uses a separate database with all files and their associated packages.

To view the dependency tree of a package:

To view the dependent tree of a package, pass the reverse flag -r to pactree.

The pacman databases are normally located at /var/lib/pacman/sync. For each repository specified in /etc/pacman.conf, there will be a corresponding database file located there. Database files are gzipped tar archives containing one directory for each package, for example for the which package:

The desc file contains meta data such as the package description, dependencies, file size and MD5 hash.

Pacman stores its downloaded packages in /var/cache/pacman/pkg/ and does not remove the old or uninstalled versions automatically. This has some advantages:

However, it is necessary to deliberately clean up the cache periodically to prevent the directory to grow indefinitely in size.

The paccache(8) script, provided within the pacman-contrib package, deletes all cached versions of installed and uninstalled packages, except for the most recent three, by default:

Enable and start paccache.timer to discard unused packages weekly. You can configure the arguments for the service in /etc/conf.d/pacman-contrib, e.g with PACCACHE_ARGS='-k1' or PACCACHE_ARGS='-uk0' for the two examples below.

You can also define how many recent versions you want to keep. To retain only one past version use:

Add the -u/--uninstalled switch to limit the action of paccache to uninstalled packages. For example to remove all cached versions of uninstalled packages, use the following:

See paccache -h for more options.

Pacman also has some built-in options to clean the cache and the leftover database files from repositories which are no longer listed in the configuration file /etc/pacman.conf. However pacman does not offer the possibility to keep a number of past versions and is therefore more aggressive than paccache default options.

To remove all the cached packages that are not currently installed, and the unused sync databases, execute:

To remove all files from the cache, use the clean switch twice, this is the most aggressive approach and will leave nothing in the cache directory:

pkgcachecleanAUR and pacleanerAUR are two further alternatives to clean the cache.

Download a package without installing it:

Install a 'local' package that is not from a remote repository (e.g. the package is from the AUR):

To keep a copy of the local package in pacman's cache, use:

Install a 'remote' package (not from a repository stated in pacman's configuration files):

Pacman always lists packages to be installed or removed, and asks for permission before taking any action.

To get a list in a processable format, and to prevent the actions of -S, -U and -R, you can use -p, short for --print.

--print-format can be added to format this list in various ways. --print-format %n will return a list without package versions.

The pacman database organizes installed packages into two groups, according to installation reason:

When installing a package, it is possible to force its installation reason to dependency with:

The command is normally used because explicitly-installed packages may offer optional packages, usually for non-essential features for which the user has discretion.

When reinstalling a package, though, the current installation reason is preserved by default.

The list of explicitly-installed packages can be shown with pacman -Qe, while the complementary list of dependencies can be shown with pacman -Qd.

To change the installation reason of an already installed package, execute:

Use --asexplicit to do the opposite operation.

When successful, the workflow of a transaction follows five high-level steps plus pre/post transaction hooks:

Pacman settings are located in /etc/pacman.conf: this is the place where the user configures the program to work in the desired manner. In-depth information about the configuration file can be found in pacman.conf(5).

General options are in the [options] section. Read pacman.conf(5) or look in the default pacman.conf for information on what can be done here.

To see old and new versions of available packages, uncomment the "VerbosePkgLists" line in /etc/pacman.conf. The output of pacman -Syu will be like this:

The number of packages being downloaded in parallel (at the same time) are configured in /etc/pacman.conf with the ParallelDownloads option under [options]. The /etc/pacman.conf shipped with the pacman package sets it to 5. If the option is unset, packages will be downloaded sequentially.

To have a specific package skipped when upgrading the system, add this line in the [options] section:

For multiple packages use a space-separated list, or use additional IgnorePkg lines. Also, glob patterns can be used. If you want to skip packages just once, you can also use the --ignore option on the command-line - this time with a comma-separated list.

It will still be possible to upgrade the ignored packages using pacman -S: in this case pacman will remind you that the packages have been included in an IgnorePkg statement.

As with packages, skipping a whole package group is also possible:

All files listed with a NoUpgrade directive will never be touched during a package install/upgrade, and the new files will be installed with a .pacnew extension.

Multiple files can be specified like this:

To always skip installation of specific files or directories list them under NoExtract. For example, to avoid installing bash completion scripts, use:

Later rules override previous ones, and you can negate a rule by prepending !.

If you have several configuration files (e.g. main configuration and configuration with testing repository enabled) and would have to share options between configurations you may use Include option declared in the configuration files, e.g.:

where /path/to/common/settings file contains the same options for both configurations.

Pacman can run pre- and post-transaction hooks from the /usr/share/libalpm/hooks/ directory; more directories can be specified with the HookDir option in pacman.conf, which defaults to /etc/pacman.d/hooks. Hook file names must be suffixed with .hook. Pacman hooks are not interactive.

Pacman hooks are used, for example, in combination with systemd-sysusers and systemd-tmpfiles to automatically create system users and files during the installation of packages. For example, tomcat8 specifies that it wants a system user called tomcat8 and certain directories owned by this user. The pacman hooks systemd-sysusers.hook and systemd-tmpfiles.hook invoke systemd-sysusers and systemd-tmpfiles when pacman determines that tomcat8 contains files specifying users and tmp files.

For more information on alpm hooks, see alpm-hooks(5).

Besides the special [options] section, each other [section] in pacman.conf defines a package repository to be used. A repository is a logical collection of packages, which are physically stored on one or more servers: for this reason each server is called a mirror for the repository.

Repositories are distinguished between official and unofficial. The order of repositories in the configuration file matters; repositories listed first will take precedence over those listed later in the file when packages in two repositories have identical names, regardless of version number. In order to use a repository after adding it, you will need to upgrade the whole system first.

Each repository section allows defining the list of its mirrors directly or in a dedicated external file through the Include directive; for example, the mirrors for the official repositories are included from /etc/pacman.d/mirrorlist. See the Mirrors article for mirror configuration.

Pacman stores downloaded package files in cache, in a directory denoted by CacheDir in [options] section of pacman.conf (defaults to /var/cache/pacman/pkg/ if not set).

Cache directory may grow over time, even if keeping just the freshest versions of installed packages.

If you want to move that directory to some more convenient place, do one of the following:

Pacman supports package signatures, which add an extra layer of security to the packages. The default configuration, SigLevel = Required DatabaseOptional, enables signature verification for all the packages on a global level. This can be overridden by per-repository SigLevel lines. For more details on package signing and signature verification, take a look at pacman-key.

If you see the following error: [1]

This is happening because pacman has detected a file conflict, and by design, will not overwrite files for you. This is by design, not a flaw.

The problem is usually trivial to solve (although to be sure, you should try to find out how these files got there in the first place). A safe way is to first check if another package owns the file (pacman -Qo /path/to/file). If the file is owned by another package, file a bug report. If the file is not owned by another package, rename the file which "exists in filesystem" and re-issue the update command. If all goes well, the file may then be removed.

If you had installed a program manually without using pacman, for example through make install, you have to remove/uninstall this program with all of its files. See also Pacman tips#Identify files not owned by any package.

Every installed package provides a /var/lib/pacman/local/package-version/files file that contains metadata about this package. If this file gets corrupted, is empty or goes missing, it results in file exists in filesystem errors when trying to update the package. Such an error usually concerns only one package. Instead of manually renaming and later removing all the files that belong to the package in question, you may explicitly run pacman -S --overwrite glob package to force pacman to overwrite files that match glob.

This article or section is out of date.

Look for .part files (partially downloaded packages) in /var/cache/pacman/pkg/ and remove them (often caused by usage of a custom XferCommand in pacman.conf).

That same error may also appear if archlinux-keyring is out-of-date, preventing pacman from verifying signatures. See Pacman/Package signing#Upgrade system regularly for the fix and how to avoid it in the future.

When pacman is about to alter the package database, for example installing a package, it creates a lock file at /var/lib/pacman/db.lck. This prevents another instance of pacman from trying to alter the package database at the same time.

If pacman is interrupted while changing the database, this stale lock file can remain. If you are certain that no instances of pacman are running then delete the lock file:

This error manifests as Not found in sync db, Target not found or Failed retrieving file.

Firstly, ensure the package actually exists. If certain the package exists, your package list may be out-of-date. Try running pacman -Syu to force a refresh of all package lists and upgrade. Also make sure the selected mirrors are up-to-date and repositories are correctly configured. You can also use Reflector to keep the mirrors up-to-date.

If pacman reports there is nothing to update, but the Failed retrieving file error continues to be printed, consider forcing a database download with pacman -Syyu. This is never needed under normal circumstances, so inspect more closely the status and consistency of the mirror.

It could also be that the repository containing the package is not enabled on your system, e.g. the package could be in the multilib repository, but multilib is not enabled in your pacman.conf.

See also FAQ#Why is there only a single version of each shared library in the official repositories?.

This article or section needs expansion.

Whether due to power loss, kernel panic or hardware failure an update may be interrupted. In most cases, there will not be much damage but the system will likely be unbootable.

Replicating the exact upgrade is needed to ensure the right scriptlets and hooks will run.

In the case that pacman crashes with a "database write" error while removing packages, and reinstalling or upgrading packages fails thereafter, do the following:

If /var/cache/pacman/pkg is a symlink, pacman will try to make a directory instead and thus remove this symlink during self-upgrade. This will cause the update to fail. As a result, /usr/bin/pacman and other contents of the pacman package will be missing.

Never symlink /var/cache/pacman/pkg because it is controlled by pacman. Use the CacheDir option or a bind mount instead; see #Package cache directory.

If you have already encountered this problem and broke your system, you can manually extract /usr contents from the package to restore pacman and then reinstall it properly; see FS#73306 and related forum thread for details.

pacman-staticAUR is a statically compiled version of pacman, so it will be able to run even when the libraries on the system are not working. This can also come in handy when a partial upgrade was performed and pacman can not run anymore.

The pinned comment and the PKGBUILD provides a way to directly download the binary, which can be used to reinstall pacman or to upgrade the entire system in case of partial upgrades.

In some situations, your system may be too broken (e.g., due to missing or incompatible libraries) to run `makepkg` or build the `pacman-static` package from the AUR successfully.

If building from the PKGBUILD fails or `makepkg` cannot be run, you can download a precompiled `pacman-static` binary from a trusted source. This static binary does not depend on system libraries and can be used to restore a working `pacman` on your system.

A reliable source for the binary is:

This will update your system and reinstall `pacman`, fixing broken dependencies related to missing shared libraries.

If even pacman-static does not work, it is possible to recover using an external pacman. One of the easiest methods to do so is by using the archiso and simply using --sysroot or --root to specify the mount point of the system to perform the operation on. See Chroot#Using chroot on how to mount the necessary filesystems required by --sysroot.

Even if pacman is terribly broken, you can fix it manually by downloading the latest packages and extracting them to the correct locations. The rough steps to perform are:

If you have a healthy Arch system on hand, you can see the full list of dependencies with:

But you may only need to update a few of them depending on your issue. An example of extracting a package is

Note the use of the w flag for interactive mode. Running non-interactively is very risky since you might end up overwriting an important file. Also take care to extract packages in the correct order (i.e. dependencies first). This forum post contains an example of this process where only a couple pacman dependencies are broken.

Most likely the initramfs became corrupted during a kernel update (improper use of pacman's --overwrite option can be a cause). There are two options; first, try the Fallback entry.

Once the system starts, run this command (for the stock linux kernel) either from the console or from a terminal to rebuild the initramfs image:

If that does not work, from a current Arch release (CD/DVD or USB stick), mount your root and boot partitions to /mnt and /mnt/boot, respectively. Then chroot using arch-chroot:

Reinstalling the kernel (the linux package) will automatically re-generate the initramfs image with mkinitcpio -p linux. There is no need to do this separately.

Afterwards, it is recommended that you run exit, umount /mnt/{boot,} and reboot.

As the error message says, your locale is not correctly configured. See Locale.

When locale files are intentionally removed by tools such as bleachbit or localepurgeAUR, pacman may issue warnings about missing locales during package updates.

To suppress these warnings, you can comment out the CheckSpace option in pacman.conf. Keep in mind that disabling CheckSpace turns off the space-checking functionality for all package installations, so use this workaround only when you have alternative means to monitor disk space.

Make sure that the relevant environment variables ($http_proxy, $ftp_proxy etc.) are set up. If you use pacman with sudo, you need to configure sudo to pass these environment variables to pacman. Also, ensure the configuration of dirmngr has honor-http-proxy in /etc/pacman.d/gnupg/dirmngr.conf to honor the proxy when refreshing the keys.

To reinstall all the native packages: pacman -Qnq | pacman -S - or pacman -S $(pacman -Qnq) (the -S option preserves the installation reason by default).

You will then need to reinstall all the foreign packages, which can be listed with pacman -Qmq.

It looks like previous pacman transaction removed or corrupted shared libraries needed for pacman itself.

To recover from this situation, you need to unpack required libraries to your filesystem manually. First find what package contains the missed library and then locate it in the pacman cache (/var/cache/pacman/pkg/). Unpack required shared library to the filesystem. This will allow to run pacman.

Now you need to reinstall the broken package. Note that you need to use --overwrite flag as you just unpacked system files and pacman does not know about it. Pacman will correctly replace our shared library file with one from package.

That's it. Update the rest of the system.

Some issues have been reported regarding network problems that prevent pacman from updating/synchronizing repositories. [2] [3] When installing Arch Linux natively, these issues have been resolved by replacing the default pacman file downloader with an alternative (see Improve pacman performance for more details). When installing Arch Linux as a guest OS in VirtualBox, this issue has also been addressed by using Host interface instead of NAT in the machine properties.

If you receive this error message with correct mirrors, try setting a different name server.

If you want to install a package on an sshfs mount using pacman -U and receive this error, move the package to a local directory and try to install again.

Upon executing, e.g., pacman -Syu inside a chroot environment an error is encountered:

This is frequently caused by the chroot directory not being a mountpoint when the chroot is entered. See the note at Install Arch Linux from existing Linux#Downloading basic tools for a solution, and arch-chroot(8) for an explanation and an example of using bind mounting to make the chroot directory a mountpoint.

If you are unable to update packages and receive this error, then try rm -r /var/lib/pacman/sync/ before attempting to update.

If removing sync files doesn't help, check that the sync files are gzip compressed data using file /var/lib/pacman/sync/* before attempting to update. A router or proxy might corrupt the downloads. Corruption could possibly be HTML type.

If sync files are of the correct type, there might be an issue with the mirror server. Look up the mirror server(s) in use with pacman-conf -r core and pacman-conf -r extra. Paste the first returned url in a browser and check that a file listing is returned. In case the mirror returns an error, comment it in /etc/pacman.d/mirrorlist. You may try updating or re-ranking mirrors.

If this error occurs and you're for instance unable to update your system or any package at all, it is possible that you have DISPLAY set to a blank value, which seems to break the GPG-Flow.

In this case, unset DISPLAY or setting it to a arbitrary value will most likely allow to update again, in case any other option above didn't do the trick yet. See this post for further details.

One may use the pacman -Qk $pkg to check if the installed files of the $pkg package match the files from its database version. For several packages, one may use the following loop to reinstall all packages which have missing file(s):

Suppose that your local database located in /var/lib/pacman is more up-to-date compared to installed packages in the / filesystem (e.g., because of a partial rollback), then this method is the appropriate one to re-synchronize the root filesystem with the local database.

**Examples:**

Example 1 (unknown):
```unknown
pacman -Ql pacman pacman-contrib | grep -E 'bin/.+'
```

Example 2 (unknown):
```unknown
pacman -Sy package_name
```

Example 3 (unknown):
```unknown
pacman -Syu package_name
```

Example 4 (unknown):
```unknown
# pacman -S package_name1 package_name2 ...
```

---

## AMDGPU PRO

**URL:** https://wiki.archlinux.org/title/AMDGPU_PRO

**Contents:**
- Purpose of proprietary components
- Installation
- Usage
  - Using proprietary OpenGL
    - How to ensure you are using AMDGPU-PRO driver
  - Using proprietary Vulkan
  - Using Advanced Multimedia Framework
- Troubleshooting
  - Intel + AMD hybrid graphics
  - Uninstalling packages

This page describes close source drivers for AMD GPUs.

AMD releases their open source drivers via standard distribution channels. And they also periodically do releases of their Radeon Software for Linux suite, which includes both open and proprietary components. Open source components are not needed from there, and proprietary components are repacked from the latest Ubuntu LTS version. They are published in AUR in the amdgpu-pro-installer package base.

Comment by John Bridgman from AMD explaining why they still package close source drivers:

There are several proprietary components: OpenGL, OpenCL, Vulkan and AMF. Sometimes you may want to use these components due to specific features that open source components may lack.

AMDGPU PRO OpenGL is a proprietary, binary userland driver, which works on top of the open-source amdgpu kernel driver. From Radeon Software 18.50 vs Mesa 19 benchmarks article: When it comes to OpenGL games, the RadeonSI Gallium3D driver simply dominates the proprietary AMD OpenGL driver. Users of graphic cards other than Radeon Pro are advised to use the amdgpu graphics stack. Mostly used because of lacking compatibility layers that some software relies on. See gentoo wiki linked below.

AMDGPU PRO Vulkan - required dependency for AMF.

AMDGPU PRO OpenCL - used because Mesa OpenCL is not fully complete. Proprietary component only for Polaris GPUs. The onward GPUs use the open ROCm OpenCL.

AMDGPU AMF - used for GPU encoding/decoding.

For proprietary OpenGL implementation, use the amdgpu-pro-installer package base. It contains all the following packages:

For available OpenCL implementations see GPGPU#OpenCL on AMD/ATI GPU.

Launch your application with progl, for example:

Run the following command:

If it returns AMD, then you are running open source driver. If it returns Advanced Micro Devices, Inc. or ATI Technologies Inc., then you are running proprietary driver.

Alternatively, run glmark2. When using open driver, in OpenGL Information you will see:

But when using closed driver, you will see:

AMD Vulkan Prefixes is a script for switching between different Vulkan implementations. Install amd-vulkan-prefixesAUR and prepend your application with the prefix you want. The executables provided are vk_radv and vk_pro. For example, to use the proprietary Vulkan implementation:

For users of a hybrid setup with both an Intel GPU and an AMD GPU, usage of the proprietary AMDGPU Pro Workstation Driver might not work as expected due to different MESA implementations.

The symptom is the following: when you boot your machine, you get a black screen, but with your mouse cursor is moving normally.

Unfortunately, Reverse PRIME is not a solution. See the developer response.

If you are in trouble, for example, you cannot login to your system due to black screen, you can revert all back by uninstalling all packages related to AMDGPU PRO.

Switch a virtual console (with e.g. Ctrl+Alt+F2), login and run:

If using Southern Islands (SI) or Sea Islands (CIK) GPU, when running clinfo, you get:

then ensure you are using the amdgpu driver, but not radeon.

Check which driver is currently in use:

See AMDGPU#Enable Southern Islands (SI) and Sea Islands (CIK) support for more information.

AMD drivers and firmware (especially recent firmware) can get out of sync and create issues or not work at all. You can search in the journal for VCN:

Downgrading the firmware seems to fix the problem.

**Examples:**

Example 1 (unknown):
```unknown
$ progl glmark2
```

Example 2 (unknown):
```unknown
$ glxinfo | grep "OpenGL vendor string" | cut -f2 -d":" | xargs
```

Example 3 (unknown):
```unknown
Advanced Micro Devices, Inc.
```

Example 4 (unknown):
```unknown
ATI Technologies Inc.
```

---

## Font package guidelines

**URL:** https://wiki.archlinux.org/title/Font_package_guidelines

**Contents:**
- General guidelines
  - Package naming
  - Package description
  - Architecture
  - Dependencies
  - Provides
  - Source
- Package
- Example packages
- See also

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

This document covers proposed standards and guidelines on writing PKGBUILDs for Fonts.

If the font is a variable font, add the suffix -variable.

The package description should at least contain the word font and what type of font it is: sans-serif, serif or monospace.

Fonts are architecture-independent. Use arch=(any).

Fonts do not depend on anything. Many packages in the repositories, however, include fontconfig and xorg-mkfontscale as dependencies. Those were required when font packages needed to use install scripts to update the font cache – a lot of duplicate work now done by pacman hooks. If you install fontconfig or xorg-mkfontscale, all existing fonts in /usr/share/fonts/ will be cached making it unnecessary to force people to use fontconfig or mkfontscale.

Many applications rely on the virtual package ttf-font. If your font family meets the criteria, add provides=('ttf-font').

See whether a font is available from the following sources in this order:

The following sites are not recommended:

The following snippet is an example for an OTF font released under the SIL Open Font License 1.1 with Reserved Font Name:

**Examples:**

Example 1 (unknown):
```unknown
ttf-fontname
```

Example 2 (unknown):
```unknown
otf-fontname
```

Example 3 (unknown):
```unknown
/usr/share/fonts/
```

Example 4 (unknown):
```unknown
provides=('ttf-font')
```

---

## Meson package guidelines

**URL:** https://wiki.archlinux.org/title/Meson_package_guidelines

**Contents:**
- Usage
  - Requirements
  - prepare()
  - build()
    - Using meson binary directly
    - Using arch-meson wrapper script
    - Setting software-specific build options
  - check()
  - package()
- Troubleshooting

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

From Meson's official website:

Written in Python, Meson features multi-platform support, support for several programming languages, cross compilation, and more.

Meson does not build software directly, but rather sets up a back-end build system. While it is commonly used with ninja, other build systems can be used. It is commonly used to replace GNU Build System.

This document covers standards and guidelines on writing PKGBUILDs for software that uses Meson.

meson has to be included to the PKGBUILD's makedepends array.

Meson has a utility to manage subprojects and can download them all in advance. Running this command in the prepare() stage allows the build() and other stages to be executed completely offline.

Configuring and building is normally done using meson binary, but it can also be done by using Arch Linux's arch-meson wrapper script.

Both meson and arch-meson commands include in the usage syntax options, source directory and build directory:

This method uses meson setup, which is the similar to the ./configure command used by the GNU Build System.

The --prefix=/usr command-line flag must always be passed to meson setup because Arch Linux packages must not install files to /usr/local, according Arch package guidelines#Package etiquette. The --buildtype=plain built-in option can be set to another value, if you know what you are doing.

meson compile is a wrapper for supported back-end build systems, which currently defaults to ninja[1]

arch-meson is a wrapper script included in meson package which has the advantage of setting some of Meson built-in options that would probably be used in an Arch package, saving packager's time and code in the PKGBUILD. Quoting the description written in arch-meson, it is a "Highly opinionated wrapper for Arch Linux packaging".

While Meson has some built-in build options (e.g. --prefix), the software being packaged could have other build options which the packager should consider. Valid software-specific build options, if present, are normally found in a file named meson.options (supported since Meson 1.1) or meson_options.txt. Look for option(settings) in these files, then read the settings.

To use a software-specific build option, use the notation -D key=value, where key is the build option name set in the project and value is a valid value, like e.g. true.

For instance, gtranslator has the following build options:

So, to build its documentation, one must run Meson appending -D gtk_doc=true build option, resulting in a command line like e.g.

If the software being packaged provides test suite, consider running it in the PKGBUILD's check() function. This can be accomplished with meson test command.

where build is the same build directory name used in the above #build() step.

See meson test --help and Unit tests in Meson docs for more info.

Packaging normally requires running only meson install, but check if another installation command is required (e.g. an uncommon license). Use the same build directory as above and set the --destdir flag:

Example of error output:

Error present since Meson 0.60, which promoted from warning to error the use of positional arguments. One very common example of this error is to add invalid arguments to i18n.merge_file(). For instance, aisleriot had:

where 'sol.metainfo.xml' is the now invalid argument that should be removed. For the fix applied in the upstream, see this commit.

Measures to be taken in this case:

To sum up the above instructions and to provide a single copy-and-paste point, see the template below:

This is a small list of packages that use Meson. See other packages in the list "Required by" in meson package's page.

**Examples:**

Example 1 (unknown):
```unknown
makedepends=(meson other_deps)
```

Example 2 (unknown):
```unknown
prepare() {
  meson subprojects download --sourcedir=source
}
```

Example 3 (unknown):
```unknown
--prefix /usr
```

Example 4 (unknown):
```unknown
meson setup --help
```

---

## CLR package guidelines

**URL:** https://wiki.archlinux.org/title/CLR_package_guidelines

**Contents:**
- Packaging gotchas
  - Signed assemblies
- Sample PKGBUILDs
  - xbuild
    - Unsigned DLL

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

This document defines the standard for packaging Common Language Runtime (.NET) projects under Arch Linux. Currently only Mono is capable of providing a usable, efficient CLR runtime for multiple systems and this standard will reflect its use. Be aware that a lot of CLR programs were developed with Microsoft .NET in mind and, as such, may or may not run under Mono because of .NET-exclusive factors such as P/Invoke calls and Microsoft digital rights management (DRM) APIs and are thus will not yield a usable package for Arch Linux. However, if combined with Wine as of version 1.5.6 (?), your package may have a chance to run under it. Please see the Wine PKGBUILD Guidelines for more information if such is the case.

If the package is to be installed into the GAC, be sure it has a signed key file. If not, you can generate one like this: sn -k 1024 Foo.snk. Following that, the easiest way to embed the key file into the assembly is to disassemble it like this: monodis Foo.dll --output=Foo.il. Afterwards, reassemble it like so: ilasm /dll /key:Foo.snk Foo.il

The following examples will try to cover some of the most common conventions and build systems.

**Examples:**

Example 1 (unknown):
```unknown
pdb2mdb Foo.dll
```

Example 2 (unknown):
```unknown
#!/bin/sh
exec mono foo.exe "$@"
```

Example 3 (unknown):
```unknown
sn -k 1024 Foo.snk
```

Example 4 (unknown):
```unknown
monodis Foo.dll --output=Foo.il
```

---

## makepkg

**URL:** https://wiki.archlinux.org/title/Makepkg

**Contents:**
- Configuration
  - Packager information
  - Package output
  - Signature checking
- Usage
- Optimization
  - Building optimized binaries
    - C and C++
    - Rust
  - Improving build times

makepkg is a script to automate the building of packages. The requirements for using the script are a build-capable Unix platform and a PKGBUILD.

makepkg is provided by the pacman package.

The system configuration is available in /etc/makepkg.conf, but user-specific changes can be made in $XDG_CONFIG_HOME/pacman/makepkg.conf or ~/.makepkg.conf. Also, system wide changes can be made with a drop-in file /etc/makepkg.conf.d/makepkg.conf. It is recommended to review the configuration prior to building packages.

See makepkg.conf(5) for more information.

Each package is tagged with metadata identifying amongst others also the packager. By default, user-compiled packages are marked with Unknown Packager. If multiple users will be compiling packages on a system, or if one is otherwise distributing packages to other users, it is convenient to provide real contact. This can be done by setting the PACKAGER variable in makepkg.conf.

To check this on an installed package:

To automatically produce signed packages, also set the GPGKEY variable in makepkg.conf.

By default, makepkg creates the package tarballs in the working directory and downloads source data directly to the src/ directory. Custom paths can be configured, for example to keep all built packages in ~/build/packages/ and all sources in ~/build/sources/.

Configure the following makepkg.conf variables if needed:

You can also use relative paths inside each package directory.

If a signature file in the form of .sig or .asc is part of the PKGBUILD source array, makepkg automatically attempts to verify it. In case the user's keyring does not contain the needed public key for signature verification, makepkg will abort the installation with a message that the PGP key could not be verified.

If a needed public key for a package is missing, the PKGBUILD will most likely contain a validpgpkeys entry with the required key IDs. Import it manually, or find it on a keyserver and import it from there. To temporarily disable signature checking, run makepkg with the --skippgpcheck option.

Before continuing, install the base-devel meta package. Dependencies of this package are not required to be listed as build-time dependencies (makedepends) in PKGBUILD files.

To build a package, one must first create a PKGBUILD, or build script, as described in Creating packages. Existing scripts are available from the Arch build system (ABS) tree or the AUR. Once in possession of a PKGBUILD, change to the directory where it is saved and run the following command to build the package:

If required dependencies are missing, makepkg will issue a warning before failing. To build the package and install needed dependencies, add the flag -s/--syncdeps:

Adding the -r/--rmdeps flag causes makepkg to remove the make dependencies later, which are no longer needed. If constantly building packages, consider using Pacman/Tips and tricks#Removing unused packages (orphans) once in a while instead.

Once all dependencies are satisfied and the package builds successfully, a package file (pkgname-pkgver.pkg.tar.zst) will be created in the working directory. To install, use -i/--install (same as pacman -U pkgname-pkgver.pkg.tar.zst):

To clean up leftover files and directories, such as files extracted to the $srcdir, add the option -c/--clean. This is useful for multiple builds of the same package or updating the package version, while using the same build directory. It prevents obsolete and remnant files from carrying over to the new builds:

For more, see makepkg(8).

The default options match the options devtools uses to build packages for the official repositories.[4] As such, end users may realize more or less significant gains by tweaking the following options to match their local environment.

A performance improvement of the packaged software can be achieved by enabling compiler optimizations for the host machine. The downside is that binaries compiled for a specific processor architecture will not run correctly on other machines. On x86_64 machines, there are rarely significant enough real world performance gains that would warrant investing the time to rebuild official packages.

However, it is very easy to reduce performance by using "nonstandard" compiler flags. Many compiler optimizations are only useful in certain situations and should not be indiscriminately applied to every package. Unless benchmark data are available to prove that something is faster, there is a very good chance it is not! The Gentoo GCC optimization and Safe CFLAGS wiki articles provide more in-depth information about compiler optimization.

The options passed to a C/C++ compiler (e.g. gcc or clang) are controlled by the CFLAGS, CXXFLAGS, and CPPFLAGS environment variables. For use in the Arch build system, makepkg exposes these environment variables as configuration options in makepkg.conf. The default values are configured to produce generic binaries that can be installed on a wide range of machines.

GCC can automatically detect and enable safe architecture-specific optimizations. To use this feature, first remove any -march and -mtune flags, then add -march=native. For example:

To see what flags this enables, run:

Further optimization of binaries can be achieved by enabling optimizations that are considered expensive in terms of memory usage and compile time. This can be achieved by changing the optimization level flag from -O2 to -O3. Using this flag will in most cases improve the performance of the binary, although this is not guaranteed and depends on the binary. See Gentoo:GCC optimization#-O and GCC optimization options page for details.

Starting in pacman version 5.2.2, makepkg.conf also includes overrides for the RUSTFLAGS environment variable, for flags given to the Rust compiler. The Rust compiler can also detect and enable architecture-specific optimizations by adding -C target-cpu=native to the given RUSTFLAGS value:

To see which CPU features this will enable, run:

Running --print cfg without -C target-cpu=native will print the default configuration.

Additional optimization-related options that may be added to RUSTFLAGS:

See the Rust compiler's documentation for details.

The make build system uses the MAKEFLAGS environment variable to specify additional options for make. The variable can also be set in the makepkg.conf file.

Users with multi-core/multi-processor systems can specify the number of jobs to run simultaneously. This can be accomplished with the use of nproc(1) to determine the number of available processors, e.g. MAKEFLAGS="--jobs=$(nproc)".

Some PKGBUILDs specifically override this with -j1, because of race conditions in certain versions or simply because it is not supported in the first place. Packages that fail to build because of this should be reported on the bug tracker (or in the case of AUR packages, to the package maintainer) after making sure that the error is indeed being caused by MAKEFLAGS.

See make(1) for a complete list of available options.

As compiling requires many I/O operations and handling of small files, moving the working directory to a tmpfs may bring improvements in build times.

The BUILDDIR variable can be temporarily exported to makepkg to set the build directory to an existing tmpfs. For example:

Persistent configuration can be done in makepkg.conf by uncommenting the BUILDDIR option, which is found at the end of the BUILD ENVIRONMENT section in the default /etc/makepkg.conf file. Setting its value to e.g. BUILDDIR=/tmp/makepkg will make use of the Arch's default /tmp temporary file system.

The use of ccache can improve build times by caching the results of compilations for successive use.

mold is a drop-in replacement for ld/lld linkers, which claims to be significantly faster.

To use mold, append -fuse-ld=mold to LDFLAGS. For example:

To pass extra options to mold, additionally add those to LDFLAGS. For example:

To use mold for Rust packages, append -C link-arg=-fuse-ld=mold to RUSTFLAGS. For example:

Commit 90bf367e included in pacman 6.0.2-9 from February 2024 enabled the debug and lto options by default.

Building debug packages enables the official repositories to provide more tools to troubleshoot issues for users (archlinux/packaging/packages/pacman#23#note_173528), but it is not required when building packages on your own and slows down the build process. See archlinux/packaging/packages/pacman#23#note_173782.

Link-time optimization produces more optimized binaries but greatly lengthens the build process (archlinux/packaging/packages/pacman#23#note_173678), which might not be a desired tradeoff.

To disable those options, add a ! character directly in front of them in the OPTIONS=() array, e.g. OPTIONS=(...!debug !lto...).

To speed up both packaging and installation, with the tradeoff of having larger package archives, change PKGEXT.

For example, the following skips compression of the package file, which will in turn have no need to be decompressed on install:

As another example, the following uses the LZ4 algorithm, which is focused on speed:

To make one of these settings permanent, set PKGEXT in /etc/makepkg.conf.

zstd supports symmetric multiprocessing (SMP) via the -T/--threads flag to speed up compression. The -T0 flag is included by default in the COMPRESSZST array in /etc/makepkg.conf, which lets zstd use as many threads as there are physical CPU cores to compress packages. The number of used threads can be further increased by instructing zstd to base it on the logical CPU count using the --auto-threads=logical flag:

lz4 and xz are multithreaded by default, so nothing needs to be changed in /etc/makepkg.conf.

pigz is a drop-in, parallel implementation for gzip which by default uses all available CPU cores (the -p/--processes flag can be used to employ less cores):

pbzip2 is a drop-in, parallel implementation for bzip2 which also uses all available CPU cores by default. The -p# flag can be used to employ less cores (note: no space between the -p and number of cores).

lbzip2 is another drop-in, parallel implementation for bzip2 which also uses all available CPU cores by default. The -n flag can be used to employ less cores.

plzipAUR is a multithreaded implementation for lzip which also uses all available CPU cores by default. The -n/--threads flag can be used to employ less cores.

Several compression algorithms (including zstd and xz) support setting a compression level which defines a tradeoff between speed, memory and compression efficiency.

Make use of SRCDEST, especially when building VCS packages, to save time acquiring and unpacking sources in subsequent rebuilds.

Install pacman-contrib and run the following command in the same directory as the PKGBUILD file to generate new checksums:

updpkgsums uses makepkg --geninteg to generate the checksums. See this forum discussion for more details.

The checksums can also be obtained with e.g sha256sum and added to the sha256sums array by hand.

If you want to make changes to the source code you can download the source code without building the package by using the -o, --nobuild Download and extract files only option.

You can now make changes to the sources and then build the package by using the -e, --noextract Do not extract source files (use existing $srcdir/ dir) option. Use the -f option to overwrite already built and existing packages.

expac is a pacman database extraction utility. This command shows all packages installed on the system with the packager named packagername:

This shows all packages installed on the system with the packager set in the /etc/makepkg variable PACKAGER. This shows only packages that are in a repository defined in /etc/pacman.conf.

See 32-bit package guidelines.

This article or section is a candidate for merging with GnuPG#Unattended_passphrase.

This article or section needs expansion.

A person may not be available to provide the passphrase for the gpg private key used to sign with in automated build environments such as Jenkins. It is ill-advised to store a private gpg key on a system without a passphrase.

A resulting zst package made with makepkg can still be signed after creation:

where the GPG passphrase is securely provided and obscured by your automation suite of choice.

The resulting zst and sig file can be referenced by pacman clients expecting a valid signature and repositories created with repo-add --sign when hosting your own repo.

Support for magnet URIs resources (with magnet:// prefix) in the source field can be added using the transmission-dlagentAUR download agent.

If the package you are building takes too many resources to build with your default make flags, which are otherwise set properly for most packages, you can try running it in its own control group. makepkg-cgAUR is a wrapper for makepkg that achieved this via systemd control groups (see systemd.resource-control(5)).

Package build process can lead to high CPU utilization, especially in case of #Parallel compilation. Under heavy CPU load, the system can issue a significant slowdown up to becoming unusable, even with the highest nice(1) value. User interface and foreground applications may stutter or even became unresponsive.

This can be worked around by changing the scheduling policy to SCHED_IDLE before running makepkg. It ensures that package building process does not interfere with regular tasks and only utilizes remaining unused CPU time.

From sched(7) § SCHED_IDLE: Scheduling very low priority jobs:

The SCHED_IDLE policy can be set by running chrt(1) command with the -i flag, specifying priority 0 (the only valid option for SCHED_IDLE) and specifying the PID of the current shell.

For the fish shell, where $$ is not set:

Instead of using absolute paths for the package output options, you can also configure relative paths inside each package directory.

For example, you can define target paths in your makepkg.conf file as follows. The $startdir variable refers to the directory where a PKGBUILD is located when you build a package.

makepkg will still create src/ and pkg/ directories as usual, so this is expected behaviour.

The makefile generated by qmake uses the environment variable INSTALL_ROOT to specify where the program should be installed. Thus this package function should work:

Note, that qmake also has to be configured appropriately. For example put this in the corresponding .pro file:

Somehow, the literal strings contained in the variables $srcdir or $pkgdir ended up in one of the installed files in the package. [6]

To identify which files, run the following from the makepkg build directory:

One possible cause would be from the usage of __FILE__ macro in C/C++ code with full path passed to compiler.

Dotnet binaries also sometimes contain full paths to the .pdb files in the default config.

When makepkg calls dependencies, it calls pacman to install the packages, which requires administrative privileges via sudo. However, sudo does not pass any environment variables to the privileged environment, and includes the proxy-related variables ftp_proxy, http_proxy, https_proxy, and no_proxy.

In order to have makepkg working behind a proxy, invoke one of the following methods.

The XferCommand can be set to use the desired proxy URL in /etc/pacman.conf. Add or uncomment the following line in pacman.conf:

Alternatively, one may want to use sudoer's env_keep option, which enables preserving given variables the privileged environment. See Pacman#Pacman does not honor proxy settings for more details.

If something successfully compiles using make, but fails through makepkg, it is almost certainly because /etc/makepkg.conf sets an incompatible compilation variable. Try adding these flags to the PKGBUILD options array:

!buildflags, to prevent its default CPPFLAGS, CFLAGS, CXXFLAGS, and LDFLAGS.

!makeflags, to prevent its default MAKEFLAGS.

!debug, to prevent its default DEBUG_CFLAGS, and DEBUG_CXXFLAGS, in case the PKGBUILD is a debug build.

If any of these fix the problem, this could warrant an upstream bug report assuming the offending flag has been identified.

**Examples:**

Example 1 (unknown):
```unknown
/etc/makepkg.conf
```

Example 2 (unknown):
```unknown
$XDG_CONFIG_HOME/pacman/makepkg.conf
```

Example 3 (unknown):
```unknown
~/.makepkg.conf
```

Example 4 (unknown):
```unknown
/etc/makepkg.conf.d/makepkg.conf
```

---

## dhcpcd

**URL:** https://wiki.archlinux.org/title/Dhcpcd

**Contents:**
- Installation
- Running
- Configuration
  - DHCP static route(s)
  - DHCP Client Identifier
  - Static profile
    - Fallback profile
- Hooks
  - 10-wpa_supplicant
- Tips and tricks

dhcpcd is a DHCP and DHCPv6 client. It is currently the most feature-rich open source DHCP client; see the home page for the full list of features.

Install the dhcpcd package.

dhcpcd-uiAUR is a GTK frontend for the dhcpcd daemon, and optionally wpa_supplicant. It features a configuration dialogue and the ability to enter a pass phrase for wireless networks.

To start the daemon for all network interfaces, start/enable dhcpcd.service.

To start the daemon for a specific interface alone, start/enable the template unit dhcpcd@interface.service, where interface can be found with Network configuration#Listing network interfaces.

Using the template unit is recommended; see #dhcpcd and systemd network interfaces for details. In either case, you will be assigned a dynamic IP address. To assign a static IP address, see #Static profile.

The main configuration is done in /etc/dhcpcd.conf. See dhcpcd.conf(5) for details. Some of the frequently used options are highlighted below.

If you need to add a static route client-side, add it to /etc/dhcpcd.exit-hook. The example shows a new hook-script which adds a static route to a VPN subnet on 10.11.12.0/24 via a gateway machine at 192.168.192.5:

You can add multiple routes to this file.

The DHCP client may be uniquely identified in different ways by the server:

For a further description, see RFC 3315.

It depends on the DHCP-server configuration which options are optional or required to request a DHCP IP lease.

If the dhcpcd default configuration fails to obtain an IP, the following options are available to use in dhcpcd.conf:

The DUID value is set in /var/lib/dhcpcd/duid. For efficient DHCP lease operation it is important that it is unique for the system and applies to all network interfaces alike, while the IAID represents an identifier for each of the systems' interfaces (see RFC 4361).

Care must be taken on a network running Dynamic DNS to ensure that all three IDs are unique. If duplicate DUID values are presented to the DNS server, e.g. in the case where a virtual machine has been cloned and the hostname and MAC have been made unique but the DUID has not been changed, then the result will be that as each client with the duplicated DUID requests a lease the server will remove the predecessor from the DNS record.

Required settings are explained in Network configuration. These typically include the network interface name, IP address, router address, and name server.

Configure a static profile for dhcpcd in /etc/dhcpcd.conf, for example:

More complicated configurations are possible, for example combining with the arping option. See dhcpcd.conf(5) for details.

It is possible to configure a static profile within dhcpcd and fall back to it when DHCP lease fails. This is useful particularly for headless machines, where the static profile can be used as "recovery" profile to ensure that it is always possible to connect to the machine.

The following example configures a static_eth0 profile with 192.168.1.23 as IP address, 192.168.1.1 as gateway and name server, and makes this profile fallback for interface eth0.

dhcpcd executes all scripts found in /usr/lib/dhcpcd/dhcpcd-hooks/ in a lexical order. See dhcpcd.conf(5) and dhcpcd-run-hooks(8) for details.

This article or section needs expansion.

Enable this hook by creating a symbolic link, which ensures the current version is used, even after package updates:

The 10-wpa_supplicant hook, if enabled, automatically launches wpa_supplicant on wireless interfaces. It is started only if:

by default, in that order, but a custom path can be set by adding env wpa_supplicant_conf=configuration_file_path into /etc/dhcpcd.conf.

If you manage wireless connections with wpa_supplicant itself, the hook may create unwanted connection events. For example, if you stop wpa_supplicant the hook may bring the interface up again. Also, if you use netctl-auto, wpa_supplicant is started automatically with /run/network/wpa_supplicant_interface.conf for config, so starting it again from the hook is unnecessary and may result in boot-time parse errors of the /etc/wpa_supplicant/wpa_supplicant.conf file, which only contains dummy values in the default packaged version.

To disable the hook remove the symbolic link you added, or add nohook wpa_supplicant to dhcpcd.conf.

dhcpcd contains an implementation of a recommendation of the DHCP standard (RFC 2131) to verify via ARP if the assigned IP is not used by something else. This is usually not needed in home networks, so it is possible to save about 5 seconds on every connect by disabling it:

This is equivalent to passing --noarp to dhcpcd, and disables the described ARP probing, speeding up connections to networks with DHCP.

The file /var/lib/dhcpcd/interface.lease, where interface is the name of the interface on which you have a lease, contains the actual DHCP lease reply sent by the DHCP server. For a wireless interface, the filename is /var/lib/dhcpcd/interface-ssid.lease, where ssid is the name of the wireless network. It is used to determine the last lease from the server, and its mtime attribute is used to determine when it was issued. This last lease information is then used to request the same IP address previously held on a network, if it is available. If you do not want that, simply delete this file.

If the DHCP server still assigns the same IP address, this may happen because it is configured to keep the assignment stable and recognizes the requesting DHCP client id or DUID (see #DHCP Client Identifier). You can test it by stopping dhcpcd and removing or renaming /var/lib/dhcpcd/duid. dhcpcd will generate a new one on next run.

Keep in mind that the DUID is intended as persistent machine identifier across reboots and interfaces. If you are transferring the system to new computer, preserving this file should make it appear as old one.

If you are dualbooting Arch and macOS or Windows and want each to receive different IP addresses, you can exert control about the IPs leased by specifying a different DUID in each operating system installation.

In Windows the DUID should be stored in the

On macOS it is directly accessible in Network\adapter\dhcp preferences panel.

If you are using a dnsmasq DHCP server, the different DUIDs can be used in appropriate dhcp-host= rules in its configuration.

If resolvconf is available, DNS information will be sent to it; otherwise, dhcpcd itself will write to /etc/resolv.conf.

/etc/resolv.conf overwriting can be stopped by disabling the hook /usr/lib/dhcpcd/dhcpcd-hooks/20-resolv.conf. Do so by adding the following to the last section of /etc/dhcpcd.conf:

Note that disabling this hook also disables dhcpcd's use of resolvconf in general.

Alternatively, you can create a file called /etc/resolv.conf.head containing your DNS servers. dhcpcd will prepend this file to the beginning of /etc/resolv.conf.

Or you can configure dhcpcd to use the same DNS servers every time. To do this, add the following line at the end of your /etc/dhcpcd.conf, where dns-server-ip-addressses is a space separated list of DNS IP addresses.

For example, to set it to Google's DNS servers:

If you are on a network with DHCPv4 that filters Client IDs based on MAC addresses, you may need to change the following line:

Else, you may not obtain a lease since the DHCP server may not read your DHCPv6-style Client ID correctly. See RFC 4361 for more information.

A problem may occur when DHCP gets a wrong IP assignment, such as when two routers are tied together through a VPN. The router that is connected through the VPN may be assigning IP address. To fix it, as root, release the IP address:

Then request a new one:

You may have to run those two commands many times.

For some (noncompliant) routers, you will not be able to connect properly unless you comment the line

in /etc/dhcpcd.conf. This should not cause issues unless you have multiple DHCP servers on your network (not typical); see this page for more information.

dhcpcd.service can be enabled without specifying an interface. This may, however, create a race condition at boot with systemd-udevd trying to apply a predictable network interface name:

To avoid this problem use denyinterfaces or allowinterfaces in dhcpcd.conf(5) to stop dhcpcd from binding to kernel names, for example:

It is also possible to enable dhcpcd on a per interface basis as described in #Running. The downside of the template unit is, however, that it does not support hot-plugging of a wired connection and will fail if the network cable is not connected. To work-around the failure, see #Timeout delay.

If dhcpcd operates on a single interface and fails to obtain a lease after 30 seconds (for example when the server is not ready or the cable not plugged), it will exit with an error.

To have dhcpcd wait indefinitely for one-time, edit the unit and set the timeout option to 0:

To have it wait indefinitely, let the unit restart after it exited:

By default the dhcpcd@.service waits to get an IP address before forking into the background via the -w flag for dhcpcd. If the unit is enabled, this may cause the boot to wait for an IP address before continuing. To fix this, create a drop-in file for the unit with the following:

**Examples:**

Example 1 (unknown):
```unknown
dhcpcd.service
```

Example 2 (unknown):
```unknown
dhcpcd@interface.service
```

Example 3 (unknown):
```unknown
systemctl --type=service
```

Example 4 (unknown):
```unknown
/etc/dhcpcd.conf
```

---

## pacman/Pacnew and Pacsave

**URL:** https://wiki.archlinux.org/title/Pacnew_files

**Contents:**
- Why these files are created
- Package backup files
- Types explained
  - .pacnew
  - .pacsave
- Locating .pac* files
- Managing .pac* files
  - pacdiff
  - Third-party utilities
- See also

When pacman removes a package that has a configuration file, it normally creates a backup copy of that configuration file and appends .pacsave to the name of the file. Likewise, when pacman upgrades a package which includes a new configuration file created by the maintainer differing from the currently installed file, it saves a .pacnew file with the new configuration. pacman provides notice when these files are written.

A .pacnew file may be created during a package upgrade (pacman -Syu, pacman -Su or pacman -U) to avoid overwriting a file which already exists and was previously modified by the user. When this happens, a message like the following will appear in the output of pacman:

A .pacsave file may be created during a package removal (pacman -R), or by a package upgrade (the package must be removed first). When the pacman database has a record that a certain file owned by the package should be backed up, it will create a .pacsave file. When this happens pacman outputs a message like the following:

These files require manual intervention from the user and it is good practice to handle them right after every package upgrade or removal. If left unhandled, improper configurations can result in improper function of the software or the software being unable to run altogether.

A package's PKGBUILD file specifies which files should be preserved or backed up when the package is upgraded or removed. For example, the PKGBUILD for pulseaudio contains the following line:

After installation, this list can be queried from the pacman database using pacman -Qii package_name.

To prevent any package from overwriting a certain file, see Pacman#Skip file from being upgraded.

For each of the #Package backup files being upgraded, pacman cross-compares three md5sums generated from the file's contents: one sum for the version originally installed by the package, one for the version currently in the filesystem, and one for the version in the new package. If the version of the file currently in the filesystem has been modified from the version originally installed by the package, pacman cannot know how to merge those changes with the new version of the file. Therefore, instead of overwriting the modified file when upgrading, pacman saves the new version with a .pacnew extension and leaves the modified version untouched.

Going into further detail, the 3-way MD5 sum comparison results in one of the following outcomes:

Rarely, when an upgraded package includes a backup file the previous version did not, the situation is correctly handled as X/Y/Y or X/Y/Z, with X being a non-existant value.

If the user has modified one of the files specified in backup then that file will be renamed with a .pacsave extension and will remain in the filesystem after the rest of the package is removed.

Pacman does not deal with .pacnew files automatically: you must maintain these yourself. A few tools are presented in the next section. To do this manually, you will first need to locate them. When upgrading or removing a large number of packages, updated .pac* files may be missed. To discover whether any .pac* files have been installed, use one of the following:

pacman-contrib provides the simple pacdiff(8) tool for managing .pac* files.

It will search for .pacnew, .pacsave and .pacorig files, and will then prompt to take action upon them.

It uses --pacmandb by default, to search using the backup array information from currently installed packages. If this is not sufficient for your use case, you can specify --find or --locate instead, for a more thorough search.

It uses vimdiff by default, but you may specify a different tool with DIFFPROG=your_editor pacdiff. See List of applications/Utilities#Comparison, diff, merge for other common comparison tools.

A few third-party utilities providing various levels of automation for these tasks are available:

**Examples:**

Example 1 (unknown):
```unknown
pacman -Syu
```

Example 2 (unknown):
```unknown
warning: /etc/pam.d/usermod installed as /etc/pam.d/usermod.pacnew
```

Example 3 (unknown):
```unknown
warning: /etc/pam.d/usermod saved as /etc/pam.d/usermod.pacsave
```

Example 4 (unknown):
```unknown
backup=(etc/pulse/{daemon.conf,default.pa,system.pa})
```

---

## Package Maintainers

**URL:** https://wiki.archlinux.org/title/Package_maintainer

**Contents:**
- How do I become a Package Maintainer?
- Active Package Maintainers
- Past Package Maintainers

Package Maintainers (previously called Trusted Users) are an official Arch Linux staff role. Package Maintainers fulfill the following tasks:

The generic term "package maintainer" is also used to describe any person maintaining a package, regardless of the repository, as described in Arch terminology#Package maintainer.

The minimum requirements to becoming a Package Maintainer are as follows:

Even though you could become a Package Maintainer by merely fulfilling those minimum requirements, the people judging you during the standard voting procedure might expect more from you. Such as:

If you still feel up to becoming a Package Maintainer after reading these lines, the first step is to find two Package Maintainers who agree to sponsor you. Once sponsored, you should write a witty application signed with your GPG key to the aur-general mailing list.

For more information, see the Package Maintainer Bylaws and Package Maintainer guidelines.

See https://archlinux.org/people/package-maintainers/

See https://archlinux.org/people/package-maintainer-fellows/

---

## Package Maintainers

**URL:** https://wiki.archlinux.org/title/Package_Maintainer

**Contents:**
- How do I become a Package Maintainer?
- Active Package Maintainers
- Past Package Maintainers

Package Maintainers (previously called Trusted Users) are an official Arch Linux staff role. Package Maintainers fulfill the following tasks:

The generic term "package maintainer" is also used to describe any person maintaining a package, regardless of the repository, as described in Arch terminology#Package maintainer.

The minimum requirements to becoming a Package Maintainer are as follows:

Even though you could become a Package Maintainer by merely fulfilling those minimum requirements, the people judging you during the standard voting procedure might expect more from you. Such as:

If you still feel up to becoming a Package Maintainer after reading these lines, the first step is to find two Package Maintainers who agree to sponsor you. Once sponsored, you should write a witty application signed with your GPG key to the aur-general mailing list.

For more information, see the Package Maintainer Bylaws and Package Maintainer guidelines.

See https://archlinux.org/people/package-maintainers/

See https://archlinux.org/people/package-maintainer-fellows/

---

## VCS package guidelines

**URL:** https://wiki.archlinux.org/title/VCS_PKGBUILD_Guidelines

**Contents:**
- Package naming
- Versioning
- Conflicts and dependencies
- Authentication and security
- VCS sources
- The pkgver() function
  - Bazaar
  - Git
  - Mercurial
  - Subversion

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

Version control systems can be used for retrieval of source code for usual statically versioned packages, and the latest (trunk) version of a development branch.

Suffix pkgname with -bzr, -cvs, -darcs, -git, -hg, -svn, etc., unless the package fetches a specific release.

If the resulting package is different after changing e.g. the dependencies, URL or sources — update pkgver to the latest version. If pkgver has not changed since the last update to the PKGBUILD, increase pkgrel instead.

It is recommended to have following version format: RELEASE.rREVISION, where REVISION is a monotonically increasing number that uniquely identifies the source tree (VCS revisions do this). If there are no public releases and no repository tags then zero could be used as a release number or you can drop RELEASE completely and use version number that looks like rREVISION. If there are public releases but repository has no tags then the developer should get the release version somehow e.g. by parsing the project files.

The revision number delimiter — r right before REVISION — is important. This delimiter allows to avoid problems in case if upstream decides to make its first release or uses versions with different number of components. E.g. if at revision 455 upstream decides to release version 0.1, then the revision delimiter preserves version monotonicity: 0.1.r456 > r454. Without the delimiter monotonicity fails: 0.1.456 < 454.

The VCS sources should be specified in the source array and will be treated like any other source. makepkg will clone/checkout/branch the repository into $SRCDEST — same as $startdir if not set in makepkg.conf(5), and copy it to $srcdir (in a specific way to each VCS). The local repository is left untouched, thus invalidating the need for a -build directory.

The general format of a source array is:

An example Git source array:

The pkgver autobump is now achieved via a dedicated pkgver() function. This allows for better control over the pkgver, and maintainers should favor a pkgver that makes sense. To use pkgver(), you still need to declare the pkgver variable with the most recent value. makepkg will invoke function pkgver(), and update variable pkgver accordingly.

Using the most recent annotated tag reachable from the last commit:

Using the most recent un-annotated tag reachable from the last commit:

In case if the git-tag(1) does not contain dashes then one can use simpler sed(1) expression sed 's/-/.r/;s/-/./'.

If tag contains a prefix, like v or project name then it should be cut off:

If there are no tags then use number of revisions since beginning of the history:

Version and only commit/revision number (SHA-1 omitted; however, without a SHA-1 quick referencing of an exact revision is lost if not mindful of versioning):

Both methods can also be combined, to support repositories that start without a tag but get tagged later on (uses a bashism):

In case no satisfactory pkgver can be extracted from the repository, the current date(1) can be used:

Git submodules are a little tricky to do. The idea is to add the URLs of the submodules themselves directly to the sources array and then reference them during prepare().

Downstream project developers may not name their submodule as the same name as the upstream module's repository. To view the name of the Git submodules, go to the .gitmodules file in the project's repository and preview it. For example, a repository named lib-dependency by the upstream developers may be registered as a submodule named libs/libdep in .gitmodules downstream.

Git LFS needs a bit of extra setup:

This also works when the LFS is used in submodules:

When referencing stable git tags or specific commits as a source via git+https://domain.invalid/repository.git#tag=v1.0.0, it is possible to specify their checksum in the PKGBUILD. To do so, simply use makepkg -g or updpkgsums to generate them as you would for any other non-git source.

**Examples:**

Example 1 (unknown):
```unknown
/usr/share/pacman/PKGBUILD-vcs.proto
```

Example 2 (unknown):
```unknown
RELEASE.rREVISION
```

Example 3 (unknown):
```unknown
0.1.r456 > r454
```

Example 4 (unknown):
```unknown
0.1.456 < 454
```

---

## OCaml package guidelines

**URL:** https://wiki.archlinux.org/title/OCaml_package_guidelines

**Contents:**
- Package naming
- File placement
  - Libraries
  - OASIS
- OCaml bytecode and levels
- Example PKGBUILD using Dune
- Example PKGBUILD using plain findlib

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

Writing PKGBUILDs for software written in OCaml.

For libraries, use ocaml-modulename. For applications, use the program name. In either case, the name should be entirely lowercase.

OCaml libraries should be installed under /usr/lib/ocaml. Installation in /usr/lib/ocaml/site-lib is deprecated.

OCaml libraries should be installed using ocaml-findlib. ocaml-findlib includes library metadata in the package that makes it easy to manage libraries. It is a de-facto standard and a lot of OCaml software now requires it.

ocaml-findlib extracts necessary data from a file named META that should be included in the source archive. If this file is not included, one should either be obtained from the corresponding Debian, Ubuntu, or Fedora package, or created for the package by the maintainer. A request to include the file should also be made to the upstream developers of the package.

The OCAMLFIND_DESTDIR variable should be used when installing packages with ocaml-findlib. See the example PKGBUILD below for details.

OCaml packages that install executables using OASIS ignore DESTDIR. This is a known limitation of OASIS (issue #493). One way to enable DESTDIR-like functionality is to run the configure script with the --destdir argument, like so:

OCaml can run code on multiple "levels", the top level interprets OCaml Code without compiling, the bytecode level creates machine independent bytecode and the native level creates machine code binaries (just like C/C++).

When building OCaml Packages you need to be aware if the build process is compiling native machine code, bytecode, or as in many cases both. This creates a number of situations which can cause problems with package options and the right dependencies.

If bytecode is produced at all then the PKGBUILD must contain the following to protect the bytecode:

If the package does not contain bytecode and only distributes a binary, then ocaml is not needed as a dependency, but it of course is required as a makedepends since the ocaml package provides the OCaml compiler. If the package contains both native code and bytecode then ocaml should be a dependency and a makedepends.

OCaml code is rarely (if ever) distributed as bytecode only and will almost always include native code: the only case where using any as the arch is advisable is when only un-compiled source code is distributed, usually with a library, though many libraries still distribute native code.

The moral of the story here is to be aware of what it is you are distributing, chances are your package contains both native machine code and bytecode.

Dune is a new build system that is becoming more and more used by OCaml projects.

One thing to be aware is that a single project can build several "packages" in the OPAM/findlib sense, each with its own directory in /usr/lib/ocaml/. See ocaml-cairo for an example. For release builds, all "packages" have to be explicitly listed.

Keep in mind that many OCaml Packages will often need extra parameters passed to make and make install. Also remember to remove the !strip option and change the architecture if the package does not produce bytecode.

**Examples:**

Example 1 (unknown):
```unknown
ocaml-modulename
```

Example 2 (unknown):
```unknown
/usr/lib/ocaml
```

Example 3 (unknown):
```unknown
/usr/lib/ocaml/site-lib
```

Example 4 (unknown):
```unknown
ocaml-findlib
```

---

## DeveloperWiki:UID / GID Database

**URL:** https://wiki.archlinux.org/title/DeveloperWiki:UID_/_GID_Database

**Contents:**
- Users
- Groups

This is intended to be a starting point for creating standard uid and gid numbers.

I really think this should be moved directly into arch at some point and just have a keyword in PKGBUILD like

and if they did not exist they would be created according to this database by makepkg when building or by pacman when installing.

Actually, for this to work, we will need to add the primary and secondary groups to the database as well.

This article or section is out of date.

**Examples:**

Example 1 (unknown):
```unknown
require_user('user1' 'user2')
require_group('group1')
```

---

## ntop

**URL:** https://wiki.archlinux.org/title/Ntop

**Contents:**
- Installation and configuration
- Tips and tricks
  - Web interface
  - Group and user
- Troubleshooting
  - **ERROR** RRD: Disabled - unable to create base directory (err 13, /var/lib/ntop/rrd)
  - Please enable make sure that the ntop html/ directory is properly installed

This article or section is a candidate for moving to ntopng.

ntop is a network traffic probe based on libpcap, that offers RMON-like network traffic statistics accessible via a web browser.

ntop's final release was in 2012 and is currently unmaintained. It has been succeeded by ntopng (ntopngAUR).

Install the ntopAUR package. The first run of ntop, you must set the admin password:

The factual accuracy of this article or section is disputed.

Next, you need to edit the configuration file (/etc/conf.d/ntop) to adapt on your needs. Below is an example configuration, with the focus on the host to get as much as information from the hosts connections:

Before starting and possibly enabling the ntop service, you may have to edit its ntop command options:

To access ntop's web interface, enter http://127.0.0.1:3000/ into your web browser. To make changes to the server, you will need to enter your username (default = admin) and password.

If ntop is not just used locally on your machine, but network wide by multiple users, you would be better off by allowing SSL connections (https) only.

On firefox, the self-signed certificat should be a problem. Page will not be shown like that.

Additional paramethers are allowed. Now direct our browser to https://127.0.0.1:4223/.

You can also provide ntop with your own SSL certificate. Simply put it in ntop's configuration directory and name it ntop-cert.pem

Instead of make a self-signed certificat who will make your page unable to print on firefox, you should look at letsencrypt service. This service will make a free well recognized certificat for your domain. Then you will have to copy privkey.pem and fullchain.pem inside ntop-cert.pem:

you can also copy your private key in the same place.

In order for the -u parameter to work properly and to make your ntop setup a bit more secure, you should create your own group and user for it.

Directory /var/lib/ntop/rrd/ may not exist. Create it and make sure it belongs to user nobody.

If you receive this warning while trying to access the web interface, edit /etc/conf.d/ntop to include your IP and restart the daemon. For example:

This is the IP you will use to access the web interface.

**Examples:**

Example 1 (unknown):
```unknown
/etc/conf.d/ntop
```

Example 2 (unknown):
```unknown
/etc/conf.d/ntop
```

Example 3 (unknown):
```unknown
/etc/conf.d/ntop
```

Example 4 (unknown):
```unknown
# Parameters to be passed to ntop.
NTOP_ARGS="-K -W 2323 -i enp1s0,wlp2s0 -M -s -4 -6 -s -u ntop -c -r 30 --w3c -t 3 -a /var/log/ntop/http.log -O /var/log/ntop/ -q --skip-version-check 0"

# Location of the log file.
NTOP_LOG="/var/log/ntop/ntop.log"
```

---

## Trinity

**URL:** https://wiki.archlinux.org/title/TDE

**Contents:**
- Installation
  - Binary packages
  - Build from source
- Starting
  - Manually
  - Graphically
- Tips and tricks
  - Trinity "Kicker" panel with other desktop environments
- Troubleshooting
  - TDE Display Manager

From the Trinity Desktop Environment (TDE) project page:

TDE depends on End of Life libraries like Qt 3, which they maintain themselves.

The Trinity applications and applets should also work with other desktop environments.

Install either the tde-tdebase package from the trinity repository for a base Trinity environment, or tde-meta for a more complete one.

If you have any errors during an upgrade, add the 0x8685AD8B key by following pacman/Package signing#Adding unofficial keys.

Trinity Packaging repository contains PKGBUILD files for most Trinity packages in the "arch" folder.

The sources are in a git repository. More info on cloning it is at their GIT information page.

The suggested build order is specified in the How to Build TDE page.

To start Trinity from the Linux console:

tde-tdebase comes with TDE Display Manager. To start it at boot, enable the tdm.service.

To use the Trinity "kicker" Desktop Panel and Applets with another desktop environment, create this script and make it executable. For Plasma5, use System Settings > Startup and Shutdown > Autostart > Add Script.

If you encounter any issues, the default.target may have to be manually configured. See Display manager#Loading the display manager for resolution.

**Examples:**

Example 1 (unknown):
```unknown
$ startx /opt/trinity/bin/starttde
```

Example 2 (unknown):
```unknown
tdm.service
```

Example 3 (unknown):
```unknown
#!/bin/bash
/opt/trinity/bin/tdeinit
/opt/trinity/bin/kicker
/opt/trinity/bin/tdebuildsycoca --noincremental
```

Example 4 (unknown):
```unknown
default.target
```

---

## TrackPoint

**URL:** https://wiki.archlinux.org/title/TrackPoint

**Contents:**
- GUI configuration
- Middle button scroll
  - Xorg configuration
  - Two-button trackpoints
- Sysfs attributes
  - Configuration at boot
    - udev rule
    - systemd.path unit
    - udev hwdb entry
    - device-quirks

The TrackPoint is Lenovo's trademark for the pointing stick in the middle of the keyboard. It is supported by xf86-input-evdev and xf86-input-libinput.

Default Xorg behavior supports click and point. For the evdev driver middle-click and scrolling requires extra configuration.

Install the gpointing-device-settingsAUR package.

When using xf86-input-libinput, middle-button scrolling is enabled by default.

When using xf86-input-evdev, middle-button scrolling is supported via xinput from the xorg-xinput package. For example:

Alternative to an ~/.xinitrc configuration, you can also create an Xorg#Configuration for the evdev(4)driver. For example, as /etc/X11/xorg.conf.d/20-thinkpad.conf, replacing TPPS/2 IBM TrackPoint with the device name from xinput:

On two-button trackpoints, using xf86-input-libinput, the scroll button can be set to right-click button without removing functionality.

Replacing device with the device name from xinput:

TrackPoints expose their attributes as files in /sys/devices/platform/i8042/serio1/. For example, to manually enable the tap-to-click functionality:

This rule increases the trackpoint speed and enables tap to select (see above) on boot.

There have been reports on the forums that the attributes/files under /sys/devices/platform/i8042/serio1/serio2/ appear too late in the boot process for the above (or similar) udev rule(s) to have an effect on them. Instead, a systemd.path unit can be used to configure attributes of the TrackPoint.

First create an executable script named e.g. /usr/local/bin/trackpoint_configuration.sh that sets the TrackPoint attributes as shown in the #Sysfs attributes section.

The following example disables the trackpoint in some laptops, leaving the trackpoint left and right buttons (the ones over the touchpad) keep working just fine (however, if one disables the TrackPoint directly from the UEFI/BIOS settings, right and left trackpoint buttons will necessarily be disabled).

Afterwards, create the following systemd units. Make sure that all attributes modified by the script are listed with PathExists.

Finally, enable and start the trackpoint_parameters.path systemd unit.

This article or section is out of date.

Libinput applies its own parameters to sysfs based on entries in the udev hardware database. This is the behavior on systems running a Wayland compositor, as libinput is the only supported input interface in that environment. Changes made prior to the start of a Wayland compositor or X session will be overwritten.

To override libinput's default settings, add a local hwdb entry:

You can find various vendor/model keys in the udev hardware database. Note that since this commit libinput ignores the POINTINGSTICK_CONST_ACCEL parameter and uses POINTINGSTICK_SENSITIVITY. The range is 0-255.

Update the hardware database index, then to test the changes prior to restarting your compositor or X session, first find your device input node /dev/input/eventX using:

Run the following to generate some debug output:

Finally, restart your Wayland compositor or X session to apply the changes.

With the libinput switch to the new device-quirks .ini-style configuration files, you can adjust trackpoint parameters via local overrides in /etc/libinput/.

For example, to override the pointing speed, create the following file:

For more information, see libinput: Installing temporary local device quirks

This appears to be a kernel bug.[1]

A workaround is passing proto=bare to the psmouse module as a kernel module parameter. However, this disables scrolling with the clickpad and the two-finger middle click.

For some ThinkPad models with Elantech touchpad the Trackpoint and the corresponding hardware buttons do not get recognized. The above mentioned command does work but disables the two finger scrolling on the touchpad. To keep two finger interactions possible, use the following kernel module parameter:

If you discover that disabling the touchpad in the BIOS disables the wrong buttons and/or that the trackpoint buttons are very unreliable a workaround is to pass proto=imps to the psmouse module as a kernel module parameter.

On some laptops, psmouse seems to fail on start up, or after suspend:

One workaround is to use add synaptics_intertouch=0 to psmouse as a kernel module parameter.

On some ThinkPads the TrackPoint cursor moves spontaneously after release and it does not stop. This happens because of a low value of the drift_time parameter (e.g. 5), you need to change it to 25 or 30 to fix the problem. This can be done with a udev rule:

If this method does not fix your issue, change the psmouse protocol to bare (i.e. add psmouse.proto=bare to your kernel parameters). This way the trackpoint will be identified as a "PS/2 Generic Mouse" instead of using the dedicated kernel driver.

If you do not need the cursor, you can use a libinput quirks override to disable cursor events. Button events will continue to work.

Clicking the middle mouse button pastes from the PRIMARY selection by default, which is an inconvenience when using the middle mouse button to scroll with the TrackPoint. See Clipboard#Disabling middle-click paste to disable this behavior.

**Examples:**

Example 1 (unknown):
```unknown
xinput set-prop "TPPS/2 IBM TrackPoint" "Evdev Wheel Emulation" 1
xinput set-prop "TPPS/2 IBM TrackPoint" "Evdev Wheel Emulation Button" 2
xinput set-prop "TPPS/2 IBM TrackPoint" "Evdev Wheel Emulation Timeout" 200
xinput set-prop "TPPS/2 IBM TrackPoint" "Evdev Wheel Emulation Axes" 6 7 4 5
```

Example 2 (unknown):
```unknown
xinput --list
```

Example 3 (unknown):
```unknown
"Device Accel Constant Deceleration"
```

Example 4 (unknown):
```unknown
/etc/X11/xorg.conf.d/20-thinkpad.conf
```

---

## Arch terminology

**URL:** https://wiki.archlinux.org/title/Packager

**Contents:**
- ABS
- Arch Linux
- Arch Linux Archive
- ArchWiki
- AUR
- BBS
- core
- Custom repository
- Developer
- extra

This page is intended to be a page to demystify common terms used among the Arch Linux community.

ABS stands for Arch build system.

Arch should be referred to as:

Archlinux, ArchLinux, archLinux, aRcHlInUx, etc. are all weird, and weirder mutations.

Officially, the "Arch" in "Arch Linux" is pronounced /ɑːrtʃ/ as in an "archer" (bowman) or "archnemesis", and not as in "ark" or "archangel".

The Arch Linux Archive (a.k.a. ALA), formerly known as Arch Linux Rollback Machine (a.k.a. ARM), stores official repositories snapshots, ISO images and bootstrap tarballs across time.

ArchWiki is a place to find documentation about Arch Linux. Anyone can contribute to the wiki.

The Arch User Repository (AUR) is a community-driven repository for Arch users. It contains package descriptions—PKGBUILDs—that allow you to build a package from source with makepkg and then install it via pacman. The AUR was created to organize and share new packages from the community and to help expedite popular packages' inclusion into the extra repository.

A good number of new packages that enter the official repositories start in the AUR. In the AUR, users are able to contribute their own package builds—PKGBUILD—and related files. The AUR community has the ability to vote for packages in the AUR. If a package becomes popular enough—provided it has a compatible license and good packaging technique—it may be entered into the extra repository (directly accessible by pacman or the ABS).

You can access the Arch Linux User Community Repository at https://aur.archlinux.org.

Bulletin board system, but in Arch's case, it is just the support forum.

The core repository contains the bare packages needed for an Arch Linux system. core has everything needed to get a working command-line system.

Anyone can create a custom local repository and put it online for other users. To create a repository, you need a set of packages and a pacman-compatible database file for your packages. Host your files online and everyone will be able to use your repository by adding it as a regular repository.

Half-gods working to improve Arch for no financial gain. Developers are outranked only by our gods, Judd Vinet and Aaron Griffin, who in turn are outranked by tacos.

Arch core package set is fairly streamlined, but we supplement this with a larger, more complete extra repository. This repository is constantly growing with the help of packages submitted from our strong community.

This is where GUI tools—such as desktop environments and window managers—and common programs are found.

See Arch boot process#initramfs.

KISS principle (Keep It Simple, Stupid)—simplicity is a main principle Arch Linux tries to achieve.

makepkg will build packages for you. makepkg will read the metadata required from a PKGBUILD file. All it needs is a build-capable Linux platform, curl, and some build scripts. The advantage to a script-based build is that you only really do the work once. Once you have the build script for a package, you just need to run makepkg and it will do the rest: download and validate source files, check dependencies, configure the build time settings, build the package, install the package into a temporary root, make customization, generate meta-info, and package the whole thing up for pacman to use.

namcap is a package analysis utility that looks for problems with Arch Linux packages or their PKGBUILD files. It can apply rules to the file list, the files themselves, or individual PKGBUILD files.

See pacman#Installing packages.

The role of a package maintainer is to update packages as new versions become available upstream, and to field support questions relating to bugs in said packages. The term applies to:

The maintainer of a package is the person currently responsible for the package. Previous maintainers should be listed as contributors in the PKGBUILD along with others who have contributed to the package.

PKGBUILDs are small Bash scripts that are used to build Arch Linux packages. See Creating packages for more detail.

A repository—informally referred as "repo"—has the pre-built packages of PKGBUILDs.

Official repositories are split into different parts for easy maintenance.

Pacman uses repositories to search for packages and install them.

A repository can be local (i.e. on your own computer) or remote (i.e. the packages are downloaded before they are installed).

See also #Custom repository.

RTFM (Read The Friendly Manual)—this simple message is replied to some newcomers who ask about the functionality of a program when it is clearly defined in a program's manual.

This acronym is an invitation to self-care, not an insult. It is often used when a user is seen as failing to make any attempt to find a solution to the problem themselves. If someone tells you this, they are not trying to offend you—they are just feeling frustrated with a perceived lack of effort.

The best thing to do if you are told to do this is to read the manual page.

If you do not find the answer to your question in the program manual, there are more ways to find the answer. You can:

They are the repositories where major package updates are kept prior to release into the main repositories, so they can be bug tested and upgrade issues can be found. They are disabled by default but can be enabled in /etc/pacman.conf.

The unofficial term traditionally used to refer to the main Arch Linux principles.

Trusted User (TU) is the old name for the package maintainer role.

The same as Custom repository.

The same as ArchWiki.

**Examples:**

Example 1 (unknown):
```unknown
man program_name
```

Example 2 (unknown):
```unknown
/etc/pacman.conf
```

---

## Nessus

**URL:** https://wiki.archlinux.org/title/Nessus

**Contents:**
- Installation
- Usage
- License
- Plugins update
- Removal
- See also

Nessus is a proprietary vulnerability scanner available free of charge for personal use. There are over 40,000 plugins covering a large range of both local and remote flaws.

Install the nessusAUR package.

Start/enable nessusd.service.

Access the web interface at https://localhost:8834 and/or use the commandline interface (/opt/nessus/sbin/nessuscli). In most browsers, you will need to manually accept the SSL certificate you created for the server.

Register your email at the tenable site and wait for your key to be emailed to you.

Stop nessusd.service before doing anything with nessuscli.

Activate the license:

View your current license activation code:

Stop nessusd.service before doing anything with nessuscli.

The package can be removed with pacman, but files created by Nessus, such as the plugin database it downloads, must be removed manually:

**Examples:**

Example 1 (unknown):
```unknown
nessusd.service
```

Example 2 (unknown):
```unknown
/opt/nessus/sbin/nessuscli
```

Example 3 (unknown):
```unknown
nessusd.service
```

Example 4 (unknown):
```unknown
# nessuscli fetch --register Activation Code
```

---

## Unofficial mirrors

**URL:** https://wiki.archlinux.org/title/Unofficial_mirrors

**Contents:**
- Up to date
  - Worldwide
  - Belgium
  - China
  - Finland
  - France
  - Japan
  - Netherlands
  - New Zealand
  - Russia

These mirrors are not listed by default in /etc/pacman.d/mirrorlist, therefore not distributed within pacman-mirrorlist.

Up to date mirrors have the latest packages, and remain synchronised with the official arch repositories. These mirrors can be used like any official mirror distributed by pacman-mirrorlist.

Out of date mirrors do not have the latest packages, these are either no longer maintained, or designed to distribute older packages which are no longer available within the official mirrors.

**Examples:**

Example 1 (unknown):
```unknown
/etc/pacman.d/mirrorlist
```

Example 2 (unknown):
```unknown
$repo/os/$arch
```

Example 3 (unknown):
```unknown
/etc/pacman.d/mirrorlist
```

---

## spectrwm

**URL:** https://wiki.archlinux.org/title/Spectrwm

**Contents:**
- Installation
- Starting
- Configuration
  - Keybindings
  - Multiple monitors (Xinerama)
  - Statusbar
    - Bash scripts
    - Conky
  - Alternative status bar
- Screenshots

From spectrwm website:

Spectrwm is written in C and configured with a text configuration file. It was previously known as scrotwm.

Install the spectrwmAUR package.

Run spectrwm with xinit.

spectrwm looks for the user configuration file in ~/.config/spectrwm/spectrwm.conf and ~/.spectrwm.conf. If none of these exist it opens the global configuration file at /etc/spectrwm.conf. It also supports the XDG Base Directory paths.

Optionally, spectrwm can call baraction.sh (in the user's path), which should output a text status message to stdout for the status bar.

The modkey (the main key to issue commands with) is set to Mod4, which is usually the Super key.

There is also a screen lock key binding, which by default calls xlock from the xlockmore package.

xscreensaver is also useful for screen saving and power management after an idle period and screen locking.

See Xdefaults for details of how to set up fonts, colours and other settings for xterm and xscreensaver. Run xscreensaver-demo to select the animation (or blank) and display power management (recommended).

Default keybindings are in /etc/spectrwm/spectrwm_<<keyboard layout>>.conf. In order to customize keybindings:

With a non-Xrandr multiple monitor setup create regions to split the total desktop area into one region per monitor:

To enable the statusbar, uncomment these two items in /etc/spectrwm.conf (or ~/.spectrwm.conf). By default they are commented out and the statusbar is disabled.

To test the status bar, place the following simple baraction.sh in a ~/scripts (or ~/bin) directory which you have previously added to your $PATH in your ~/.bashrc file.

Press Modkey+Q to restart spectrwm and after a few seconds you should see the output in the status bar. If you have problems at this stage, make sure the script is executable, test it from the command line, and check the path/filename you specified in bar_action.

Here are some other ideas for status bar items: ethernet, email notification, disk space, mounts, now playing (mpc current).

The script may also show the date, in which case the built-in clock can be disabled:

Instead of a bash script, Conky may be used. It should be used in non-graphical mode as shown below to output a text string to stdout which can be read in by spectrwm. First install conky. It is not necessary to install the cut-down conky-cliAUR (although that would work too).

In ~/.spectrwm.conf set

Then in each user's ~/.conkyrc file place for example:

An alternative is to use dzen2 to create a status bar. This has the advantage that colors and even icons may be used, but the disadvantage that the bar is not integrated with spectrwm. So the current workspace number and layout and the bar-toggle keybinding are not available. The "region" option can be used to reserve the required screen space.

For example to reserve 14 pixels at the top of the screen:

(adjust for your screen resolution).

Then, for example using i3status to supply the information:

Spectrwm's own bar can still be enabled and disabled with Meta+b.

Spectrwm has the facility to execute a script called screenshot.sh with the keybindings

First install scrot, then copy the default script supplied in the spectrwm package to a location in your $PATH, for example:

By default the lock keybinding Mod+Shift+Delete executes xlock

An alternative, if xscreensaver is already running, is to use

Some of the most useful key bindings to be used with Meta:

Advanced stacking (still accompanying Meta):

Other useful bindings (accompanying Meta):

Press Shift+Super+Enter and an xterm will start. See the manual for other default key bindings. Also check your configuration file.

Currently the PID of window is used to determine the desktop for new windows. To workaround this with terminals for example, you can often pass an argument to open the terminal in a new process.

Make sure all the dependencies such as xlockmore are installed.

You may also use Xephyr against your xinitrc within another xsession to troubleshoot.

**Examples:**

Example 1 (unknown):
```unknown
~/.config/spectrwm/spectrwm.conf
```

Example 2 (unknown):
```unknown
~/.spectrwm.conf
```

Example 3 (unknown):
```unknown
/etc/spectrwm.conf
```

Example 4 (unknown):
```unknown
baraction.sh
```

---

## Creating packages for other distributions

**URL:** https://wiki.archlinux.org/title/Creating_packages_for_other_distributions

**Contents:**
- General
- Alpine
- Debian
  - Tips and Tricks about Debian
    - Override dependency handling
    - Set up a chroot
  - See also about Debian
- Fedora
  - See also about Fedora
- openSUSE

Arch is the best. But you may still want to package for other distributions.

The Debian Packaging Tutorial explains the groundwork. It describes use of the following tools:

This article or section needs expansion.

dpkg does not recognize dependencies installed by pacman. This means dpkg-buildpackage will generally fail with errors such as:

To override this, use the -d flag:

You may also need to override dh_shlibdeps by adding the following lines to debian/rules:

See the Pbuilder How-To for an introduction to pbuilder-ubuntu. Using cowdancer in addition is recommended as copy-on-write offers a significant performance benefit.

This article or section needs expansion.

Fedora Packaging Tutorial

The Open Build Service (OBS) is a generic system to build and distribute packages from sources in an automatic, consistent and reproducible way. It supports at least .deb, .rpm and Arch packages.

Now it is time to decide how we will manage our project. There are two practical ways to do this:

The first version is more flexible and dynamic. To proceed:

Here is an example for gimp-gitAUR:

Now, after a while, OBS will begin building your package.

This article or section is out of date.

If OBS build fails because of the ca-certificates-utils package, you can add this line to your project config (from your project page, go to Advanced -> Project Config).

Some tools such as Pacur allow building packages for multiple Linux distributions with a consistent package specification format. The package format is very similar to PKGBUILD so it is easy to re-use an existing PKGBUILD and add a few distribution-specific variables to be able to build debian and rpm packages effortlessly. By quickly adapting a PKGBUILD one is able to build package for Amazon Linux, Centos, Debian, Oracle Linux, Fedora and Ubuntu.

**Examples:**

Example 1 (unknown):
```unknown
dpkg-buildpackage
```

Example 2 (unknown):
```unknown
dpkg-checkbuilddeps: Unmet build dependencies: build-essential:native debhelper (>= 8.0.0)
dpkg-buildpackage: warning: build dependencies/conflicts unsatisfied; aborting
```

Example 3 (unknown):
```unknown
$ dpkg-buildpackage -d -us -uc
```

Example 4 (unknown):
```unknown
dh_shlibdeps
```

---

## Kernel/Arch build system

**URL:** https://wiki.archlinux.org/title/Kernel/Arch_build_system

**Contents:**
- Getting the ingredients
- Modifying the PKGBUILD
  - Avoid creating the doc
  - Changing prepare()
  - Generate new checksums
- Compiling
- Installing
- Boot loader
- Updating
  - Cleanup

The Arch build system can be used to build a custom kernel based on the official linux package. This compilation method can automate the entire process, and is based on a very well tested package. You can edit the PKGBUILD to use a custom kernel configuration or add additional patches.

Since you will be using makepkg, follow the best practices outlined there first. For example, you cannot run makepkg as the root user. Therefore, create a build directory in your user home first.

Install the devtools and base-devel package.

You need a clean kernel to start your customization from. Retrieve PKGBUILD source and few other files into your build directory by running:

At this point, the directory tree looks like (there may be a few other files):

Then, get any other file you need (e.g. custom configuration files, patches, etc.) from the respective sources.

Edit PKGBUILD and look for the pkgbase parameter. Change this to your custom package name, e.g.:

A large portion of the lengthy compiling effort is devoted to creating the documentation. To avoid creating the documents:

In prepare() function, you can apply needed kernel patches or change kernel build configuration. Since 2018-08-01, the PKGBUILD automatically applies all *.patch files in source.

If you need to change a few configuration options you can edit config in the source.

Or you can use a GUI tool to tweak the options. Comment make olddefconfig in the prepare() function of the PKGBUILD, and add your favorite tool (run make help to list all of the possible configuration targets):

#Changing prepare() suggests a possible modification to $_srcname/.config. Since this path is not where downloading the package files ended, its checksum was not checked by makepkg (which actually checked $_srcname/../../config).

If you replaced the downloaded config with another one before running makepkg, install the pacman-contrib package and generate new checksums by running:

You can now proceed to compile your kernel by the usual command makepkg.

If you have chosen an interactive program for configuring the kernel parameters (like menuconfig), you need to be there during the compilation.

The -s parameter will download any additional dependencies used by recent kernels such as xml and docs.

The compile step will leave two packages in the ~/build/linux folder, one for the kernel and one for the kernel headers. They might have names like:

Best practice is to install both packages together as they might be both needed (e.g. DKMS):

(substitute the actual names of the files you have in the folder)

If you have modified pkgbase in order to have your new kernel installed alongside the default kernel you will need to update your boot loader configuration file and add new entries ('default' and 'fallback') for your custom kernel and the associated initramfs images.

This article or section is out of date.

Assuming one has an arch kernel source that they want to update, one method to do that is with https://github.com/archlinux/linux. In what follows, the top kernel source directory is assumed at ~/build/linux/.

In general, arch sets an arch kernel source with two local git repositories. The one at archlinux-linux/ is a local bare git repository pointing to https://github.com/archlinux/linux.git. The other one is at src/archlinux-linux/, pulling from the bare repository. Possible local patches, and building, are expected at src/archlinux-linux/.

For this example, the HEAD of the locally installed bare git repository source at archlinux-linux/ was initially pointing to

which is somewhere between v5.2.5-arch1 and v5.2.6-arch1.

One can see it fetched v5.2.7-arch1, which was the newest archlinux tag, because it prints what new tags were obtained. If no new tags were obtained then there is no newer archlinux source available.

Now the source can be updated where the actual build will take place.

You can verify you are on track with something like

This shows few specific archlinux patches between Arch Linux kernel v5.2.7-arch1 and Linux 5.2.7.

The up to date PKGBUILD, as well archlinux kernel configuration file, can be pulled in using git in the package directory:

Now you should merge files located in ~/build/linux/linux/* into ~/build/linux/. Merging can also done manually, or with specific utilities. Review #Changing prepare(), and run manually most, if not all, the shell commands of PKGBUILD::prepare().

At this point, makepkg --verifysource should succeed. While #Compiling, make sure to also add --noextract option to the makepkg command, since it should be able to build the packages as if the source was extracted by makepkg --nobuild. And you are back to #Installing.

One will probably want to remove ~/build/linux/linux/ after merging. In addition, ~/build/linux/src/archlinux will accumulate branches in the form of 5.2.7-arch1 if more recent updates are done in this fashion. These can be deleted with

**Examples:**

Example 1 (unknown):
```unknown
$ mkdir ~/build/
$ cd ~/build/
```

Example 2 (unknown):
```unknown
$ pkgctl repo clone --protocol=https linux
```

Example 3 (unknown):
```unknown
~/build/linux/-+
               +--config
               \__PKGBUILD
```

Example 4 (unknown):
```unknown
pkgbase=linux-custom
```

---

## Dynamic Kernel Module Support

**URL:** https://wiki.archlinux.org/title/Dynamic_Kernel_Module_Support

**Contents:**
- Installation
- Upgrades
- Usage
  - List modules
  - Rebuild modules
  - Remove modules
- DKMS package creation
- See also

This means that a user does not have to wait for a company, project, or package maintainer to release a new version of the module. Since the introduction of pacman hooks, the rebuild of the modules is handled automatically when a kernel is upgraded.

Install the dkms package and the headers for the target kernel/kernels. For example, for the default linux kernel this would be linux-headers. Other kernels have their own respective headers packages.

A good number of modules that lie outside the kernel source tree have a DKMS variant; a few are hosted in the official repositories, most are found in the AUR.

Though the rebuild of the DKMS modules is usually seamless during a kernel upgrade, it may still happen that the rebuild fails. You should pay extra attention to the pacman output. This applies in particular if the system relies on the DKMS module to boot successfully and/or if you use DKMS with a custom kernel not in the official repositories.

To deal with changes in the kernel, fix bugs, or add necessary features consider upgrading the DKMS package before rebooting.

Usage for invoking DKMS manually.

Tab-completion is available by doing:

To list the current status of modules, versions and kernels within the tree:

Rebuild all modules for the currently running kernel:

or for a specific kernel:

To build a specific module for the currently running kernel:

To build a module for all kernels:

To remove a module (old ones are not automatically removed):

If the package dkms is removed the information regarding previous module build files is lost. If this is the case, go through /usr/lib/modules/kernel_release and /var/lib/dkms/package_name and delete all files and directories no longer in use.

See DKMS package guidelines.

**Examples:**

Example 1 (unknown):
```unknown
# source /usr/share/bash-completion/completions/dkms
```

Example 2 (unknown):
```unknown
# dkms status
```

Example 3 (unknown):
```unknown
# dkms autoinstall
```

Example 4 (unknown):
```unknown
# dkms autoinstall -k 3.16.4-1-ARCH
```

---

## Creating packages

**URL:** https://wiki.archlinux.org/title/Create_a_package

**Contents:**
- Overview
- Preparation
  - Prerequisite software
  - Download and test the installation
  - Set up clean chroot
- Creating a PKGBUILD
  - PKGBUILD variables
  - PKGBUILD functions
    - prepare()
    - pkgver()

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

This article aims to assist users creating their own packages using the ports–like Arch build system, also for submission in Arch User Repository. It covers creation of a PKGBUILD(5)—a package build description file sourced by makepkg to create a binary package from source.

For instructions regarding existing rules and ways to improve package quality, see Arch package guidelines.

Packages in Arch Linux are built using the makepkg utility and the information stored in a PKGBUILD file. When makepkg runs, it searches for a PKGBUILD in the current directory and follows the instructions in it to acquire the required files and/or compile them to be packed within a package file pkgname.pkg.tar.zst. The resulting package contains binary files and installation instructions ready to be installed by pacman.

An Arch package is no more than a tar(1) archive, or a tarball, compressed using zstd(1), which contains the following files generated by makepkg:

First, ensure that the necessary tools are installed: the meta package base-devel should be sufficient; it pulls in make(1) and additional tools needed for compiling from source.

The key tool for building packages is makepkg (provided by pacman). The tasks it performs can be found in Arch package guidelines#Makepkg duties.

Download the source tarball of the software you want to package, extract it, and follow the author's steps to install the program. Make a note of all commands and/or steps needed to compile and install it. You will be repeating those same commands in the PKGBUILD file.

Most software authors stick to the 3-step build cycle:

This is a good time to make sure the program is working correctly.

It is recommended to follow Building in a clean chroot to ensure that packages and configuration of your system do not lead to mistakes in the PKGBUILD. This is a more robust and correct way to build packages and will often catch missing dependencies that you did not realize were needed because they already existed in your system.

When makepkg is run, it looks for a PKGBUILD file in the current working directory. If it finds one, it downloads the software's source code and compiles it according to the instructions specified in the PKGBUILD file. The instructions must be fully interpretable by the Bash shell.

After successful completion, the resulting binaries and metadata of the package, i.e. package version and dependencies, are packed in a pkgname.pkg.tar.zst package file. The newly created package can be installed by simply using makepkg --install which will call pacman in the background, or by directly using pacman -U pkgname.pkg.tar.zst.

To start building a new package, first create a new directory for the package and change current directory into this one. Then, a PKGBUILD file needs to be created: a prototype PKGBUILD found in /usr/share/pacman/ can be used or you can start from a PKGBUILD from another package. The latter may be a good choice if a similar package already exists.

makepkg predefines the following variables that should be used by packagers to refer to temporary locations during the build process:

They contain absolute paths, which means you do not have to worry about your working directory if you use these variables properly.

When building a package, makepkg will invoke the following five functions if they have been defined in the PKGBUILD. Function package() is required in every PKGBUILD and will always be invoked. If any of the other functions is not defined, makepkg will simply skip the invocation of that function.

During the build, the functions are invoked in the order in which they are listed here.

Also see PKGBUILD(5) § PACKAGING FUNCTIONS.

With this function, commands that are used to prepare sources for building are run, such as patching. This function runs right after package extraction, before pkgver() and the build function. If extraction is skipped (makepkg --noextract), then prepare() is not run.

When it is not clear whether to put something in prepare() or build(), one rule of thumb is to put in prepare() the steps that should run exactly once after extracting the sources, and put in build() the steps which would make sense to re-run after any manual edits to the extracted files.

pkgver() runs after the sources are fetched, extracted and prepare() executed. So you can update the pkgver variable during a makepkg stage.

This is particularly useful if you are making git/svn/hg/etc. packages, where the build process may remain the same, but the source could be updated every day, even every hour. The old way of doing this was to put the date into the pkgver field which, if the software was not updated, makepkg would still rebuild it thinking the version had changed. Some useful commands for this are git describe, hg identify -ni, etc. Please test these before submitting a PKGBUILD, as a failure in the pkgver() function can stop a build in its tracks.

Now, you need to implement the build() function in the PKGBUILD file. This function uses common shell commands in Bash syntax to automatically compile software and create a directory called pkg to install the software to. This allows makepkg to package files without having to sift through your file system.

The first step in the build() function is to change into the directory created by uncompressing the source tarball. makepkg will change the current directory to $srcdir before executing the build() function. Therefore, in most cases, like suggested in /usr/share/pacman/PKGBUILD.proto, the first command will look like this:

Now, you need to list the same commands you used when you manually compiled the software. The build() function in essence automates everything you did by hand and compiles the software in the fakeroot build environment. If the software you are packaging uses a configure script, it is good practice to use --prefix=/usr when building packages for pacman. A lot of software installs files relative to the /usr/local directory, which should only be done if you are manually building from source. All Arch Linux packages should use the /usr directory. As seen in the /usr/share/pacman/PKGBUILD.proto file, the next two lines often look like this:

Place for calls to make check and similar testing routines. It is highly recommended to have check() as it helps to make sure software has been built correctly and works fine with its dependencies.

Users who do not need it (and occasionally maintainers who can not fix a package for this to pass) can disable it by adding !check into the options array in PKGBUILD/makepkg.conf(5) or call makepkg with --nocheck flag.

If you are testing a GUI application, you can run it in a virtual xserver.

The final step is to put the compiled files in a directory where makepkg can retrieve them to create a package. This by default is the pkg directory—a simple fakeroot environment. The pkg directory replicates the hierarchy of the root file system of the software's installation paths. If you have to manually place files under the root of your filesystem, you should install them in the pkg directory under the same directory structure. For example, if you want to install a file to /usr/bin, it should instead be placed under $pkgdir/usr/bin. Very few install procedures require the user to copy dozens of files manually. Instead, for most software, calling make install will do so. The final line should look like the following in order to correctly install the software in the pkg directory:

makepkg --repackage runs only the package() function, so it creates a package without building. This may save time e.g. if you have changed just the depends variable of the package.

As you are writing the build() function, you will want to test your changes frequently to ensure there are no bugs. You can do this using the makepkg command in the directory containing the PKGBUILD file. With a properly formatted PKGBUILD, makepkg will create a package; with a broken or unfinished PKGBUILD, it will raise an error.

If makepkg finishes successfully, it will place a file named pkgname-pkgver.pkg.tar.zst in your working directory. This package can be installed with the pacman -U command. However, just because a package file was built does not imply that it is fully functional. It might conceivably contain only the directory and no files whatsoever if, for example, a prefix was specified improperly. You can use pacman's query functions to display a list of files contained in the package with pacman -Qlp pkgname, and the dependencies it requires with pacman -Qip pkgname.

If the package looks sane, then you are done! However, if you plan on releasing the PKGBUILD file, it is imperative that you check and double-check the contents of the depends array.

Also ensure that the package binaries actually run flawlessly! It is annoying to release a package that contains all necessary files, but crashes because of some obscure configuration option that does not quite work well with the rest of the system. If you are only going to compile packages for your own system, though, you do not need to worry too much about this quality assurance step, as you are the only person suffering from mistakes, after all.

After testing package functionality, check it for errors using namcap:

Get into the habit of checking your packages with namcap to avoid having to fix the simplest mistakes after package submission.

This article or section is a candidate for merging with Arch build system#Build package.

You can use pkgctl from devtools to check if the package can be built where no other packages are already installed. While in the PKGBUILD directory:

And check the output for potential errors or warnings. If the package depends on other AUR packages, those packages must be built and brought into chroot jail:

Refer to pkgctl-build(1) for more options.

Please read AUR submission guidelines for a detailed description of the submission process.

The process of updating checksums for new software releases can be automated by the updpkgsums tool; see Makepkg#Generate new checksums for details.

PKGBUILDs for some packages can be generated automatically.

pkgctl (from the devtools package) supports nvchecker integration in the form of a .nvchecker.toml configuration file (which should be placed in the same directory as the PKGBUILD). See the pacman package's .nvchecker.toml configuration file for an example.

You can then use pkgctl version check to check if a new upstream version has been released (compared to the one specified as pkgver in the PKGBUILD) and pkgctl version upgrade to update the PKGBUILD accordingly. See pkgctl-version(1) for more details.

**Examples:**

Example 1 (unknown):
```unknown
pkgname.pkg.tar.zst
```

Example 2 (unknown):
```unknown
$ ./configure
$ make
# make install
```

Example 3 (unknown):
```unknown
pkgname.pkg.tar.zst
```

Example 4 (unknown):
```unknown
makepkg --install
```

---

## Python package guidelines

**URL:** https://wiki.archlinux.org/title/Python_package_guidelines

**Contents:**
- Package naming
- Architecture
- Source
- Installation methods
  - Standards based (PEP 517)
  - setuptools or distutils
- Check
- Tips and tricks
  - Using Python version
  - Using site-packages

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

This document covers standards and guidelines on writing PKGBUILDs for Python software.

For Python 3 library modules, use python-modulename. Also use the prefix if the package provides a program that is strongly coupled to the Python ecosystem (e.g. pip or tox). For other applications, use only the program name.

A Python package that contains C extensions is architecture-dependent. Otherwise it is most likely architecture-independent.

Packages built using setuptools define their C extensions using the ext_modules keyword in setup.py.

Download URLs linked from the PyPI website include an unpredictable hash that needs to be fetched from the PyPI website each time a package must be updated. This makes them unsuitable for use in a PKGBUILD. PyPI provides an alternative stable scheme: PKGBUILD#source source=() array should use the following URL templates:

Note that a custom _name variable is used instead of pkgname since Python packages are generally prefixed with python-. This variable can generically be defined as follows:

Python packages are generally installed using language-specific package manager such as pip, which fetches packages from an online repository (usually PyPI, the Python Package Index) and tracks the relevant files.

However, for managing Python packages from within PKGBUILDs, one needs to "install" the Python package to the temporary location $pkgdir/usr/lib/python<Python version>/site-packages/$pkgname.

For Python packages using standard metadata to specify their build backend in pyproject.toml, this can most easily achieved using python-build and python-installer. Old packages might fail to specify that they use setuptools, and only offer a setup.py that has to be invoked manually.

A standards based workflow is straightforward: Build a wheel using python-build and install it to $pkgdir using python-installer:

If no pyproject.toml can be found or it fails to contain a [build-system] table, it means the project is using the old legacy format, where the project provides a setup.py file, which invokes the setup function from setuptools or distutils.core.

Such packages usually can also be built and installed using the method described above using python-build and python-installer, and this is the preferred method. But they will also additionally need python-setuptools in makedepends.

You can still build and install these packages using the old, deprecated way of running setup.py directly, which is shown below and it is described here for those cases, where the pep-517 compliant way does not work for some reason.

But note that you will get the following warning in the output of the package step, when building a package using this method:

Also note that Python versions from 3.12 onwards do not include distutils in the standard library any more, which means that packages for projects still using setup.py generally need to have python-setuptools in makedepends, since that provides its own version of distutils.

If a package uses python-setuptools-scm, the package most likely will not build with an error such as:

To get it building SETUPTOOLS_SCM_PRETEND_VERSION has to be exported as an environment variable with $pkgver as the value:

Most Python projects providing a testsuite use the unittest runner or nosetests or pytest (provided by python and python-nose and python-pytest, respectively) to run tests with test in the name of the file or directory containing the testsuite. In general, simply running nosetests or pytest is enough to run the testsuite.

If there is a compiled C extension, the tests need to be run using a $PYTHONPATH, that reflects the current major and minor version of Python in order to find and load it.

Sometimes during preparing, building, testing or installation it is required to refer to the system's major and minor Python version (e.g. 3.9 or 3.10). Do not hardcode this and instead use a call to the Python interpreter to retrieve the information and store it in a local variable:

Sometimes during building, testing or installation it is required to refer to the system's site-packages directory. Do not hardcode this directory and use a call to the Python interpreter instead to retrieve the path and store it in a local variable:

Make sure to not install a directory named just tests/ directly under site-packages/ (i.e. /usr/lib/pythonX.Y/site-packages/tests/). Doing so could lead to conflicts between packages. Python package projects using setuptools are sometimes misconfigured to include the directory containing its tests as a top level Python package. If you encounter this, you can help by filing an issue with the package project and ask them to fix this, e.g. like this.

When running pytest, it is mostly desirable to not run with additional plugins. Especially plugins for linting and coverage are counterproductive in packaging, as changes in behavior may have tests fail. To disable pytest options such as addopts it is preferred to use an option override on the command line over patching any configuration files used by pytest due to the maintenance overhead.

To unset all additional options use

When using meson-python as a PEP 517 build backend it uses randomized folder paths that create reproducibility issues. This can be circumvented by hardcoding the used folder with the -Cbuild-dir flag:

Some packages require being installed to have the tests run successfully. In such cases, such as for example python-narwhals, you can create a virtual environment to install the built package and run the tests there.

**Examples:**

Example 1 (unknown):
```unknown
python-modulename
```

Example 2 (unknown):
```unknown
ext_modules
```

Example 3 (unknown):
```unknown
https://files.pythonhosted.org/packages/source/${_name::1}/${_name//-/_}/${_name//-/_}-$pkgver.tar.gz
```

Example 4 (unknown):
```unknown
https://files.pythonhosted.org/packages/py2.py3/${_name::1}/$_name/${_name//-/_}-$pkgver-py2.py3-none-any.whl
```

---

## Perl package guidelines

**URL:** https://wiki.archlinux.org/title/Perl_package_guidelines

**Contents:**
- Arch Linux packaging conventions
  - Package names
  - Package file placement
  - Architecture
  - Automation
- PKGBUILD examples
- CPAN module mechanics
  - Modules
  - Distributions
  - CPAN

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

This document covers the creation of PKGBUILDs for perl modules distributed over CPAN, the Comprehensive Perl Authors Network. The target audience of this document is intended to be packagers of perl modules. For Perl policies see Perl Policy.

The following conventions should be used to keep perl module packages consistent. This section serves as an introduction to the concept of perl packaging, from the point of view of Arch Linux; that is, package management and system administration. In an effort to please the casual TL;DR reader, the easiest and/or most popular material is at the top.

For modules the package name should begin with perl- and the rest of the name should be constructed from the module name by converting it to lowercase and then replacing colons with hyphens. For example the package name corresponding to HTML::Parser will be perl-html-parser. Perl applications should have the same name as that of the application but in lowercase.

Perl packages should install module files into /usr/lib/perl5/$version/vendor_perl/ (use perl -V:vendorarch in scripts), or /usr/share/perl5/vendor_perl/. This is done by setting the INSTALLDIRS command line parameter to vendor as shown below. No files should be stored in /usr/lib/perl5/$version/site_perl/ as that directory is reserved for use by the system administrator to install Perl packages outside the package management system. When a user installs modules system-wide by using the cpan shell, modules end up in the site-perl sub-directories.

The files perllocal.pod and .packlist also should not be present; this is taken care of by the example PKGBUILD described below.

In most cases, the arch array should contain 'any' because most Perl packages are architecture independent. XS modules are compiled into dynamically loaded libraries (.so files) and should explicitly set their architecture to ('x86_64') in order to indicate that they are architecture dependent when built. An XS module usually contains one or more .xs files which dynamically generate .c files.

A plugin for the second-generation CPAN shell, CPANPLUS, is available in the perl-cpanplus-dist-archAUR package. This plugin packages distributions on the fly as they are installed by CPANPLUS. Online documentation is available at https://metacpan.org/release/CPANPLUS-Dist-Arch

An example PKGBUILD can be found at [1].

The following two PKGBUILD examples use techniques, introduced in this page, that are intended to make a PKGBUILD more resilient to more sophisticated problems. Because there are two styles of build scripts, there are two example PKGBUILDS. The first PKGBUILD is an example of how to package a distribution that uses Makefile.PL. The second PKGBUILD can be used as a starting point for a distribution which uses Build.PL.

Justification for the added complexity of these PKGBUILDs is attempted in the latter sections.

There are a number of carefully, and not so carefully, designed mechanics that work together to create the module system. When making use of the CPAN, procedures must be followed to fetch the source code of a module, build that fetched module, and insert it into the system software for later execution. In order to understand how modules should be packaged, it helps immensely if one understands how modules work without any involvement from pacman and Arch Linux packages. Our goal in the end is to try to be unobtrusive as possible, while improving organization and consistency in the end product.

Modules are declared with the package keyword in perl. Modules are contained inside a .pm ("dot-pee-em") file. Though it is possible more than one module (package) is in the file. Modules have namespaces separated with :: (double colons), like: Archlinux::Module. When loading a module, the ::s are replaced with directory separators. For example: Archlinux/Module.pm will be loaded for the module Archlinux::Module.

Core modules are included with an installation of perl. Some core modules are only available bundled with perl. Other modules can still be downloaded and installed separately from CPAN.

(aka dist, package) This is the equivalent of an Arch Linux package in CPAN-lingo. Distributions are .tar.gz archives full of files. These archives contain primarily .pm module files, tests for the included modules, documentation for the modules, and whatever else is deemed necessary.

Usually a distribution contains a primary module with the same name. Sometimes this is not true, like with the Template-Toolkit distribution. The latest package, Template-Toolkit-2.22.tar.gz, for the Template-Toolkit dist, contains no Template::Toolkit module!

Sometimes because distributions are named after a main module, their names are used interchangeably and they get muddled together. However it is sometimes useful to consider them a separate entity (like in Template-Toolkit's case).

Each CPAN mirror contains indices that list the distributions on CPAN, the modules in the dists, and the name of the author who uploaded the dist. These are simply text files. The most useful index is in the /modules/02packages.details.txt.gz file available from each CPAN mirror. The term "packages" here refers to the package keyword in the perl language itself, not something similar to pacman packages. The CPAN shell, referred to as lowercased, italicized cpan, is simply the venerable perl script which navigates indices to find the module you want to install.

Modules are found in the 02packages.details.txt.gz list. On the same line as the module/package name is the path to the distribution tarball that contains the module. When you ask cpan to install a module, it will look up the module and install the relevant distribution. As the distribution is installing it will generate a list of module dependencies. Cpan will try to load each module dependency into the perl interpreter. If a module of the given version cannot be loaded the process is repeated.

The cpan shell does not have to worry about what version of the required module it is installing. cpan can rely on the fact that the latest version of the module must satisfy the requirements of the original module that it began installing in the first place. Only the latest versions of modules are listed in the packages details file. Unfortunately for the perl package author, we cannot always rely on the fact that our packages offer the most recent version of a perl distribution and the modules contained within. Pacman dependency checking is much more static and strongly enforced.

Perl has a unique way of defining dependencies compared to similar systems like Python eggs and Ruby gems. Eggs define dependencies on other eggs. Gems depend on gems. Perl dists depend on modules. Modules are only available from CPAN distributions, so in a way Perl distributions depend on distributions only indirectly. Modules can define their own versions independent from distributions inside the module source code. This is done by defining a package variable called $VERSION. When using strict and warnings, this is defined with the our keyword. For example:

Modules can change their versions however they like and even have a version distinct from the distribution version. The utility of this is questionable but it is important to keep in mind. Module versions are more difficult to determine from outside of the perl interpreter and require parsing the perl code itself, and maybe even loading the module into perl. The advantage is that from inside the perl interpreter, module versions are easy to determine. For example:

Where are dependencies defined in perl distributions? They are "defined" inside of the Makefile.PL or Build.PL script. For example, inside of the Makefile.PL script the WriteMakeFile function is called to generate the Makefile like this:

This is a contrived example but it is important to understand the dependencies are not final until after the Makefile.PL or Build.PL script is run. Dependencies are specified at runtime, which means they can be changed or modified using the full power of perl. This means the module author can add, remove, or change versions of dependencies right before the distribution is installed. Some modules authors use this to do overly clever things like depend on modules only if they are installed. Some multi-platform dists also depend on system-specific modules when installed on different operating systems.

As an example, the CPANPLUS distribution looks for CPANPLUS::Dist plugins that are currently installed. If any plugins are installed for the currently installed version of CPANPLUS it adds them to the new CPANPLUS's prerequisites. I'm not quite sure why. Luckily for the perl packager most dependencies are static like in the above example that requires the POSIX module with a minimum version of 0.01.

Meta files are included in recent distributions which contain meta-information about distributions such as the name, author, abstract description, and module requirements. Previously there were META.yml files in the YAML format but more recently the switch has been made to META.json files in the JSON format. These files can be edited by hand but more often they are generated automatically by Makefile.PL or Build.PL scripts when packaging a distribution for release. The latest specification is described in CPAN::Meta::Spec's online docs.

Remember that dependencies can be changed at runtime! For this reason another meta file is generated after running the build script. This second meta file is called MYMETA.json and reflects changes the script made at runtime and may be different from the meta file generated when the distribution was packaged for CPAN.

Elderly distributions on the CPAN have no meta file at all. These old releases predate the idea of the META.yml file and only describe their prerequisites in their Makefile.PL.

This article or section needs language, wiki syntax or style improvements. See Help:Style for reference.

One of perl's greatest strengths is the sheer number of modules available on CPAN. Not too surprisingly, there are also several different modules used for installing... well... modules! TMTOWTDI! I am not aware of a standard name for these types of modules, so I just called them "Installation Modules".

These modules are concerned with building the distribution and installing module files wherever the user prefers. This seems straightforward, but considering the number of different systems perl runs on, this can get complex. Installation modules all place a perl code file inside the dist tarball. Running this perl script will initiate the build and install process. The script always ends with the .PL suffix and is termed the "Build script" in the below list.

The original, oldest module for installing modules is ExtUtils::MakeMaker. The major downside to this module is that it requires the make program to build and install everything. This may not seem like a big deal to linux users but is a real hassle for Windows people!

The main advantage of Module::Build is that it is pure-perl. This means it does not require a make program to be installed for you to build/install modules. Its adoption was rocky because if Module::Build was not already installed, you could not run the bundled Build.PL script! This is not a problem with recent versions of perl because Module::Build is a core module. (NOTE As of perl 5.22, Module::Build will no longer be a core module)

This is another pure-perl build tool. As an interface it implements a subset of Module::Build's interface, in particular it requires dashes before its arguments (Module::Build accepts with and without) and does not support .modulebuildrc.

Another modern build/installation module, Module::Install still requires the make program be installed to function. MI was designed as a drop-in replacement for MakeMaker, to address some of MakeMaker's shortcomings. Ironically, it depends on MakeMaker in order to operate. The Makefile.PL files that are generated by MI look much different and are implemented using a simple domain specific language.

One very interesting feature is that Module::Install bundles a complete copy of itself into the distribution file. Because of this, unlike MakeMaker or M::B, you do not need Module::Install to be installed on your system.

Another very unique feature is auto-install. Though not recommended by Module::Install's authors this feature is used quite often. When the module author enables auto-install for their distribution, Module::Install will search for and install any pre-requisite modules that are not installed when Makefile.PL is executed. This feature is skipped when Module::Install detects it is being run by CPAN or CPANPLUS. However, this feature is not skipped when run inside... oh I do not know... a PKGBUILD! I hope you can see how a rogue perl program downloading and installing modules willy-nilly inside a PKGBUILD can be a problem. See the #PERL_AUTOINSTALL environment variable to see how to fix this.

A number of environment variables can affect the way the modules are built or installed. Some have a very dramatic effect and can cause problems if misunderstood. An advanced user could be using these environment variables. Some of these will break an unsuspecting PKGBUILD or cause unexpected behavior.

When this variable is set to a true value, the installation module will pretend the default answer was given to any question it would normally ask. This does not always work, but all of the installation modules honour it. That does not mean the module author will!

You can pass additional command-line arguments to Module::Install's Makefile.PL with this variable. In order to turn off auto-install (highly recommended), assign --skipdeps to this.

You can pass additional command-line arguments to Makefile.PL and/or Build.PL with this variable. For example, you can install modules into your home-dir by using:

This is the same thing as PERL_MM_OPT except it is only for Module::Build. For example, you could install modules into your home-dir by using:

Module::Build allows you to override its command-line-arguments with an rcfile. This defaults to ~/.modulebuildrc. This is considered deprecated within the perl toolchain. You can override which file it uses by setting the path to the rcfile in MODULEBUILDRC. The paranoid might set MODULEBUILDRC to /dev/null... just in case.

The directories searched for libraries can be set by the user (particularly if they are using Local::Lib) by setting PERL5LIB. That should be cleared before building.

If the user is using Local::Lib it will set PERL_LOCAL_LIB_ROOT. That should be cleared before building.

A subtle problem is that advanced perl programmers may like to have multiple versions of perl installed. This is useful for testing backwards-compatibility in created programs. There are also speed benefits to compiling your own custom perl interpreter (i.e. without threads). Another reason for a custom perl is simply because the official perl Arch Linux package sometimes lags behind perl releases. The user may be trying out the latest perl... who knows?

If the user has the custom perl executable in their $PATH, the custom perl will be run when the user types the perl command on the shell. In fact the custom perl will run inside the PKGBUILD as well! This can lead to insidious problems that are difficult to understand.

The problem lies in compiled XS modules. These modules bridge perl and C. As such they must use perl's internal C API to accomplish this bridge. Perl's C API changes slightly with different versions of perl. If the user has a different version of perl than the system perl (/usr/bin/perl) then any XS module compiled with the user's perl will be incompatible with the system-wide perl. When trying to use the compiled XS module with the system perl, the module will fail to load with a link error.

A simple solution is to always use the absolute path of the system-wide perl interpreter (/usr/bin/perl) when running perl in the PKGBUILD.

**Examples:**

Example 1 (unknown):
```unknown
HTML::Parser
```

Example 2 (unknown):
```unknown
perl-html-parser
```

Example 3 (unknown):
```unknown
/usr/lib/perl5/$version/vendor_perl/
```

Example 4 (unknown):
```unknown
perl -V:vendorarch
```

---

## 32-bit package guidelines

**URL:** https://wiki.archlinux.org/title/32-bit_package_guidelines

**Contents:**
- Package naming
- Variables and parameters
  - lib32
    - File placement

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

Legacy 32-bit software can be built and installed on machines of another native architecture, such as x86_64. This article explains the production and conventions of such packages.

Specify these bash variables in a PKGBUILD to tell the compiler to output 32-bit code:

Ensure lib32 package files do not conflict with native package files and include all necessary files, such as architecture-specific includes. For example, if a package builds using GNU Autoconf, specify the following to configure:

If a package builds using Meson, specify the following to arch-meson:

**Examples:**

Example 1 (unknown):
```unknown
pkgdesc+=" (32-bit)"
```

Example 2 (unknown):
```unknown
export CFLAGS+=" -m32"
export CXXFLAGS+=" -m32"
export LDFLAGS+=" -m32"
export PKG_CONFIG_PATH='/usr/lib32/pkgconfig'
```

Example 3 (unknown):
```unknown
--program-suffix="-32" \
--lib{exec,}dir=/usr/lib32 \
--includedir=/usr/include/"$pkgbase"32 \
--build=i686-pc-linux-gnu
```

Example 4 (unknown):
```unknown
--cross-file lib32
```

---

## Package proxy cache

**URL:** https://wiki.archlinux.org/title/Package_Proxy_Cache

**Contents:**
- Package cache sharing
  - Read-only cache
  - Overlay mount of read-only cache
  - Distributed read-only cache
  - Read-write cache
  - Two-way with rsync or FTP
  - Synchronize pacman package cache using synchronization programs
- Proxy server
  - Dynamic reverse proxy cache using nginx
  - Squid

If you want to install the same Arch packages over and over —e.g. for testing purposes— it could help if you would not have to get the packages every time from the internet. This article shows you how to share packages so that you can greatly decrease your download times.

Which solution is best depends on your individual use-case. The methods can be grouped into #Package cache sharing of the machines, or deploying a #Proxy server for extra caching on one machine and configuring the machines to use it accordingly.

For all solutions to share the package cache, keep in mind that, by default, pacman -Sc removes package tarballs from the cache that correspond to packages that are not installed on the machine the command was issued on. Because pacman cannot predict what packages are installed on all machines that share the cache, it will end up deleting files that should not be.

To clean up the cache so that only outdated tarballs are deleted:

Pacman 6.1.0 supports cache servers directly. Cache servers will be tried before any non-cache servers, will not be removed from the server pool because of HTTP 404 download errors, and will not be used for database files.

If you are looking for a quick solution, you can simply run a basic temporary webserver which other computers can use as their cache server.

Start serving this directory. For example, with Python http.server module:

Then edit /etc/pacman.d/mirrorlist on each client machine to add this server:

If looking for a more standalone solution, darkhttpd offers a very minimal webserver. Replace the previous python command with e.g.:

You could also run darkhttpd as a systemd service for convenience: see Systemd#Writing unit files.

miniserve, a small web server written in Rust, can also be used:

Then edit /etc/pacman.d/mirrorlist as above with the first url miniserve is available at.

If you are already running a web server for some other purpose, you might wish to reuse that as your local repository server instead. For example, if you already serve a site with nginx, you can add an nginx server block listening on port 8080:

Remember to restart nginx.service after making this change.

It is possible to use one machine on a local network as a read-only package cache by overlay mounting its /var/cache/pacman/pkg directory. Such a configuration is advantageous if this server has installed on it a reasonably comprehensive selection of up-to-date packages which are also used by other boxes. This is useful for maintaining a number of machines at the end of a low bandwidth upstream connection.

As an example, to use this method:

After this, run pacman using the option --cachedir /tmp/pacman_pkg, e.g.:

There are Arch-specific tools for automatically discovering other computers on your network offering a package cache. Try pacredir, pacserve, pkgdistcacheAUR, or paclanAUR. pkgdistcache uses Avahi instead of plain UDP which may work better in certain home networks that route instead of bridge between Wi-Fi and Ethernet.

Historically, there was PkgD and multipkg, but they are no longer maintained.

In order to share packages between multiple computers, simply share /var/cache/pacman/ using any network-based mount protocol. This section shows how to use SSHFS to share a package cache plus the related library-directories between multiple computers on the same local network. Keep in mind that a network shared cache can be slow depending on the file-system choice, among other factors.

First, install any network-supporting filesystem packages: sshfs, curlftpfs, samba or nfs-utils.

Then, to share the actual packages, mount /var/cache/pacman/pkg from the server to /var/cache/pacman/pkg on every client machine.

Another approach in a local environment is rsync. Choose a server for caching and enable the rsync daemon. On clients synchronize two-way with this share via the rsync protocol. Filenames that contain colons are no problem for the rsync protocol.

Draft example for a client, using uname -m within the share name ensures an architecture-dependent sync:

Instead of relying on unencrypted rsync daemon a more secure security option is rsync over ssh, Rsync#Automated backup with SSH gives an overview.

In case rsync is not available in your local environment, a simple ftp service is suitable for the two-way sync as well. lftp provides a --mirror and a --delete option to sync a local with a remote storage.

Use Syncthing or Resilio Sync to synchronize the pacman cache directories (i.e. /var/cache/pacman/pkg).

For proxy server solutions, keep in mind the machines should only use HTTP mirrors, because a proxy server cannot introspect HTTPS connections by default.

nginx can be used to proxy package requests to official upstream mirrors and cache the results to the local disk. All subsequent requests for that package will be served directly from the local cache, minimizing the amount of internet traffic needed to update a large number of computers.

In this example, the cache server will run at http://cache.domain.example:8080/ and store the packages in /srv/http/pacman-cache/.

Install nginx on the computer that is going to host the cache. Create the directory for the cache and adjust the permissions so nginx can write files to it:

Use the nginx pacman cache config as a starting point for /etc/nginx/nginx.conf. Check that the resolver directive works for your needs. In the upstream server blocks, configure the proxy_pass directives with addresses of official mirrors, see examples in the configuration file about the expected format. Once you are satisfied with the configuration file start and enable nginx.

In order to use the cache each Arch Linux computer (including the one hosting the cache) must have the following line at the top of the mirrorlist file:

Squid proxy can be setup to only cache arch packages and can be used with aif/pacman/wget/etc with minimal configuration on the client system.

This is the minimum configuration to get squid cache arch packages.

Before defining these rules, remove/comment (if you do not need them) all the default refresh_patterns

That should define that *.pkg.tar.* gets cached, and anything else should not.

Objects larger than this size will NOT be saved on disk:

Set the cache dir and its maximum size and subdirs:

Time to wait until all active client sockets are closed:

Every time you change the cache_dir path (and after fresh install), you need to (re)create this directory:

and it could be helpful to check the configuration file before running squid:

Just start squid.service or if squid is already running restart it.

It could be helpful to check the configuration file before running:

To see the access to squid:

You should see this for packages that are directed to original host:

and for packages that are delivered from the cache:

On the individual machines, add environment variables for your proxy. To do so for testing:

Now it should use your proxy. Watch the squid logs to verify this. Once it works, add the http_proxy and/or ftp_proxy variables in an appropriate place on the installed system, e.g. in /etc/profile.d/proxy.sh.

If you want all HTTP requests on local machine automagically go through squid, we first need to add an intercepting port for squid:

and iptables rules to redirect all (except the ones from squid) port 80 requests to squid:

Pacoloco is an easy-to-use proxy cache server for pacman repositories. It also allows automatic prefetching of the cached packages.

It can be installed as pacoloco. Open the configuration file and add pacman mirrors:

Restart pacoloco.service and the proxy repository will be available at http://myserver:9129/repo/mycopy.

Flexo is yet another proxy cache server for pacman repositories. Flexo is available as flexo-gitAUR. Once installed, start the flexo.service unit.

Flexo runs on port 7878 by default. Enter Server = http://myserver:7878/$repo/os/$arch to the top of your /etc/pacman.d/mirrorlist so that pacman downloads packages via Flexo.

**Examples:**

Example 1 (unknown):
```unknown
/etc/pacman.conf
```

Example 2 (unknown):
```unknown
[options]
CleanMethod = KeepCurrent
```

Example 3 (unknown):
```unknown
$ python -m http.server -d /var/cache/pacman/pkg/
```

Example 4 (unknown):
```unknown
http.server
```

---

## Gamescope

**URL:** https://wiki.archlinux.org/title/Gamescope

**Contents:**
- Installation
  - Requirements
- Usage
  - From a display manager
  - From a desktop session
  - From Steam
  - From Wine
  - From Flatpak
  - Upscaling
  - HDR support

Gamescope is a microcompositor from Valve that is used on the Steam Deck. Its goal is to provide an isolated compositor that is tailored towards gaming and supports many gaming-centric features such as:

As a microcompositor it is designed to run as a nested session on top of your existing desktop environment though it is also possible to use it as an embedded compositor as well.

Gamescope can be installed with the gamescope package. Additionally there is also gamescope-plusAUR which includes extra patches not present in the mainline build.

Gamescope offers many options, far too many to cover here. For a full list use the gamescope --help command from a terminal.

See Steam#Big Picture Mode from a display manager.

The following command will run supertuxkart using Gamescope and force a 1920x1080 resolution at 60 FPS

You can run games from Steam using Gamescope by adding the following to the games launch options

To run programs using Gamescope through Wine, simply append wine followed by the executable.

Almost all the popular Wine managers such as Lutris, Bottles, and PlayOnLinux have support for Gamescope. Using them is as simple as installing the desired Gamescope package and checking the Use Gamescope (or similar) option.

You can also use Gamescope from Flatpak versions of Wine managers and Steam in the same way as you would from a package install. It does however require that you first install Gamescope from Flathub with the following command:

The -F fsr and -F nis flags can be used to upscale games using AMD FidelityFX™ Super Resolution 1.0 (FSR) or NVIDIA Image Scaling v1.0.3 (NIS) respectively. You can also use -S integer for integer upscaling or -S stretch for stretch scaling.

To upscale a 720p game to 1440p using FSR:

To run a game at 1080p internal resolution but display it at 4K using NIS:

Games with low resolutions typically use linear filtering on fullscreen by default and sometimes get stretched. This is specially noticeable in classic JRPG. To have a pixelated look and keep aspect ratio:

Filters can be changed while the game is running:

Gamescope is a requirement for HDR10 support when playing games, to make use of this feature you must launch your Gamescope session using the --hdr-enabled flag.

Gamescope does not support Wayland clients by default. To enable support for Wayland clients, add the --expose-wayland flag to Gamescope's parameters.

Since SteamOS 3.5.5, Valve has changed the default color rendering for the Steam Deck LCD. The effect is achieved through Gamescope by changing the "wideness" of the gamut for SDR content, which can result in a warmer and more vibrant color appearance depending on the adjustment.

In a Steam game's launch options, simply add --sdr-gamut-wideness followed by a value that's equal or between 0-1:

Using traditional MangoHud with gamescope is not supported. Instead the gamescope argument --mangoapp should be used. This allows MangoHud to run on top of gamescope instead of the underlying application. Certain MangoHud configurations, such as displaying FSR or HDR status, require the use of mangoapp with gamescope in order to work.

If your monitor supports it, enable variable refresh rate by passing the --adaptive-sync flag.

Gamescope exposes a video node in PipeWire for recording. You can record this with GStreamer.

If the cursor is not captured by the application, for example by limiting your camera movement or by not properly disappearing out of menu, use the --force-grab-cursor option. Some proton/wine games require this workaround.

This is a known bug when using Gamescopes fullscreen hotkey Meta+f, if you encounter this issue it can be worked around by using the fullscreen flag -f when launching the game.

Another known cause of low performance and/or stuttering is not having Gamescope's priority set correctly. You can tell this is the case if you see an error like this in the terminal while Gamescope is running:

The following command will fix this:

This is because Flatpak Gamescope fails to access the NVIDIA DRM's GBM backend. It can be solved by simply setting an environment variable with the following command:

where packageid is the Flatpak package identifier of Gamescope or the app you want to use Gamescope with, such as Bottles. Replace nvidia-XXX-YY-ZZ with the currently installed NVIDIA driver version; inside Flatpak, it can be queried with this command:

where packageid is any Flatpak package identifier; do note that the directory only exists inside Flatpak.

This article or section needs expansion.

The command must be reran, and modified accordingly, on every driver update.

If gamescope outputs corrupted image colors on Intel graphics disabling lossless color compression can be a work-around at the cost of increased memory bandwidth utilization. [1] To disable it pass INTEL_DEBUG=noccs environment variable.

If VRR and HDR work independently, but the framerate is unstable when they're both enabled, then you may be hitting issues with long HDR compositing times. See https://github.com/ValveSoftware/gamescope/issues/1006. This only applies to using Gamescope in embedded mode, and not when using gamescope within an existing wayland or X session.

When using AMD graphics this can be fixed by using experimental AMD color management, which uses hardware planes to composite the final image. This requires one of two setups:

Linux 6.8 or newer compiled with KCFLAGS including -DAMD_PRIVATE_COLOR, eg linux-amd-colorAUR

Moving a high polling rate mouse (observed with 4000Hz) in the game window might cause stuttering or temporary freezes [2]. Setting a lower polling rate like 1000Hz should work around this issue.

A common cause of swapchain errors is improperly attempting to use mangohud instead of mangoapp. See the Mangoapp section of #Usage, above.

If after launching gamescope from Steam you experience heavy stuttering setting in around ~24 minutes, then you can fix this by either enabling the Steam Overlay -e option on your Steam Client, or by overwriting the environment variable LD_PRELOAD with an empty value. For example:

This, however, will disable the Steam Overlay and any additional Steam features; game recording being one of them. Depending on the game, you may be able to restore Steam functionality by bypassing LD_PRELOAD running on gamescope, and passing it instead as an env directly to the desired command. For example:

The above seems to work well for games that do not contain a secondary launcher (Rockstar, EA, etc.)

See ValveSoftware/gamescope#163.

Several reports have indicated that some games on certain systems will crash if Gamescope is not launched in fullscreen, and the current workaround is to add --fullscreen to the launch options. This will, however, lead to issues where the camera can pan in games rotationally indefinitely due to a failure to capture the mouse cursor correctly (see 4.1). Thus, --force-grab-cursor is recommended to be used in conjunction with this fix.

See ValveSoftware/gamescope#495 for a report regarding the details. Causes are unconfirmed, and no fixes have been listed yet.

**Examples:**

Example 1 (unknown):
```unknown
nvidia_drm.modeset=1
```

Example 2 (unknown):
```unknown
gamescope --help
```

Example 3 (unknown):
```unknown
$ gamescope -W 1920 -H 1080 -r 60 -- supertuxkart
```

Example 4 (unknown):
```unknown
gamescope -- %command%
```

---

## pacman

**URL:** https://wiki.archlinux.org/title/Pacman

**Contents:**
- Usage
  - Installing packages
    - Installing specific packages
      - Virtual packages
    - Installing package groups
  - Removing packages
  - Upgrading packages
  - Querying package databases
    - Pactree
    - Database structure

The pacman package manager is one of the major distinguishing features of Arch Linux. It combines a simple binary package format with an easy-to-use Arch build system. The goal of pacman is to make it possible to easily manage packages, whether they are from the official repositories or the user's own builds.

Pacman keeps the system up-to-date by synchronizing package lists with the master server. This server/client model also allows the user to download/install packages with a simple command, complete with all required dependencies.

Pacman is written in the C programming language and uses the bsdtar(1) tar format for packaging.

What follows is just a small sample of the operations that pacman can perform. To read more examples, refer to pacman(8).

A package is an archive containing:

Arch's package manager pacman can install, update, and remove those packages. Using packages instead of compiling and installing programs yourself has various benefits:

To install a single package or list of packages, including dependencies, issue the following command:

To install a list of packages with regex (see this forum thread):

Sometimes there are multiple versions of a package in different repositories (e.g. extra and extra-testing). To install the version from the extra repository in this example, the repository needs to be defined in front of the package name:

To install a number of packages sharing similar patterns in their names, one can use curly brace expansion. For example:

This can be expanded to however many levels needed:

A virtual package is a special package which does not exist by itself, but is provided by one or more other packages. Virtual packages allow other packages to not name a specific package as a dependency, in case there are several candidates. Virtual packages cannot be installed by their name, instead they become installed in your system when you have installed a package providing the virtual package. An example is the dbus-units package.

Some packages belong to a group of packages that can all be installed simultaneously. For example, issuing the command:

will prompt you to select the packages from the gnome group that you wish to install.

Sometimes a package group will contain a large amount of packages, and there may be only a few that you do or do not want to install. Instead of having to enter all the numbers except the ones you do not want, it is sometimes more convenient to select or exclude packages or ranges of packages with the following syntax:

which will select packages 1 through 10 and 15 for installation, or:

which will select all packages except 5 through 8 and 2 for installation.

To see what packages belong to the gnome group, run:

Also visit https://archlinux.org/groups/ to see what package groups are available.

To remove a single package, leaving all of its dependencies installed:

To remove a package and its dependencies which are not required by any other installed package:

The above may sometimes refuse to run when removing a group which contains otherwise needed packages. In this case try:

To remove a package, its dependencies and all the packages that depend on the target package:

To remove a package, which is required by another package, without removing the dependent package:

Pacman saves important configuration files when removing certain applications and names them with the extension: .pacsave. To prevent the creation of these backup files use the -n option:

Pacman can update all packages on the system with just one command. This could take quite a while depending on how up-to-date the system is. The following command synchronizes the repository databases and updates the system's packages, excluding "local" packages that are not in the configured repositories:

Pacman queries the local package database with the -Q flag, the sync database with the -S flag and the files database with the -F flag. See pacman -Q --help, pacman -S --help and pacman -F --help for the respective suboptions of each flag.

Pacman can search for packages in the database, searching both in packages' names and descriptions:

Sometimes, -s's builtin ERE (Extended Regular Expressions) can cause a lot of unwanted results, so it has to be limited to match the package name only; not the description nor any other field:

To search for already installed packages:

To search for package file names in remote packages:

To display extensive information about a given package (e.g. its dependencies):

For locally installed packages:

Passing two -i flags will also display the list of backup files and their modification states:

To retrieve a list of the files installed by a package:

To retrieve a list of the files installed by a remote package:

To verify the presence of the files installed by a package:

Passing the k flag twice will perform a more thorough check.

To query the database to know which package a file in the file system belongs to:

To query the database to know which remote package a file belongs to:

To list all packages no longer required as dependencies (orphans):

To list all packages explicitly installed and not required as dependencies:

See pacman/Tips and tricks for more examples.

For advanced functionality, install pkgfile, which uses a separate database with all files and their associated packages.

To view the dependency tree of a package:

To view the dependent tree of a package, pass the reverse flag -r to pactree.

The pacman databases are normally located at /var/lib/pacman/sync. For each repository specified in /etc/pacman.conf, there will be a corresponding database file located there. Database files are gzipped tar archives containing one directory for each package, for example for the which package:

The desc file contains meta data such as the package description, dependencies, file size and MD5 hash.

Pacman stores its downloaded packages in /var/cache/pacman/pkg/ and does not remove the old or uninstalled versions automatically. This has some advantages:

However, it is necessary to deliberately clean up the cache periodically to prevent the directory to grow indefinitely in size.

The paccache(8) script, provided within the pacman-contrib package, deletes all cached versions of installed and uninstalled packages, except for the most recent three, by default:

Enable and start paccache.timer to discard unused packages weekly. You can configure the arguments for the service in /etc/conf.d/pacman-contrib, e.g with PACCACHE_ARGS='-k1' or PACCACHE_ARGS='-uk0' for the two examples below.

You can also define how many recent versions you want to keep. To retain only one past version use:

Add the -u/--uninstalled switch to limit the action of paccache to uninstalled packages. For example to remove all cached versions of uninstalled packages, use the following:

See paccache -h for more options.

Pacman also has some built-in options to clean the cache and the leftover database files from repositories which are no longer listed in the configuration file /etc/pacman.conf. However pacman does not offer the possibility to keep a number of past versions and is therefore more aggressive than paccache default options.

To remove all the cached packages that are not currently installed, and the unused sync databases, execute:

To remove all files from the cache, use the clean switch twice, this is the most aggressive approach and will leave nothing in the cache directory:

pkgcachecleanAUR and pacleanerAUR are two further alternatives to clean the cache.

Download a package without installing it:

Install a 'local' package that is not from a remote repository (e.g. the package is from the AUR):

To keep a copy of the local package in pacman's cache, use:

Install a 'remote' package (not from a repository stated in pacman's configuration files):

Pacman always lists packages to be installed or removed, and asks for permission before taking any action.

To get a list in a processable format, and to prevent the actions of -S, -U and -R, you can use -p, short for --print.

--print-format can be added to format this list in various ways. --print-format %n will return a list without package versions.

The pacman database organizes installed packages into two groups, according to installation reason:

When installing a package, it is possible to force its installation reason to dependency with:

The command is normally used because explicitly-installed packages may offer optional packages, usually for non-essential features for which the user has discretion.

When reinstalling a package, though, the current installation reason is preserved by default.

The list of explicitly-installed packages can be shown with pacman -Qe, while the complementary list of dependencies can be shown with pacman -Qd.

To change the installation reason of an already installed package, execute:

Use --asexplicit to do the opposite operation.

When successful, the workflow of a transaction follows five high-level steps plus pre/post transaction hooks:

Pacman settings are located in /etc/pacman.conf: this is the place where the user configures the program to work in the desired manner. In-depth information about the configuration file can be found in pacman.conf(5).

General options are in the [options] section. Read pacman.conf(5) or look in the default pacman.conf for information on what can be done here.

To see old and new versions of available packages, uncomment the "VerbosePkgLists" line in /etc/pacman.conf. The output of pacman -Syu will be like this:

The number of packages being downloaded in parallel (at the same time) are configured in /etc/pacman.conf with the ParallelDownloads option under [options]. The /etc/pacman.conf shipped with the pacman package sets it to 5. If the option is unset, packages will be downloaded sequentially.

To have a specific package skipped when upgrading the system, add this line in the [options] section:

For multiple packages use a space-separated list, or use additional IgnorePkg lines. Also, glob patterns can be used. If you want to skip packages just once, you can also use the --ignore option on the command-line - this time with a comma-separated list.

It will still be possible to upgrade the ignored packages using pacman -S: in this case pacman will remind you that the packages have been included in an IgnorePkg statement.

As with packages, skipping a whole package group is also possible:

All files listed with a NoUpgrade directive will never be touched during a package install/upgrade, and the new files will be installed with a .pacnew extension.

Multiple files can be specified like this:

To always skip installation of specific files or directories list them under NoExtract. For example, to avoid installing bash completion scripts, use:

Later rules override previous ones, and you can negate a rule by prepending !.

If you have several configuration files (e.g. main configuration and configuration with testing repository enabled) and would have to share options between configurations you may use Include option declared in the configuration files, e.g.:

where /path/to/common/settings file contains the same options for both configurations.

Pacman can run pre- and post-transaction hooks from the /usr/share/libalpm/hooks/ directory; more directories can be specified with the HookDir option in pacman.conf, which defaults to /etc/pacman.d/hooks. Hook file names must be suffixed with .hook. Pacman hooks are not interactive.

Pacman hooks are used, for example, in combination with systemd-sysusers and systemd-tmpfiles to automatically create system users and files during the installation of packages. For example, tomcat8 specifies that it wants a system user called tomcat8 and certain directories owned by this user. The pacman hooks systemd-sysusers.hook and systemd-tmpfiles.hook invoke systemd-sysusers and systemd-tmpfiles when pacman determines that tomcat8 contains files specifying users and tmp files.

For more information on alpm hooks, see alpm-hooks(5).

Besides the special [options] section, each other [section] in pacman.conf defines a package repository to be used. A repository is a logical collection of packages, which are physically stored on one or more servers: for this reason each server is called a mirror for the repository.

Repositories are distinguished between official and unofficial. The order of repositories in the configuration file matters; repositories listed first will take precedence over those listed later in the file when packages in two repositories have identical names, regardless of version number. In order to use a repository after adding it, you will need to upgrade the whole system first.

Each repository section allows defining the list of its mirrors directly or in a dedicated external file through the Include directive; for example, the mirrors for the official repositories are included from /etc/pacman.d/mirrorlist. See the Mirrors article for mirror configuration.

Pacman stores downloaded package files in cache, in a directory denoted by CacheDir in [options] section of pacman.conf (defaults to /var/cache/pacman/pkg/ if not set).

Cache directory may grow over time, even if keeping just the freshest versions of installed packages.

If you want to move that directory to some more convenient place, do one of the following:

Pacman supports package signatures, which add an extra layer of security to the packages. The default configuration, SigLevel = Required DatabaseOptional, enables signature verification for all the packages on a global level. This can be overridden by per-repository SigLevel lines. For more details on package signing and signature verification, take a look at pacman-key.

If you see the following error: [1]

This is happening because pacman has detected a file conflict, and by design, will not overwrite files for you. This is by design, not a flaw.

The problem is usually trivial to solve (although to be sure, you should try to find out how these files got there in the first place). A safe way is to first check if another package owns the file (pacman -Qo /path/to/file). If the file is owned by another package, file a bug report. If the file is not owned by another package, rename the file which "exists in filesystem" and re-issue the update command. If all goes well, the file may then be removed.

If you had installed a program manually without using pacman, for example through make install, you have to remove/uninstall this program with all of its files. See also Pacman tips#Identify files not owned by any package.

Every installed package provides a /var/lib/pacman/local/package-version/files file that contains metadata about this package. If this file gets corrupted, is empty or goes missing, it results in file exists in filesystem errors when trying to update the package. Such an error usually concerns only one package. Instead of manually renaming and later removing all the files that belong to the package in question, you may explicitly run pacman -S --overwrite glob package to force pacman to overwrite files that match glob.

This article or section is out of date.

Look for .part files (partially downloaded packages) in /var/cache/pacman/pkg/ and remove them (often caused by usage of a custom XferCommand in pacman.conf).

That same error may also appear if archlinux-keyring is out-of-date, preventing pacman from verifying signatures. See Pacman/Package signing#Upgrade system regularly for the fix and how to avoid it in the future.

When pacman is about to alter the package database, for example installing a package, it creates a lock file at /var/lib/pacman/db.lck. This prevents another instance of pacman from trying to alter the package database at the same time.

If pacman is interrupted while changing the database, this stale lock file can remain. If you are certain that no instances of pacman are running then delete the lock file:

This error manifests as Not found in sync db, Target not found or Failed retrieving file.

Firstly, ensure the package actually exists. If certain the package exists, your package list may be out-of-date. Try running pacman -Syu to force a refresh of all package lists and upgrade. Also make sure the selected mirrors are up-to-date and repositories are correctly configured. You can also use Reflector to keep the mirrors up-to-date.

If pacman reports there is nothing to update, but the Failed retrieving file error continues to be printed, consider forcing a database download with pacman -Syyu. This is never needed under normal circumstances, so inspect more closely the status and consistency of the mirror.

It could also be that the repository containing the package is not enabled on your system, e.g. the package could be in the multilib repository, but multilib is not enabled in your pacman.conf.

See also FAQ#Why is there only a single version of each shared library in the official repositories?.

This article or section needs expansion.

Whether due to power loss, kernel panic or hardware failure an update may be interrupted. In most cases, there will not be much damage but the system will likely be unbootable.

Replicating the exact upgrade is needed to ensure the right scriptlets and hooks will run.

In the case that pacman crashes with a "database write" error while removing packages, and reinstalling or upgrading packages fails thereafter, do the following:

If /var/cache/pacman/pkg is a symlink, pacman will try to make a directory instead and thus remove this symlink during self-upgrade. This will cause the update to fail. As a result, /usr/bin/pacman and other contents of the pacman package will be missing.

Never symlink /var/cache/pacman/pkg because it is controlled by pacman. Use the CacheDir option or a bind mount instead; see #Package cache directory.

If you have already encountered this problem and broke your system, you can manually extract /usr contents from the package to restore pacman and then reinstall it properly; see FS#73306 and related forum thread for details.

pacman-staticAUR is a statically compiled version of pacman, so it will be able to run even when the libraries on the system are not working. This can also come in handy when a partial upgrade was performed and pacman can not run anymore.

The pinned comment and the PKGBUILD provides a way to directly download the binary, which can be used to reinstall pacman or to upgrade the entire system in case of partial upgrades.

In some situations, your system may be too broken (e.g., due to missing or incompatible libraries) to run `makepkg` or build the `pacman-static` package from the AUR successfully.

If building from the PKGBUILD fails or `makepkg` cannot be run, you can download a precompiled `pacman-static` binary from a trusted source. This static binary does not depend on system libraries and can be used to restore a working `pacman` on your system.

A reliable source for the binary is:

This will update your system and reinstall `pacman`, fixing broken dependencies related to missing shared libraries.

If even pacman-static does not work, it is possible to recover using an external pacman. One of the easiest methods to do so is by using the archiso and simply using --sysroot or --root to specify the mount point of the system to perform the operation on. See Chroot#Using chroot on how to mount the necessary filesystems required by --sysroot.

Even if pacman is terribly broken, you can fix it manually by downloading the latest packages and extracting them to the correct locations. The rough steps to perform are:

If you have a healthy Arch system on hand, you can see the full list of dependencies with:

But you may only need to update a few of them depending on your issue. An example of extracting a package is

Note the use of the w flag for interactive mode. Running non-interactively is very risky since you might end up overwriting an important file. Also take care to extract packages in the correct order (i.e. dependencies first). This forum post contains an example of this process where only a couple pacman dependencies are broken.

Most likely the initramfs became corrupted during a kernel update (improper use of pacman's --overwrite option can be a cause). There are two options; first, try the Fallback entry.

Once the system starts, run this command (for the stock linux kernel) either from the console or from a terminal to rebuild the initramfs image:

If that does not work, from a current Arch release (CD/DVD or USB stick), mount your root and boot partitions to /mnt and /mnt/boot, respectively. Then chroot using arch-chroot:

Reinstalling the kernel (the linux package) will automatically re-generate the initramfs image with mkinitcpio -p linux. There is no need to do this separately.

Afterwards, it is recommended that you run exit, umount /mnt/{boot,} and reboot.

As the error message says, your locale is not correctly configured. See Locale.

When locale files are intentionally removed by tools such as bleachbit or localepurgeAUR, pacman may issue warnings about missing locales during package updates.

To suppress these warnings, you can comment out the CheckSpace option in pacman.conf. Keep in mind that disabling CheckSpace turns off the space-checking functionality for all package installations, so use this workaround only when you have alternative means to monitor disk space.

Make sure that the relevant environment variables ($http_proxy, $ftp_proxy etc.) are set up. If you use pacman with sudo, you need to configure sudo to pass these environment variables to pacman. Also, ensure the configuration of dirmngr has honor-http-proxy in /etc/pacman.d/gnupg/dirmngr.conf to honor the proxy when refreshing the keys.

To reinstall all the native packages: pacman -Qnq | pacman -S - or pacman -S $(pacman -Qnq) (the -S option preserves the installation reason by default).

You will then need to reinstall all the foreign packages, which can be listed with pacman -Qmq.

It looks like previous pacman transaction removed or corrupted shared libraries needed for pacman itself.

To recover from this situation, you need to unpack required libraries to your filesystem manually. First find what package contains the missed library and then locate it in the pacman cache (/var/cache/pacman/pkg/). Unpack required shared library to the filesystem. This will allow to run pacman.

Now you need to reinstall the broken package. Note that you need to use --overwrite flag as you just unpacked system files and pacman does not know about it. Pacman will correctly replace our shared library file with one from package.

That's it. Update the rest of the system.

Some issues have been reported regarding network problems that prevent pacman from updating/synchronizing repositories. [2] [3] When installing Arch Linux natively, these issues have been resolved by replacing the default pacman file downloader with an alternative (see Improve pacman performance for more details). When installing Arch Linux as a guest OS in VirtualBox, this issue has also been addressed by using Host interface instead of NAT in the machine properties.

If you receive this error message with correct mirrors, try setting a different name server.

If you want to install a package on an sshfs mount using pacman -U and receive this error, move the package to a local directory and try to install again.

Upon executing, e.g., pacman -Syu inside a chroot environment an error is encountered:

This is frequently caused by the chroot directory not being a mountpoint when the chroot is entered. See the note at Install Arch Linux from existing Linux#Downloading basic tools for a solution, and arch-chroot(8) for an explanation and an example of using bind mounting to make the chroot directory a mountpoint.

If you are unable to update packages and receive this error, then try rm -r /var/lib/pacman/sync/ before attempting to update.

If removing sync files doesn't help, check that the sync files are gzip compressed data using file /var/lib/pacman/sync/* before attempting to update. A router or proxy might corrupt the downloads. Corruption could possibly be HTML type.

If sync files are of the correct type, there might be an issue with the mirror server. Look up the mirror server(s) in use with pacman-conf -r core and pacman-conf -r extra. Paste the first returned url in a browser and check that a file listing is returned. In case the mirror returns an error, comment it in /etc/pacman.d/mirrorlist. You may try updating or re-ranking mirrors.

If this error occurs and you're for instance unable to update your system or any package at all, it is possible that you have DISPLAY set to a blank value, which seems to break the GPG-Flow.

In this case, unset DISPLAY or setting it to a arbitrary value will most likely allow to update again, in case any other option above didn't do the trick yet. See this post for further details.

One may use the pacman -Qk $pkg to check if the installed files of the $pkg package match the files from its database version. For several packages, one may use the following loop to reinstall all packages which have missing file(s):

Suppose that your local database located in /var/lib/pacman is more up-to-date compared to installed packages in the / filesystem (e.g., because of a partial rollback), then this method is the appropriate one to re-synchronize the root filesystem with the local database.

**Examples:**

Example 1 (unknown):
```unknown
pacman -Ql pacman pacman-contrib | grep -E 'bin/.+'
```

Example 2 (unknown):
```unknown
pacman -Sy package_name
```

Example 3 (unknown):
```unknown
pacman -Syu package_name
```

Example 4 (unknown):
```unknown
# pacman -S package_name1 package_name2 ...
```

---

## pacman

**URL:** https://wiki.archlinux.org/title/Pacman_repositories

**Contents:**
- Usage
  - Installing packages
    - Installing specific packages
      - Virtual packages
    - Installing package groups
  - Removing packages
  - Upgrading packages
  - Querying package databases
    - Pactree
    - Database structure

The pacman package manager is one of the major distinguishing features of Arch Linux. It combines a simple binary package format with an easy-to-use Arch build system. The goal of pacman is to make it possible to easily manage packages, whether they are from the official repositories or the user's own builds.

Pacman keeps the system up-to-date by synchronizing package lists with the master server. This server/client model also allows the user to download/install packages with a simple command, complete with all required dependencies.

Pacman is written in the C programming language and uses the bsdtar(1) tar format for packaging.

What follows is just a small sample of the operations that pacman can perform. To read more examples, refer to pacman(8).

A package is an archive containing:

Arch's package manager pacman can install, update, and remove those packages. Using packages instead of compiling and installing programs yourself has various benefits:

To install a single package or list of packages, including dependencies, issue the following command:

To install a list of packages with regex (see this forum thread):

Sometimes there are multiple versions of a package in different repositories (e.g. extra and extra-testing). To install the version from the extra repository in this example, the repository needs to be defined in front of the package name:

To install a number of packages sharing similar patterns in their names, one can use curly brace expansion. For example:

This can be expanded to however many levels needed:

A virtual package is a special package which does not exist by itself, but is provided by one or more other packages. Virtual packages allow other packages to not name a specific package as a dependency, in case there are several candidates. Virtual packages cannot be installed by their name, instead they become installed in your system when you have installed a package providing the virtual package. An example is the dbus-units package.

Some packages belong to a group of packages that can all be installed simultaneously. For example, issuing the command:

will prompt you to select the packages from the gnome group that you wish to install.

Sometimes a package group will contain a large amount of packages, and there may be only a few that you do or do not want to install. Instead of having to enter all the numbers except the ones you do not want, it is sometimes more convenient to select or exclude packages or ranges of packages with the following syntax:

which will select packages 1 through 10 and 15 for installation, or:

which will select all packages except 5 through 8 and 2 for installation.

To see what packages belong to the gnome group, run:

Also visit https://archlinux.org/groups/ to see what package groups are available.

To remove a single package, leaving all of its dependencies installed:

To remove a package and its dependencies which are not required by any other installed package:

The above may sometimes refuse to run when removing a group which contains otherwise needed packages. In this case try:

To remove a package, its dependencies and all the packages that depend on the target package:

To remove a package, which is required by another package, without removing the dependent package:

Pacman saves important configuration files when removing certain applications and names them with the extension: .pacsave. To prevent the creation of these backup files use the -n option:

Pacman can update all packages on the system with just one command. This could take quite a while depending on how up-to-date the system is. The following command synchronizes the repository databases and updates the system's packages, excluding "local" packages that are not in the configured repositories:

Pacman queries the local package database with the -Q flag, the sync database with the -S flag and the files database with the -F flag. See pacman -Q --help, pacman -S --help and pacman -F --help for the respective suboptions of each flag.

Pacman can search for packages in the database, searching both in packages' names and descriptions:

Sometimes, -s's builtin ERE (Extended Regular Expressions) can cause a lot of unwanted results, so it has to be limited to match the package name only; not the description nor any other field:

To search for already installed packages:

To search for package file names in remote packages:

To display extensive information about a given package (e.g. its dependencies):

For locally installed packages:

Passing two -i flags will also display the list of backup files and their modification states:

To retrieve a list of the files installed by a package:

To retrieve a list of the files installed by a remote package:

To verify the presence of the files installed by a package:

Passing the k flag twice will perform a more thorough check.

To query the database to know which package a file in the file system belongs to:

To query the database to know which remote package a file belongs to:

To list all packages no longer required as dependencies (orphans):

To list all packages explicitly installed and not required as dependencies:

See pacman/Tips and tricks for more examples.

For advanced functionality, install pkgfile, which uses a separate database with all files and their associated packages.

To view the dependency tree of a package:

To view the dependent tree of a package, pass the reverse flag -r to pactree.

The pacman databases are normally located at /var/lib/pacman/sync. For each repository specified in /etc/pacman.conf, there will be a corresponding database file located there. Database files are gzipped tar archives containing one directory for each package, for example for the which package:

The desc file contains meta data such as the package description, dependencies, file size and MD5 hash.

Pacman stores its downloaded packages in /var/cache/pacman/pkg/ and does not remove the old or uninstalled versions automatically. This has some advantages:

However, it is necessary to deliberately clean up the cache periodically to prevent the directory to grow indefinitely in size.

The paccache(8) script, provided within the pacman-contrib package, deletes all cached versions of installed and uninstalled packages, except for the most recent three, by default:

Enable and start paccache.timer to discard unused packages weekly. You can configure the arguments for the service in /etc/conf.d/pacman-contrib, e.g with PACCACHE_ARGS='-k1' or PACCACHE_ARGS='-uk0' for the two examples below.

You can also define how many recent versions you want to keep. To retain only one past version use:

Add the -u/--uninstalled switch to limit the action of paccache to uninstalled packages. For example to remove all cached versions of uninstalled packages, use the following:

See paccache -h for more options.

Pacman also has some built-in options to clean the cache and the leftover database files from repositories which are no longer listed in the configuration file /etc/pacman.conf. However pacman does not offer the possibility to keep a number of past versions and is therefore more aggressive than paccache default options.

To remove all the cached packages that are not currently installed, and the unused sync databases, execute:

To remove all files from the cache, use the clean switch twice, this is the most aggressive approach and will leave nothing in the cache directory:

pkgcachecleanAUR and pacleanerAUR are two further alternatives to clean the cache.

Download a package without installing it:

Install a 'local' package that is not from a remote repository (e.g. the package is from the AUR):

To keep a copy of the local package in pacman's cache, use:

Install a 'remote' package (not from a repository stated in pacman's configuration files):

Pacman always lists packages to be installed or removed, and asks for permission before taking any action.

To get a list in a processable format, and to prevent the actions of -S, -U and -R, you can use -p, short for --print.

--print-format can be added to format this list in various ways. --print-format %n will return a list without package versions.

The pacman database organizes installed packages into two groups, according to installation reason:

When installing a package, it is possible to force its installation reason to dependency with:

The command is normally used because explicitly-installed packages may offer optional packages, usually for non-essential features for which the user has discretion.

When reinstalling a package, though, the current installation reason is preserved by default.

The list of explicitly-installed packages can be shown with pacman -Qe, while the complementary list of dependencies can be shown with pacman -Qd.

To change the installation reason of an already installed package, execute:

Use --asexplicit to do the opposite operation.

When successful, the workflow of a transaction follows five high-level steps plus pre/post transaction hooks:

Pacman settings are located in /etc/pacman.conf: this is the place where the user configures the program to work in the desired manner. In-depth information about the configuration file can be found in pacman.conf(5).

General options are in the [options] section. Read pacman.conf(5) or look in the default pacman.conf for information on what can be done here.

To see old and new versions of available packages, uncomment the "VerbosePkgLists" line in /etc/pacman.conf. The output of pacman -Syu will be like this:

The number of packages being downloaded in parallel (at the same time) are configured in /etc/pacman.conf with the ParallelDownloads option under [options]. The /etc/pacman.conf shipped with the pacman package sets it to 5. If the option is unset, packages will be downloaded sequentially.

To have a specific package skipped when upgrading the system, add this line in the [options] section:

For multiple packages use a space-separated list, or use additional IgnorePkg lines. Also, glob patterns can be used. If you want to skip packages just once, you can also use the --ignore option on the command-line - this time with a comma-separated list.

It will still be possible to upgrade the ignored packages using pacman -S: in this case pacman will remind you that the packages have been included in an IgnorePkg statement.

As with packages, skipping a whole package group is also possible:

All files listed with a NoUpgrade directive will never be touched during a package install/upgrade, and the new files will be installed with a .pacnew extension.

Multiple files can be specified like this:

To always skip installation of specific files or directories list them under NoExtract. For example, to avoid installing bash completion scripts, use:

Later rules override previous ones, and you can negate a rule by prepending !.

If you have several configuration files (e.g. main configuration and configuration with testing repository enabled) and would have to share options between configurations you may use Include option declared in the configuration files, e.g.:

where /path/to/common/settings file contains the same options for both configurations.

Pacman can run pre- and post-transaction hooks from the /usr/share/libalpm/hooks/ directory; more directories can be specified with the HookDir option in pacman.conf, which defaults to /etc/pacman.d/hooks. Hook file names must be suffixed with .hook. Pacman hooks are not interactive.

Pacman hooks are used, for example, in combination with systemd-sysusers and systemd-tmpfiles to automatically create system users and files during the installation of packages. For example, tomcat8 specifies that it wants a system user called tomcat8 and certain directories owned by this user. The pacman hooks systemd-sysusers.hook and systemd-tmpfiles.hook invoke systemd-sysusers and systemd-tmpfiles when pacman determines that tomcat8 contains files specifying users and tmp files.

For more information on alpm hooks, see alpm-hooks(5).

Besides the special [options] section, each other [section] in pacman.conf defines a package repository to be used. A repository is a logical collection of packages, which are physically stored on one or more servers: for this reason each server is called a mirror for the repository.

Repositories are distinguished between official and unofficial. The order of repositories in the configuration file matters; repositories listed first will take precedence over those listed later in the file when packages in two repositories have identical names, regardless of version number. In order to use a repository after adding it, you will need to upgrade the whole system first.

Each repository section allows defining the list of its mirrors directly or in a dedicated external file through the Include directive; for example, the mirrors for the official repositories are included from /etc/pacman.d/mirrorlist. See the Mirrors article for mirror configuration.

Pacman stores downloaded package files in cache, in a directory denoted by CacheDir in [options] section of pacman.conf (defaults to /var/cache/pacman/pkg/ if not set).

Cache directory may grow over time, even if keeping just the freshest versions of installed packages.

If you want to move that directory to some more convenient place, do one of the following:

Pacman supports package signatures, which add an extra layer of security to the packages. The default configuration, SigLevel = Required DatabaseOptional, enables signature verification for all the packages on a global level. This can be overridden by per-repository SigLevel lines. For more details on package signing and signature verification, take a look at pacman-key.

If you see the following error: [1]

This is happening because pacman has detected a file conflict, and by design, will not overwrite files for you. This is by design, not a flaw.

The problem is usually trivial to solve (although to be sure, you should try to find out how these files got there in the first place). A safe way is to first check if another package owns the file (pacman -Qo /path/to/file). If the file is owned by another package, file a bug report. If the file is not owned by another package, rename the file which "exists in filesystem" and re-issue the update command. If all goes well, the file may then be removed.

If you had installed a program manually without using pacman, for example through make install, you have to remove/uninstall this program with all of its files. See also Pacman tips#Identify files not owned by any package.

Every installed package provides a /var/lib/pacman/local/package-version/files file that contains metadata about this package. If this file gets corrupted, is empty or goes missing, it results in file exists in filesystem errors when trying to update the package. Such an error usually concerns only one package. Instead of manually renaming and later removing all the files that belong to the package in question, you may explicitly run pacman -S --overwrite glob package to force pacman to overwrite files that match glob.

This article or section is out of date.

Look for .part files (partially downloaded packages) in /var/cache/pacman/pkg/ and remove them (often caused by usage of a custom XferCommand in pacman.conf).

That same error may also appear if archlinux-keyring is out-of-date, preventing pacman from verifying signatures. See Pacman/Package signing#Upgrade system regularly for the fix and how to avoid it in the future.

When pacman is about to alter the package database, for example installing a package, it creates a lock file at /var/lib/pacman/db.lck. This prevents another instance of pacman from trying to alter the package database at the same time.

If pacman is interrupted while changing the database, this stale lock file can remain. If you are certain that no instances of pacman are running then delete the lock file:

This error manifests as Not found in sync db, Target not found or Failed retrieving file.

Firstly, ensure the package actually exists. If certain the package exists, your package list may be out-of-date. Try running pacman -Syu to force a refresh of all package lists and upgrade. Also make sure the selected mirrors are up-to-date and repositories are correctly configured. You can also use Reflector to keep the mirrors up-to-date.

If pacman reports there is nothing to update, but the Failed retrieving file error continues to be printed, consider forcing a database download with pacman -Syyu. This is never needed under normal circumstances, so inspect more closely the status and consistency of the mirror.

It could also be that the repository containing the package is not enabled on your system, e.g. the package could be in the multilib repository, but multilib is not enabled in your pacman.conf.

See also FAQ#Why is there only a single version of each shared library in the official repositories?.

This article or section needs expansion.

Whether due to power loss, kernel panic or hardware failure an update may be interrupted. In most cases, there will not be much damage but the system will likely be unbootable.

Replicating the exact upgrade is needed to ensure the right scriptlets and hooks will run.

In the case that pacman crashes with a "database write" error while removing packages, and reinstalling or upgrading packages fails thereafter, do the following:

If /var/cache/pacman/pkg is a symlink, pacman will try to make a directory instead and thus remove this symlink during self-upgrade. This will cause the update to fail. As a result, /usr/bin/pacman and other contents of the pacman package will be missing.

Never symlink /var/cache/pacman/pkg because it is controlled by pacman. Use the CacheDir option or a bind mount instead; see #Package cache directory.

If you have already encountered this problem and broke your system, you can manually extract /usr contents from the package to restore pacman and then reinstall it properly; see FS#73306 and related forum thread for details.

pacman-staticAUR is a statically compiled version of pacman, so it will be able to run even when the libraries on the system are not working. This can also come in handy when a partial upgrade was performed and pacman can not run anymore.

The pinned comment and the PKGBUILD provides a way to directly download the binary, which can be used to reinstall pacman or to upgrade the entire system in case of partial upgrades.

In some situations, your system may be too broken (e.g., due to missing or incompatible libraries) to run `makepkg` or build the `pacman-static` package from the AUR successfully.

If building from the PKGBUILD fails or `makepkg` cannot be run, you can download a precompiled `pacman-static` binary from a trusted source. This static binary does not depend on system libraries and can be used to restore a working `pacman` on your system.

A reliable source for the binary is:

This will update your system and reinstall `pacman`, fixing broken dependencies related to missing shared libraries.

If even pacman-static does not work, it is possible to recover using an external pacman. One of the easiest methods to do so is by using the archiso and simply using --sysroot or --root to specify the mount point of the system to perform the operation on. See Chroot#Using chroot on how to mount the necessary filesystems required by --sysroot.

Even if pacman is terribly broken, you can fix it manually by downloading the latest packages and extracting them to the correct locations. The rough steps to perform are:

If you have a healthy Arch system on hand, you can see the full list of dependencies with:

But you may only need to update a few of them depending on your issue. An example of extracting a package is

Note the use of the w flag for interactive mode. Running non-interactively is very risky since you might end up overwriting an important file. Also take care to extract packages in the correct order (i.e. dependencies first). This forum post contains an example of this process where only a couple pacman dependencies are broken.

Most likely the initramfs became corrupted during a kernel update (improper use of pacman's --overwrite option can be a cause). There are two options; first, try the Fallback entry.

Once the system starts, run this command (for the stock linux kernel) either from the console or from a terminal to rebuild the initramfs image:

If that does not work, from a current Arch release (CD/DVD or USB stick), mount your root and boot partitions to /mnt and /mnt/boot, respectively. Then chroot using arch-chroot:

Reinstalling the kernel (the linux package) will automatically re-generate the initramfs image with mkinitcpio -p linux. There is no need to do this separately.

Afterwards, it is recommended that you run exit, umount /mnt/{boot,} and reboot.

As the error message says, your locale is not correctly configured. See Locale.

When locale files are intentionally removed by tools such as bleachbit or localepurgeAUR, pacman may issue warnings about missing locales during package updates.

To suppress these warnings, you can comment out the CheckSpace option in pacman.conf. Keep in mind that disabling CheckSpace turns off the space-checking functionality for all package installations, so use this workaround only when you have alternative means to monitor disk space.

Make sure that the relevant environment variables ($http_proxy, $ftp_proxy etc.) are set up. If you use pacman with sudo, you need to configure sudo to pass these environment variables to pacman. Also, ensure the configuration of dirmngr has honor-http-proxy in /etc/pacman.d/gnupg/dirmngr.conf to honor the proxy when refreshing the keys.

To reinstall all the native packages: pacman -Qnq | pacman -S - or pacman -S $(pacman -Qnq) (the -S option preserves the installation reason by default).

You will then need to reinstall all the foreign packages, which can be listed with pacman -Qmq.

It looks like previous pacman transaction removed or corrupted shared libraries needed for pacman itself.

To recover from this situation, you need to unpack required libraries to your filesystem manually. First find what package contains the missed library and then locate it in the pacman cache (/var/cache/pacman/pkg/). Unpack required shared library to the filesystem. This will allow to run pacman.

Now you need to reinstall the broken package. Note that you need to use --overwrite flag as you just unpacked system files and pacman does not know about it. Pacman will correctly replace our shared library file with one from package.

That's it. Update the rest of the system.

Some issues have been reported regarding network problems that prevent pacman from updating/synchronizing repositories. [2] [3] When installing Arch Linux natively, these issues have been resolved by replacing the default pacman file downloader with an alternative (see Improve pacman performance for more details). When installing Arch Linux as a guest OS in VirtualBox, this issue has also been addressed by using Host interface instead of NAT in the machine properties.

If you receive this error message with correct mirrors, try setting a different name server.

If you want to install a package on an sshfs mount using pacman -U and receive this error, move the package to a local directory and try to install again.

Upon executing, e.g., pacman -Syu inside a chroot environment an error is encountered:

This is frequently caused by the chroot directory not being a mountpoint when the chroot is entered. See the note at Install Arch Linux from existing Linux#Downloading basic tools for a solution, and arch-chroot(8) for an explanation and an example of using bind mounting to make the chroot directory a mountpoint.

If you are unable to update packages and receive this error, then try rm -r /var/lib/pacman/sync/ before attempting to update.

If removing sync files doesn't help, check that the sync files are gzip compressed data using file /var/lib/pacman/sync/* before attempting to update. A router or proxy might corrupt the downloads. Corruption could possibly be HTML type.

If sync files are of the correct type, there might be an issue with the mirror server. Look up the mirror server(s) in use with pacman-conf -r core and pacman-conf -r extra. Paste the first returned url in a browser and check that a file listing is returned. In case the mirror returns an error, comment it in /etc/pacman.d/mirrorlist. You may try updating or re-ranking mirrors.

If this error occurs and you're for instance unable to update your system or any package at all, it is possible that you have DISPLAY set to a blank value, which seems to break the GPG-Flow.

In this case, unset DISPLAY or setting it to a arbitrary value will most likely allow to update again, in case any other option above didn't do the trick yet. See this post for further details.

One may use the pacman -Qk $pkg to check if the installed files of the $pkg package match the files from its database version. For several packages, one may use the following loop to reinstall all packages which have missing file(s):

Suppose that your local database located in /var/lib/pacman is more up-to-date compared to installed packages in the / filesystem (e.g., because of a partial rollback), then this method is the appropriate one to re-synchronize the root filesystem with the local database.

**Examples:**

Example 1 (unknown):
```unknown
pacman -Ql pacman pacman-contrib | grep -E 'bin/.+'
```

Example 2 (unknown):
```unknown
pacman -Sy package_name
```

Example 3 (unknown):
```unknown
pacman -Syu package_name
```

Example 4 (unknown):
```unknown
# pacman -S package_name1 package_name2 ...
```

---

## Go package guidelines

**URL:** https://wiki.archlinux.org/title/Go_package_guidelines

**Contents:**
- General guidelines
  - Package naming
- Building
  - Dependencies
    - Upstream project without go modules
    - Upstream project with go modules
  - Flags and build options
    - Flag meaning
    - Supporting debug packages
  - Output directory

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

This document covers standards and guidelines on writing PKGBUILDs for Go.

Use go-modulename if the package provides a program that is strongly coupled to the Go ecosystem. For other applications, use only the program name.

Go 1.11 introduced the initial support for go modules. This allows Go upstream code to declare dependencies and pin them to the given project version. Currently our packaging efforts utilize this to vendor dependencies.

For upstream code that does not utilise Go modules, the following workaround exists. Consider filing an issue upstream.

By default, go will use GOPATH to download and store go modules. It will grow the user ~/go directory.

To keep all go modules in the package build environment, you can can add a prepare step to configure GOPATH="${srcdir}", and download the go modules in the package src directory.

Most Makefiles written for go applications do not respect the build flags provided by build systems along with overwriting GOFLAGS, this causes Go binaries to not be compiled with RELRO as we need CGO_CFLAGS and CGO_LDFLAGS to be set for the compiler. This needs to be patched into the Makefile, or the Makefile should be omitted.

Enabling debug packages with source listing and proper symbol look ups require a few modifications to the default buildflags.

The above options should produce a debug package with proper detached symbols and source listings which can then be picked up by the debugger.

There are currently a few ways to build all go binaries in a project.

... is a shorthand for the compiler to recursively descend into the directory and find all binaries. It can be used in conjunction with a output directory to build everything.

**Examples:**

Example 1 (unknown):
```unknown
go-modulename
```

Example 2 (unknown):
```unknown
url=https://github.com/upstream_user/upstream_project

prepare() {
  cd "$pkgname-$pkgver"
  go mod init "${url#https://}" # strip https:// from canonical URL
  go mod tidy
}
```

Example 3 (unknown):
```unknown
GOPATH="${srcdir}"
```

Example 4 (unknown):
```unknown
prepare() {
  cd "${pkgname}-${pkgver}"
  export GOPATH="${srcdir}"
  go mod download -modcacherw
}
```

---

## R package guidelines

**URL:** https://wiki.archlinux.org/title/R_package_guidelines

**Contents:**
- Package naming
- Package Version
- Arch
- Dependencies
- Source
- Build and Package
  - MRAN
  - CRAN
  - Bioconductor
- Tips and tricks

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

This document covers standards and guidelines on writing PKGBUILDs for R packages. Most information can be obtained by looking at the package's DESCRIPTION file. You can get most of this from inside R by running tools::CRAN_package_db(). You could also visit CRAN, Bioconductor link1, and Bioconductor link2 for all the R packages' information.

Packages should be named r-pkgname, where pkgname is taken from the Package field from the DESCRIPTION file. The package name should be lowercase.

Take it from the Version field. R allows packages to have colons and hyphens in their version, this is disallowed in PKGBUILDs. Convert these to a period or underscore.

See PKGBUILD#arch. If the package's CRAN webpage has NeedsCompilation: yes it is likely architecture-specific. Otherwise, it is likely not.

R packages listed in Depends, Imports, or the LinkingTo fields in a package's DESCRIPTION file should be listed under depends.

R packages listed in Suggests should be listed as optdepends.

Some packages require external tools, these are listed under SystemRequirements.

gcc-fortran is needed as depends for some packages but is not always listed in the DESCRIPTION file.

All R packages available on CRAN are available at the website https://cran.r-project.org/src/contrib/cranname_cranversion.tar.gz where cranname is the name of the package on CRAN and cranversion the cran version.

R packages avalable on Bioconductor are available at the website https://bioconductor.org/packages/release/bioc/src/contrib/bcname_bcname.tar.gz or https://bioconductor.org/packages/release/data/annotation/src/contrib/bcname_bcname.tar.gz where bcname is the name of the package on Bioconductor and bcver the version.

R has built-in support for building packages. Here are three templates of PKGBUILDs for three repositories: MRAN, CRAN and Bioconductor. MRAN is a snapshot mirror of CRAN, using this template will allow the package to build even when out-of-date.

To access the bioconductor packages easily, you can add the bioarchlinux repository.

**Examples:**

Example 1 (unknown):
```unknown
DESCRIPTION
```

Example 2 (unknown):
```unknown
tools::CRAN_package_db()
```

Example 3 (unknown):
```unknown
DESCRIPTION
```

Example 4 (unknown):
```unknown
NeedsCompilation: yes
```

---

## DeveloperWiki:Building in a clean chroot

**URL:** https://wiki.archlinux.org/title/Building_in_a_clean_chroot

**Contents:**
- Convenience way
- Classic way
  - Setting up a chroot
    - Custom pacman.conf
  - Building in the chroot
    - Pre-install required packages
    - Passing arguments to makepkg
- Handling major rebuilds
- Tips and tricks
  - Build in tmpfs

Building in a clean chroot prevents missing dependencies in packages, whether due to unwanted linking or packages missing in the depends array in a PKGBUILD file. It also allows users to build a package for the stable repositories (core, extra) while having packages from core-testing or extra-testing installed.

To quickly build a package in a clean chroot without any further tinkering, one can use the helper scripts from the devtools package.

These helper scripts—for example, pkgctl build—should be called in the same directory where the PKGBUILD file is, just like with makepkg. For instance, extra-x86_64-build automatically sets up a chroot from a clean chroot matrix in /var/lib/archbuild, updates it, and builds a package for the extra repository. For multilib builds there is just multilib-build without an architecture. Consult the table below for information on which script to use when building for a specific repository and architecture.

The -c parameter resets the chroot matrix, which can be useful in case of breakage. It is not needed for building in a clean chroot.

The devtools package provides tools for creating and building within clean chroots. Install it if not done already.

To make a clean chroot, create a directory in which the chroot will reside. For example, $HOME/chroot.

Define the CHROOT variable:

Now create the chroot (the sub directory root is required because the $CHROOT directory will get other sub directories for clean working copies):

Edit ~/.makepkg.conf to set the packager name and any makeflags. Also adjust the mirrorlist in $CHROOT/root/etc/pacman.d/mirrorlist and enable the testing repositories in $CHROOT/root/etc/pacman.conf, if desired.

Alternatively, provide a custom pacman.conf and makepkg.conf with the following:

Firstly, make sure the base chroot ($CHROOT/root) is up to date:

Then, build a package by calling makechrootpkg in the directory containing its PKGBUILD file:

To build a package with dependencies unavailable from the repositories enabled in $CHROOT/root/pacman.conf, pre-install them to the working chroot with -I package:

To pass arguments to makepkg, list them after an end-of-options marker[dead link 2025-08-16—domain name not resolved]; e.g., to force a check():

The cleanest way to handle a major rebuild is to use the staging repositories. Build the first package against extra and push it to staging. Then rebuild all following packages against staging and push them there.

If you cannot use staging, you can build against custom packages using a command like this:

You can specify more than one package to be installed using multiple -I arguments.

A simpler, but dirtier way to handle a major rebuild is to install all built packages in the chroot, never cleaning it. Build the first package using:

And build all following packages using:

Running namcap (the -n argument) implies installing the package in the chroot. *-build also does this by default.

If the system has enough RAM, it is possible to specify a tmpfs for the devtools build scripts:

Just delete the chroot directory and its corresponding .lock file.

**Examples:**

Example 1 (unknown):
```unknown
pkgctl build
```

Example 2 (unknown):
```unknown
extra-x86_64-build
```

Example 3 (unknown):
```unknown
/var/lib/archbuild
```

Example 4 (unknown):
```unknown
multilib-build
```

---

## Package Maintainers

**URL:** https://wiki.archlinux.org/title/TU

**Contents:**
- How do I become a Package Maintainer?
- Active Package Maintainers
- Past Package Maintainers

Package Maintainers (previously called Trusted Users) are an official Arch Linux staff role. Package Maintainers fulfill the following tasks:

The generic term "package maintainer" is also used to describe any person maintaining a package, regardless of the repository, as described in Arch terminology#Package maintainer.

The minimum requirements to becoming a Package Maintainer are as follows:

Even though you could become a Package Maintainer by merely fulfilling those minimum requirements, the people judging you during the standard voting procedure might expect more from you. Such as:

If you still feel up to becoming a Package Maintainer after reading these lines, the first step is to find two Package Maintainers who agree to sponsor you. Once sponsored, you should write a witty application signed with your GPG key to the aur-general mailing list.

For more information, see the Package Maintainer Bylaws and Package Maintainer guidelines.

See https://archlinux.org/people/package-maintainers/

See https://archlinux.org/people/package-maintainer-fellows/

---

## Meta package and package group

**URL:** https://wiki.archlinux.org/title/Package_group

**Contents:**
- Difference between meta package and package group
- Meta packages
- Groups

A meta package and a package group can be defined by the packager to denote a set of related packages. Both can allow to install or uninstall this set of packages simultaneously by using the meta package or the group name as a substitute for each individual package name. While a group is not a package, it can be installed in a similar fashion to a package, see pacman#Installing package groups and PKGBUILD#groups.

The difference between a meta package and a regular package is that a meta package is empty and exists purely to link related packages together via dependencies. A meta package, often (though not always) titled with the "-meta" suffix, provides similar functionality to a package group in that it enables multiple related packages to be installed or uninstalled simultaneously.

Each solution has advantages and disadvantages:

The most important meta package is base. It contains a minimal package set that defines a basic Arch Linux installation. It includes:

The kernel is an optional dependency. See the announcement when it was introduced, and reasoning why base is a meta package.

An other common meta package is base-devel. It contains a complete build environment for makepkg. See the reasoning why it has become a meta package.

Package groups are commonly used to facilitate the installation of desktop environments. See Desktop environment#List of desktop environments.

An other example is the pro-audio group for the professional audio software available in the official repositories.

See the list of all package groups.

**Examples:**

Example 1 (unknown):
```unknown
pacman -R groupname
```

Example 2 (unknown):
```unknown
comm -23 <(pacman -Sg package_group | awk '{print $2}' | sort) <(pacman -Qq | sort)
```

Example 3 (unknown):
```unknown
package_group
```

---

## Common Desktop Environment

**URL:** https://wiki.archlinux.org/title/CDE

**Contents:**
- Installation
- Usage
  - dtlogin
  - xinit
- See also

The Common Desktop Environment is a desktop environment for Unix and OpenVMS, based on the Motif widget toolkit. It was part of the UNIX98 Workstation Product Standard, and was long the "classic" Unix desktop associated with commercial Unix workstations. Despite being a legacy environment, it is still kept alive with support for Linux systems as well.

The base CDE system is installed through the cdesktopenvAUR package.

The cdesktopenvAUR package supplies dtlogin.service which upon starting will launch the CDE login manager.

CDE can be directly launched with startx (install xorg-xinit):

**Examples:**

Example 1 (unknown):
```unknown
dtlogin.service
```

Example 2 (unknown):
```unknown
$ export PATH=$PATH:/usr/dt/bin
$ export LANG=C
$ startx /usr/dt/bin/Xsession
```

---

## distcc

**URL:** https://wiki.archlinux.org/title/Distcc

**Contents:**
- Installation
- Configuration
  - Modes of operation
  - Volunteers
  - Client
    - For use with makepkg
      - Plain mode example
      - Pump mode example
    - For use without makepkg
      - Plain mode example

distcc is a program to distribute builds of C, C++, Objective C or Objective C++ code across several machines on a network to speed up building. It should always generate the same results as a local build, is simple to install and use, and is usually much faster than a local compile. Further, one can use it together with native Arch build tools such as makepkg.

This page uses the following terms:

Install the distcc package on all participating PCs in the distcc cluster. For other distributions, or even operating systems including Windows through using Cygwin, refer to the distcc docs or the included man pages distcc(1) and distccd(1). Be sure to allow traffic through the port on which distcc runs (the default is 3632/tcp), see Category:Firewalls.

Distcc can be run in plain mode (default) or in pump mode. At a high level, the key difference is in how distcc deals with preprocessed source. Plain mode transfers the complete source and compiler arguments. Preprocessing is kept on the client. Pump mode distributes both preprocessing and compilation to the distcc cluster which, in many cases, is more efficient and faster. See distcc(1) for more details.

The configuration for the volunteer is stored in /etc/conf.d/distccd. At a minimum, add the --allow-private switch which covers a number of ipv4 private network ranges, or if you have a ipv6 capable network then use --allow with your ipv6 CIDR. Logging to a file is also nice for troubleshooting if needed.

Or if you need to allow ipv6 access and your network CIDR is /64:

If multiple interfaces are present on the machine, consider passing the --listen ADDRESS option as well. Other options can be defined. Refer to distccd(1).

Start distccd.service on every participating volunteer. To have distccd.service start at boot-up, enable it.

Edit /etc/makepkg.conf in the following sections:

It should be noted that there are no true universal configurations. Try one, test it, compare the results to other setups. The following are a few common setups:

Several things to call out here:

The minimal configuration for distcc on the client includes the setting of the available volunteers and re-defining the PATH.

No special steps are needed once /etc/makepkg.conf has been configured. Simply call makepkg as normal.

The user must start pump prior to compiling whether with makepkg or on the shell. Since pump includes a check to make sure there is a set of DISTCC_HOSTS correctly configured, we need to first define a bogus DISTCC_HOSTS line. Remember that makepkg will use the values specified in /etc/makepkg.conf.

Now call makepkg as normal.

When finished, optionally stop pump:

After exporting the two variables described in #For use without makepkg, simply call the compiler:

Some programs may require one to define the CC and/or CXX variable to work properly:

Start pump as illustrated above. Compilation is no different than plain mode.

Use the following CMake options to build a CMake-based project with distcc:

distcc ships with a cli monitor distccmon-text one can use to check on compilation status.

The cli monitor can run continuously by appending a space followed by integer to the command which corresponds to the number of sec to wait for a repeat query:

One can use distcc to help cross compile:

This section details how to use Arch Linux (x86_64) volunteers to help an Arch ARM device cross-compile. See these tests for evidence that speed gains on the order of 2-4x can be realized with just a single x86_64 machine helping an ARM device compile.

The Arch ARM developers highly recommend using the official project toolchains which should be installed on the x86_64 volunteer(s). Rather than manually managing these, the AUR provides two toolchains as well as configuration and systemd service units:

Setup on the volunteer containing the arm/arm64 toolchains is identical to #Volunteers except that the name of the configuration and systemd service file matches that of the respective package. For example, for armv7h the configuration file is /etc/conf.d/distccd-armv7h and the systemd service unit is distccd-armv7h.service.

Note that each of the toolchains runs on a unique port thus allowing all four of them to co-exist on the volunteer if needed. Be sure to allow traffic to the port on which distcc runs see Category:Firewalls and distcc(1).

The easiest method to setup the Arch ARM client is to use distccd-arch-armAUR. It provides all four configurations and systemd service units covering all four flavors of Arch ARM. For example, if the Arch ARM client is running an armv7h image, optionally edit /etc/conf.d/distccd-armv7h and change the defaults therein. When ready to build, enable distccd-armv7h.service and compile.

For a more detailed tutorial, see usage-examples.

If one would rather setup the client without using the AUR package mentioned above, manual setup of the client is identical to #Client except, one needs to modify the following two files to define the now non-standard port the volunteers are expected to use. Refer to the table above if using the AUR package.

When building on Arch ARM devices using x86_64 volunteers, it is highly recommended to exclude the localhost directive from DISTCC_HOSTS since many ARM devices do not have the needed processing power.

To illustrate this effect, consider the following example compiling the linux kernel version 5.10.44's Image target. The client is a RPi4B (aarch64) and the volunteer (192.168.1.288) is a quad core/hyper threaded Intel machine. Each compile job was run only once and make clean was run in between them.

This section details how to use Arch ARM volunteers to help an x86_64 client cross-compile. See these tests for evidence that compilation times can be significantly sped up using even 1 Arch ARM volunteer and that up to 2 can double that gain.

Setup of the client is identical to #Client with distcc running on the standard port 3632.

distccd-x86_64AUR will provide a toolchain to install on the Arch ARM devices to enable cross compilation.

The EmbToolkit provides a nice graphical configuration menu (make xconfig) for configuring the tool chain.

If building the kernel from the official PKGBUILD (or many from the AUR), distcc will not work due to the fact that the kernel is hard-coded to use GCC plugins which cannot be supported by distccd due to technical reasons.

A workaround is to edit the kernel source removing the hard-coded requirement of GCC plugins. This can be accomplished with a sed one liner in the PKGBUILD itself inserted before the make step:

Failure to do this will result in distcc not working during the build. See FS#64275.

Another option is to pass the CC=distcc and CXX=distcc variables as part of the build command:

Compiling chromium which uses clang is currently affected by issue#386. In order to circumvent the bug, add the following to the _flags array in the PKGBUILD:

Use journalctl to find out what was going wrong:

By default, distcc will log to /var/log/messages.log as it goes along. One trick (actually recommended in the distccd manpage) is to log to an alternative file directly. Again, one can locate this in RAM via /tmp. Another trick is to lower to log level of minimum severity of error that will be included in the log file. Useful if only wanting to see error messages rather than an entry for each connection. LEVEL can be any of the standard syslog levels, and in particular critical, error, warning, notice, info, or debug.

Either call distcc with the arguments mentioned here on the client or appended it to DISTCC_ARGS in /etc/conf.d/distccd on the volunteers:

By default, distcc creates $HOME/.distcc which stores transient relevant info as it serves up work for nodes to compile. This will avoid needless HDD read/writes and is particularly important for SSDs.

Errors similar to the following indicate that the user is mistakenly running the distccd service provided by distcc and NOT provided by the distccd-alarm packages (i.e. distccd-alarm-armv7hAUR, or distccd-alarm-armv8AUR.)

Be sure to start the correct service for the target architecture.

The factual accuracy of this article or section is disputed.

Launching distccd.service as a service might cause avahi-daemon to stop working. This can be mitigated by making sure avahi-daemon.service starts after distccd.service by editing avahi-daemon.service's unit file (see systemd#Editing provided units) and adding After=distccd.service at the end of the [Unit] section:

**Examples:**

Example 1 (unknown):
```unknown
/etc/conf.d/distccd
```

Example 2 (unknown):
```unknown
--allow-private
```

Example 3 (unknown):
```unknown
DISTCC_ARGS="--allow-private --log-file /tmp/distccd.log"
```

Example 4 (unknown):
```unknown
DISTCC_ARGS="--allow-private --allow aaaa:bbbb:cccc:dddd:eeee:::/64 --log-file /tmp/distccd.log"
```

---

## AUR Cleanup Day

**URL:** https://wiki.archlinux.org/title/AUR_Cleanup_Day

**Contents:**
- About
- Template

AUR Cleanup Day is a bi-yearly (odd years) event on the 20th of September.

The AUR has a large number of obsolete packages which could use cleaning up. Post suggestions of packages to the collaborative doc (template below) linked in the announcement email, submit them to the aur-general mailing list, or file requests directly. Package Maintainers will get together and confirm which packages should be removed.

Join #archlinux-aur to collaborate and chat.

**Examples:**

Example 1 (unknown):
```unknown
# AUR Cleanup Day September 20th 20XY

## About

AUR Cleanup Day is a bi-yearly (odd years) event on the 20th of September.

The [AUR](https://wiki.archlinux.org/title/Arch_User_Repository) has a large number of obsolete packages which could use cleaning up. Post suggestions of packages below, submit them to the [aur-general mailing list](https://lists.archlinux.org/listinfo/aur-general), or file [requests](https://wiki.archlinux.org/title/AUR_submission_guidelines#Requests) directly. [Package Maintainers](https://wiki.archlinux.org/title/Package_Maintainers) will get together and confirm which packages should be removed.

Join [#archlinux-aur](https://wiki.archlinux.org/title/Arch_IRC_channels) to collaborate and chat.

## Template (Package list)

### Candidates

Check for the package in the sorted lists below before adding.

- [PKGNAME](https://aur.archlinux.org/packages/PKGNAME) - Reason

#### Informative heading

- [PKGBASE](https://aur.archlinux.org/pkgbase/PKGBASE) - Reason

### Possible reasons

- Does not work anymore

- Deprecated by [PKGNAME](https://aur.archlinux.org/packages/PKGNAME)

- Obsoleted by [PKGNAME](https://aur.archlinux.org/packages/PKGNAME)

- Replaced by [PKGNAME](https://aur.archlinux.org/packages/PKGNAME)

- Duplicate of [PKGNAME](https://aur.archlinux.org/packages/PKGNAME)

- Project page and sources are not available

- "Dead" project; it's very old and does not work with the latest versions of its dependencies

- "Dead" project and too old to be useful

- Project page and sources are not available

- Not needed anymore (it's for old PKGNAME), broken source link

- Old dev-version (CVS/SVN/etc), PKGNAME project uses Git now

- Is it needed in Arch Linux?

- Broken links (see comment by USERNAME)

- Outdated for a long time

- This one should be renamed

- Deprecated by upstream

- Outdated, orphaned

- Broken links, too old, not maintained

- Included in extra/PKGNAME

- Already included in core/PKGNAME

- Old beta version, broken source link, replaced by [PKGNAME](https://aur.archlinux.org/packages/PKGNAME)

- Maintainer wrote that it may be deleted

- Dropped upstream

- Depends on [PKGNAME](https://aur.archlinux.org/packages/PKGNAME) and has not been updated for N years...

- Development discontinued, project page deleted and current version does not work

- Too old to be useful, broken source link -- hm, what is USERNAME's Opinion?

- This package is no longer needed (see comments)

## Template (TU)

**For editing by TUs only!**

### Packages to Remove

In extra:

- [PKGNAME](https://aur.archlinux.org/packages/PKGNAME) - Replaced by PKGNAME

### Packages to Keep

- [PKGNAME](https://aur.archlinux.org/packages/PKGNAME) - Reason

#### Possible reasons

- It is for compiling old stuff, let's keep it, does not harm

- Seems to be actively maintained

- Still useful, because ...

- So this package should maybe be orphaned, no obvious reason to delete it

- Needed by PKGNAME

- Package has new and active maintainer

- Seems to be down sometimes, but sometimes it works again. Package is maintained and has votes

- Should be rewritten, not dropped

- I orphaned the package

- It's not dead, it only needs some changes to work again

- Package builds with little tweaking

- Builds fine with a little patch in pkgrel N
```

---

## Nemo

**URL:** https://wiki.archlinux.org/title/Nemo

**Contents:**
- Installation
  - Extensions
- Configuration
  - Set Nemo as default file browser
  - Show / hide desktop icons
  - Change the default terminal emulator for Nemo
  - Set keyboard shortcut for "Open in terminal"
- Tips and tricks
  - Nemo Actions
    - Clam Scan

Nemo is a fork of GNOME Files (formerly known as Nautilus). It is also the default file manager of the Cinnamon desktop. Nemo is based on the Files 3.4 code. It was created as a response to the changes in Files 3.6 which saw features such as type ahead find and split pane view removed.

Install the nemo package.

Some programs can add extra functionality to Nemo. Here are a few packages that do just that:

See AUR and nemo-extensions github repo for all extensions.

Nemo is simple to configure graphically but not all options are in the preferences screen in Nemo. More options are available in the dconf-editor under org.nemo.

To set Nemo as the default file browser, execute the following:

To enable/disable desktop icons rendering feature in nemo, change the following setting true or false (false to hide, true to show):

This fixes the console warning WARNING **: Can not determine workarea, guessing at layout for tiling window managers (such as i3).

gnome-terminal is set as the default, if it is not installed, neither the "Open in terminal" context menu entry feature will not work, nor shell scripts or terminal applications will not run from Nemo.

You can change the default setting with gsettings to the preferred terminal application.

To be able to run shell scripts from Nemo, make sure you set up the proper argument for the preferred terminal application (the default is -x for gnome-terminal).

If you want to edit keyboard shortcuts, you need first to change /org/cinnamon/desktop/interface/can-change-accels respectively /org/gnome/desktop/interface/can-change-accels if you are using Gnome desktop. You can do that with dconf-editor or with this code in terminal:

Edit or create ~/.gnome2/accels/nemo and add the following line (replacing "F4" with the desired key combination):

<Alt>, <Primary>, and <Shift> can be used as key modifiers (for example, <Primary><Shift>t).

Nemo allows the user to add new entries to the context menu. The file /usr/share/nemo/actions/sample.nemo_action contains an example of a Nemo action. Directories to place custom action files:

Action files must have the .nemo_action file extension.

By default, Nemo does not escape filenames. This means that actions for multiple files with some names containing spaces are broken. To fix this, use Quote=double.

By installing gvfs and the various gvfs-* packages, you can add support for various network based filesystems (e.g. SMB, NFS, WebDAV, Nextcloud) and some mobile phones (Android MTP, Apple AFC).

For more information and other supported virtual filesystems, see File manager functionality.

By default, nemo does not generate thumbnails for certain video files due to licensing or patent problems (AVC encoded mp4 and mkv files for example). As such, you might see errors similar to the following in the console:

for mp4 and other video files.

To fix this, ensure that you have a thumbnailer for video files installed—see File manager functionality#Thumbnail previews—and also ensure you have the necessary GStreamer packages installed that will allow the video file to be played.

Since Nemo v3.4.2, the desktop is managed by nemo-desktop. This can be configured to auto start by copying the file /usr/share/applications/nemo-autostart.desktop to ~/.config/autostart/nemo-autostart.desktop and removing the line OnlyShowIn=X-Cinnamon;.

Nemo was changed since v5.0.1 to allow the sort order to be maintained when passing multiple files to the image viewer. There is also a new GNOME setting to enable or disable it.

See https://github.com/linuxmint/nemo/issues/2771 for more information.

**Examples:**

Example 1 (unknown):
```unknown
$ xdg-mime default nemo.desktop inode/directory application/x-gnome-saved-search
```

Example 2 (unknown):
```unknown
$ gsettings set org.nemo.desktop show-desktop-icons false
```

Example 3 (unknown):
```unknown
WARNING **: Can not determine workarea, guessing at layout
```

Example 4 (unknown):
```unknown
$ gsettings set org.cinnamon.desktop.default-applications.terminal exec terminal-name
```

---

## getty

**URL:** https://wiki.archlinux.org/title/Tty

**Contents:**
- Installation
- Tips and tricks
  - Staircase effect
  - Add additional virtual consoles
  - Automatic login to virtual console
    - Virtual console
    - Serial console
    - Nspawn console
  - Prompt only the password for a default user in virtual console login
  - Have boot messages stay on tty1

A getty is the generic name for a program which manages a terminal line and its connected terminal. Its purpose is to protect the system from unauthorized access. Generally, each getty process is started by systemd and manages a single terminal line.

agetty is the default getty in Arch Linux, as part of the util-linux package.

An alternative is mingettyAUR.

agetty modifies the TTY settings while waiting for a login so that the newlines are not translated to CR-LFs. This tends to cause a "staircase effect" for messages printed to the console.

It is entirely harmless, but in the event it persists once logged, you can fix this behavior with:

See this forums discussion on the subject.

Agetty manages virtual consoles and six of these virtual consoles are provided by default in Arch Linux. They are usually accessible by pressing Ctrl+Alt+F1 through Ctrl+Alt+F6.

Open the file /etc/systemd/logind.conf and set the option NAutoVTs=6 to the number of virtual terminals that you want at boot.

If needed, it is possible to temporarily start a getty@ttyN.service service directly.

Configuration relies on systemd unit drop-in files to override the default parameters passed to agetty.

Configuration differs for virtual versus serial consoles. In most cases, you want to set up automatic login on a virtual console, (whose device name is ttyN, where N is a number). The configuration of automatic login for serial consoles will be slightly different. Device names of the serial consoles look like ttySN, where N is a number.

Create a drop-in file for getty@tty1.service with the following contents:

If you do not want full automatic login, but also do not want to type your username, see #Prompt only the password for a default user in virtual console login.

If you want to use a tty other than tty1, see systemd/FAQ#How do I change the default number of gettys?.

Create a drop-in file:

To configure auto-login for a systemd-nspawn container, override console-getty.service by creating a drop-in file:

If machinectl login my-container method is used to access the container, also adjust the container-getty@.service template that manages pts/[0-9] pseudo ttys:

Getty can be used to login from a virtual console with a default user, typing the password but without needing to insert the username. For instance, to prompt the password for username on tty1:

By default, Arch has the getty@tty1 service enabled. The service file already passes --noclear, which stops agetty from clearing the screen. However systemd clears the screen before starting it. To disable this behavior, create a drop-in file:

This article or section is a candidate for merging with Display Power Management Signaling#Linux console.

When the system is used as a server but has a display connected, the display will be turned on forever. To turn off display after 5 minutes create a drop-in file. On any key press, display will turn back on.

**Examples:**

Example 1 (unknown):
```unknown
$ stty onlcr
```

Example 2 (unknown):
```unknown
Ctrl+Alt+F1
```

Example 3 (unknown):
```unknown
Ctrl+Alt+F6
```

Example 4 (unknown):
```unknown
/etc/systemd/logind.conf
```

---

## Meta package and package group

**URL:** https://wiki.archlinux.org/title/Meta_package

**Contents:**
- Difference between meta package and package group
- Meta packages
- Groups

A meta package and a package group can be defined by the packager to denote a set of related packages. Both can allow to install or uninstall this set of packages simultaneously by using the meta package or the group name as a substitute for each individual package name. While a group is not a package, it can be installed in a similar fashion to a package, see pacman#Installing package groups and PKGBUILD#groups.

The difference between a meta package and a regular package is that a meta package is empty and exists purely to link related packages together via dependencies. A meta package, often (though not always) titled with the "-meta" suffix, provides similar functionality to a package group in that it enables multiple related packages to be installed or uninstalled simultaneously.

Each solution has advantages and disadvantages:

The most important meta package is base. It contains a minimal package set that defines a basic Arch Linux installation. It includes:

The kernel is an optional dependency. See the announcement when it was introduced, and reasoning why base is a meta package.

An other common meta package is base-devel. It contains a complete build environment for makepkg. See the reasoning why it has become a meta package.

Package groups are commonly used to facilitate the installation of desktop environments. See Desktop environment#List of desktop environments.

An other example is the pro-audio group for the professional audio software available in the official repositories.

See the list of all package groups.

**Examples:**

Example 1 (unknown):
```unknown
pacman -R groupname
```

Example 2 (unknown):
```unknown
comm -23 <(pacman -Sg package_group | awk '{print $2}' | sort) <(pacman -Qq | sort)
```

Example 3 (unknown):
```unknown
package_group
```

---

## AUR submission guidelines

**URL:** https://wiki.archlinux.org/title/AUR_submission_guidelines

**Contents:**
- Submitting packages
  - Rules of submission
  - Authentication
  - Creating package repositories
  - Publishing new package content
- Maintaining packages
- Requests
  - Deletion
  - Merge
  - Orphan

Users can share PKGBUILD scripts using the Arch User Repository. It does not contain any binary packages but allows users to upload PKGBUILDs that can be downloaded by others. These PKGBUILDs are completely unofficial and have not been thoroughly vetted, so they should be used at your own risk.

If you are unsure in any way about the package or the build/submission process even after reading this section twice, submit the PKGBUILD to the AUR mailing list, the AUR forum on the Arch forums, or ask on our IRC channel for public review before adding it to the AUR.

When submitting a package to the AUR, observe the following rules:

For write access to the AUR, you need to have an SSH key pair. The content of the public key needs to be copied to your profile in My Account, and the corresponding private key configured for the aur.archlinux.org host. For example:

You should create a new key pair rather than use an existing one, so that you can selectively revoke the keys should something happen:

If you are creating a new package from scratch, establish a local Git repository and an AUR remote by cloning the intended pkgbase. If the package does not yet exist, the following warning is expected:

If you already have a package, initialize it as a Git repository if it is not one:

and add an AUR remote:

Then fetch this remote to initialize it in the AUR.

When releasing a new version of the packaged software, update the pkgver or pkgrel variables to notify all users that an upgrade is needed. Do not update those values if only minor changes to the PKGBUILD such as the correction of a typo are being published.

Do not commit mere pkgver bumps for VCS packages. They are not considered out of date when the upstream has new commits. Only do a new commit when other changes are introduced, such as changing the build process.

Be sure to regenerate .SRCINFO whenever PKGBUILD metadata changes, such as pkgver() updates; otherwise the AUR will not show updated version numbers.

To upload or update a package:

Deletion, merge, and orphan requests can be created by clicking on the "Submit Request" link under "Package Actions" on the right hand side. This dispatches notification emails to the current package maintainer and to the aur-requests mailing list for discussion. Package Maintainers will then either accept or reject the request.

Request to unlist a pkgbase from the AUR. A short note explaining the reason for deletion is required, as well as supporting details (like when a package is provided by another package, if you are the maintainer yourself, it is renamed and the original owner agreed, etc).

Request to delete a pkgbase and transfer its votes and comments to another pkgbase. The name of the package to merge into is required.

This is the action to use if, for example, an upstream has renamed their project.

Request that a pkgbase be disowned. These requests will be granted after two weeks if the current maintainer did not react. The exception is if a package was flagged out-of-date for at least 180 days; orphan requests are then automatically accepted.

**Examples:**

Example 1 (unknown):
```unknown
screen-sidebar
```

Example 2 (unknown):
```unknown
conflicts=('screen')
```

Example 3 (unknown):
```unknown
# Maintainer: Your Name <address at domain dot tld>
```

Example 4 (unknown):
```unknown
# Maintainer: Your name <address at domain dot tld>
# Maintainer: Other maintainer's name <address at domain dot tld>
# Contributor: Previous maintainer's name <address at domain dot tld>
# Contributor: Original submitter's name <address at domain dot tld>
```

---

## dwl

**URL:** https://wiki.archlinux.org/title/Dwl

**Contents:**
- Installation
- Configuration
  - Enable XWayland
- Usage
- Tips and tricks
  - Floating layout for some windows
  - Taking screenshots
  - Adjusting volume
  - Autostart
  - Better mouse resizing

dwl is a wlroots-based Wayland compositor, similar in spirit to dwm. It is minimal, fast, and extensible through community-made patches. By default, it comes with very little functionality, it is usable in its base state, but more QOL features can be applied if desired.

dwl can be installed with the dwlAUR or dwl-gitAUR packages. Make any required configuration changes before building and installing, see makepkg.

dwl is configured at compile-time by editing some of its source files, specifically config.h. For detailed information on these settings, see the included, well-commented config.def.h.

The official website has a number of patches that can add extra functionality to dwl. These patches primarily make changes to the dwl.c file but also make changes to the config.h file where appropriate. For information on applying patches, see the Patching packages article.

To build dwl with Xwayland enabled, install xorg-xwayland and uncomment the following lines in the build file like so:

dwl can be started from a display manager of choice, by selecting the desktop entry in the menu that it provides.

For starting dwl from a getty, execute the command as follows:

You can also autostart a command using the -s flag. This command will have information about selected layouts, current window title, app-id, and tags written to it's stdin by dwl. You can use this to populate your status bar. If your command does not consume the data sent by dwl, append <&- to it like this:

If using a display manager, this can be appended to the Exec line in the desktop entry.

For some windows, such as preferences dialogs, it does not make sense for these windows to be tiled - they should be free-floating instead. For example, to make Firefox's preferences dialog float, add the following to your rules array:

The script below will first create a directory /path/to/pics, then if that succeeds it will take a screenshot and save it to a file with the current date and extension .png in that newly made directory:

Additionally, if you also want to take screenshots with a selection box instead of taking a screenshot of all monitors, create the following:

For taking a screenshot and saving it to the clipboard instead of it being saved to a place on the filesystem create the script below:

Finally add the following:

This maps taking screenshots to the print key, taking screenshots with a selection box to the shift + print keys, and finally taking screenshots then copying it to the clipboard with ctrl + print keys.

install pipewire-pulse, or pulseaudio, then add these options for volume management:

A patch is available, that allows you to autostart specified applications. One such example can be seen below:

You can specify more applications by adding them to the list, each entry comma-separated and followed by NULL. For example, you could start a bar, a notification daemon, or any background service you need. Just make sure each command and its arguments are properly quoted.

By default when resizing dwl will warp the cursor to the bottom right corner, with a patch this behavior can be changed.

That patch allows you to configure window resizing to be more flexible, instead of warping to the bottom right corner it comes with multiple modes:

A working configuration example of this patch can be found below:

With this, when resizing the corner closest to the cursor will be selected, the cursor will not warp, and finally the cursor will not lock itself in place.

See Java#Gray window, applications not resizing with WM, menus immediately closing.

If there are empty gaps of desktop space outside terminal windows, it is likely due to the terminal's font size. Either adjust the size until finding the ideal scale that closes the gap, or toggle resizehints to 0 in config.h.

This will cause dwl to ignore resize requests from all client windows, not just terminals. The downside to this workaround is that some terminals may suffer redraw anomalies, such as ghost lines and premature line wraps, among others.

Alternatively, if you use the st terminal emulator, you can apply the anysize patch and recompile st.

**Examples:**

Example 1 (unknown):
```unknown
config.def.h
```

Example 2 (unknown):
```unknown
/path/to/config.mk
```

Example 3 (unknown):
```unknown
# Uncomment to build XWayland support
XWAYLAND = -DXWAYLAND
XLIBS = xcb xcb-icccm
```

Example 4 (unknown):
```unknown
dwl -s 'sh /path/to/autostart.sh <&-'
```

---

## Creating packages

**URL:** https://wiki.archlinux.org/title/Creating_packages

**Contents:**
- Overview
- Preparation
  - Prerequisite software
  - Download and test the installation
  - Set up clean chroot
- Creating a PKGBUILD
  - PKGBUILD variables
  - PKGBUILD functions
    - prepare()
    - pkgver()

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

This article aims to assist users creating their own packages using the ports–like Arch build system, also for submission in Arch User Repository. It covers creation of a PKGBUILD(5)—a package build description file sourced by makepkg to create a binary package from source.

For instructions regarding existing rules and ways to improve package quality, see Arch package guidelines.

Packages in Arch Linux are built using the makepkg utility and the information stored in a PKGBUILD file. When makepkg runs, it searches for a PKGBUILD in the current directory and follows the instructions in it to acquire the required files and/or compile them to be packed within a package file pkgname.pkg.tar.zst. The resulting package contains binary files and installation instructions ready to be installed by pacman.

An Arch package is no more than a tar(1) archive, or a tarball, compressed using zstd(1), which contains the following files generated by makepkg:

First, ensure that the necessary tools are installed: the meta package base-devel should be sufficient; it pulls in make(1) and additional tools needed for compiling from source.

The key tool for building packages is makepkg (provided by pacman). The tasks it performs can be found in Arch package guidelines#Makepkg duties.

Download the source tarball of the software you want to package, extract it, and follow the author's steps to install the program. Make a note of all commands and/or steps needed to compile and install it. You will be repeating those same commands in the PKGBUILD file.

Most software authors stick to the 3-step build cycle:

This is a good time to make sure the program is working correctly.

It is recommended to follow Building in a clean chroot to ensure that packages and configuration of your system do not lead to mistakes in the PKGBUILD. This is a more robust and correct way to build packages and will often catch missing dependencies that you did not realize were needed because they already existed in your system.

When makepkg is run, it looks for a PKGBUILD file in the current working directory. If it finds one, it downloads the software's source code and compiles it according to the instructions specified in the PKGBUILD file. The instructions must be fully interpretable by the Bash shell.

After successful completion, the resulting binaries and metadata of the package, i.e. package version and dependencies, are packed in a pkgname.pkg.tar.zst package file. The newly created package can be installed by simply using makepkg --install which will call pacman in the background, or by directly using pacman -U pkgname.pkg.tar.zst.

To start building a new package, first create a new directory for the package and change current directory into this one. Then, a PKGBUILD file needs to be created: a prototype PKGBUILD found in /usr/share/pacman/ can be used or you can start from a PKGBUILD from another package. The latter may be a good choice if a similar package already exists.

makepkg predefines the following variables that should be used by packagers to refer to temporary locations during the build process:

They contain absolute paths, which means you do not have to worry about your working directory if you use these variables properly.

When building a package, makepkg will invoke the following five functions if they have been defined in the PKGBUILD. Function package() is required in every PKGBUILD and will always be invoked. If any of the other functions is not defined, makepkg will simply skip the invocation of that function.

During the build, the functions are invoked in the order in which they are listed here.

Also see PKGBUILD(5) § PACKAGING FUNCTIONS.

With this function, commands that are used to prepare sources for building are run, such as patching. This function runs right after package extraction, before pkgver() and the build function. If extraction is skipped (makepkg --noextract), then prepare() is not run.

When it is not clear whether to put something in prepare() or build(), one rule of thumb is to put in prepare() the steps that should run exactly once after extracting the sources, and put in build() the steps which would make sense to re-run after any manual edits to the extracted files.

pkgver() runs after the sources are fetched, extracted and prepare() executed. So you can update the pkgver variable during a makepkg stage.

This is particularly useful if you are making git/svn/hg/etc. packages, where the build process may remain the same, but the source could be updated every day, even every hour. The old way of doing this was to put the date into the pkgver field which, if the software was not updated, makepkg would still rebuild it thinking the version had changed. Some useful commands for this are git describe, hg identify -ni, etc. Please test these before submitting a PKGBUILD, as a failure in the pkgver() function can stop a build in its tracks.

Now, you need to implement the build() function in the PKGBUILD file. This function uses common shell commands in Bash syntax to automatically compile software and create a directory called pkg to install the software to. This allows makepkg to package files without having to sift through your file system.

The first step in the build() function is to change into the directory created by uncompressing the source tarball. makepkg will change the current directory to $srcdir before executing the build() function. Therefore, in most cases, like suggested in /usr/share/pacman/PKGBUILD.proto, the first command will look like this:

Now, you need to list the same commands you used when you manually compiled the software. The build() function in essence automates everything you did by hand and compiles the software in the fakeroot build environment. If the software you are packaging uses a configure script, it is good practice to use --prefix=/usr when building packages for pacman. A lot of software installs files relative to the /usr/local directory, which should only be done if you are manually building from source. All Arch Linux packages should use the /usr directory. As seen in the /usr/share/pacman/PKGBUILD.proto file, the next two lines often look like this:

Place for calls to make check and similar testing routines. It is highly recommended to have check() as it helps to make sure software has been built correctly and works fine with its dependencies.

Users who do not need it (and occasionally maintainers who can not fix a package for this to pass) can disable it by adding !check into the options array in PKGBUILD/makepkg.conf(5) or call makepkg with --nocheck flag.

If you are testing a GUI application, you can run it in a virtual xserver.

The final step is to put the compiled files in a directory where makepkg can retrieve them to create a package. This by default is the pkg directory—a simple fakeroot environment. The pkg directory replicates the hierarchy of the root file system of the software's installation paths. If you have to manually place files under the root of your filesystem, you should install them in the pkg directory under the same directory structure. For example, if you want to install a file to /usr/bin, it should instead be placed under $pkgdir/usr/bin. Very few install procedures require the user to copy dozens of files manually. Instead, for most software, calling make install will do so. The final line should look like the following in order to correctly install the software in the pkg directory:

makepkg --repackage runs only the package() function, so it creates a package without building. This may save time e.g. if you have changed just the depends variable of the package.

As you are writing the build() function, you will want to test your changes frequently to ensure there are no bugs. You can do this using the makepkg command in the directory containing the PKGBUILD file. With a properly formatted PKGBUILD, makepkg will create a package; with a broken or unfinished PKGBUILD, it will raise an error.

If makepkg finishes successfully, it will place a file named pkgname-pkgver.pkg.tar.zst in your working directory. This package can be installed with the pacman -U command. However, just because a package file was built does not imply that it is fully functional. It might conceivably contain only the directory and no files whatsoever if, for example, a prefix was specified improperly. You can use pacman's query functions to display a list of files contained in the package with pacman -Qlp pkgname, and the dependencies it requires with pacman -Qip pkgname.

If the package looks sane, then you are done! However, if you plan on releasing the PKGBUILD file, it is imperative that you check and double-check the contents of the depends array.

Also ensure that the package binaries actually run flawlessly! It is annoying to release a package that contains all necessary files, but crashes because of some obscure configuration option that does not quite work well with the rest of the system. If you are only going to compile packages for your own system, though, you do not need to worry too much about this quality assurance step, as you are the only person suffering from mistakes, after all.

After testing package functionality, check it for errors using namcap:

Get into the habit of checking your packages with namcap to avoid having to fix the simplest mistakes after package submission.

This article or section is a candidate for merging with Arch build system#Build package.

You can use pkgctl from devtools to check if the package can be built where no other packages are already installed. While in the PKGBUILD directory:

And check the output for potential errors or warnings. If the package depends on other AUR packages, those packages must be built and brought into chroot jail:

Refer to pkgctl-build(1) for more options.

Please read AUR submission guidelines for a detailed description of the submission process.

The process of updating checksums for new software releases can be automated by the updpkgsums tool; see Makepkg#Generate new checksums for details.

PKGBUILDs for some packages can be generated automatically.

pkgctl (from the devtools package) supports nvchecker integration in the form of a .nvchecker.toml configuration file (which should be placed in the same directory as the PKGBUILD). See the pacman package's .nvchecker.toml configuration file for an example.

You can then use pkgctl version check to check if a new upstream version has been released (compared to the one specified as pkgver in the PKGBUILD) and pkgctl version upgrade to update the PKGBUILD accordingly. See pkgctl-version(1) for more details.

**Examples:**

Example 1 (unknown):
```unknown
pkgname.pkg.tar.zst
```

Example 2 (unknown):
```unknown
$ ./configure
$ make
# make install
```

Example 3 (unknown):
```unknown
pkgname.pkg.tar.zst
```

Example 4 (unknown):
```unknown
makepkg --install
```

---

## Clang

**URL:** https://wiki.archlinux.org/title/Clang

**Contents:**
- Installation
- Build packages with Clang
  - Generic setup
  - Qt packages
  - Rust packages
- Using the Static Analyzer
- Tips and tricks
  - Bash completion
- Troubleshooting
  - Stack protector

Clang is a C/C++/Objective C/CUDA compiler based on LLVM. The most recent iteration is distributed under the "Apache 2.0 License with LLVM exceptions".

Install the clang package.

This article or section is a candidate for merging with makepkg.

To change the default compiler for building packages, edit:

To use libc++ as the C++ Standard Library instead of GCC's libstdc++: install the libc++ package, then add -stdlib=libc++ to CXXFLAGS in your /etc/makepkg.conf.

For LTO support: install the lld package, then add -fuse-ld=lld to LDFLAGS in your /etc/makepkg.conf.

If you are building with debug, you also need to remove -fvar-tracking-assignments from DEBUG_CFLAGS and DEBUG_CXXFLAGS, as Clang does not support it.

Qt packages may require extra setup. Qt has predefined build configurations called "mkspecs", defaulting to GCC for Linux.

In some cases, mkspec will be automatically set to linux-clang based on CC/CXX variables. But in other cases (e.g. packages with direct call of qmake) it will not, so we can set it explicitly:

Whenever clang is set as the system default compiler, Rust needs to be configured to use clang as the linker for C code often compiled as a part of the process for building Rust applications.

To do so, clang (and optionally lld) needs to be specified in /etc/makepkg.conf.d/rust.conf.

For example, to use clang and lld:

To analyze a project, simply place the word scan-build in front of your build command. For example:

If your project is already compiled, scan-build will not rebuild and will not analyse it. To force recompilation and analysis, use -B switch:

It is also possible to analyze specific files:

This article or section needs expansion.

In order to enable Bash completion, install bash-completion.

The clang package enables -fstack-protector-strong on default. This practice should not cause any problem for compiling most programs and improve the overall security and robustness with a minimal cost. However, there are situations where the stack protector canary is uninitialized in TLS (for example, when you are implementing the _start function on yourself). In such cases, compiling with -fstack-protector-strong may lead to segmentation faults or other unexpected errors. One should be aware of the divergence between the clang package and upstream.

**Examples:**

Example 1 (unknown):
```unknown
/etc/makepkg.conf
```

Example 2 (unknown):
```unknown
...
export CC=clang
export CXX=clang++
```

Example 3 (unknown):
```unknown
-stdlib=libc++
```

Example 4 (unknown):
```unknown
/etc/makepkg.conf
```

---

## Eclipse plugin package guidelines

**URL:** https://wiki.archlinux.org/title/Eclipse_plugin_package_guidelines

**Contents:**
- Eclipse plugin structure and installation
- Packaging
  - Sample PKGBUILD
  - How to customize the build
  - In-depth PKGBUILD review
    - Package naming
    - Files
      - Extraction
      - Locations
    - The build() function

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

There are many ways to install working Eclipse plugins, especially since the introduction of the dropins directory in Eclipse 3.4, but some of them are messy, and having a standardized and consistent way of packaging is very important to lead to a clean system structure. It is not easy, however, to achieve this without the packager knowing every detail about how Eclipse plugins work. This page aims to define a standard and simple structure for Eclipse plugin PKGBUILDs, so that the filesystem structure can remain consistent between all plugins without having the packager to start again for every new package.

The typical Eclipse plugin contains two directories, features and plugins, and since Eclipse 3.3 they could only be placed in /usr/lib/eclipse/. The content of these two directories could be mixed with that of other plugins, and it created a mess and rendered the structure difficult to manage. It was also very difficult to tell at a glance which package contained which file.

This installation method is still supported in Eclipse 3.4, but the preferred one is now using the /usr/lib/eclipse/dropins/ directory. Inside this directory can live an unlimited number of subdirectories, each one containing its own features and plugins subdirectories. This allows to keep a tidy and clean structure, and should be the standard packaging way.

Here is an example, we will detail how to customize it below.

The main variable which needs to be customized is the pkgname. If you are packaging a typical plugin, then this is the only thing you need to do: most plugins are distributed in zip files which only contain the two features and plugins subdirectories. So, if you are packaging the foo plugin and the source file only contains the features and plugins, you just need to change pkgname to eclipse-foo and you are set.

Read on to get to the internals of the PKGBUILD, which help to understand how to setup the build for all the other cases.

Packages should be named eclipse-pluginname, so that they are recognizable as Eclipse-related packages and it is easy to extract the plugin name with a simple shell substitution like ${pkgname/eclipse-}, not having to resort to an unneeded ${_realname} variable. The plugin name is necessary to tidy up everything during installation and to avoid conflicts.

Some plugins need the features to be extracted from jar files. The jar utility, already included in the JRE, is used to do this. However, jar cannot extract to directories other than the current one: this means that, after every directory creation, it is necessary to cd inside it before extracting. The ${_dest} variable is used in this context to improve readability and PKGBUILD tidiness.

As we said, source archives provide two directories, features and plugins, each one packed up with jar files. The preferred dropins structure should look like this:

This structure allows for mixing different versions of libraries that may be needed by different plugins while being clear about which package owns what. It will also avoid conflicts in case different packages provide the same library. The only alternative would be splitting every package from its libraries, with all the extra fuss it requires, and it would not even be guaranteed to work because of packages needing older library versions. Features have to be unjarred since Eclipse will not detect them otherwise, and the whole plugin installation will not work. This happens because Eclipse treats update sites and local installations differently (do not ask why, it just does).

First thing to be noticed is the cd ${srcdir} command. Usually source archives extract the features and plugins folders directly under ${srcdir}, but this is not always the case. Anyway, for most non-(de facto)-standard plugins this is the only line that needs to be changed.

Some released features include their sources, too. For a normal release version these sources are not needed and can be removed. Furthermore same features include *.pack.gz files, which contain the same files compared to the jar archives. So these files can be removed, too.

Next is the features section. It creates the necessary directories, one for every jar file, and extracts the jar in the corresponding directory. Similarly, the plugins section installs the jar files in their directory. A while cycle is used to prevent funny-named files.

**Examples:**

Example 1 (unknown):
```unknown
/usr/lib/eclipse/
```

Example 2 (unknown):
```unknown
/usr/lib/eclipse/dropins/
```

Example 3 (unknown):
```unknown
PKGBUILD-eclipse.proto
```

Example 4 (unknown):
```unknown
pkgname=eclipse-mylyn
pkgver=3.0.3
pkgrel=1
pkgdesc="A task-focused interface for Eclipse"
arch=('any')
url="https://eclipse.org/mylyn/"
license=('EPL')
depends=('eclipse')
optdepends=('bugzilla: ticketing support')
source=(https://download.eclipse.org/tools/mylyn/update/mylyn-${pkgver}-e3.4.zip)
sha512sums=('aa6289046df4c254567010b30706cc9cb0a1355e9634adcb2052127030d2640f399caf20fce10e8b4fab5885da29057ab9117af42472bcc1645dcf9881f84236')

prepare() {
  # remove features and plug-ins containing sources
  rm -f features/*.source_*
  rm -f plugins/*.source_*
  # remove gz files
  rm -f plugins/*.pack.gz
}

package() {
  _dest="${pkgdir}/usr/lib/eclipse/dropins/${pkgname/eclipse-}/eclipse"

  # Features
  find features -type f | while read -r _feature ; do
    if [[ "${_feature}" =~ (.*\.jar$) ]] ; then
      install -dm755 "${_dest}/${_feature%*.jar}"
      cd "${_dest}/${_feature/.jar}"
      # extract features (otherwise they are not visible in about dialog)
      jar xf "${srcdir}/${_feature}" || return 1
    else
      install -Dm644 "${_feature}" "${_dest}/${_feature}"
    fi
  done

  # Plugins
  find plugins -type f | while read -r _plugin ; do
    install -Dm644 "${_plugin}" "${_dest}/${_plugin}"
  done
}
```

---

## Patching packages

**URL:** https://wiki.archlinux.org/title/Patching_in_ABS

**Contents:**
- Creating patches
- Applying patches
- Using quilt
- See also

This article covers how to create and how to apply patches to packages in the Arch build system (ABS).

A patch describes a set of line changes for one or multiple files. Patches are typically used to automate the changing of source code.

The diff tool compares files line by line. If you save its output you have a patch, e.g. diff --unified --recursive --text foo bar > foobar.patch (which can be shortened to diff -ura). If you pass directories diff will compare the files they contain.

See diff(1) and git-diff(1) for more info.

This section outlines how to apply patches you created or downloaded from the Internet from within a PKGBUILD's prepare() function. Follow these steps:

An example prepare-function:

Alternatively, you can use the --directory/-d flag of patch without having to cd first. The example above would then become:

Run makepkg from the terminal now. If all goes well, the patch will be automatically applied, and your new package will contain whatever changes were included in the patch. If not, you may have to experiment with the --strip/-p option of patch. While experimenting, you might find --dry-run, --reverse or --verbose options usable. Read patch(1) for more information.

Basically it works as follows. If the diff file was created to apply patches to files in myversion/, the diff files will be applied to myversion/file. You are running it from within the yourversion/ directory (because you would cd into that directory in the PKGBUILD), so when patch applies the file, you want it to apply it to the file file, taking off the myversion/ part. -p1 does this, by removing one directory from the path. However, if the developer patched in myfiles/myversion, you need to remove two directories, so you use -p2.

If you do not apply a -p option, it will take off all directory structure. This is OK if all the files are in the base directory, but if the patch was created on myversion/ and one of the edited files was myversion/src/file, and you run the patch without a -p option from within yourversion, it will try to patch a file named yourversion/file.

Most developers create patches from the parent directory of the directory that is being patched, so -p1 will usually be right.

A simpler way to create patches is using quilt which provides better support for managing many patches, such as applying patches, refreshing patches, and reverting patched files to original state. quilt is used on Debian to manage their patches. See Using Quilt for basic information about basic quilt usage to generate, apply patches, and reverting patched files.

**Examples:**

Example 1 (unknown):
```unknown
diff --unified --recursive --text foo bar > foobar.patch
```

Example 2 (unknown):
```unknown
makepkg --nobuild
```

Example 3 (unknown):
```unknown
makepkg --nobuild --nodeps
```

Example 4 (unknown):
```unknown
makepkg -od
```

---

## pacman

**URL:** https://wiki.archlinux.org/title/Pacman_hook

**Contents:**
- Usage
  - Installing packages
    - Installing specific packages
      - Virtual packages
    - Installing package groups
  - Removing packages
  - Upgrading packages
  - Querying package databases
    - Pactree
    - Database structure

The pacman package manager is one of the major distinguishing features of Arch Linux. It combines a simple binary package format with an easy-to-use Arch build system. The goal of pacman is to make it possible to easily manage packages, whether they are from the official repositories or the user's own builds.

Pacman keeps the system up-to-date by synchronizing package lists with the master server. This server/client model also allows the user to download/install packages with a simple command, complete with all required dependencies.

Pacman is written in the C programming language and uses the bsdtar(1) tar format for packaging.

What follows is just a small sample of the operations that pacman can perform. To read more examples, refer to pacman(8).

A package is an archive containing:

Arch's package manager pacman can install, update, and remove those packages. Using packages instead of compiling and installing programs yourself has various benefits:

To install a single package or list of packages, including dependencies, issue the following command:

To install a list of packages with regex (see this forum thread):

Sometimes there are multiple versions of a package in different repositories (e.g. extra and extra-testing). To install the version from the extra repository in this example, the repository needs to be defined in front of the package name:

To install a number of packages sharing similar patterns in their names, one can use curly brace expansion. For example:

This can be expanded to however many levels needed:

A virtual package is a special package which does not exist by itself, but is provided by one or more other packages. Virtual packages allow other packages to not name a specific package as a dependency, in case there are several candidates. Virtual packages cannot be installed by their name, instead they become installed in your system when you have installed a package providing the virtual package. An example is the dbus-units package.

Some packages belong to a group of packages that can all be installed simultaneously. For example, issuing the command:

will prompt you to select the packages from the gnome group that you wish to install.

Sometimes a package group will contain a large amount of packages, and there may be only a few that you do or do not want to install. Instead of having to enter all the numbers except the ones you do not want, it is sometimes more convenient to select or exclude packages or ranges of packages with the following syntax:

which will select packages 1 through 10 and 15 for installation, or:

which will select all packages except 5 through 8 and 2 for installation.

To see what packages belong to the gnome group, run:

Also visit https://archlinux.org/groups/ to see what package groups are available.

To remove a single package, leaving all of its dependencies installed:

To remove a package and its dependencies which are not required by any other installed package:

The above may sometimes refuse to run when removing a group which contains otherwise needed packages. In this case try:

To remove a package, its dependencies and all the packages that depend on the target package:

To remove a package, which is required by another package, without removing the dependent package:

Pacman saves important configuration files when removing certain applications and names them with the extension: .pacsave. To prevent the creation of these backup files use the -n option:

Pacman can update all packages on the system with just one command. This could take quite a while depending on how up-to-date the system is. The following command synchronizes the repository databases and updates the system's packages, excluding "local" packages that are not in the configured repositories:

Pacman queries the local package database with the -Q flag, the sync database with the -S flag and the files database with the -F flag. See pacman -Q --help, pacman -S --help and pacman -F --help for the respective suboptions of each flag.

Pacman can search for packages in the database, searching both in packages' names and descriptions:

Sometimes, -s's builtin ERE (Extended Regular Expressions) can cause a lot of unwanted results, so it has to be limited to match the package name only; not the description nor any other field:

To search for already installed packages:

To search for package file names in remote packages:

To display extensive information about a given package (e.g. its dependencies):

For locally installed packages:

Passing two -i flags will also display the list of backup files and their modification states:

To retrieve a list of the files installed by a package:

To retrieve a list of the files installed by a remote package:

To verify the presence of the files installed by a package:

Passing the k flag twice will perform a more thorough check.

To query the database to know which package a file in the file system belongs to:

To query the database to know which remote package a file belongs to:

To list all packages no longer required as dependencies (orphans):

To list all packages explicitly installed and not required as dependencies:

See pacman/Tips and tricks for more examples.

For advanced functionality, install pkgfile, which uses a separate database with all files and their associated packages.

To view the dependency tree of a package:

To view the dependent tree of a package, pass the reverse flag -r to pactree.

The pacman databases are normally located at /var/lib/pacman/sync. For each repository specified in /etc/pacman.conf, there will be a corresponding database file located there. Database files are gzipped tar archives containing one directory for each package, for example for the which package:

The desc file contains meta data such as the package description, dependencies, file size and MD5 hash.

Pacman stores its downloaded packages in /var/cache/pacman/pkg/ and does not remove the old or uninstalled versions automatically. This has some advantages:

However, it is necessary to deliberately clean up the cache periodically to prevent the directory to grow indefinitely in size.

The paccache(8) script, provided within the pacman-contrib package, deletes all cached versions of installed and uninstalled packages, except for the most recent three, by default:

Enable and start paccache.timer to discard unused packages weekly. You can configure the arguments for the service in /etc/conf.d/pacman-contrib, e.g with PACCACHE_ARGS='-k1' or PACCACHE_ARGS='-uk0' for the two examples below.

You can also define how many recent versions you want to keep. To retain only one past version use:

Add the -u/--uninstalled switch to limit the action of paccache to uninstalled packages. For example to remove all cached versions of uninstalled packages, use the following:

See paccache -h for more options.

Pacman also has some built-in options to clean the cache and the leftover database files from repositories which are no longer listed in the configuration file /etc/pacman.conf. However pacman does not offer the possibility to keep a number of past versions and is therefore more aggressive than paccache default options.

To remove all the cached packages that are not currently installed, and the unused sync databases, execute:

To remove all files from the cache, use the clean switch twice, this is the most aggressive approach and will leave nothing in the cache directory:

pkgcachecleanAUR and pacleanerAUR are two further alternatives to clean the cache.

Download a package without installing it:

Install a 'local' package that is not from a remote repository (e.g. the package is from the AUR):

To keep a copy of the local package in pacman's cache, use:

Install a 'remote' package (not from a repository stated in pacman's configuration files):

Pacman always lists packages to be installed or removed, and asks for permission before taking any action.

To get a list in a processable format, and to prevent the actions of -S, -U and -R, you can use -p, short for --print.

--print-format can be added to format this list in various ways. --print-format %n will return a list without package versions.

The pacman database organizes installed packages into two groups, according to installation reason:

When installing a package, it is possible to force its installation reason to dependency with:

The command is normally used because explicitly-installed packages may offer optional packages, usually for non-essential features for which the user has discretion.

When reinstalling a package, though, the current installation reason is preserved by default.

The list of explicitly-installed packages can be shown with pacman -Qe, while the complementary list of dependencies can be shown with pacman -Qd.

To change the installation reason of an already installed package, execute:

Use --asexplicit to do the opposite operation.

When successful, the workflow of a transaction follows five high-level steps plus pre/post transaction hooks:

Pacman settings are located in /etc/pacman.conf: this is the place where the user configures the program to work in the desired manner. In-depth information about the configuration file can be found in pacman.conf(5).

General options are in the [options] section. Read pacman.conf(5) or look in the default pacman.conf for information on what can be done here.

To see old and new versions of available packages, uncomment the "VerbosePkgLists" line in /etc/pacman.conf. The output of pacman -Syu will be like this:

The number of packages being downloaded in parallel (at the same time) are configured in /etc/pacman.conf with the ParallelDownloads option under [options]. The /etc/pacman.conf shipped with the pacman package sets it to 5. If the option is unset, packages will be downloaded sequentially.

To have a specific package skipped when upgrading the system, add this line in the [options] section:

For multiple packages use a space-separated list, or use additional IgnorePkg lines. Also, glob patterns can be used. If you want to skip packages just once, you can also use the --ignore option on the command-line - this time with a comma-separated list.

It will still be possible to upgrade the ignored packages using pacman -S: in this case pacman will remind you that the packages have been included in an IgnorePkg statement.

As with packages, skipping a whole package group is also possible:

All files listed with a NoUpgrade directive will never be touched during a package install/upgrade, and the new files will be installed with a .pacnew extension.

Multiple files can be specified like this:

To always skip installation of specific files or directories list them under NoExtract. For example, to avoid installing bash completion scripts, use:

Later rules override previous ones, and you can negate a rule by prepending !.

If you have several configuration files (e.g. main configuration and configuration with testing repository enabled) and would have to share options between configurations you may use Include option declared in the configuration files, e.g.:

where /path/to/common/settings file contains the same options for both configurations.

Pacman can run pre- and post-transaction hooks from the /usr/share/libalpm/hooks/ directory; more directories can be specified with the HookDir option in pacman.conf, which defaults to /etc/pacman.d/hooks. Hook file names must be suffixed with .hook. Pacman hooks are not interactive.

Pacman hooks are used, for example, in combination with systemd-sysusers and systemd-tmpfiles to automatically create system users and files during the installation of packages. For example, tomcat8 specifies that it wants a system user called tomcat8 and certain directories owned by this user. The pacman hooks systemd-sysusers.hook and systemd-tmpfiles.hook invoke systemd-sysusers and systemd-tmpfiles when pacman determines that tomcat8 contains files specifying users and tmp files.

For more information on alpm hooks, see alpm-hooks(5).

Besides the special [options] section, each other [section] in pacman.conf defines a package repository to be used. A repository is a logical collection of packages, which are physically stored on one or more servers: for this reason each server is called a mirror for the repository.

Repositories are distinguished between official and unofficial. The order of repositories in the configuration file matters; repositories listed first will take precedence over those listed later in the file when packages in two repositories have identical names, regardless of version number. In order to use a repository after adding it, you will need to upgrade the whole system first.

Each repository section allows defining the list of its mirrors directly or in a dedicated external file through the Include directive; for example, the mirrors for the official repositories are included from /etc/pacman.d/mirrorlist. See the Mirrors article for mirror configuration.

Pacman stores downloaded package files in cache, in a directory denoted by CacheDir in [options] section of pacman.conf (defaults to /var/cache/pacman/pkg/ if not set).

Cache directory may grow over time, even if keeping just the freshest versions of installed packages.

If you want to move that directory to some more convenient place, do one of the following:

Pacman supports package signatures, which add an extra layer of security to the packages. The default configuration, SigLevel = Required DatabaseOptional, enables signature verification for all the packages on a global level. This can be overridden by per-repository SigLevel lines. For more details on package signing and signature verification, take a look at pacman-key.

If you see the following error: [1]

This is happening because pacman has detected a file conflict, and by design, will not overwrite files for you. This is by design, not a flaw.

The problem is usually trivial to solve (although to be sure, you should try to find out how these files got there in the first place). A safe way is to first check if another package owns the file (pacman -Qo /path/to/file). If the file is owned by another package, file a bug report. If the file is not owned by another package, rename the file which "exists in filesystem" and re-issue the update command. If all goes well, the file may then be removed.

If you had installed a program manually without using pacman, for example through make install, you have to remove/uninstall this program with all of its files. See also Pacman tips#Identify files not owned by any package.

Every installed package provides a /var/lib/pacman/local/package-version/files file that contains metadata about this package. If this file gets corrupted, is empty or goes missing, it results in file exists in filesystem errors when trying to update the package. Such an error usually concerns only one package. Instead of manually renaming and later removing all the files that belong to the package in question, you may explicitly run pacman -S --overwrite glob package to force pacman to overwrite files that match glob.

This article or section is out of date.

Look for .part files (partially downloaded packages) in /var/cache/pacman/pkg/ and remove them (often caused by usage of a custom XferCommand in pacman.conf).

That same error may also appear if archlinux-keyring is out-of-date, preventing pacman from verifying signatures. See Pacman/Package signing#Upgrade system regularly for the fix and how to avoid it in the future.

When pacman is about to alter the package database, for example installing a package, it creates a lock file at /var/lib/pacman/db.lck. This prevents another instance of pacman from trying to alter the package database at the same time.

If pacman is interrupted while changing the database, this stale lock file can remain. If you are certain that no instances of pacman are running then delete the lock file:

This error manifests as Not found in sync db, Target not found or Failed retrieving file.

Firstly, ensure the package actually exists. If certain the package exists, your package list may be out-of-date. Try running pacman -Syu to force a refresh of all package lists and upgrade. Also make sure the selected mirrors are up-to-date and repositories are correctly configured. You can also use Reflector to keep the mirrors up-to-date.

If pacman reports there is nothing to update, but the Failed retrieving file error continues to be printed, consider forcing a database download with pacman -Syyu. This is never needed under normal circumstances, so inspect more closely the status and consistency of the mirror.

It could also be that the repository containing the package is not enabled on your system, e.g. the package could be in the multilib repository, but multilib is not enabled in your pacman.conf.

See also FAQ#Why is there only a single version of each shared library in the official repositories?.

This article or section needs expansion.

Whether due to power loss, kernel panic or hardware failure an update may be interrupted. In most cases, there will not be much damage but the system will likely be unbootable.

Replicating the exact upgrade is needed to ensure the right scriptlets and hooks will run.

In the case that pacman crashes with a "database write" error while removing packages, and reinstalling or upgrading packages fails thereafter, do the following:

If /var/cache/pacman/pkg is a symlink, pacman will try to make a directory instead and thus remove this symlink during self-upgrade. This will cause the update to fail. As a result, /usr/bin/pacman and other contents of the pacman package will be missing.

Never symlink /var/cache/pacman/pkg because it is controlled by pacman. Use the CacheDir option or a bind mount instead; see #Package cache directory.

If you have already encountered this problem and broke your system, you can manually extract /usr contents from the package to restore pacman and then reinstall it properly; see FS#73306 and related forum thread for details.

pacman-staticAUR is a statically compiled version of pacman, so it will be able to run even when the libraries on the system are not working. This can also come in handy when a partial upgrade was performed and pacman can not run anymore.

The pinned comment and the PKGBUILD provides a way to directly download the binary, which can be used to reinstall pacman or to upgrade the entire system in case of partial upgrades.

In some situations, your system may be too broken (e.g., due to missing or incompatible libraries) to run `makepkg` or build the `pacman-static` package from the AUR successfully.

If building from the PKGBUILD fails or `makepkg` cannot be run, you can download a precompiled `pacman-static` binary from a trusted source. This static binary does not depend on system libraries and can be used to restore a working `pacman` on your system.

A reliable source for the binary is:

This will update your system and reinstall `pacman`, fixing broken dependencies related to missing shared libraries.

If even pacman-static does not work, it is possible to recover using an external pacman. One of the easiest methods to do so is by using the archiso and simply using --sysroot or --root to specify the mount point of the system to perform the operation on. See Chroot#Using chroot on how to mount the necessary filesystems required by --sysroot.

Even if pacman is terribly broken, you can fix it manually by downloading the latest packages and extracting them to the correct locations. The rough steps to perform are:

If you have a healthy Arch system on hand, you can see the full list of dependencies with:

But you may only need to update a few of them depending on your issue. An example of extracting a package is

Note the use of the w flag for interactive mode. Running non-interactively is very risky since you might end up overwriting an important file. Also take care to extract packages in the correct order (i.e. dependencies first). This forum post contains an example of this process where only a couple pacman dependencies are broken.

Most likely the initramfs became corrupted during a kernel update (improper use of pacman's --overwrite option can be a cause). There are two options; first, try the Fallback entry.

Once the system starts, run this command (for the stock linux kernel) either from the console or from a terminal to rebuild the initramfs image:

If that does not work, from a current Arch release (CD/DVD or USB stick), mount your root and boot partitions to /mnt and /mnt/boot, respectively. Then chroot using arch-chroot:

Reinstalling the kernel (the linux package) will automatically re-generate the initramfs image with mkinitcpio -p linux. There is no need to do this separately.

Afterwards, it is recommended that you run exit, umount /mnt/{boot,} and reboot.

As the error message says, your locale is not correctly configured. See Locale.

When locale files are intentionally removed by tools such as bleachbit or localepurgeAUR, pacman may issue warnings about missing locales during package updates.

To suppress these warnings, you can comment out the CheckSpace option in pacman.conf. Keep in mind that disabling CheckSpace turns off the space-checking functionality for all package installations, so use this workaround only when you have alternative means to monitor disk space.

Make sure that the relevant environment variables ($http_proxy, $ftp_proxy etc.) are set up. If you use pacman with sudo, you need to configure sudo to pass these environment variables to pacman. Also, ensure the configuration of dirmngr has honor-http-proxy in /etc/pacman.d/gnupg/dirmngr.conf to honor the proxy when refreshing the keys.

To reinstall all the native packages: pacman -Qnq | pacman -S - or pacman -S $(pacman -Qnq) (the -S option preserves the installation reason by default).

You will then need to reinstall all the foreign packages, which can be listed with pacman -Qmq.

It looks like previous pacman transaction removed or corrupted shared libraries needed for pacman itself.

To recover from this situation, you need to unpack required libraries to your filesystem manually. First find what package contains the missed library and then locate it in the pacman cache (/var/cache/pacman/pkg/). Unpack required shared library to the filesystem. This will allow to run pacman.

Now you need to reinstall the broken package. Note that you need to use --overwrite flag as you just unpacked system files and pacman does not know about it. Pacman will correctly replace our shared library file with one from package.

That's it. Update the rest of the system.

Some issues have been reported regarding network problems that prevent pacman from updating/synchronizing repositories. [2] [3] When installing Arch Linux natively, these issues have been resolved by replacing the default pacman file downloader with an alternative (see Improve pacman performance for more details). When installing Arch Linux as a guest OS in VirtualBox, this issue has also been addressed by using Host interface instead of NAT in the machine properties.

If you receive this error message with correct mirrors, try setting a different name server.

If you want to install a package on an sshfs mount using pacman -U and receive this error, move the package to a local directory and try to install again.

Upon executing, e.g., pacman -Syu inside a chroot environment an error is encountered:

This is frequently caused by the chroot directory not being a mountpoint when the chroot is entered. See the note at Install Arch Linux from existing Linux#Downloading basic tools for a solution, and arch-chroot(8) for an explanation and an example of using bind mounting to make the chroot directory a mountpoint.

If you are unable to update packages and receive this error, then try rm -r /var/lib/pacman/sync/ before attempting to update.

If removing sync files doesn't help, check that the sync files are gzip compressed data using file /var/lib/pacman/sync/* before attempting to update. A router or proxy might corrupt the downloads. Corruption could possibly be HTML type.

If sync files are of the correct type, there might be an issue with the mirror server. Look up the mirror server(s) in use with pacman-conf -r core and pacman-conf -r extra. Paste the first returned url in a browser and check that a file listing is returned. In case the mirror returns an error, comment it in /etc/pacman.d/mirrorlist. You may try updating or re-ranking mirrors.

If this error occurs and you're for instance unable to update your system or any package at all, it is possible that you have DISPLAY set to a blank value, which seems to break the GPG-Flow.

In this case, unset DISPLAY or setting it to a arbitrary value will most likely allow to update again, in case any other option above didn't do the trick yet. See this post for further details.

One may use the pacman -Qk $pkg to check if the installed files of the $pkg package match the files from its database version. For several packages, one may use the following loop to reinstall all packages which have missing file(s):

Suppose that your local database located in /var/lib/pacman is more up-to-date compared to installed packages in the / filesystem (e.g., because of a partial rollback), then this method is the appropriate one to re-synchronize the root filesystem with the local database.

**Examples:**

Example 1 (unknown):
```unknown
pacman -Ql pacman pacman-contrib | grep -E 'bin/.+'
```

Example 2 (unknown):
```unknown
pacman -Sy package_name
```

Example 3 (unknown):
```unknown
pacman -Syu package_name
```

Example 4 (unknown):
```unknown
# pacman -S package_name1 package_name2 ...
```

---

## GNU Compiler Collection

**URL:** https://wiki.archlinux.org/title/GCC

**Contents:**
- Installation
  - Old versions
- See also

The GNU Compiler Collection (GCC) is part of the GNU toolchain and includes front ends for C and C++.

Install the gcc package.

Other available front-ends are:

Old versions of GCC may be useful for historical curiosity, old projects that cannot be compiled on the current versions, or for testing the compatibility of projects:

Other front-ends for old versions of GCC may be found on the official repositories and the AUR by searching for gcc<version_without_period>, e.g. searching for gcc9 for GCC 9 front-ends.

**Examples:**

Example 1 (unknown):
```unknown
gcc<version_without_period>
```

Example 2 (unknown):
```unknown
$ export CC=gcc-12 CXX=g++-12
```

---

## Official repositories web interface

**URL:** https://wiki.archlinux.org/title/Official_repositories_web_interface

**Contents:**
- Package information
  - Details
  - Files
- Package search
  - Name or description
  - Exact name
  - Description
  - Repository
  - Architecture
  - Maintainer

This article or section needs expansion.

This article provides documentation for the web interface through which it is possible to query the official repositories and obtain results in JSON format.

Base URL: https://archlinux.org/packages/

Syntax: /repository/architecture/package/json/

Example: https://archlinux.org/packages/core/x86_64/coreutils/json/

Syntax: /repository/architecture/package/files/json/

Example: https://archlinux.org/packages/core/x86_64/coreutils/files/json/

The interface supports the same query parameters as the HTML search form, except for sort.

Base URL: https://www.archlinux.org/packages/search/json/

Example: https://archlinux.org/packages/search/json/?q=pacman

Example: https://archlinux.org/packages/search/json/?name=coreutils

Example: https://archlinux.org/packages/search/json/?desc=pacman

It is possible to use this parameter more than once in order to search in more than one repository (but note that omitting it altogether will search in all repositories).

Values: Core, Core-Testing, Extra, Extra-Testing, Multilib, Multilib-Testing.

Example: https://archlinux.org/packages/search/json/?q=cursor&repo=Core&repo=Extra

It is possible to use this parameter more than once in order to search for more than one architecture (but note that omitting it altogether will search for all architectures).

Example: https://archlinux.org/packages/search/json/?q=cursor&arch=any&arch=x86_64

Parameter: maintainer

Example: https://archlinux.org/packages/search/json/?repo=Extra&maintainer=orphan

Values: Flagged, Not+Flagged

Example: https://archlinux.org/packages/search/json/?arch=x86_64&flagged=Flagged

**Examples:**

Example 1 (unknown):
```unknown
https://archlinux.org/packages/
```

Example 2 (unknown):
```unknown
/repository/architecture/package/json/
```

Example 3 (unknown):
```unknown
/repository/architecture/package/files/json/
```

Example 4 (unknown):
```unknown
https://www.archlinux.org/packages/search/json/
```

---

## Arch build system

**URL:** https://wiki.archlinux.org/title/Arch_build_system

**Contents:**
- Toolchain
  - Repository structure
- Use cases
- Usage
  - Retrieve PKGBUILD source
    - Using the pkgctl tool
    - Using git directly
  - Build package
- Tips and tricks
  - Preserve modified packages

The Arch build system (ABS) is a system for building and packaging software from source code. While pacman is the specialized Arch tool for binary package management, the Arch build system is a collection of tools for compiling source into installable .pkg.tar.zst packages.

The Arch build system can be compared to ports for *BSD, which automates the process of building software from source code. The system uses a port to download, unpack, patch, compile, and install the given software. A port is merely a small directory on the user's computer, named after the corresponding software to be installed, that contains a few files with the instructions for building and installing the software from source. This makes installing software as simple as typing make or make install clean within the port's directory.

The Arch build system is based on a similar concept. It comprises a collection of git repositories for every package available in Arch Linux. Each repository contains a PKGBUILD file (and sometimes other files), and does not contain the software source nor binary. By running makepkg inside a directory, the software sources are downloaded, the software is compiled, and then packaged within the build directory. Then you can use pacman to install the package.

The Arch build system includes and relies on several components and tools that are used in the process of building packages from source:

Each package has its own source repository in the archlinux/packaging/packages namespace on the Arch Linux GitLab instance. Each repository contains the PKGBUILD and files used in official builds. Also some files which are used by the developers for the build process can be found there.

For example, the tree for acl looks like this:

The source code for the package is not present in the directory. Instead, the PKGBUILD contains a URL that will download the source code when the package is built.

When an official package is built, it is released into one of the official repositories: core, extra, multilib, or some testing repository first. These repositories are binary and not hosted on GitLab, but rather served by mirrors.

The Arch build system automates certain tasks related to compilation from source. Its use cases are:

To retrieve the PKGBUILD file required to build a certain package from source, you can either use the pkgctl tool or directly use Git.

As a precondition, install the devtools package. pkgctl is a tool to help work with building source files for Arch Linux packages.

To clone the git repository that contains the latest build files for the package pkgname using pkgctl, the following command is used:

Note that here, build source files refers to PKGBUILD, possibly with some few other required files, such as keys. That is, the essential files that are required for Arch Linux build system. It does not refer to the source files of the package that were written by the team that authored the package, such as C or Python files.

This will give you not only the current source build files, but also their previous versions. Furthermore, you can use all other git commands to checkout an older version of the package or to track custom changes.

If you want to get a specific version of a package you can use something like the following:

Do read pkgctl-repo-clone(1) for more insight, and for the other commands available.

Use the following git command to clone a package:

For example, to copy the Apache build files:

Configure makepkg for building packages from the PKGBUILDs you have checked out, as explained in makepkg#Configuration.

Then, copy the directory containing the PKGBUILD you wish to modify to a new location. Make the desired modifications there and use makepkg there as described in makepkg#Usage to create and install the new package.

Updating the system with pacman will replace a modified package with the package of the same name from the official repositories. See the following instructions for how to avoid this.

Insert a group array into the PKGBUILD, and add the package to a group called modified.

Add this group to the section IgnoreGroup in /etc/pacman.conf.

If new versions are available in the official repositories during a system update, pacman prints a note that it is skipping this update because it is in the IgnoreGroup section. At this point, the modified package should be rebuilt to avoid partial upgrades.

**Examples:**

Example 1 (unknown):
```unknown
make install clean
```

Example 2 (unknown):
```unknown
makepkg.conf
```

Example 3 (unknown):
```unknown
acl
├── keys
│   └── pgp
│       ├── 259B3792B3D6D319212CC4DCD5BF9FEB0313653A.asc
│       ├── 600CD204FBCEA418BD2CA74F154343260542DF34.asc
│       └── B902B5271325F892AC251AD441633B9FE837F581.asc
├── PKGBUILD
└── .SRCINFO
```

Example 4 (unknown):
```unknown
$ pkgctl repo clone pkgname
```

---

## Arch build system

**URL:** https://wiki.archlinux.org/title/ABS

**Contents:**
- Toolchain
  - Repository structure
- Use cases
- Usage
  - Retrieve PKGBUILD source
    - Using the pkgctl tool
    - Using git directly
  - Build package
- Tips and tricks
  - Preserve modified packages

The Arch build system (ABS) is a system for building and packaging software from source code. While pacman is the specialized Arch tool for binary package management, the Arch build system is a collection of tools for compiling source into installable .pkg.tar.zst packages.

The Arch build system can be compared to ports for *BSD, which automates the process of building software from source code. The system uses a port to download, unpack, patch, compile, and install the given software. A port is merely a small directory on the user's computer, named after the corresponding software to be installed, that contains a few files with the instructions for building and installing the software from source. This makes installing software as simple as typing make or make install clean within the port's directory.

The Arch build system is based on a similar concept. It comprises a collection of git repositories for every package available in Arch Linux. Each repository contains a PKGBUILD file (and sometimes other files), and does not contain the software source nor binary. By running makepkg inside a directory, the software sources are downloaded, the software is compiled, and then packaged within the build directory. Then you can use pacman to install the package.

The Arch build system includes and relies on several components and tools that are used in the process of building packages from source:

Each package has its own source repository in the archlinux/packaging/packages namespace on the Arch Linux GitLab instance. Each repository contains the PKGBUILD and files used in official builds. Also some files which are used by the developers for the build process can be found there.

For example, the tree for acl looks like this:

The source code for the package is not present in the directory. Instead, the PKGBUILD contains a URL that will download the source code when the package is built.

When an official package is built, it is released into one of the official repositories: core, extra, multilib, or some testing repository first. These repositories are binary and not hosted on GitLab, but rather served by mirrors.

The Arch build system automates certain tasks related to compilation from source. Its use cases are:

To retrieve the PKGBUILD file required to build a certain package from source, you can either use the pkgctl tool or directly use Git.

As a precondition, install the devtools package. pkgctl is a tool to help work with building source files for Arch Linux packages.

To clone the git repository that contains the latest build files for the package pkgname using pkgctl, the following command is used:

Note that here, build source files refers to PKGBUILD, possibly with some few other required files, such as keys. That is, the essential files that are required for Arch Linux build system. It does not refer to the source files of the package that were written by the team that authored the package, such as C or Python files.

This will give you not only the current source build files, but also their previous versions. Furthermore, you can use all other git commands to checkout an older version of the package or to track custom changes.

If you want to get a specific version of a package you can use something like the following:

Do read pkgctl-repo-clone(1) for more insight, and for the other commands available.

Use the following git command to clone a package:

For example, to copy the Apache build files:

Configure makepkg for building packages from the PKGBUILDs you have checked out, as explained in makepkg#Configuration.

Then, copy the directory containing the PKGBUILD you wish to modify to a new location. Make the desired modifications there and use makepkg there as described in makepkg#Usage to create and install the new package.

Updating the system with pacman will replace a modified package with the package of the same name from the official repositories. See the following instructions for how to avoid this.

Insert a group array into the PKGBUILD, and add the package to a group called modified.

Add this group to the section IgnoreGroup in /etc/pacman.conf.

If new versions are available in the official repositories during a system update, pacman prints a note that it is skipping this update because it is in the IgnoreGroup section. At this point, the modified package should be rebuilt to avoid partial upgrades.

**Examples:**

Example 1 (unknown):
```unknown
make install clean
```

Example 2 (unknown):
```unknown
makepkg.conf
```

Example 3 (unknown):
```unknown
acl
├── keys
│   └── pgp
│       ├── 259B3792B3D6D319212CC4DCD5BF9FEB0313653A.asc
│       ├── 600CD204FBCEA418BD2CA74F154343260542DF34.asc
│       └── B902B5271325F892AC251AD441633B9FE837F581.asc
├── PKGBUILD
└── .SRCINFO
```

Example 4 (unknown):
```unknown
$ pkgctl repo clone pkgname
```

---

## Ruby package guidelines

**URL:** https://wiki.archlinux.org/title/Ruby_package_guidelines

**Contents:**
- Package naming
- Build and tests
- Template
- Tips and tricks
  - The gem is deriving the files to add with "git ls-files"
  - The upstream project is using "rspec" to run tests
- See also

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

This document covers standards and guidelines on writing PKGBUILDs for software that uses ruby.

For libraries, use ruby-$_name (where $_name is the upstream project name). For applications, use the project name (without the ruby- prefix) and optionally add ruby-$_name to provides.

Ruby packages should be built from upstream sources as this provides a transparent chain of trust for the build. To ensure integration with the existing set of Ruby packages, it is expected to run tests using ruby-rake or ruby-rspec.

In this case you can add the following sed command to the prepare() function:

In this case you can replace the code line in the check() function with the following:

**Examples:**

Example 1 (unknown):
```unknown
ruby-$_name
```

Example 2 (unknown):
```unknown
ruby-$_name
```

Example 3 (unknown):
```unknown
prepare() {
  cd "${_name}-${pkgver}"

  # update gemspec/Gemfile to allow newer version of the dependencies
  sed --in-place --regexp-extended 's|~>|>=|g' "${_name}.gemspec"
}

build() {
  cd "${_name}-${pkgver}"

  local _gemdir="$(gem env gemdir)"

  gem build "${_name}.gemspec"

  gem install \
    --local \
    --verbose \
    --ignore-dependencies \
    --build-root "tmp_install" \
    "${_name}-${pkgver}.gem"

  # remove unrepreducible files
  rm --force --recursive --verbose \
    "tmp_install/${_gemdir}/cache/" \
    "tmp_install/${_gemdir}/gems/${_name}-${pkgver}/vendor/" \
    "tmp_install/${_gemdir}/doc/${_name}-${pkgver}/ri/ext/"

  find "tmp_install/${_gemdir}/gems/" \
    -type f \
    \( \
      -iname "*.o" -o \
      -iname "*.c" -o \
      -iname "*.so" -o \
      -iname "*.time" -o \
      -iname "gem.build_complete" -o \
      -iname "Makefile" \
    \) \
    -delete

  find "tmp_install/${_gemdir}/extensions/" \
    -type f \
    \( \
      -iname "mkmf.log" -o \
      -iname "gem_make.out" \
    \) \
    -delete
}

check() {
  cd "${_name}-${pkgver}"

  local _gemdir="$(gem env gemdir)"

  GEM_HOME="tmp_install/${_gemdir}" rake test
}

package() {
  cd "${_name}-${pkgver}"

  cp --archive --verbose tmp_install/* "${pkgdir}"

  install --verbose -D --mode=0644 LICENSE --target-directory "${pkgdir}/usr/share/licenses/${pkgname}"
  install --verbose -D --mode=0644 *.md --target-directory "${pkgdir}/usr/share/doc/${pkgname}"
}
```

Example 4 (unknown):
```unknown
# we don't build from a git checkout
sed --in-place --regexp-extended 's|git ls-files|find . -type f -not -path "*/\.git/*"|' "${_name}.gemspec"
```

---

## FFmpeg

**URL:** https://wiki.archlinux.org/title/FFmpeg

**Contents:**
- Installation
- Encoding examples
  - Screen capture
  - Recording webcam
  - VOB to any container
  - x264
    - Lossless
    - Constant rate factor
    - Two-pass (very high-quality)
    - Video stabilization

From the project home page:

Install the ffmpeg package. A notable variant is ffmpeg-fullAUR, which is built with as many optional features enabled as possible.

See FFmpeg encoding wiki and ffmpeg(1) § EXAMPLES.

FFmpeg includes the x11grab and ALSA virtual devices that enable capturing the entire user display and audio input.

To take a screenshot screen.png:

where -video_size specifies the size of the area to capture.

To take a screencast screen.mkv with lossless encoding and without audio:

Here, the Huffyuv codec is used, which is fast, but produces huge file sizes.

To take a screencast screen.mp4 with lossy encoding and with audio:

Here, the x264 codec with the fastest possible encoding speed is used. Other codecs can be used; if writing each frame is too slow (either due to inadequate disk performance or slow encoding), then frames will be dropped and video output will be choppy.

If the video stream should not be saved as a file, but used as a virtual webcam for screen sharing purposes, see v4l2loopback#Casting X11 using FFmpeg.

See also the official documentation.

FFmpeg includes the video4linux2 and ALSA input devices that enable capturing webcam and audio input.

The following command will record a video webcam.mp4 from the webcam without audio, assuming that the webcam is correctly recognized under /dev/video0:

where -video_size specifies the largest allowed image size from the webcam.

The above produces a silent video. To record a video webcam.mp4 from the webcam with audio:

Here, the x264 codec with the fastest possible encoding speed is used. Other codecs can be used; if writing each frame is too slow (either due to inadequate disk performance or slow encoding), then frames will be dropped and video output will be choppy.

See also the official documentation.

Concatenate the desired VOB files into a single stream and mux them to MPEG-2:

The ultrafast preset will provide the fastest encoding and is useful for quick capturing (such as screencasting):

On the opposite end of the preset spectrum is veryslow and will encode slower than ultrafast but provide a smaller output file size:

Both examples will provide the same quality output.

Used when you want a specific quality output. General usage is to use the highest -crf value that still provides an acceptable quality. Lower values are higher quality; 0 is lossless, 18 is visually lossless, and 23 is the default value. A sane range is between 18 and 28. Use the slowest -preset you have patience for. See the x264 Encoding Guide for more information.

-tune option can be used to match the type and content of the media being encoded.

Audio deactivated as only video statistics are recorded during the first of multiple pass runs:

Container format is automatically detected and muxed into from the output file extension (.mkv):

Video stablization using the vid.stab plugin entails two passes.

The first pass records stabilization parameters to a file and/or a test video for visual analysis.

The second pass parses the stabilization parameters generated from the first pass and applies them to produce "output-stab_final". You will want to apply any additional filters at this point so as to avoid subsequent transcoding to preserve as much video quality as possible. The following example performs the following in addition to video stabilization:

Example command showing the defaults when libx265 is invoked without any parameters (Constant Rate Factor encoding):

See FFmpeg H.265/HEVC Video Encoding Guide for more information.

Allow FFmpeg to automatically set DVD standardized parameters. Encode to DVD MPEG-2 at ~30 FPS:

Encode to DVD MPEG-2 at ~24 FPS:

Subtitles embedded in container files, such as MPEG-2 and Matroska, can be extracted and converted into SRT, SSA, WebVTT among other subtitle formats [1].

Add -c:s srt to save subtitles in desirable format, e.g. SubRip:

When dealing with multiple subtitles, you may need to specify the stream that needs to be extracted using the -map key:stream parameter:

(instructions based on HowToBurnSubtitlesIntoVideo at the FFmpeg wiki)

Hardsubbing entails merging subtitles with the video. Hardsubs cannot be disabled, nor language switched or the font size customized, therefore considered as discouraged sometimes. In case of doubt use SoftSubs instead of HardSubs.

Volume gain can be modified through ffmpeg's filter function. First select the audio stream by using -af or -filter:a, then select the volume filter followed by the number that you want to change the stream by. For example:

Here volume=1.5 provides a 150% volume gain, instead of 1.5 use for example 0.5 to half the volume. The volume filter can also take a decibel measure, use volume=3dB to increase the volume by 3dB or volume=-3dB to decrease it by 3dB.

A given average and peak volume can also be achieved through normalization using the loudnorm filter. To normalize the perceived loudness of a file using fmpeg's default values for target average, peak and range loudness (respectively -24 LUFS, -2 dBTP and 7 LU), use:

To obtain a different loudness profile, use the i, tp and lra parameters of the filter to indicate respectively the integrated, true peak and loudness range. For example for a higher perceived loudness than the default, use:

In this example, print_format=summary is also added to display the input and output loudness values of the audio file.

Extract the first (-map 0:1) AC-3 encoded audio stream exactly as it was multiplexed into the file:

Convert the third (-map 0:3) DTS audio stream to an AAC file with a bitrate of 192 kb/s and a sampling rate of 96000 Hz:

-vn disables the processing of the video stream.

Extract audio stream with certain time interval:

-ss specifies the start point, and -t specifies the duration.

You can use the copy codec to perform operations on a file without changing the encoding. For example, this allows you to easily split any kind of media file into two:

Encoding/decoding performance may be improved by using hardware acceleration API's, however only a specific kind of codec(s) are allowed and/or may not always produce the same result when using software encoding.

VA-API can be used for encoding and decoding on Intel CPUs (requires intel-media-driver or libva-intel-driver) and on certain AMD GPUs when using the open-source AMDGPU driver (requires mesa). See the FFmpeg documentation for information about available parameters and supported platforms.

An example of encoding using the supported H.264 codec:

For a quick reference, a constant quality encoding can be achieved with:

If using hevc_vaapi, tune -qp between 25 (visually identical) and more (28 starts to have very small visual loss). If using h264_vaapi, tune between 18 (visually identical) and more (20 starts to have very small visual loss). Also, hevc_vaapi seems to encode 50% faster than h264_vaapi.

NVENC and NVDEC can be used for encoding/decoding when using the proprietary NVIDIA driver with the nvidia-utils package installed. Minimum supported GPUs are from 600 series, see Hardware video acceleration#NVIDIA for details.

This old gist provides some techniques. NVENC is somewhat similar to CUDA, thus it works even from terminal session. Depending on hardware NVENC is several times faster than Intel's VA-API encoders.

To print available options execute (hevc_nvenc may also be available):

This article or section is a candidate for merging with Hardware video acceleration#Intel Video Processing Library (Intel VPL).

Intel® Quick Sync Video uses media processing capabilities of an Intel GPU to decode and encode fast, enabling the processor to complete other tasks and improving system responsiveness.

This requires a libmfx runtime implementation to be installed. libmfx is a dispatcher library that loads an implementation at runtime based on the underlying hardware platform.

When running under Iron Lake (Gen5) to Ice Lake (Gen10) GPUs, it will load intel-media-sdk as the runtime implementation.

When running under Tiger Lake (Gen11) and newer GPUs, libmfx will load vpl-gpu-rt. See also the vpl-gpu-rt system-requirements.

The runtime implementation cannot be changed or chosen on systems with a single Intel GPU, and the corresponding implementation should be installed following the hardware where it will run.

Failure to install said runtime will result in errors like the following:

The usage of QuickSync is described in the FFmpeg Wiki. It is recommended to use VA-API [2] with either the iHD or i965 driver instead of using libmfx directly, see the FFmpeg Wiki section Hybrid transcode for encoding examples and Hardware video acceleration#Configuring VA-API for driver instructions.

AMD added support for H264 only video encoding on Linux through AMD Video Coding Engine (GPU encoding) with the AMDGPU PRO proprietary packages, and ffmpeg added support for AMF video encoding, so in order to encode using the h264_amf video encoder, amf-amdgpu-proAUR is required. You may need to link to the ICD file provided by the AMDGPU PRO packages as a variable or ffmpeg could use the open AMDGPU's ICD file and not be able to use this video encoder. An example of a command for encoding could be as follows:

For a quick reference, a constant quality encoding can be achieved with:

Tune the three -qp_(b|i|p) together being 18 visually identical and 22 starting to have very small visual loss.

Whilst animated GIFs are generally a poor choice of video format due to their poor image quality, relatively large file size and lack of audio support, they are still in frequent use on the web. The following command can be used to turn a video into an animated GIF:

See https://blog.pkh.me/p/21-high-quality-gif-with-ffmpeg.html for more information on using the palette filters to generate high quality GIFs.

Populate ~/.ffmpeg with the default preset files:

Create new and/or modify the default preset files:

Enable the -vpre option after declaring the desired -vcodec

Use a combination of the following options to reduce verbosity to the desired level:

Direct metadata modification is not possible, they have to be exported, changed, then merged into a new file.

Extract existing (global) metadata into a textfile:

Create new file with metadata from a textfile:

-map_metadata 1 tells ffmpeg to use the metadata from the 2nd file (index start at 0).

Next to global metadata each stream can have own metadata as well, export e.g. with -map_metadata:s:v 0:s:v and -map_metadata:s:a 0:s:a.

ffprobe (from ffmpeg package as well) offers more export formats: default, compact/csv, flat, ini, json and xml.

**Examples:**

Example 1 (unknown):
```unknown
-threads number
```

Example 2 (unknown):
```unknown
$ ffmpeg -f x11grab -video_size 1920x1080 -i $DISPLAY -vframes 1 screen.png
```

Example 3 (unknown):
```unknown
-video_size
```

Example 4 (unknown):
```unknown
$ ffmpeg -f x11grab -video_size 1920x1080 -framerate 25 -i $DISPLAY -c:v ffvhuff screen.mkv
```

---

## Python

**URL:** https://wiki.archlinux.org/title/Python

**Contents:**
- Installation
  - Other versions
  - Alternative implementations
  - Alternative shells
- Package management
  - Arch repositories
  - Third-party packages
  - Historical notes
- Widget bindings
- Tips and tricks

From What is Python?:

Install the python package.

Previous and future versions of Python are available via the Arch User Repository (AUR). These are useful for applications or projects that require specific versions, or just for curiosity:

Each of these packages installs a distinct binary named after the version number, e.g. python3.13 for Python 3.13, allowing multiple versions to coexist on a system. You can also use pyenv(1) or uv to easily install and switch between multiple versions of Python.

Extra modules and libraries for old versions of Python may be found in the AUR by searching for python<version without period>, e.g. searching for python39 for Python 3.9 modules.

You can also download the source for any release on the https://www.python.org/downloads/ page.

The python package installs CPython, the reference implementation of Python. However, there are also other implementations available. These implementations are usually based on older versions of Python and are not fully compatible with CPython.

Implementations available on Arch Linux include:

More implementations exist. Some, such Cinder, are used internally at large technology companies. Others are historically notable but are no longer maintained due to improvements in the most popular implementations.

The python package includes an interactive Python shell/REPL which can be launched with the python command. The following shells are also available:

There are several ways to install Python packages on Arch Linux.

A large number of popular packages are available in the official repositories and AUR. This is the preferred way to install system-wide packages, and the only method officially supported on Arch Linux.

Developers working with Python may need to use packages or package versions not available in the Arch repositories. The recommended practice is to use a separate virtual environment to isolate each project, preventing conflicts with system packages in /usr. Various tools are available to install packages within a virtual environment:

pip, pipx, poetry and uv install packages from the Python Package Index and other indexes. Conda and Miniconda use the Anaconda repositories.

As an alternative to virtual environments, pip install --user can be used to install packages into the user scheme instead of /usr. This separates packages per-user rather than per-project. Virtual environments are usually the better choice.

See the Python Packaging User Guide for the official best practices for package management.

Historically, easy_install (part of python-setuptools) was used to install packages distributed as Eggs. easy_install and Eggs have been replaced with pip and Wheels. See pip vs easy_install and Package Formats for more information.

Previous versions of pip could install third-party packages system-wide, but this caused a number of problems outlined in PEP668. The system-wide environment is now marked as an externally managed environment, and pip no longer allows system-wide installation.

The following widget toolkit bindings are available:

To use these with Python, you may also need to install the associated widget toolkit packages (e.g. tk must also be installed to use Tkinter).

Python provides tools to create isolated virtual environments into which packages may be installed without conflicting with other virtual environments or the system packages. Virtual environments can also run applications with different versions of Python on the same system.

See Python/Virtual environment for details.

Tab completion is available in the interactive shell by default. Note that the readline completer will only complete names in the global namespace. You can use python-jedi for a richer tab completion experience [1].

Sometimes it is useful to know which installed packages were built for a specific version of Python. For example,

will list all those built for Python version 3.12. This is especially useful when the official Python version is updated and one wants to get a list of packages from the AUR that need rebuilding because they were built for a possibly no longer installed Python version, see #Module not found after Python version update.

A Python-based application might output No module named module_name for an installed dependency named module_name after having upgraded the python package to a new minor version (e.g. from version 3.10 to 3.11).

The above scenario happens when a dependency is not available for that Python version or not installed at all. Python packages are installed in a versioned site-packages directory (/usr/lib/pythonX.Y/site-packages if system-wide, or ~/.local/lib/pythonX.Y/site-packages/ if per-user, where X.Y is a version like "3.11"). So whenever there is a new minor version upgrade, the Python-based package built with previous Python version must be rebuilt against the new one in order to be properly used.

Please notice it is the user's responsibility to rebuild non-official packages, including Python-based packages installed from AUR. See AUR#Updating packages and FAQ#What if I run a full system upgrade and there will be an update for a shared library, but not for the applications that depend on it?

**Examples:**

Example 1 (unknown):
```unknown
python<version without period>
```

Example 2 (unknown):
```unknown
pip install --user
```

Example 3 (unknown):
```unknown
$ pacman -Qoq /usr/lib/python3.12
```

Example 4 (unknown):
```unknown
No module named module_name
```

---

## Sendmail

**URL:** https://wiki.archlinux.org/title/Sendmail

**Contents:**
- Installation
- Adding users
- Configuration
  - Obtain TLS certificate
  - sendmail.cf
  - local-host-names
  - access.db
  - aliases.db
  - virtusertable.db
  - Start on boot

Sendmail is the classic mail transfer agent from the Unix world. This article builds upon Mail server.

The goal of this article is to setup Sendmail for local user accounts, without using MySQL or other databases, and also allowing the creation of mail-only accounts.

The factual accuracy of this article or section is disputed.

Install the sendmailAUR, procmailAUR and m4 packages.

Create a Linux user for each user that wants to receive email at username@your-domain.com. To add mail-only accounts, that is, users who can get email, but cannot have shell access or login on X, you can add them like this:

To obtain a certificate, see OpenSSL#Usage.

The factual accuracy of this article or section is disputed.

Create the file /etc/mail/sendmail.mc. You can read all the options for configuring sendmail on the file /usr/share/sendmail-cf/README.

Here is an example using auth over TLS. The example has comments explaing how it works. The comments start with dnl .

Put your domains on the local-host-names file:

Make sure the domains are also resolved by your /etc/hosts file.

Create the file /etc/mail/access and put there the base addresses where you want to be able to relay mail. Lets suppose you have a vpn on 10.5.0.0/24, and you want to relay mails from any ip in that range:

Edit the file /etc/mail/aliases and uncomment the line #root: human being here and change it to be like this:

You can add aliases for your usernames there, like:

Create your virtusertable file and put there aliases that includes domains (useful if your server is hosting several domains)

Enable/start the following units.

Add a user to the SASL database for SMTP authentication.

To forward all mail addressed to any user in the my-other.tld domain to your-username@your-domain.com:

Do not forget to process it again with

**Examples:**

Example 1 (unknown):
```unknown
# useradd -m -s /usr/bin/nologin username
```

Example 2 (unknown):
```unknown
/etc/mail/sendmail.mc
```

Example 3 (unknown):
```unknown
/usr/share/sendmail-cf/README
```

Example 4 (unknown):
```unknown
/etc/mail/sendmail.mc
```

---

## XScreenSaver

**URL:** https://wiki.archlinux.org/title/XScreenSaver

**Contents:**
- Installation
- Configuration
  - Theming
  - DPMS and blanking settings
- Usage
  - Lock on suspend
  - User switching from the lock screen
    - LXDM
    - LightDM
    - SDDM

XScreenSaver is a screen saver and screen locker with graphical effects. The X Window System has functional screen-saving (in the power management sense) by default.

Install the xscreensaver package.

For an Arch Linux branded experience, install the xscreensaver-arch-logoAUR package.

Most options are configured on a user-by-user basis by running xscreensaver-settings. xscreensaver-settings writes the chosen configuration to ~/.xscreensaver, discarding any manual modifications to the file. Global options are defined in /usr/lib/X11/app-defaults/XScreenSaver.

Since at least XScreenSaver 5.22, there is another way to edit XScreenSaver's user configuration, using X resources.

Starting from version 6.0, XScreenSaver comes with several pre-installed themes. You can select a theme using xscreensaver-settings or by changing the dialogTheme option (dialogTheme: themename in ~/.xscreensaver or using X resources: xscreensaver-auth.dialogTheme: themename).

You can customize themes using X resources. The example below demonstrates changing some colors and fonts. If you are using a non-default theme, replace default with the name of your chosen theme in lower case, or use question mark (?) to affect all themes:

You can view a list of the available X resources in /usr/lib/X11/app-defaults/XScreenSaver.

Do not forget to reload the resource file after changes.

This article or section needs language, wiki syntax or style improvements. See Help:Style for reference.

XScreenSaver manages screen blanking and display energy saving (DPMS) independently of X itself and overrides it. To configure the timings for blanking, standby, display poweroff and such, use xscreensaver-demo or edit the configuration file manually, e.g. ~/.xscreensaver:

DPMS and screen blanking can be disabled by starting xscreensaver-demo and, for the Mode setting, choosing Disable Screen Saver.

In the LXDE and LXQt environments, XScreenSaver is autostarted automatically if it is available - no further action is required.

For other environments, see Autostarting.

In KDE Plasma, screen saver and locker features are handled by ksmserver, which conflicts with XScreenSaver. To disable it, edit the plasma-ksmserver.service user unit:

Also open KDE System Settings and disable Power Management > Turn off screen.

Then logout and login again, and XScreenSaver should work properly now. See xscreensaver(1) § INSTALLING XSCREENSAVER ON KDE for more information.

To immediately trigger xscreensaver, if it is running, and lock the screen, execute the following command:

XScreenSaver ships with a small utility named xscreensaver-systemd, which handles signals from systemd using D-Bus and automatically locks the screen on suspend and hibernate. It is started automatically with xscreensaver, no further action required. See xscreensaver-systemd(6) for more information.

By default, XScreenSaver's New Login button in the lock screen will call gdmflexiserver -ls to switch users. Display managers other than GDM that support user switching require a different command.

As modifications in ~/.xscreensaver are discarded by xscreensaver-settings, ~/.Xresources is used in this section.

To use LXDM's switching mode:

To use LightDM's switching mode:

SDDM does not support user switching. [1] You can try to call the SwitchToGreeter method using dbus-send, but it may not work properly.

Starting from version 5.45, the xscreensaver-systemd utility implements the D-Bus ScreenSaver interface. It is started automatically with xscreensaver, so most applications should properly disable the screensaver without additional configuration. However, some applications do not support D-Bus or use another interfaces.

By default mpv uses the X11 Screen Saver extension (XSS). It turns off the screensaver at startup and turns it on again on exit. The screensaver is always re-enabled when the player is paused. The option can be controlled in mpv's configuration file located in ~/.config/mpv/mpv.conf:

This is not supported on all video outputs or platforms. If you face some issues you might use a Lua script to manually disable the screensaver. Create a file at ~/.config/mpv/scripts/xscreensaver.lua with the following contents:

The above script will call xscreensaver-command -deactivate every 30 seconds.

Add the following to ~/.mplayer/config:

Kodi has no native support to disable XScreenSaver (it uses its own screensaver). Install the kodi-prevent-xscreensaverAUR package as a workaround or try Kodi extension from https://sourceforge.net/projects/osscreensavermanager/.

Most browsers (Chromium and Chromium-based spin-offs, Firefox, GNOME Web, Otter Browser etc.) support the D-Bus ScreenSaver interface and should disable the screensaver during HTML5 video playback.

If you are using applications that do not disable the screensaver, you can try a script named lightsonplus, which disables the screensaver when a fullscreen video is detected. Some applications (such as totem, Steam and others) are supported out of the box, you just need to enable their detection in the lightson+ script. If your application is unsupported but has a permanent window name, you can set it in the window_name variable.

One can run xscreensaver in the background, just like a wallpaper. First, kill any process that is controlling the background (the root window).

Then, locate the desired XScreenSaver executable (typically in /usr/lib/xscreensaver/) and run it with the -root flag, for example:

To log verbose debugging information, start xscreensaver with the --verbose command line option. You can also add verbose: True to the ~/.xscreensaver file to make it persistent.

To save the log to a file, you can set the path using the --log option. Using this option also implies verbose output. (There is no equivalent option in ~/.xscreensaver or X resources).

**Examples:**

Example 1 (unknown):
```unknown
~/.xscreensaver
```

Example 2 (unknown):
```unknown
/usr/lib/X11/app-defaults/XScreenSaver
```

Example 3 (unknown):
```unknown
dialogTheme
```

Example 4 (unknown):
```unknown
dialogTheme: themename
```

---

## Himitsu

**URL:** https://wiki.archlinux.org/title/Himitsu

**Contents:**
- Installation
- Configuration
- Usage
- Integrations
  - SSH
  - Firefox

Himitsu is a secure secret storage system for Unix-like systems. It is extensible and suitable for storing passwords, private keys, logins, etc.

Himitsu secrets are stored in a arbitrary key/value store, accessible via a daemon. Himitsu also provides a command-line interface and query language for the store. Himitsu is designed for various integrations and frontends, including the graphical himitsu-keyring application.

Install the himitsuAUR package.

You will also need a Himitsu prompter: hiprompt-gtk-pyAUR.

The himitsu(7) man page is worth reading. The following is a guide specific to an Arch Linux installation of himitsuAUR.

Firstly, you will need a himitsu secstore (secrets store) and some basic configuration. Initialize these with himitsu-store(1).

You will then need to configure Himitsu to use your prompter of choice. Edit the himitsu.ini(5) config file. For example, for hiprompt-gtk-pyAUR:

The Himitsu daemon himitsud(1) can now be run. The Himitsu package comes with a systemd user unit, himitsud.service. Starting/enabling it runs himitsud in the background.

Use the hiq(1) command to query and manage the keystore.

You can manage the keystore graphically using himitsu-keyringAUR.

Himitsu has integrations for various software.

The himitsu-sshAUR package provides an SSH agent and utilities for using and storing SSH keys in the Himitsu keystore.

For ssh to use the Himitsu SSH agent, it is required that:

With that, ssh will consult the Himitsu keystore for SSH key data.

The himitsu-firefoxAUR package provides the backend (a native messaging component) for the official Firefox Himitsu Add-on. Once both installed, Firefox can consult the Himitsu keystore for logins/passwords, from keystore entries with the proto=web key-value pair. The add-on implements the "web" protocol.

**Examples:**

Example 1 (unknown):
```unknown
$ himitsu-store -i
```

Example 2 (unknown):
```unknown
~/.config/himitsu/config.ini
```

Example 3 (unknown):
```unknown
[himitsud]
prompter=hiprompt-gtk
```

Example 4 (unknown):
```unknown
himitsud.service
```

---

## pacman/Package signing

**URL:** https://wiki.archlinux.org/title/Pacman/Package_signing

**Contents:**
- Setup
  - Configuring pacman
  - Initializing the keyring
- Managing the keyring
  - Verifying the master keys
  - Adding developer keys
  - Adding unofficial keys
  - Debugging with gpg
- Tips and tricks
  - Upgrade system regularly

To determine if packages are authentic, pacman uses OpenPGP keys in a web of trust model. The current Master Signing Keys are found here. At least three of these Master Signing Keys are used to sign the Developers' and Package Maintainers' own keys. They are then used to sign their packages. Each user also has a unique OpenPGP key, which is generated when you configure pacman-key(8). It is this web of trust that links the user's key to the master keys.

Examples of webs of trust:

The SigLevel option in /etc/pacman.conf determines the level of trust required to install a package with pacman -S. For a detailed explanation of SigLevel, see pacman.conf(5) § PACKAGE AND DATABASE SIGNATURE CHECKING, and the file comments. One can set signature checking globally, or per repository. If SigLevel is set globally in the [options] section, all packages installed with pacman -S will require signing. With the LocalFileSigLevel setting from the default pacman.conf, any packages you build, and install with pacman -U, will not need to be signed using makepkg.

For remote packages, the default configuration will only support the installation of packages signed by trusted keys:

TrustedOnly is a default compiled-in pacman parameter. The default configuration is identical to using the global option of:

The above can be achieved too on a repository level further below in the configuration, e.g.:

explicitly adds signature checking for the packages of the repository, but does not require the database to be signed. Optional here would turn off a global Required for this repository.

To initialize the pacman keyring run:

The initial setup of keys is achieved using:

Take time to verify the Master Signing Keys when prompted as these are used to co-sign (and therefore trust) all other packager's keys.

OpenPGP keys are too large (2048 bits or more) for humans to work with, so they are usually hashed to create a 40-hex-digit fingerprint which can be used to check by hand that two keys are the same. The last eight digits of the fingerprint serve as a name for the key known as the '(short) key ID' (the last sixteen digits of the fingerprint would be the 'long key ID').

The official Developers' and Package Maintainers' keys are signed by the master keys, so you do not need to use pacman-key to sign them yourself. Whenever pacman encounters a key it does not recognize, it will prompt you to download it from a keyserver configured in /etc/pacman.d/gnupg/gpg.conf (or by using the --keyserver option on the command line). Wikipedia maintains a list of keyservers.

Once you have downloaded a developer key, you will not have to download it again, and it can be used to verify any other packages signed by that developer.

This article or section needs expansion.

This method can be utilized to add a key to the pacman keyring, or to enable signed unofficial user repositories.

First, get the key ID (keyid) from its owner. Then add it to the keyring using one of the two methods:

It is recommended to verify the fingerprint, as with any master key or any other key you are going to sign:

Finally, you must locally sign the imported key:

You now trust this key to sign packages.

For debugging purposes, you can access pacman's keyring directly with gpg, e.g.:

Upgrading the system regularly via pacman#Upgrading packages prevents most signing errors. If delay is unavoidable and system upgrade gets delayed for an extended period, manually sync the package database and upgrade the archlinux-keyring package before system upgrade:

This command is not considered a partial upgrade since it syncs the package database and upgrades the keyring package first. Both must be processed just before starting system upgrade to ensure signatures of all upgraded packages can be properly verified.

When the system time is faulty, signing keys could be considered expired (or invalid) and signature checks on packages will fail. Synchronize the system clock regularly by using the Network Time Protocol daemon.

pacman-key depends on system time. If your system clock is not synchronized, system installation/upgrade may fail with:

If using ntpd, correct the system time (as root) with ntpd -qg followed by hwclock -w.

Other NTP clients can be used. See time synchronization.

If correction of the system clock does not resolve the failure, try one of the following approaches:

Some packages could be corrupted or may be unsigned, causing failure. Remove each offending package from the system cache rm /var/cache/pacman/pkg/pkgname so it gets freshly downloaded, or clear the entire cache.

Remove or reset all the keys installed in your system by removing the /etc/pacman.d/gnupg directory (as root) and by rerunning pacman-key --init followed by pacman-key --populate to re-add the default keys.

If you are not concerned about package signing, you can disable OpenPGP signature checking completely. Edit /etc/pacman.conf to have the following lines under [options]:

You need to comment out any repository-specific SigLevel settings because they override the global settings. This will result in no signature checking, which was the behavior before pacman 4. If you do this, you do not need to set up a keyring with pacman-key. You can change those options later if you decide to enable package verification.

This article or section needs language, wiki syntax or style improvements. See Help:Style for reference.

There are multiple possible sources of this problem:

You might be stuck because of an outdated archlinux-keyring package when doing an upgrade synchronization.

Below are a few solutions that could work depending on your case.

See if upgrading the system can fix it first.

If you suspect that something is not working right with the keyserver, you could try to switch to the Ubuntu keyserver. To do this, edit /etc/pacman.d/gnupg/gpg.conf and change the keyserver line to:

If you suspect that your pacman cache at /var/cache/pacman/pkg/ might contain unsigned packages, try cleaning the cache manually or run:

which removes all cached packages that have not been installed.

Sometimes when running pacman -Syu you might encounter this error:

This occurs because the packager's key used in the package package-name is not present and/or not trusted in the local pacman-key gpg database. Pacman does not seem to always be able to check if the key was received and marked as trusted before continuing. This could also be because a key has expired since it was added to your keychain.

The last two options above break the chain of trust, and should be used with care.

In order to use a proxy when updating keys the honor-http-proxy option must be set in both /etc/gnupg/dirmngr.conf and /etc/pacman.d/gnupg/dirmngr.conf. See GnuPG#Use a keyserver for more information.

**Examples:**

Example 1 (unknown):
```unknown
/etc/pacman.conf
```

Example 2 (unknown):
```unknown
LocalFileSigLevel
```

Example 3 (unknown):
```unknown
pacman.conf
```

Example 4 (unknown):
```unknown
DatabaseOptional
```

---

## CoreDNS

**URL:** https://wiki.archlinux.org/title/CoreDNS

**Contents:**
- Installation
- Configuration
  - Forwarding
- See also

CoreDNS is a DNS server/forwarder, written in Go, that chains plugins. Each plugin performs a (DNS) function making it very flexible. If some functionality is not provided out of the box you can add it by writing a plugin.

CoreDNS can listen for DNS requests coming in over UDP/TCP (Do53), DNS over TLS (DoT, RFC 7858) and DNS over HTTPS (DoH, RFC 8484).

Install the corednsAUR package.

See the documentation on configuration.

coredns.service will look for /etc/coredns/Corefile and fail to start if the file is missing. After creating the configuration file in that location, Start/enable coredns.service.

Below is an example configuration with useful plugins. CoreDNS will start on port 53, serve DNS to the listed subnets and forward everything to Wikimedia DNS servers. You can use drill command to verify that CoreDNS is working locally: drill archlinux.org @127.0.0.1.

To forward queries to a different resolver, use the forward plugin. It supports regular DNS and DNS over TLS. For DNS over TLS, use the tls:// protocol and specify the server hostname with tls_servername.

For example, to forward everything using DNS over TLS to Wikimedia DNS, edit /etc/coredns/Corefile as follows:

Configure 127.0.0.1 and ::1 as your nameserver; see Domain name resolution. Restart coredns.service after that.

Run journalctl -u coredns as root to verify things are working by default. The resolver will now listen on port 53.

If the resolver should be accessible from other hosts, configure other network interfaces or IP addresses in /etc/coredns/Corefile with bind. Also the acl plugin can be used to block ranges that should be use the server for recursion. Refer to CoreDNS plugin documentation for more information.

If the resolver should respect entries from the /etc/hosts file, add a hosts line to /etc/coredns/Corefile. See coredns-hosts(7).

**Examples:**

Example 1 (unknown):
```unknown
coredns.service
```

Example 2 (unknown):
```unknown
/etc/coredns/Corefile
```

Example 3 (unknown):
```unknown
coredns.service
```

Example 4 (unknown):
```unknown
drill archlinux.org @127.0.0.1
```

---

## Console TDM

**URL:** https://wiki.archlinux.org/title/Console_TDM

**Contents:**
- Installation
- Configuration
- See also

Console TDM is an extension for xorg-xinit written in pure bash. It is inspired by CDM, which aimed to be a replacement of display managers such as GDM.

Install the console-tdmAUR package.

Now ensure no other display managers get started by disabling their systemd services.

After installing Console TDM, you should modify your ~/.bash_profile, and add a line:

If you use zsh, add to your ~/.zprofile the following line:

Regardless of which shell is used you should edit ~/.xinitrc and replace your existing exec line with:

You should copy the links to your WM/DE starter to $XDG_CONFIG_HOME/tdm/sessions, and links to non-X programs to $XDG_CONFIG_HOME/tdm/extra. For convenience, you can just run tdmctl init.

The use of the program tdmctl is much like systemctl, and it is a powerful tool to configure Console TDM.

You can customize Console TDM by editing $XDG_CONFIG_HOME/tdm/tdminit (sourced before the user is prompted for a session) and $XDG_CONFIG_HOME/tdm/tdmexit (sourced before the session is actually started).

**Examples:**

Example 1 (unknown):
```unknown
~/.bash_profile
```

Example 2 (unknown):
```unknown
source /usr/bin/tdm
```

Example 3 (unknown):
```unknown
~/.zprofile
```

Example 4 (unknown):
```unknown
bash /usr/bin/tdm
```

---

## Kernel module package guidelines

**URL:** https://wiki.archlinux.org/title/Kernel_module_package_guidelines

**Contents:**
- Package separation
  - Guidelines
  - Rationale
- File placement

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

Packages that contain kernel modules should be treated specially, to support users who wish to have more than one kernel installed on a system.

When packaging software containing a kernel module and other non-module supporting files/utilities, it is important to separate the kernel modules from the supporting files.

When packaging such software (using the NVIDIA drivers as an example) the convention is:

While kernel modules built for different kernels always live in different directories and can peacefully coexist, the supporting files are expected to be found in one location. If one package contained module and supporting files, you would be unable to install the modules for more than one kernel because the supporting files in the packages would cause pacman file conflicts.

The separation of modules and accompanying files allows multiple kernel module packages to be installed for multiple kernels on the same system while sharing the supporting files among them in the expected location.

If a package includes a kernel module that is meant to override an existing module of the same name, such module should be placed in the /lib/modules/X.Y.Z-arch1-1/updates directory. When depmod is run, modules in this directory will take precedence.

**Examples:**

Example 1 (unknown):
```unknown
depends=('linux' 'nvidia-utils')
```

Example 2 (unknown):
```unknown
/lib/modules/X.Y.Z-arch1-1/updates
```

---

## Evilwm

**URL:** https://wiki.archlinux.org/title/Evilwm

**Contents:**
- Installation
- Starting
  - Startup options
- Using evilwm
  - Keyboard controls
  - Mouse controls
  - Virtual desktops
- Tips and tricks
  - Horizontal window maximize
  - Exit evilwm by ending a program

evilwm is a minimalist window manager for the X Window system. It is minimalist in that it omits unnecessary stuff like window decorations and icons. But it is very usable in that it provides good keyboard control with repositioning and maximize toggles, solid window drags, snap-to-border support, and virtual desktops. Its installed binary size is only 0.07 MB.

Install the evilwmAUR package.

Run evilwm with xinit.

evilwm does not control the desktop background or mouse cursor, so you may want to use xsetroot(1).

evilwm can read options via command line switches. Some examples:

A full list of the evilwm options can be found in evilwm(1) § OPTIONS.

By default, evilwm draws a one pixel gold border around the currenly active window. An example of the use of switches to change this would be a ~/.xinitrc file such as:

From evilwm(1) § OPTIONS:

After starting evilwm you will see nothing but a mouse cursor and a black background (or other background if you specified it as above). To open a terminal, use the key combination Ctrl+Alt+Enter. Programs can then be run from the terminal using executable &.

Using the keyboard combination of Ctrl+Alt plus a third key gives you these functions:

By holding down the Alt key, you can perform these functions with the mouse:

Using the keyboard combination of Ctrl+Alt plus a third key gives you these virtual desktop functions:

To move a window from one virtual desktop to another, fix it, switch desktop, then unfix it. Alt+Tab can also be used to cycle through windows on the current desktop.

The key combination of Ctrl+Alt+= will maximize a window vertically. To maximize a window horizontally, use Ctrl+Alt+= to maximize it vertically, then Ctrl+Alt+x to maximize it horizontally (as opposed to just using Ctrl+Alt+x to maximize it full-screen).

By default, evilwm has no quit option. To exit, simply kill X with Ctrl+Alt+Backspace. If you wish, you can exit evilwm by closing a specific program. Instead of using exec evilwm in your ~/.xinitrc file, you can transfer exec to another program. Killing this program will then exit evilwm. For example:

Although not mentioned in the man-page, you can resize windows with the keyboard as well as the mouse. Using the same key-combinations for moving a window, just add the Shift key to the mix to resize a window.

Ctrl+Alt+Shift: h,j,k,l - Resize window smaller horizontally, larger vertically, smaller vertically, larger horizontally

You can make life easier by using xbindkeys to run commands in evilwm. See Xbindkeys for more details.

When you run evilwm, Xorg presents error messages in the log file and/or on the screen and exits. The messages may vary from system to system. Commonly, xorg-fonts-100dpi or xorg-fonts-75dpi is missing. Install either font to solve the problem.

See the following forum thread.

If the default /etc/X11/xinit/xinitrc successfully starts Twm but your ~/.xinitrc fails to start evilwm and .local/share/xorg/Xorg.0.log contains a warning about a missing or invalid file fonts.dir in /usr/share/fonts/misc/, follow the advice below the warning and run

See also Fonts#Older applications

**Examples:**

Example 1 (unknown):
```unknown
-mask1 modifier
```

Example 2 (unknown):
```unknown
-nosoliddrag
```

Example 3 (unknown):
```unknown
exec evilwm -snap 10 -bw 2 -fg red
```

Example 4 (unknown):
```unknown
Ctrl+Alt+Enter
```

---

## Arch User Repository

**URL:** https://wiki.archlinux.org/title/AUR

**Contents:**
- Getting started
- Installing and upgrading packages
  - Prerequisites
  - Acquire build files
  - Acquire a PGP public key if needed
  - Build the package
  - Install the package
  - Upgrading packages
  - Updating packages
- Account status

The Arch User Repository (AUR) is a community-driven repository for Arch Linux users. It contains package descriptions (PKGBUILDs) that allow you to compile a package from source with makepkg and then install it via pacman. The AUR was created to organize and share new packages from the community and to help expedite popular packages' inclusion into the extra repository. This document explains how users can access and utilize the AUR.

A good number of new packages that enter the official repositories start in the AUR. In the AUR, users are able to contribute their own package builds (PKGBUILD and related files). The AUR community has the ability to vote for packages in the AUR. If a package becomes popular enough—provided it has a compatible license and good packaging technique—it may be entered into the extra repository (directly accessible by pacman or from the Arch build system).

Users can search and download PKGBUILDs from the AUR Web Interface. These PKGBUILDs can be built into installable packages using makepkg, then installed using pacman.

if you have set up AUR SSH authentication then it is also possible to interact with the AUR through SSH: type ssh aur@aur.archlinux.org help for a list of available commands.

Installing packages from the AUR is a relatively simple process. Essentially:

First, ensure that the necessary tools are installed by installing base-devel; this meta package has make and other tools needed for compiling from source, listed as dependencies.

Next, choose an appropriate build directory. A build directory is simply a directory where the package will be made or "built" from source, and can be any directory. The examples in the following sections will use ~/builds as the build directory.

Locate the package in the AUR. This is done using the search field at the top of the AUR home page. Clicking the application's name in the search list brings up an information page on the package. Read through the description to confirm that this is the desired package, note when the package was last updated, and read any comments.

There are several methods for acquiring the build files for a package:

Check if a signature file in the form of .sig or .asc is part of the PKGBUILD source array. If that is the case, then acquire one of the public keys listed in the PKGBUILD validpgpkeys array. Refer to makepkg#Signature checking for more information.

Change directories to the directory containing the package PKGBUILD.

View the contents of all provided files. For example, to use the pager less to view PKGBUILD, do:

Make the package. After manually confirming the contents of the files, run makepkg as a normal user. Some helpful flags:

The package can now be installed with pacman:

In the directory containing the package's PKGBUILD, you must first update the files and changes by using the command

then follow the previous build and install instructions.

The AUR is unsupported, so any packages you install are your responsibility to update, not pacman's. If packages in the official repositories are updated, you will need to rebuild any AUR packages that depend on those libraries. The checkrebuild tool and rebuild-detector hook from rebuild-detector can help find packages needing rebuilt.

When editing a user as a Package Maintainer, the Suspended field can be set, which suspends the target user. When a user is suspended, they cannot:

When editing your own account or another as a Package Maintainer, the Inactive field can be set. Inactive accounts are used for two reasons:

The AUR Web Interface has a comments facility that allows users to provide suggestions and feedback on improvements to the PKGBUILD contributor.

Python-Markdown provides basic Markdown syntax to format comments.

One of the easiest activities for all Arch users is to browse the AUR and vote for their favourite packages using the online interface. All packages are eligible for adoption by a Package Maintainer for inclusion in the extra repository, and the vote count is one of the considerations in that process; it is in everyone's interest to vote!

Sign up on the AUR website to get a "Vote for this package" option while browsing packages. After signing up, it is also possible to vote from the commandline with aur-auto-vote-gitAUR.

Alternatively, if you have set up AUR SSH authentication, you can directly vote from the command line using your ssh key. This means that you will not need to save or type in your AUR password.

First, you should flag the package out-of-date indicating details on why the package is outdated, preferably including links to the release announcement or the new release tarball.

You should also try to reach out to the maintainer directly by email. If there is no response from the maintainer after two weeks, you can file an orphan request. See AUR submission guidelines#Requests for details.

If you are having trouble building a package, first read its PKGBUILD and the comments on its AUR page.

It is possible that a PKGBUILD is broken for everyone. If you cannot figure it out on your own, report it to the maintainer (e.g. by posting the errors you are getting in the comments on the AUR page). You may also seek help in the AUR Issues, Discussion & PKGBUILD Requests forum.

The reason might not be trivial after all. Custom CFLAGS, LDFLAGS and MAKEFLAGS can cause failures. To avoid problems caused by your particular system configuration, build packages in a clean chroot. If the build process still fails in a clean chroot, the issue is probably with the PKGBUILD.

See Creating packages#Checking package sanity about using namcap. If you would like to have a PKGBUILD reviewed, post it on the aur-general mailing list to get feedback from the Package Maintainers and fellow AUR members, or the Creating & Modifying Packages forum. You could also seek help in the IRC channel #archlinux-aur on the Libera Chat network.

Users can share PKGBUILDs using the Arch User Repository. See AUR submission guidelines for details.

See i18n.md in the AUR source tree for information about creating and maintaining translation of the AUR Web Interface.

In the beginning, there was ftp://ftp.archlinux.org/incoming, and people contributed by simply uploading the PKGBUILD, the needed supplementary files, and the built package itself to the server. The package and associated files remained there until a "Trusted user" (renamed as Package Maintainer) saw the program and adopted it.

Then the Trusted User Repositories were born. Certain individuals in the community were allowed to host their own repositories for anyone to use. The AUR expanded on this basis, with the aim of making it both more flexible and more usable. In fact, the AUR maintainers were referred to as TUs (Trusted Users) until the change in naming to Package Maintainers.

Between 2015-06-08 and 2015-08-08, the AUR transitioned from version 3.5.1 to 4.0.0, introducing the use of Git repositories for publishing the PKGBUILDs. Existing packages were dropped unless manually migrated to the new infrastructure by their maintainers.

The AUR Archive on GitHub has a repository for every package that was in AUR 3 at the time of the migration. Alternatively, there is the aur3-mirror repository which provides the same.

The packages on the AUR are merely "build scripts", i.e. recipes to build binaries for pacman. For most cases, everything is permitted, subject to usefulness and scope guidelines, as long as you are in compliance with the licensing terms of the content. For other cases, where it is mentioned that "you may not link" to downloads, i.e. contents that are not redistributable, you may only use the file name itself as the source. This means and requires that users already have the restricted source in the build directory prior to building the package. When in doubt, ask.

See #Voting for packages.

See Arch terminology#Package maintainer.

The Arch User Repository is where all PKGBUILDs that users submit are stored, and must be built manually with makepkg. When PKGBUILDs receive enough community interest and the support of a Package Maintainer, they are moved into the extra repository (maintained by the Package Maintainers), where the binary packages can be installed with pacman.

See #Flagging packages out-of-date.

In the meantime, you can try updating the package yourself by editing the PKGBUILD locally. Sometimes, updates do not require changes to the build or package process, in which case simply updating the pkgver or source array is sufficient.

You are probably missing something trivial; see #Debugging the package build process.

Most likely, you do not have the required public key(s) in your personal keyring to verify downloaded files. See Makepkg#Signature checking for details.

Consult the AUR submission guidelines#Rules of submission, then see creating packages.

There are several channels available to submit your package for review; see #Debugging the package build process.

Usually, at least 10 votes are required for something to move into extra. However, if a Package Maintainer wants to support a package, it will often be found in the repository.

Reaching the required minimum of votes is not the only requirement; there has to be a package maintainer willing to maintain the package. Package Maintainers are not required to move a package into the extra repository even if it has thousands of votes.

Usually, when a very popular package stays in the AUR, it is because:

See also Rules for Packages Entering the extra repository

See Makepkg#Improving build times.

Many AUR packages come in "stable" release and "unstable" development versions. Development packages usually have a suffix denoting their Version Control System and are not intended for regular use, but may offer new features or bugfixes. Because these packages only download the latest available source when you execute makepkg, their pkgver() in the AUR does not reflect upstream changes. Likewise, these packages cannot perform an authenticity checksum on any VCS source.

See also System maintenance#Use proven software packages.

It is possible the package has been adopted by a Package Maintainer and is now in the extra repository.

Packages may be deleted if they did not fulfill the rules of submission. See the aur-requests archives for the reason for deletion.

The simplest way is to check the HTTP status of the package's AUR page:

**Examples:**

Example 1 (unknown):
```unknown
/etc/makepkg.conf
```

Example 2 (unknown):
```unknown
ssh aur@aur.archlinux.org help
```

Example 3 (unknown):
```unknown
pacman -U package_file
```

Example 4 (unknown):
```unknown
$ git clone https://aur.archlinux.org/package_name.git
```

---

## Herbstluftwm

**URL:** https://wiki.archlinux.org/title/Herbstluftwm

**Contents:**
- Installation
- Starting
  - From tty
  - Display manager
  - From inside other window manager
- First steps
- Configuration
  - Multi-Monitor Support
- Commands
- Scripts and hooks

Herbstluftwm is a manual tiling window manager for X11 using Xlib.

install the herbstluftwm package or herbstluftwm-gitAUR for the development version.

Run herbstluftwm with xinit.

herbstluftwm includes herbstluftwm.desktop as Xsession which starts the window manager.

If you are already inside a window manager session, you can replace that window manager with herbstluft by running herbstluftwm --replace.

Read the herbstluftwm(1) and herbstclient(1) man pages, they contain a lot of information from an explanation of the binary tree in which the layout is kept to configuration file options and possible values.

Copy /etc/xdg/herbstluftwm/autostart file to ~/.config/herbstluftwm/autostart. You can edit that file for your needs. Make sure the autostart file is executable, else you will probably end up without keybindings!

The configuration of herbstluftwm can be updated on-the-fly by running herbstclient reload (See #Commands). Autostart is called on each reload, therefore within autostart you typically unmap all existing configuration first.

Herbstluftwm supports multiple monitors as a virtual concept; monitors in herbstluftwm do not have to match the real monitor configuration as reported by xrandr. It brings a lot of flexibility and gives the user more control over their monitor-arrangement. You can use herbstclient detect_monitors to automatically adapt to the physical setup. Otherwise, see the manpage on how to add, remove, resize and move monitors. Tags in a multi-monitor set-up are not "owned" by a monitor. This means that when one monitor switches to a tag that is active in another monitor, the two monitors will swap tags.

Herbstclient is a very powerful tool, as it provides you with full control over your window manager from the command line.

There is a tab-completion for the parameters for herbstclient. Try herbstclient list_commands to show all parameters.

Right now there is no error message if you use wrong parameters on a command, but only a non-zero return value. If you do not show the return value of a command anyway (e.g. in your $SHELL-prompt), you might want to echo $? to find the return value of the last command.

The main way to control herbstluftwm is though commands to herbstclient. Since herbstclient can be called from any script, you have great flexibility in controlling herbstluftwm this way. Furthermore, you can listen to window management events and react to them accordingly.

Herbstluftwm includes a number of example scripts: /usr/share/doc/herbstluftwm/examples/ or https://github.com/herbstluftwm/herbstluftwm/tree/master/scripts

The following python script allows you to switch to the (next or previous) (full or empty) tag. Call it with the arguments (+1 or -1) and (full or empty). For example, if you save the script to herbst-move.py, then

will move you to the next full tag. I use the following key bindings.

And here is the script.

Here is a ruby script to cycle through a set of paddings, although you can modify it to cycle though any collection of settings. The script knows the previous layout by looking for the presence of two dummy files in /tmp.

The following Perl script demonstrates how to use hooks to react to window management events. It can be called in autostart (with backgrounding).

**Examples:**

Example 1 (unknown):
```unknown
herbstluftwm
```

Example 2 (unknown):
```unknown
herbstluftwm.desktop
```

Example 3 (unknown):
```unknown
herbstluftwm --replace
```

Example 4 (unknown):
```unknown
/etc/xdg/herbstluftwm/autostart
```

---

## Chromium

**URL:** https://wiki.archlinux.org/title/Chrome

**Contents:**
- Installation
- Configuration
  - Default applications
  - Certificates
  - Making flags persistent
  - Force GPU acceleration
  - Hardware video acceleration
    - Vulkan
    - Tips and tricks
  - KDE integration

Chromium is an open-source graphical web browser based on the Blink rendering engine. It is the basis for the proprietary Google Chrome browser.

See this page for an explanation of the differences between Chromium and Google Chrome. Additionally:

Consider switching to xbrowsersync for bookmarks syncing as long term solution.

See List of applications/Internet#Blink-based for other browsers based on Chromium.

Install the chromium package, which tracks the google-chromeAUR releases.

This article or section is a candidate for merging with #Tips and tricks.

To set Chromium as the default browser and to change which applications Chromium launches when opening downloaded files, see default applications.

Chromium uses Network Security Services for certificate management. Certificates can be managed in chrome://certificate-manager.

The "Local certificates" tab manages server certificates. Certificates added in the "Custom" section are per-profile, and stored in the ServerCertificate SQLite database in the profile directory. Certificates in the "Linux" section are read from the NSS Shared DB at ~/.pki/nssdb, and cannot be modified in this UI. To add to NSS Shared DB, use another tool such as certutil. See #SSL certificates for usage examples.

The "Your certificates" tab manages client certificates. Certificates added here are stored in the NSS Shared DB.

You can put your flags in a chromium-flags.conf file under $HOME/.config/ (or under $XDG_CONFIG_HOME if you have configured that environment variable) or /etc/ for global.

No special syntax is used; flags are defined as if they were written in a terminal.

Below is an example chromium-flags.conf file that defines the flags --start-maximized --incognito:

Since at least Chromium 110, GPU acceleration is enabled by default for most systems. You may have to append the following flags to persistent configuration if your system configuration is matched by the block list:

If you have confirmed working VA-API support by checking the output of vainfo (see Hardware video acceleration#Verifying VA-API), you might first try the following flag alone:

--enable-features=AcceleratedVideoDecodeLinuxZeroCopyGL.

Otherwise, continue reading.

To enable accelerated encoding in Chromium:

To enable VA-API support:

When using Vulkan, the following flags are required and might also be sufficient on Chromium 126 and Mesa 24.1:

without any of the additional flags mentioned above.

This article or section is out of date.

To check if it is working play a video which is using a codec supported by your VA-API driver (vainfo tells you which codecs are supported, but Chromium will only support VP9 and h264):

Test on a large enough video. Starting with version 86, Chromium on desktop will only accelerate videos larger than 720p.

To reduce CPU usage while watching YouTube where VP8/VP9 hardware decoding is not available use the h264ify, enhanced-h264ify or Not yet, AV1[7] extension.

On some systems (especially on Xwayland) you might need to #Force GPU acceleration. Only --ignore-gpu-blocklist is enough for our purposes.

This article or section needs expansion.

You might need to disable the Skia renderer, as it is currently not compatible with video decode acceleration: --disable-features=UseSkiaRenderer

For integration into Plasma install plasma-browser-integration. See KDE Plasma Browser Integration for more details.

Chromium and Google Chrome are bundled with the Chromium PDF Viewer plugin. If you do not want to use this plugin, check Download PDFs in chrome://settings/content/pdfDocuments.

If you are using NVIDIA's proprietary driver, running Chromium on Xwayland may cause the GPU process to occasionally crash. To prevent the GPU process from crashing, add the following flags:

Chromium 140 supports Wayland by default. For old versions, you can use

See #Making flags persistent for a permanent configuration. The flag is also available via browser flags menu.

This will select wayland Ozone backend when in wayland session, so you can use a single desktop entry if you switch between X11 and Wayland often.

Additionally, if you are having trouble with input methods you may also want to force newer GTK:

If a AltGr/Compose key stops working, adding this workaround might fix it:

If you are using Fcitx5 and not work properly when using the above flags, try using the --enable-wayland-ime flag instead of --gtk-version=4. [8]

To enable two finger swipe to go back and forward through your history, use the following flags:

This article or section is a candidate for merging with HiDPI#Chromium / Google Chrome.

To force a scale factor on native Wayland, use the following flags [9]:

The following tips and tricks should work for both Chromium and Chrome unless explicitly stated.

A number of tweaks can be accessed via Chrome URLs. See chrome://chrome-urls for a complete list.

An automatically updated, complete listing of Chromium switches (command line parameters) is available here.

Shift+ESC can be used to bring up the browser task manager wherein memory, CPU, and network usage can be viewed.

If you enabled syncing with a Google Account, then Chromium will override any direct edits to the Preferences file found under ~/.config/chromium/Default/Preferences. To work around this, start Chromium with the --disable-sync-preferences switch:

If Chromium is started in the background when you login in to your desktop environment, make sure the command your desktop environment uses is:

Make sites like wiki.archlinux.org and wikipedia.org easily searchable by first executing a search on those pages, then going to Settings > Search and click the Manage search engines.. button. From there, "Edit" the Wikipedia entry and change its keyword to w (or some other shortcut you prefer). Now searching Wikipedia for "Arch Linux" from the address bar is done simply by entering "w arch linux".

To limit Chromium from writing its cache to a physical disk, one can define an alternative location via the --disk-cache-dir flag:

Cache should be considered temporary and will not be saved after a reboot or hard lock. Another option is to setup the space in /etc/fstab:

Alternatively create a symbolic link to /tmp. Make sure to delete Chromium's cache folder before you run the command:

Relocate the browser profile to a tmpfs filesystem, including /tmp, or /dev/shm for improvements in application response as the entire profile is now stored in RAM.

Use an active profile management tool such as profile-sync-daemon for maximal reliability and ease of use. It symlinks or bind mounts and syncs the browser profile directories to RAM. For more, see Profile-sync-daemon.

When you launch the browser, it first checks if another instance using the same data directory is already running. If there is one, the new window is associated with the old instance. If you want to launch an independent instance of the browser, you must specify separate directory using the --user-data-dir parameter:

By default, Chromium downloads *.torrent files directly and you need to click the notification from the bottom-left corner of the screen in order for the file to be opened with your default torrent client. This can be avoided with the following method:

See xdg-open to change the default assocation.

You may need to specify which touch device to use. Find your touchscreen device with xinput list then launch Chromium with the --touch-devices=x parameter, where "x" is the id of your device.

By default, Chromium uses a separate OS process for each instance of a visited web site. [10] However, you can specify command-line switches when starting Chromium to modify this behaviour.

For example, to share one process for all instances of a website:

To use a single process model:

In addition, you can suspend or store inactive Tabs with extensions such as Tab Suspender and OneTab.

The User Agent can be arbitrarily modified at the start of Chromium's base instance via its --user-agent="[string]" parameter.

Chromium has a similar reader mode to Firefox. In this case it is called DOM Distiller, which is an open source project. It is disabled by default, but can be enabled using the chrome://flags/#enable-reader-mode flag, which you can also make persistent. Not only does DOM Distiller provide a better reading experience by distilling the content of the page, it also simplifies pages for print. Even though the latter checkbox option has been removed from the print dialog, you can still print the distilled page, which basically has the same effect.

After enabling the flag, you will find a new "Enter reader mode" menu item and corresponding icon in the address bar when Chromium thinks the website you are visiting could do with some distilling.

In multi-GPU systems, Chromium automatically detects which GPU should be used for rendering (discrete or integrated). This works 99% of the time, except when it does not - if an unavailable GPU is picked (for example, discrete graphics on VFIO GPU passthrough-enabled systems), chrome://gpu will complain about not being able to initialize the GPU process. On the same page below Driver Information there will be multiple GPUs shown (GPU0, GPU1, ...). There is no way to switch between them in a user-friendly way, but you can read the device/vendor IDs present there and configure Chromium to use a specific GPU with flags:

...where 0x8086 and 0x1912 is replaced by the IDs of the GPU you want to use (as shown on the chrome://gpu page).

To ease the transition, you can import bookmarks from Firefox into Chromium.

Navigate Chromium to chrome://settings/importData

If Firefox is already installed on your computer, you can directly import bookmarks as well as many other things from Firefox.

Make sure Mozilla Firefox is selected. Optionally, you can uncheck some unwanted items here. Click the Import and then Done. You are done with it.

If you import bookmarks from another PC, you have to export bookmarks from Firefox first.

Ctrl+Shift+o Import and Backup > Export Bookmarks To HTML in Firefox.

The procedure is pretty much the same. You need to go to chrome://settings/importData. However, this time, in the From drop-down menu, select Bookmarks HTML File and click the Choose File button and upload the desired bookmark file.

Go to chrome://flags#enable-system-notifications and select Enabled.

The autoscroll is still an experimental feature [12]. It is intended to be disabled by default if Chromium or Chromium-based browsers are not a development build and is running on a Linux environment. [13]

To enable this feature, launch your browser with the --enable-features=MiddleClickAutoscroll flag. In case you want to make the option persistent, see #Making flags persistent.

Install libfido2 library. This provides the udev rules required to enable access to the U2F key as a user. U2F keys are by default only accessible by root, and without these rules Chromium will give an error.

You can make Chromium use your current GTK theme for browser menus and controls. Simply press Use GTK in chrome://settings/appearance.

Since Chromium 114, XDG Desktop Portal is used to automatically determine the user's preferred appearance (issue), thereby dissociating dark mode enablement from the user's GTK theme. This preference will be applied to prefers-color-scheme in CSS, JavaScript, Settings and Dev-Tools.

The way to change the preferred appearance depends on your XDG Desktop Portal backend. For instance, many desktop environments have a switch in their appearance settings. Or when using e.g. xdg-desktop-portal-gtk, set the preferred mode to prefer-light, prefer-dark or default with:

You can query the current preferred appearance using dbus-send in dbus (documentation):

To enable dark mode and enable the dark theme (normally used for incognito mode) append the following flag to persistent configuration:

The Side Panel can be enabled through chrome://flags. You can enable or disable Side panel, and change options such as Side panel border and Side panel drag and drop.

Chromium uses SQLite databases to manage history and the like. Sqlite databases become fragmented over time and empty spaces appear all around. But, since there are no managing processes checking and optimizing the database, these factors eventually result in a performance hit. A good way to improve startup and some other bookmarks- and history-related tasks is to defragment and trim unused space from these databases.

profile-cleaner and browser-vacuumAUR do just this.

At the cost of reduced performance, you can disable just-in-time compilation of JavaScript to native code, which is responsible for roughly half of the security vulnerabilities in the JS engine, using the flag --js-flags=--jitless.

WebRTC is a communication protocol that relies on JavaScript that can leak one's actual IP address and hardware hash from behind a VPN. While some software may prevent the leaking scripts from running, it is probably a good idea to block this protocol directly as well, just to be safe. As of October 2016, there is no way to disable WebRTC on Chromium on desktop, there are extensions available to disable local IP address leak, one is this extension.

One can test WebRTC via https://browserleaks.com/webrtc.

See #Certificates for general information.

Grab the CAcerts and create an nssdb, if one does not already exist. To do this, first install the nss package, then complete these steps:

Now users may manually import a self-signed certificate.

Below is a simple script that will extract and add a certificate to the user's nssdb:

Syntax is advertised in the commented lines.

The firefox browser can be used to save the certificate to a file for manual import into the database.

Now import the certificate for use in Chromium:

Canvas fingerprinting is a technique that allows websites to identify users by detecting differences when rendering to an HTML5 canvas. This information can be made inaccessible by using the --disable-reading-from-canvas flag.

To confirm this is working run this test and make sure "hash of canvas fingerprint" is reported as undetermined in the full results.

See Browser extensions#Privacy.

To enable Do Not Track, visit chrome://settings, scroll down to Advanced and under Privacy and security, check Send a "Do Not Track" request with your browsing traffic.

Chromium uses a password store to store your passwords and the Chromium Safe Storage key, which is used to encrypt cookie values. [14]

By default Chromium auto-detects which password store to use, which can lead to you apparently losing your passwords and cookies when switching to another desktop environment or window manager.

You can force Chromium to use a specific password store by launching it with the --password-store flag with one of following the values [15]:

For example, to force Chromium to use Gnome Keyring in another desktop or WM use --password-store=gnome-libsecret, see #Making flags persistent for making it permanent.

When using a password store of another desktop environment you probably also want to unlock it automatically. See GNOME/Keyring#Using the keyring and KDE Wallet#Unlock KDE Wallet automatically on login.

Chromium supports the hybrid post-quantum key exchange X25519Kyber768 for TLS 1.3 since version 155 [16]. This feature is disabled by default, but can be enabled using the chrome://flags/#enable-tls13-kyber flag.

You can open any website in a tabless window intended for Progressive Web Apps:

You need to use a correct full URL. This could be combined with --user-data-dir to split configs. Local html file is also used at native application with --allow-file-access-from-files --app=file://*.

You can force offline state by --proxy-server=dummy for security when you use local html file from Chromium.

Chromium has --enable-parallel-downloading flag for parallel downloading without extensions.

Chromium will use the GTK settings as described in GTK#Configuration. When configured, Chromium will use the gtk-font-name setting for tabs (which may mismatch window font size). To override these settings, use --force-device-scale-factor=1.0.

Since Chrome Refresh 2023 became default, GNOME users with Cantarell font may notice some characters (like lowercase g) cut off in the tab title. See the issue on chromium.org.

Until the issue resolved, a workaround is to replace Cantarell with another font using a configuration based on Font configuration#Set default or fallback fonts, e.g.

This configuration will apply only if process name chromium matches. You can use chrome for Google Chrome.

There is the possibility that your graphics card has been blacklisted by Chromium. See #Force GPU acceleration.

If you are using Chromium with Bumblebee, WebGL might crash due to GPU sandboxing. In this case, you can disable GPU sandboxing with optirun chromium --disable-gpu-sandbox.

Visit chrome://gpu/ for debugging information about WebGL support.

Chromium can save incorrect data about your GPU in your user profile (e.g. if you use switch between an Nvidia card using Optimus and Intel, it will show the Nvidia card in chrome://gpu even when you are not using it or primusrun/optirun). Running using a different user directory, e.g, chromium --user-data-dir=$(mktemp -d) may solve this issue. For a persistent solution you can reset the GPU information by deleting ~/.config/chromium/Local\ State.

Chromium will automatically scale for a HiDPI display, however, this may cause an incorrect rendered GUI.

The flag --force-device-scale-factor=1 may be used to overrule the automatic scaling factor.

When native Wayland support is enabled, Chromium will automatically scale based on the configured scale of each monitor.

See GNOME/Keyring#Passwords are not remembered.

If synchronization is not working for password only (you can check it on chrome://sync-internals/) delete profile login data:

See Google Chrome Help forum for details.

If you see the message Failed to decrypt token for service AccountId-* in the terminal when you start Chromium, it might try to use the wrong password storage backend. This might happen when you switch between Desktop Environments.

See #Force a password store.

Try launching Chrome with --password-store=basic or another appropriate password store.

See #Force a password store.

If you are using KDE and have once set Firefox as the default browser (by clicking the button inside Firefox), you might find Chromium asks to be set as the default browser every time it starts, even if you click the "set as default" button.

Chromium checks for this status by running xdg-settings check default-web-browser chromium.desktop. If the output is "no", it is not considering itself to be the default browser. The script xdg-settings checks for the following MIME associations and expect all of them to be chromium.desktop:

To fix it, go to System settings > Applications > Default applications > Web browser and choose Chromium. Then, set the MIME association for text/html:

Finally, update the MIME database:

As of 2020.04.20 if you run chromium with --remote-debugging-port=9222 flag for web development, you cannot log in to your Google account. Temporarily disable this flag to login and then you can enable it back.

Upstream bug report about the general issue which may contain some additional workarounds can be found here, and a sister issue about mixed refresh rates here.

When using displays with mixed refresh rates(for example 60Hz and 144Hz), Chromium might render for the lower Hz display.

There is a suitable workaround for this issue, append the following flags to persistent configuration:

This should make Chromium run at 144 FPS when used on a 144Hz display, assuming your compositor is also refreshing at 144 FPS. Keep in mind it might be a little choppy due to FS#67035, but it is way better than being stuck at 60 FPS.

There seem to be Wayland compositor-specific problems that trigger this issue. Notably, Plasma 5 seems to only ever render on 60Hz no matter the setup, but Plasma 6(rc1, at the time of writing) makes Chromium work flawlessly on high refresh rates.

A workaround may be to switch to the XWayland backend if all else fails.

Mouse whell scrolling in chromium and electron based applications may be too slow for daily usage. Here are some solutions.

Libinput#Mouse wheel scrolling speed scaling injects libinput_event_pointer_get_axis_value function in libinput and provides an interface to change scale factor. This is not an application level injection, so an addition script for application specific scale factor tuning is needed. Note that scroll on chromium's small height developer tools may be too fast when scale factor is big enough.

IMWheel increases scroll distance by replaying X wheel button event for multiple times. However, chromium assumes the real scroll and the replayed ones as two events. There is a small but noticeable delay between them, so one mouse wheel scroll leads to twice page jumps. Also, touchpad scroll needs additional care.

Linux Scroll Speed Fix and SmoothScroll are two chromium extensions with support for scroll distance modification. Upon wheel scroll in a web page, the closest scrollable ancestor of current focused node will be found, then a scroll method with given pixel distance will be called on it, even if it has been scrolled to bottom. So once you scroll into a text editor or any scrollable element, you can never scroll out of it, except moving mouse. Also, extension based methods can not be used outside chromium.

This article or section is out of date.

This may be a PulseAudio issue. See the suggested fix in PulseAudio/Troubleshooting#Browsers (firefox) load videos but do no play.

The stored password database can become corrupted and in need of getting rebuilt. Doing so will destroy all data therein/lose stored passwords.

Launch chromium from a terminal and look for output like:

Exit chromium and then delete these three database files: ~/.config/chromium/Default/Login Data*

Launching chromium again should re-create them.

See KDE#Plasma cursor sometimes shown incorrectly.

Due to a bug, chromium 124 must be started with the explicit command line flag --ozone-platform=wayland.

Due to a bug, you may see the below in your log when launching from terminal, especially with hardware acceleration enabled on Wayland:

Workaround for now is adding this flag:

Chromium does not support Advanced Linux Sound Architecture#Addressing hardware directly. Set output devices pcm.dmixer and pcm.dsnooper as seen in the page and use -alsa-output-device=pcm.dmixer -alsa-input-device=pcm.dsnooper flags.

Due to extensions which define global shortcuts (such as obsidian web clipper), the gnome "Global Shortcuts" appears at startup. This is described in https://github.com/brave/brave-browser/issues/44886 and can be fixed by adding this flag:

Due to a bug the "Compose" key does not work in recent versions of chromium. This becomes apparent when user tries to type in special characters such as `@` or umlauts anywhere in the browser. The special key combinations utilizing the compose key (for example `ALT GR`) work in all applications except chromium. This issue is most likely related to gtk and cannot be resolved by switching between Wayland and X11. It is described at https://issues.chromium.org/issues/327158031 and can be fixed by adding this flag:

**Examples:**

Example 1 (unknown):
```unknown
chrome://certificate-manager
```

Example 2 (unknown):
```unknown
ServerCertificate
```

Example 3 (unknown):
```unknown
~/.pki/nssdb
```

Example 4 (unknown):
```unknown
chromium-flags.conf
```

---

## Shell package guidelines

**URL:** https://wiki.archlinux.org/title/Shell_package_guidelines

**Contents:**
- Install
- Shell completions
- Shell functions or modules

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

For users to change shells, the shell must appear in /etc/shells. Most shell packages have install scripts like below:

Most shells provide a built in set of completions for a few common commands while also scanning at least one system directory for functions that may be supplied by other packages. The following table is a summary of where packages may place completion files and what the files should be named.

**Examples:**

Example 1 (unknown):
```unknown
/etc/shells
```

Example 2 (unknown):
```unknown
shellname.install
```

Example 3 (unknown):
```unknown
post_install() {
    grep -Fqx /bin/shellname /etc/shells || echo /bin/shellname >>/etc/shells
    grep -Fqx /usr/bin/shellname /etc/shells || echo /usr/bin/shellname >>/etc/shells
}

post_upgrade() {
    post_install
}

post_remove() {
    sed -i -r '/^(\/usr)?\/bin\/shellname$/d' etc/shells
}
```

Example 4 (unknown):
```unknown
/usr/share/bash-completion/completions/
```

---

## doas

**URL:** https://wiki.archlinux.org/title/Doas

**Contents:**
- Installation
- Usage
- Configuration
- Tips and tricks
  - doas persist feature
  - Smooth transition sudo to doas
  - Bash tab completion

OpenDoas is a portable version of OpenBSD's doas command, known for being substantially smaller in size compared to sudo. Like sudo, doas is used to assume the identity of another user on the system.

Install the opendoas package.

To begin using doas as a non-privileged user, it must be properly configured. See #Configuration.

To use doas, simply prefix a command and its arguments with doas and a space:

For example, to use pacman:

To get to an interactive shell as an other user (omitting -u user will default to root):

Logging in as an other user is needed for some commands, see Sudo#Login shell.

For more information, see doas(1).

After installing OpenDoas, it will be attached with PAM, but no default configuration or examples are included.

To allow members of group wheel to run commands as other users, create a configuration file with the following content:

The owner and group for /etc/doas.conf should both be 0, file permissions should be set to 0400:

To check /etc/doas.conf for syntax errors, run:

To allow members of the plugdev group to run smartctl without password as Root user:

The general syntax form of /etc/doas.conf is:

The last matching rule determines the action taken, so rules must be ordered accordingly.

For more details please read doas.conf(5).

doas provides a persist feature: after the user successfully authenticates, they will not be prompted for a password again for 5 minutes. It is disabled by default, enable it with the persist option:

Executing doas -L clears a persisted authentication prior to its automatic timeout.

For a smooth transition from sudo to doas and to stay downward compatible, you could add to your environment:

and put doas wrapper to where sudo would normally be (but it does not provide sudoedit command):

By default Bash will only tab complete files and directories within the current or referenced directory. To tell Bash to complete arguments as if they were separate commands (also leveraging the tab completion settings of other commands) the following can be added to either the users .bashrc, or the global /etc/bash.bashrc:

If bash-completion is installed, the following can be used instead to allow for additional completion of the target command:

**Examples:**

Example 1 (unknown):
```unknown
$ doas pacman -Syu
```

Example 2 (unknown):
```unknown
$ doas -su user
```

Example 3 (unknown):
```unknown
/etc/doas.conf
```

Example 4 (unknown):
```unknown
permit setenv {PATH=/usr/local/bin:/usr/local/sbin:/usr/bin:/usr/sbin} :wheel
```

---

## Arch User Repository

**URL:** https://wiki.archlinux.org/title/Arch_User_Repository

**Contents:**
- Getting started
- Installing and upgrading packages
  - Prerequisites
  - Acquire build files
  - Acquire a PGP public key if needed
  - Build the package
  - Install the package
  - Upgrading packages
  - Updating packages
- Account status

The Arch User Repository (AUR) is a community-driven repository for Arch Linux users. It contains package descriptions (PKGBUILDs) that allow you to compile a package from source with makepkg and then install it via pacman. The AUR was created to organize and share new packages from the community and to help expedite popular packages' inclusion into the extra repository. This document explains how users can access and utilize the AUR.

A good number of new packages that enter the official repositories start in the AUR. In the AUR, users are able to contribute their own package builds (PKGBUILD and related files). The AUR community has the ability to vote for packages in the AUR. If a package becomes popular enough—provided it has a compatible license and good packaging technique—it may be entered into the extra repository (directly accessible by pacman or from the Arch build system).

Users can search and download PKGBUILDs from the AUR Web Interface. These PKGBUILDs can be built into installable packages using makepkg, then installed using pacman.

if you have set up AUR SSH authentication then it is also possible to interact with the AUR through SSH: type ssh aur@aur.archlinux.org help for a list of available commands.

Installing packages from the AUR is a relatively simple process. Essentially:

First, ensure that the necessary tools are installed by installing base-devel; this meta package has make and other tools needed for compiling from source, listed as dependencies.

Next, choose an appropriate build directory. A build directory is simply a directory where the package will be made or "built" from source, and can be any directory. The examples in the following sections will use ~/builds as the build directory.

Locate the package in the AUR. This is done using the search field at the top of the AUR home page. Clicking the application's name in the search list brings up an information page on the package. Read through the description to confirm that this is the desired package, note when the package was last updated, and read any comments.

There are several methods for acquiring the build files for a package:

Check if a signature file in the form of .sig or .asc is part of the PKGBUILD source array. If that is the case, then acquire one of the public keys listed in the PKGBUILD validpgpkeys array. Refer to makepkg#Signature checking for more information.

Change directories to the directory containing the package PKGBUILD.

View the contents of all provided files. For example, to use the pager less to view PKGBUILD, do:

Make the package. After manually confirming the contents of the files, run makepkg as a normal user. Some helpful flags:

The package can now be installed with pacman:

In the directory containing the package's PKGBUILD, you must first update the files and changes by using the command

then follow the previous build and install instructions.

The AUR is unsupported, so any packages you install are your responsibility to update, not pacman's. If packages in the official repositories are updated, you will need to rebuild any AUR packages that depend on those libraries. The checkrebuild tool and rebuild-detector hook from rebuild-detector can help find packages needing rebuilt.

When editing a user as a Package Maintainer, the Suspended field can be set, which suspends the target user. When a user is suspended, they cannot:

When editing your own account or another as a Package Maintainer, the Inactive field can be set. Inactive accounts are used for two reasons:

The AUR Web Interface has a comments facility that allows users to provide suggestions and feedback on improvements to the PKGBUILD contributor.

Python-Markdown provides basic Markdown syntax to format comments.

One of the easiest activities for all Arch users is to browse the AUR and vote for their favourite packages using the online interface. All packages are eligible for adoption by a Package Maintainer for inclusion in the extra repository, and the vote count is one of the considerations in that process; it is in everyone's interest to vote!

Sign up on the AUR website to get a "Vote for this package" option while browsing packages. After signing up, it is also possible to vote from the commandline with aur-auto-vote-gitAUR.

Alternatively, if you have set up AUR SSH authentication, you can directly vote from the command line using your ssh key. This means that you will not need to save or type in your AUR password.

First, you should flag the package out-of-date indicating details on why the package is outdated, preferably including links to the release announcement or the new release tarball.

You should also try to reach out to the maintainer directly by email. If there is no response from the maintainer after two weeks, you can file an orphan request. See AUR submission guidelines#Requests for details.

If you are having trouble building a package, first read its PKGBUILD and the comments on its AUR page.

It is possible that a PKGBUILD is broken for everyone. If you cannot figure it out on your own, report it to the maintainer (e.g. by posting the errors you are getting in the comments on the AUR page). You may also seek help in the AUR Issues, Discussion & PKGBUILD Requests forum.

The reason might not be trivial after all. Custom CFLAGS, LDFLAGS and MAKEFLAGS can cause failures. To avoid problems caused by your particular system configuration, build packages in a clean chroot. If the build process still fails in a clean chroot, the issue is probably with the PKGBUILD.

See Creating packages#Checking package sanity about using namcap. If you would like to have a PKGBUILD reviewed, post it on the aur-general mailing list to get feedback from the Package Maintainers and fellow AUR members, or the Creating & Modifying Packages forum. You could also seek help in the IRC channel #archlinux-aur on the Libera Chat network.

Users can share PKGBUILDs using the Arch User Repository. See AUR submission guidelines for details.

See i18n.md in the AUR source tree for information about creating and maintaining translation of the AUR Web Interface.

In the beginning, there was ftp://ftp.archlinux.org/incoming, and people contributed by simply uploading the PKGBUILD, the needed supplementary files, and the built package itself to the server. The package and associated files remained there until a "Trusted user" (renamed as Package Maintainer) saw the program and adopted it.

Then the Trusted User Repositories were born. Certain individuals in the community were allowed to host their own repositories for anyone to use. The AUR expanded on this basis, with the aim of making it both more flexible and more usable. In fact, the AUR maintainers were referred to as TUs (Trusted Users) until the change in naming to Package Maintainers.

Between 2015-06-08 and 2015-08-08, the AUR transitioned from version 3.5.1 to 4.0.0, introducing the use of Git repositories for publishing the PKGBUILDs. Existing packages were dropped unless manually migrated to the new infrastructure by their maintainers.

The AUR Archive on GitHub has a repository for every package that was in AUR 3 at the time of the migration. Alternatively, there is the aur3-mirror repository which provides the same.

The packages on the AUR are merely "build scripts", i.e. recipes to build binaries for pacman. For most cases, everything is permitted, subject to usefulness and scope guidelines, as long as you are in compliance with the licensing terms of the content. For other cases, where it is mentioned that "you may not link" to downloads, i.e. contents that are not redistributable, you may only use the file name itself as the source. This means and requires that users already have the restricted source in the build directory prior to building the package. When in doubt, ask.

See #Voting for packages.

See Arch terminology#Package maintainer.

The Arch User Repository is where all PKGBUILDs that users submit are stored, and must be built manually with makepkg. When PKGBUILDs receive enough community interest and the support of a Package Maintainer, they are moved into the extra repository (maintained by the Package Maintainers), where the binary packages can be installed with pacman.

See #Flagging packages out-of-date.

In the meantime, you can try updating the package yourself by editing the PKGBUILD locally. Sometimes, updates do not require changes to the build or package process, in which case simply updating the pkgver or source array is sufficient.

You are probably missing something trivial; see #Debugging the package build process.

Most likely, you do not have the required public key(s) in your personal keyring to verify downloaded files. See Makepkg#Signature checking for details.

Consult the AUR submission guidelines#Rules of submission, then see creating packages.

There are several channels available to submit your package for review; see #Debugging the package build process.

Usually, at least 10 votes are required for something to move into extra. However, if a Package Maintainer wants to support a package, it will often be found in the repository.

Reaching the required minimum of votes is not the only requirement; there has to be a package maintainer willing to maintain the package. Package Maintainers are not required to move a package into the extra repository even if it has thousands of votes.

Usually, when a very popular package stays in the AUR, it is because:

See also Rules for Packages Entering the extra repository

See Makepkg#Improving build times.

Many AUR packages come in "stable" release and "unstable" development versions. Development packages usually have a suffix denoting their Version Control System and are not intended for regular use, but may offer new features or bugfixes. Because these packages only download the latest available source when you execute makepkg, their pkgver() in the AUR does not reflect upstream changes. Likewise, these packages cannot perform an authenticity checksum on any VCS source.

See also System maintenance#Use proven software packages.

It is possible the package has been adopted by a Package Maintainer and is now in the extra repository.

Packages may be deleted if they did not fulfill the rules of submission. See the aur-requests archives for the reason for deletion.

The simplest way is to check the HTTP status of the package's AUR page:

**Examples:**

Example 1 (unknown):
```unknown
/etc/makepkg.conf
```

Example 2 (unknown):
```unknown
ssh aur@aur.archlinux.org help
```

Example 3 (unknown):
```unknown
pacman -U package_file
```

Example 4 (unknown):
```unknown
$ git clone https://aur.archlinux.org/package_name.git
```

---

## CMake package guidelines

**URL:** https://wiki.archlinux.org/title/CMake_package_guidelines

**Contents:**
- Typical usage
- CMake undesired behaviors
  - CMake can automatically override the default compiler optimization flag
    - Notes about -O3
    - Fixing the automatic optimization flag override
  - Verifying the fixes
- Prefix and library install directories
- Tips and tricks
  - Specifying directories
  - Reducing possible unneeded output

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

This document covers standards and guidelines on writing PKGBUILDs for software that uses cmake.

From the CMake web page:

The typical usage consists of running the cmake command and after that execute the building command. The cmake command usually sets some parameters, checks for the needed dependencies and creates the build files, letting the software ready to be built by other tools like make and ninja.

Due to its own internal characteristics for generating the build files, sometimes CMake can behave in undesired ways. Being such, some steps should be noted when writing PKGBUILDs for CMake-based software.

It is very common to see people running CMake with the -DCMAKE_BUILD_TYPE=Release option. Some upstream projects even inadvertently include this option in their building instructions, but this produces an undesired behavior.

Each build type causes CMake to automatically append a set of flags to CFLAGS and CXXFLAGS. When using the common Release build type, it automatically appends the -O3[1] compiler optimization flag, and this overrides the default Arch Linux flag which currently is -O2 (defined in the makepkg configuration file). This is undesired, as it deviates from the Arch Linux targeted optimization level.

Using -O3 does not guarantee that the software will perform better, and sometimes it can even slow down the program. It can also break software in some situations. There is a good reason why the Arch Linux developers choose -O2 as the target optimization level and we should stick with it. Unless you know exactly what you are doing, or if upstream explicitly tells or implies that -O3 is needed, we should avoid using it in our packages.

Fixing this in a 100% guaranteed way is not a simple question due to CMake flexibility. Please note that there is no standard solution that can be applied to all cases. This section will discuss possible solutions and some points that should be observed.

The default CMake build type is None and it does not append any flags to CFLAGS and CXXFLAGS by default, so simply omitting the usage of the CMAKE_BUILD_TYPE option can work as it will default to None. But note that omitting this option is not guaranteed to fix the problem, as many software projects automatically set the build type to Release (or other type) in the CMake files if CMAKE_BUILD_TYPE is not set at command line. Also be aware of possible references to source files in the resulting package and the corresponding makepkg's WARNING: Package contains reference to $srcdir caused by a missing NDEBUG definition in the None build type.

Since the default None build type does not append any flags to CFLAGS and CXXFLAGS by default, using the -DCMAKE_BUILD_TYPE=None option can also work. Generally speaking, using the -DCMAKE_BUILD_TYPE=None option is better than omitting the usage of CMAKE_BUILD_TYPE. It will cover the case when upstream automatically sets the build type to Release when CMAKE_BUILD_TYPE is omitted, it will not append any flags by default and it is uncommon to see software setting undesired flags for the None build type.

But unfortunately, things are not that simple like only using -DCMAKE_BUILD_TYPE=None to fix this. When using the None build type to fix the -O3 issue, one may fall into another problem. It is a common practice for many software projects to define some required compiler flags for the Release build type in the CMake files (for example, like setting the CMAKE_C_FLAGS_RELEASE and CMAKE_CXX_FLAGS_RELEASE CMake variables). Such software may break or misbehave when compiled without these upstream defined flags if you use the None build type. In order to determine if you are missing some flags you will need to look at the CMake files, or you can compare the output of make VERBOSE=1 for the None and Release build types. What to do if the None build type causes some upstream defined flags to be missed? In this case you may be at the middle of two problematic situations, because if you use the Release build type you may be using the undesired -O3 flag, and if you use the None build type you will miss some required upstream defined flags. There is no standard way of solving this situation and it should be analyzed on a case-by-case basis. If upstream defines -O2 for the Release build type, you can use -DCMAKE_BUILD_TYPE=Release (see below). Otherwise, patching the CMake files may be a solution.

Some few software projects hardcode -O2 for the Release build type in their CMake files, and thus -DCMAKE_BUILD_TYPE=Release can be safely set in this case if you are sure that -O2 is the optimization level being used.

You can verify if the fixes are being correctly used by CMake by enabling the verbose mode of the build tool. For example, when using make (which is the CMake default), this can be done by adding VERBOSE=1 to it (like make VERBOSE=1). This will enable make to output the compiler commands that are being executed. You can then run makepkg and examine the output to see if the compiler is using the -D_FORTIFY_SOURCE=2 and -O2 flags. If multiple optimization flags are being displayed in each command line, the last flag in the line will be the one used by the compiler (it means that -O2 needs to be the last optimization flag in order to be effective).

The standard Arch Linux /usr prefix can be specified by the -DCMAKE_INSTALL_PREFIX=/usr CMake option. This is usually needed because a lot of software defaults to install files into the /usr/local prefix.

Some upstream projects set their CMake files to install libraries into the /usr/lib64 directory. If this is the case, you can correctly set the library installation directory to /usr/lib by using the -DCMAKE_INSTALL_LIBDIR=lib CMake option.

Since CMake version 3.13, there is a -B option that automatically creates the build directory. This avoids the creation of the build directory by a separated mkdir (or install) command. The -S option specifies the source directory (where to search for a CMakeLists.txt file) and avoids the need of cd'ing into the source tree before executing cmake. Combined together, these two options are a convenient way to specify the build and the source directories.

Since building a typical CMake project requires many options, it is convenient to specify them in a local array in the build function. This avoids the need to use backslashes to split the long command to multiple lines and allows to include comments for each option separately.

The -Wno-dev CMake option will suppress the output of some warnings that are meant only for the upstream project developers who write the CMakeLists.txt files. Removing these warnings makes the CMake output smoother and reduces the burden on examining it. As a general rule, these warnings usually can be safely ignored by packagers.

Sometimes the resulting binaries can contain insecure references in RPATH. This can be verified by running Namcap on the built package and consists in a security issue that should be fixed. There is a good chance to fix this by using the CMAKE_SKIP_INSTALL_RPATH=YES or CMAKE_SKIP_RPATH=YES CMake options. You need to experiment with both and see what will work in the software in question (using both options is not needed).

For getting all "visible" CMake options that are available for a software project, execute cmake -LAH in the source tree (where the main CMakeLists.txt file is located).

If you want to save the output for later reference, you can redirect it to a file:

CMake provides the FetchContent module that allows fetching additional resources or subprojects at build-time. However, ideally all sources should be fetched by makepkg prior to the build, as they are specified in the sources array. This can be accomplished via the option FETCHCONTENT_SOURCE_DIR_<uppercaseName>, which allows specifying the path to the files that would otherwise be fetched. Additionally, FETCHCONTENT_FULLY_DISCONNECTED=ON can be used to skip all downloads during the build, even if you missed any FetchContent declarations.

Assume a project fetches the resource foo:

Then, instead of downloading it during the build, this resource can be added to the sources array and declared when generating the build files:

Here is a general template for the build() function that serves as a starting point for CMake-based packages. Supposing the package is C and C++ based and that it does not define any required compiler flags for the Release build type in the CMake files.

Do not forget to place cmake in makedepends.

**Examples:**

Example 1 (unknown):
```unknown
-DCMAKE_BUILD_TYPE=Release
```

Example 2 (unknown):
```unknown
CMAKE_BUILD_TYPE
```

Example 3 (unknown):
```unknown
CMAKE_BUILD_TYPE
```

Example 4 (unknown):
```unknown
WARNING: Package contains reference to $srcdir
```

---

## pacman/Pacnew and Pacsave

**URL:** https://wiki.archlinux.org/title/Pacman/Pacnew_and_Pacsave

**Contents:**
- Why these files are created
- Package backup files
- Types explained
  - .pacnew
  - .pacsave
- Locating .pac* files
- Managing .pac* files
  - pacdiff
  - Third-party utilities
- See also

When pacman removes a package that has a configuration file, it normally creates a backup copy of that configuration file and appends .pacsave to the name of the file. Likewise, when pacman upgrades a package which includes a new configuration file created by the maintainer differing from the currently installed file, it saves a .pacnew file with the new configuration. pacman provides notice when these files are written.

A .pacnew file may be created during a package upgrade (pacman -Syu, pacman -Su or pacman -U) to avoid overwriting a file which already exists and was previously modified by the user. When this happens, a message like the following will appear in the output of pacman:

A .pacsave file may be created during a package removal (pacman -R), or by a package upgrade (the package must be removed first). When the pacman database has a record that a certain file owned by the package should be backed up, it will create a .pacsave file. When this happens pacman outputs a message like the following:

These files require manual intervention from the user and it is good practice to handle them right after every package upgrade or removal. If left unhandled, improper configurations can result in improper function of the software or the software being unable to run altogether.

A package's PKGBUILD file specifies which files should be preserved or backed up when the package is upgraded or removed. For example, the PKGBUILD for pulseaudio contains the following line:

After installation, this list can be queried from the pacman database using pacman -Qii package_name.

To prevent any package from overwriting a certain file, see Pacman#Skip file from being upgraded.

For each of the #Package backup files being upgraded, pacman cross-compares three md5sums generated from the file's contents: one sum for the version originally installed by the package, one for the version currently in the filesystem, and one for the version in the new package. If the version of the file currently in the filesystem has been modified from the version originally installed by the package, pacman cannot know how to merge those changes with the new version of the file. Therefore, instead of overwriting the modified file when upgrading, pacman saves the new version with a .pacnew extension and leaves the modified version untouched.

Going into further detail, the 3-way MD5 sum comparison results in one of the following outcomes:

Rarely, when an upgraded package includes a backup file the previous version did not, the situation is correctly handled as X/Y/Y or X/Y/Z, with X being a non-existant value.

If the user has modified one of the files specified in backup then that file will be renamed with a .pacsave extension and will remain in the filesystem after the rest of the package is removed.

Pacman does not deal with .pacnew files automatically: you must maintain these yourself. A few tools are presented in the next section. To do this manually, you will first need to locate them. When upgrading or removing a large number of packages, updated .pac* files may be missed. To discover whether any .pac* files have been installed, use one of the following:

pacman-contrib provides the simple pacdiff(8) tool for managing .pac* files.

It will search for .pacnew, .pacsave and .pacorig files, and will then prompt to take action upon them.

It uses --pacmandb by default, to search using the backup array information from currently installed packages. If this is not sufficient for your use case, you can specify --find or --locate instead, for a more thorough search.

It uses vimdiff by default, but you may specify a different tool with DIFFPROG=your_editor pacdiff. See List of applications/Utilities#Comparison, diff, merge for other common comparison tools.

A few third-party utilities providing various levels of automation for these tasks are available:

**Examples:**

Example 1 (unknown):
```unknown
pacman -Syu
```

Example 2 (unknown):
```unknown
warning: /etc/pam.d/usermod installed as /etc/pam.d/usermod.pacnew
```

Example 3 (unknown):
```unknown
warning: /etc/pam.d/usermod saved as /etc/pam.d/usermod.pacsave
```

Example 4 (unknown):
```unknown
backup=(etc/pulse/{daemon.conf,default.pa,system.pa})
```

---

## Powerpill

**URL:** https://wiki.archlinux.org/title/Powerpill

**Contents:**
- Installation
- Configuration
- Using Reflector
- Using rsync
- Basic usage
  - System updating
  - Installation of packages
- Troubleshooting
- See also

This article or section is out of date.

Powerpill is a pacman wrapper that uses parallel and segmented downloading to try to speed up downloads for Pacman. Internally it uses Aria2 and Reflector to achieve this. Powerpill can also use rsync for official mirrors that support it. This can be efficient for users who already use full bandwidth when downloading from a single mirror. Pacserve is also supported via the configuration file and will be used before downloading from external mirrors. Example: One wants to update and issues a pacman -Syu which returns a list of 20 packages that are available for update totaling 200 megs. If the user downloads them via pacman, they will come down one-at-a-time. If the user downloads them via powerpill, they will come down simultaneously in many cases several times faster (depending on one's connection speed, the availability of packages on servers, and speed from server/load, etc.)

A test of pacman vs. powerpill on one system revealed a 4x speed up in the above scenario where the pacman downloads averages 300 kB/sec and the powerpill downloads averaged 1.2 MB/sec.

Install the powerpillAUR package.

Powerpill has a single configure file /etc/powerpill/powerpill.json you can edit to your liking. Refer to the powerpill.json(1) man page for details.

By default, Powerpill is configured to use Reflector to retrieve the current list of mirrors from the Arch Linux server's web API and use them for parallel downloads. This is to make sure that there are enough servers in the list for significant speed improvements.

Rsync support is available for some mirrors. When enabled, database synchronizations (pacman -Sy) and other operations may be much faster because a single connection is used. The rsync protocol itself also speeds up update checks and sometimes file transfers.

To find a suitable mirror with rsync support, use reflector:

Alternatively, you can find the n fastest servers with the flag -f n, and the m most recently synchronized servers with the flag -l m:

Select the mirror(s) you want to use. The -c option may also be used to filter by your nationality (reflector --list-countries to see a complete list, use quotes around the name, and this is case-sensitive!). Once done, edit /etc/powerpill/powerpill.json, scroll down to the rsync section, and add as many servers as you would like to the server field.

After that, all official database and packages will be downloaded from the rsync server whenever possible.

Note that there is a check to see if the databases and packages are in an official repository with reflector, so its installation is necessary for rsync feature to function.

For most operations, powerpill works just like pacman since it is a wrapper script for pacman.

To update your system (sync and update installed packages) using powerpill, simply pass the -Syu options to it as you would with pacman:

To install a package and its deps, simply use powerpill with the -S option as you would with pacman:

You may also install multiple packages with it the same way you would with pacman:

In case you get an [err] for <repo>.db.sig files:

It is because signature files are missing for that repository and you have not set

explicitly in /etc/pacman.conf as explained in this forum post.

**Examples:**

Example 1 (unknown):
```unknown
pacman -Syu
```

Example 2 (unknown):
```unknown
/etc/powerpill/powerpill.json
```

Example 3 (unknown):
```unknown
$ reflector -p rsync
```

Example 4 (unknown):
```unknown
$ reflector -p rsync -f n -l m
```

---

## Mirrors

**URL:** https://wiki.archlinux.org/title/Mirrors

**Contents:**
- Official mirrors
  - IPv6-ready mirrors
- Enabling a specific mirror
  - Force pacman to refresh the package lists
- Sorting mirrors
  - List by speed
    - Ranking an existing mirror list
    - Fetching and ranking a live mirror list
  - Server-side ranking
  - Client-side ranking

This page is a guide to selecting and configuring your mirrors, and a listing of current available mirrors.

The official Arch Linux mirror list is available from the pacman-mirrorlist package. To get an even more up-to-date list of mirrors, use the Pacman Mirrorlist Generator page.

Check the status of the mirrors by visiting the Mirror Status page. It is recommended to only use mirrors that are up to date, i.e. not out of sync.

If you want your mirror to be added to the official list, see DeveloperWiki:NewMirrors. In the meantime, add it to the Unofficial mirrors article.

The Pacman Mirrorlist Generator can also be used to find a list of current IPv6 mirrors.

To enable mirrors, edit /etc/pacman.d/mirrorlist and locate your geographic region. Uncomment mirrors you would like to use.

See #Sorting mirrors for tools that help choosing mirrors.

It is also possible to specify mirrors in /etc/pacman.conf. For the core repository, the default setup is:

To use the kernel.org mirror as a default mirror, add it before the Include line:

pacman will now try to connect to this mirror first. Proceed to do the same for core-testing, extra, and extra-testing, if applicable.

Mirrors can be out of sync and the package list from the old mirror may not correspond to the package list of the new mirror, even though the dates of the lists may suggest that they do.

After creating/editing /etc/pacman.d/mirrorlist, issue the following command:

Passing two --refresh/-y flags forces pacman to refresh all package lists even if they are considered to be up to date.

This is not necessary when using successfully syncing mirrors or checking timestamp of mirror's lastsync file to ensure package lists are up to date.

When downloading packages, pacman uses the mirrors in the order they are listed in /etc/pacman.d/mirrorlist, i.e. the order servers appear in the list sets their priority. If a package download fails (e.g. file not found, connection timeout), the next list entry is used.

It is not optimal to only rank mirrors based on speed since the fastest servers might be out-of-sync. Instead, make a list of mirrors sorted by their speed, then remove those from the list that are out of sync according to their status.

It is recommended to regularly repeat this process to keep the list of mirrors up-to-date.

The pacman-contrib package provides a Bash script, /usr/bin/rankmirrors, which can be used to rank the mirrors according to their connection and opening speeds to take advantage of using the fastest local mirror.

Back up the existing /etc/pacman.d/mirrorlist:

To prepare mirrorlist.backup for ranking with rankmirrors, the following actions can be carried out:

In order to start with a shortlist of up-to-date mirrors based in some countries and feed it to rankmirrors one can fetch the list from the Pacman Mirrorlist Generator. The command below pulls the up-to-date mirrors in either France or the United Kingdom which support the https protocol, it uncomments the servers in the list and then ranks them and outputs the 5 fastest.

The official Pacman Mirrorlist Generator provides an easy way to obtain a ranked list of mirrors. Because all ranking is done on a single server that takes multiple factors into account, the amount of load on the mirrors and the clients is significantly lower compared to ranking on each individual client.

Other popular alternatives are:

In case you encounter the following error:

Get the mirrorlist directly from the website:

Be sure to uncomment a preferred mirror as described in #Enabling a specific mirror.

Alternatively, use one of the methods for generating a mirrorlist listed under #Sorting mirrors.

If you are certain a mirror is not operating properly and that is not reflected on the mirrors status page, change the mirror and consider opening a bug report. For mirrors the issue should be opened in the arch-mirrors project at the Arch Linux GitLab. You may also send a mail to mirrors@archlinux.org.

See Pacman#Packages cannot be retrieved on installation first. If that doesn't help, use a HTTPS mirror.

**Examples:**

Example 1 (unknown):
```unknown
/etc/pacman.d/mirrorlist
```

Example 2 (unknown):
```unknown
## Worldwide
#Server = https://geo.mirror.pkgbuild.com/$repo/os/$arch
#Server = http://mirror.rackspace.com/archlinux/$repo/os/$arch
Server = https://mirror.rackspace.com/archlinux/$repo/os/$arch
```

Example 3 (unknown):
```unknown
/etc/pacman.conf
```

Example 4 (unknown):
```unknown
[core]
Include = /etc/pacman.d/mirrorlist
```

---

## rsync

**URL:** https://wiki.archlinux.org/title/Rsync

**Contents:**
- Installation
  - Front-ends
- As cp/mv alternative
  - Trailing slash caveat
- As a backup utility
  - Automated backup
  - Automated backup with SSH
  - Automated backup with NetworkManager
  - Automated backup with systemd and inotify
  - Differential backup on a week

rsync is an open source utility that provides fast incremental file transfer.

Install the rsync package.

rsync must be installed on both the source and the destination machine.

Other tools using rsync are rdiff-backupAUR, osyncAUR and yarsyncAUR.

rsync can be used as an advanced alternative for the cp or mv command, especially for copying larger files:

The -P option is the same as --partial --progress, which keeps partially transferred files and shows a progress bar.

You may want to use the -r/--recursive option to recurse into directories.

Files can be copied locally as with cp, but the motivating purpose of rsync is to copy files remotely, i.e. between two different hosts. Remote locations can be specified with a host-colon syntax:

Network file transfers use the SSH protocol by default and host can be a real hostname or a predefined profile/alias from .ssh/config.

Whether transferring files locally or remotely, rsync first creates a file-list containing information (by default, it is the file size and last modification timestamp) which will then be used to determine if a file needs to be constructed. For each file to be constructed, a weak and strong checksum is found for all blocks such that each block is of length S bytes, non-overlapping, and has an offset which is divisible by S. Using this information a large file can be constructed using rsync without having to transfer the entire file. For a more detailed practical and mathematical explanation refer to how rsync works and the rsync algorithm, respectively.

To use sane defaults quickly, you could use some aliases:

Arch by default uses GNU cp (part of GNU coreutils). However, rsync follows the convention of BSD cp, which gives special treatment to source directories with a trailing slash "/". Whereas

creates a directory "destination/source" with the contents of "source", the command

copies all of the files in "source/" directly into "destination", with no intervening subdirectory - just as if you had invoked it as

This behavior is different from that of GNU cp, which treats "source" and "source/" identically (but not "source/."). Also, some shells automatically append the trailing slash when tab-completing directory names. Because of these factors, there can be a tendency among new or occasional rsync users to forget about rsync's different behavior, and inadvertently create a mess or even overwrite important files by leaving the trailing slash on the command line.

Thus it can be prudent to use a wrapper script to automatically remove trailing slashes before invoking rsync:

This script can be put somewhere in the path, and aliased to rsync in the shell init file.

The rsync protocol can easily be used for backups, only transferring files that have changed since the last backup. This section describes a very simple scheduled backup script using rsync, typically used for copying to removable media.

For the sake of this example, the script is created in the /etc/cron.daily directory, and will be run on a daily basis if a cron daemon is installed and properly configured. Configuring and using cron is outside the scope of this article.

First, create a script containing the appropriate command options:

Here, /path/to/backup should be changed to what needs to be backed-up (e.g. /home) and /location/of/backup is where the backup should be saved (e.g. /media/disk).

Finally, the script must be executable.

If backing-up to a remote host using SSH, use this script instead:

This script starts a backup when network connection is established.

First, create a script containing the appropriate command options:

The script must be owned by root (see NetworkManager#Network services with NetworkManager dispatcher for details).

Instead of running time interval backups with time based schedules, such as those implemented in cron, it is possible to run a backup every time one of the files you are backing up changes. systemd.path units use inotify to monitor the filesystem, and can be used in conjunction with systemd.service files to start any process (in this case your rsync backup) based on a filesystem event.

First, create the systemd.path unit that will monitor the files you are backing up:

Then create a systemd.service file that will be activated when it detects a change. By default a service file of the same name as the path unit (in this case backup.path) will be activated, except with the .service extension instead of .path (in this case backup.service).

Now all you have to do is enable/start backup.path like a normal systemd service and it will start monitoring file changes and automatically start backup.service.

This is a useful option of rsync, resulting in a full backup (on each run) and keeping a differential backup copy of changed files only in a separate directory for each day of a week.

First, create a script containing the appropriate command options:

The --inplace option implies --partial and updates destination files in-place.

The same idea can be used to maintain a tree of snapshots of your files. In other words, a directory with date-ordered copies of the files. The copies are made using hardlinks, which means that only files that did change will occupy space. Generally speaking, this is the idea behind Apple's TimeMachine.

This basic script is easy to implement and creates quick incremental snapshots using the --link-dest option to hardlink unchanged files:

There must be a symlink to a full backup already in existence as a target for --link-dest. If the most recent snapshot is deleted, the symlink will need to be recreated to point to the most recent snapshot. If --link-dest does not find a working symlink, rsync will proceed to copy all source files instead of only the changes.

A more sophisticated version keeps an up-to-date full backup $SNAP/latest and in case a certain number of files has changed since the last full backup, it creates a snapshot $SNAP/$DATETAG of the current full-backup utilizing cp -al to hardlink unchanged files:

To make things really, really simple this script can be run from a systemd/Timers unit.

This section is about using rsync to transfer a copy of the entire / tree, excluding a few selected directories. This approach is considered to be better than disk cloning with dd since it allows for a different size, partition table and filesystem to be used, and better than copying with cp -a as well, because it allows greater control over file permissions, attributes, Access Control Lists and extended attributes.

rsync will work even while the system is running, but files changed during the transfer may or may not be transferred, which can cause undefined behavior of some programs using the transferred files. For mitigation log out all users and shut down all programs and databases.

This approach works well for migrating an existing installation to a new hard drive or SSD.

Run the following command as root to make sure that rsync can access all system files and preserve the ownership:

By using the -aAX set of options, the files are transferred in archive mode which ensures that symbolic links, devices, permissions, ownerships, modification times, ACLs, and extended attributes are preserved, assuming that the target file system supports the feature. The option -H preserves hard links, but uses more memory.

The --exclude option causes files/directories that match the given patterns to be excluded. Instead or in conjunction, the --exclude-from=file option excludes files/directories that match patterns (one per line) in file, similar to the example described in #Advanced usage of filter rules but without the +/- syntax.

The directories /dev, /proc, /sys, /tmp, and /run are included in the above command, but the contents of those directories are excluded. This is because they are populated on boot, but the directories themselves are not created. /lost+found is filesystem-specific. Quoting the exclude patterns will avoid expansion by the shell, which is necessary, for example, when backing up over SSH. Ending the excluded paths with * ensures that the directories themselves are created if they do not already exist.

You may want to include additional rsync options, or remove some, such as the following. See rsync(1) for the full list.

If you wish to restore a backup, use the same rsync command that was executed but with the source and destination reversed (you may also want to add a trailing slash to the source). If you used --exclude options you should probably remove those for the restore command.

Instead of specifying include and exclude rules separately rsync can read all of these from a single filter file. rsync then processes the rules in a top-down order; the first matching rule wins.

*** is a special rsync pattern which matches a folder and all of its contents recursively.

Check rsync(1) § PATTERN MATCHING RULES and rsync(1) § FILTER RULES IN DEPTH for more details.

The key word is the --filter "merge ..." parameter which will take the filter file and parse the rules in order for each sync-ed file.

An alternative to the #Advanced usage of filter rules method is to use the --files-from option. This can take an input from a text file containing a list of directory or file paths, with each entry being separated by new lines. It should be noted that the -r flag must manually be specified for this option if the user wants recursive directory copying, even when -a is already included.

For example, a list of directories and all recursive directories can be archived with the following:

rsync provides a way to do a copy of all data in a file system while preserving as much information as possible, including the file system metadata. It is a procedure of data cloning on a file system level where source and destination file systems do not need to be of the same type. It can be used for backing up, file system migration or data recovery.

rsync's archive mode comes close to being fit for the job, but it does not back up the special file system metadata such as access control lists, extended attributes or sparse file properties. For successful cloning at the file system level, some additional options need to be provided:

And their meaning is (from the manpage):

Additionally, use -x if you have other filesystems mounted under the tree that you want to exclude from the copy.

The produced copy can be simply reread and checked (for example after a data recovery attempt) at the file system level with diff's recursive option:

It is possible to do a successful file system migration by using rsync as described in this article and updating the fstab and boot loader as described in Migrate installation to new hardware. This essentially provides a way to convert any root file system to another one.

rsync can be run as daemon on a server listening on TCP port 873.

Edit the template /etc/rsyncd.conf, configure a share and start the rsyncd.service.

Usage from client, e.g. list server content:

transfer file from client to server:

Consider opening TCP port 873 in the firewall, and using user authentication.

Inside the file list, all the intermediary paths are necessary, except when the *** wildcard is used:

**Examples:**

Example 1 (unknown):
```unknown
$ rsync -P source destination
```

Example 2 (unknown):
```unknown
--partial --progress
```

Example 3 (unknown):
```unknown
--recursive
```

Example 4 (unknown):
```unknown
$ rsync source host:destination
```

---

## FrankenWM

**URL:** https://wiki.archlinux.org/title/FrankenWM

**Contents:**
- Installation
- Starting
  - From tty
- Configuration
- Usage
  - Panels
- Troubleshooting
  - I do not see anything
  - I cannot open a terminal/menu

Install the frankenwmAUR package. Due to the absence of releases since 2020, you may want to try the frankenwm-gitAUR package.

Run frankenwm with xinit

Configuration is done at compile time by editing config.h. There are lots of comments in the default configuration (config.def.h) which explain what the settings are doing.

The basic usage includes opening a terminal (Meta+Enter), opening dmenu (Meta+r) and closing windows (Meta+c). There is a complete, sorted list of the default keybinds and explanations of the tiling layouts in frankenwm(1).

FrankenWM does not come with a panel included, but gives you the possibility to leave space either at the top or bottom for one, like conky or dzen. There are a couple of settings in the configuration for this space.

If you want to use FrankenWM's status in your bar, you can pipe FrankenWM to a shell script to parse the output and pipe it to a bar. Sample scripts to accomplish this with a few different bar are located here.

This is normal behaviour, as FrankenWM does not come with a bar included or a desktop background, so after running frankenwm without anything else, you will probably see a black screen. See Panels above for information on how to add a panel to your desktop. Wallpapers can be set by using software like xsetroot, feh or hsetroot.

Have a look at the config.h used to build your currently running version of FrankenWM, which is located in the build directory. Make sure that both the shortcut to run the termcmd/menucmd command and the termcmd/menucmd itself are set properly to start an installed terminal/menu.

**Examples:**

Example 1 (unknown):
```unknown
config.def.h
```

---

## Snort

**URL:** https://wiki.archlinux.org/title/Snort

**Contents:**
- Preamble
- Installation
- Configuration
  - Inline mode
  - IDS mode
- Updating the rules with Pulledpork
  - Configuration
  - Drop traffic with Pulledpork
  - Disabling rules with Pulledpork
  - Running Pulledpork

From the project website:

You can use Snort to sniff wireless traffic with two routers. For simplicity the router with DHCP on and wireless off will be called "router A" and the router with wireless on and DHCP off "router B".

Install the snortAUR package.

Cisco Telos team also provides a Docker image: [1]

The main configuration file is located at /etc/snort/snort.lua.

Local configuration can be set in /etc/snort/local.lua. It is recommended to use pulledporkAUR to download your rule set. By default the rules are stored under, $RULE_PATH/snort.rules.

Home network can be set in /etc/snort/homenet.lua. If required, let Snort know what network (or networks) you want to monitor.

Inline mode means that packets pass through snort, rather than being diverted to snort. In this mode, snort can drop packets and abort exploitation attempts in real-time. In this mode, snort acts as an intrusion prevention system (IPS).

By default, snort runs in inline mode, which is defined as under in /etc/snort/local.lua:

This article or section is out of date.

In intrusion detection mode (IDS), packets are diverted to snort. Snort can not drop packets, which means that it can only notify you that a exploitation attempt is occuring, or have already occured.

In IDS mode start snort@ens1.

Install pulledporkAUR.

The configuration files are located in /etc/pulledpork

Edit /etc/pulledpork/pulledpork.conf and uncomment the rules you want to use. You will need an "oinkcode" to download some of the rules.

The current categories that are within your rule set can be found by running the following:

If you want to drop all traffic that matches a Snort signature instead of just alerting, add the following to your dropsid.conf:

Or if you want to drop all traffic matching an entire category:

If you only want to drop a single rule:

If you want to disable a single signature add its gen_id and sig_id to /etc/pulledpork/disablesid.conf

If you want to disable an entire category:

This will pull the new rules and write them to /etc/snort/rules/snort.rules

There are two sets of rules distributed by Snort: "Community Ruleset" and "Snort Subscriber Rule Set". The former one is freely available to all of the users. The latter one is made available to subscribed and registered users. Paid subscribers receive rulesets in real-time as they are released. Registered users will receive rulesets 30 days after the subscribers. Registration is free and available at: Snort: Sign up.

The oinkmasterAUR package is available.

Edit /etc/oinkmaster.conf and look for the URL section and uncomment the 2.4 line. Make sure to replace <oinkcode> by the Oink code you generated after logging into your Snort account. For Bleeding Snort rules, uncomment the appropriate line.

When you log into your new account, create an "Oink code". Another thing to change is

The rest of the configuration file is fine.

Create an executable script with the exact command and place it in /etc/cron.daily to update the rules daily automatically.

**Examples:**

Example 1 (unknown):
```unknown
/etc/snort/snort.lua
```

Example 2 (unknown):
```unknown
/etc/snort/local.lua
```

Example 3 (unknown):
```unknown
/etc/snort/homenet.lua
```

Example 4 (unknown):
```unknown
HOME_NET = [[ 10.0.0.0/8 172.16.0.0/12 192.168.0.0/16 ]]
```

---

## Yabsnap

**URL:** https://wiki.archlinux.org/title/Yabsnap

**Contents:**
- Installation
- Configuration
- Main commands
  - Viewing snapshots
  - Creating snapshots
- Cleaning up or deleting snapshots
  - Automatic cleanups
  - Deleting snapshots
- Creating a rollback
  - Rollback requirement: Mount by subvol and not subvolid

Yabsnap is a scheduled snapshot manager for Btrfs partitions written for Arch.

Install the yabsnapAUR package.

Run the following to create a skeleton config:

This will create /etc/yabsnap/configs/confignane.conf. Edit the file to specify the following:

You can also edit other parameters to specify when backups will be triggered and cleaned up.

To review existing snapshots, use:

To create snapshots for all configs, use:

You can also restrict to a specific mounted subvolume. Yabsnap will automatically find the right config for it and use it:

Yabsnap will automatically delete snapshots based on the configurations in /etc/yabsnap/configs/*.conf.

You can also manually remove snapshots, with the following commands:

Specifying full path deletes a specific snapshot:

Specifying a timestamp deletes all matching snapshots that were taken together:

It is recommended that you mount all the volumes with subvol instead of subvolid.

For example, this can be your fstab entry:

The reason this works is because rollback mechanism will not edit your fstab file, it will simply ensure that the correct snapshots are mounted in the respective locations.

The command for rollback is safe, until you execute the script it generates.

This generates a rollback script:

Change the timestamp to one of your existing snapshots:

Executing the script will actually cause the rollback to happen. It is recommended that you review the generated lines before rolling back.

Once you have reviewed the generated script for your rollback, you can then make it executable then run it:

This will perform a rollback of all snapshots that were taken at the specified timestamp.

It was created to overcome some of the shortcomings of Snapper, specifically it does the following which are difficult or impossible to do in Snapper (as of writing):

**Examples:**

Example 1 (unknown):
```unknown
# yabsnap create-config 'configname'
```

Example 2 (unknown):
```unknown
/etc/yabsnap/configs/confignane.conf
```

Example 3 (unknown):
```unknown
dest_prefix
```

Example 4 (unknown):
```unknown
/.snapshot/@home-
```

---

## Steam

**URL:** https://wiki.archlinux.org/title/Steam

**Contents:**
- Installation
  - SteamCMD
- Directory structure
  - Library folders
- Usage
- Launch options
  - Examples
- Tips and tricks
  - Start Minimized
  - Small Mode

Steam is a popular game distribution platform by Valve.

Enable the multilib repository and install the steam package (recommended) or alternatively the steam-native-runtimeAUR package for running Steam with native system libraries. See /Troubleshooting#Steam runtime.

In order to run Steam on Arch Linux:

Install steamcmdAUR for the command-line version of Steam.

The default Steam install location is ~/.local/share/Steam. If Steam cannot find it, it will prompt you to reinstall it or select the new location. This article uses the ~/.steam/root symlink to refer to the install location.

Every Steam application has a unique AppID, which you can find by either looking at its Steam Store page path or visiting SteamDB.

Steam installs games into a directory under LIBRARY/steamapps/common/. LIBRARY normally is ~/.steam/root but you can also have multiple library folders (Steam > Settings > Storage > (+) Add Drive).

In order for Steam to recognize a game it needs to have an appmanifest_AppId.acf file in LIBRARY/steamapps/. The appmanifest file uses the KeyValues format and its installdir property determines the game directory name.

For the available command-line options see the Command Line Options article on the Valve Developer Wiki.

Steam also accepts an optional Steam URL, see the Steam browser procotol.

When you launch a Steam game, Steam executes its launch command with /bin/sh. To let you alter the launch command Steam provides launch options, which can be set for a game by right-clicking on it in your library, selecting Properties and clicking on Set Launch Options.

By default Steam simply appends your option string to the launch command. To set environment variables or pass the launch command as an argument to another command you can use the %command% substitute.

It is possible to have Steam start minimized to the system tray, rather than taking focus. Add -silent to the list of command line arguments; see Desktop entries#Modify desktop files for doing this by default.

Steam supports an alternative, minimal UI with just your game list - the store, community and cover collection views are hidden. You can switch to it with View > Small Mode. To go back to the standard UI, select View > Large Mode.

You can also launch steam with this argument:+open steam://open/minigameslist

Valve developed a compatibility tool for Steam Play based on Wine and additional components named Proton. It allows you to launch many Windows games (see compatibility list).

It is open-source and available on GitHub. Steam will install its own versions of Proton when Steam Play is enabled.

"Proton Experimental" is enabled by default on the Steam client: Steam > Settings > Compatibility. You can enable Steam Play for games that have and have not been whitelisted by Valve in that dialog.

Proton supports Easy AntiCheat integration if the developer activates it, however EAC may require a particular patched version of glibc: if a game is been reported to be working but is not in your machine, try using Steam Flatpak because it comes with glibc patched. Additionally, setting the procfs mount option hidepid to a hardened value may cause Easy Anti-Cheat to fail with the message "Launch Error: 261".

If needed, to force enable Proton or a specific version of Proton for a game, right click on the game, click Properties > Compatibility > Force the use of a specific Steam Play compatibility tool, and select the desired version. Doing so can also be used to force games that have a Linux port to use the Windows version.

You can install proton-cachyosAUR, but extra setup is required to work with Steam. See the Proton GitHub for details on how Steam recognizes Proton installs.

When a controller is plugged in while Steam is running, Steam's default behavior is to leave it alone and let games use it as-is. The gamepad's evdev and joystick devices are exposed by the kernel, and games may use them using APIs such as SDL2 as if Steam were not in the picture.

The Steam Input subsystem offers an abstraction layer which allows for more advanced functionality such as rebinding buttons and axes, having game-specific profiles, and doing higher-level button mappings based on in-game actions. The Steam Input Configurator (SIC) is the part of the system that implements this functionality. To enable Steam Input for a controller, go to Steam > Settings > Controller > External Gamepad Settings. Here you will find toggles to Enable Steam Input corresponding to your controller.

This article or section is a candidate for moving to Steam Input Configurator.

See Steam Input Configurator for configurator usage instructions.

When SIC is enabled for a controller, there are a few different controller devices:

The SIC's behavior is context dependent:

Games are rated on how comprehensive their gamepad support is. This is dependent on the controller model.

In cases where the game does not have full gamepad support, SIC tries to fill the gaps. For example, in Bloons Tower Defense 5, a game that requires you to point and click, Steam will automatically activate the Keyboard (WASD) and Mouse profile, allowing you to use your gamepad to move and click.

To summarize what this all means for usage:

If you wish to completely disable Steam Input, launch steam with the -nojoy argument, and also disable Steam Input for each game individually, as there is no global option for doing so.

To start Steam in Big Picture Mode from a display manager with Gamescope as its compositor:

Then instruct your display manager to launch gamescope.

The Steam interface can be customized using skins. Follow this Steam guide for more information.

Some skins updated for the 2023 UI are:

The default Steam notification position is bottom right.

You can change the Steam notification position by altering Notifications.PanelPosition in

Both files are overwritten by Steam on startup and steam.styles is only read on startup.

You can create a skin to change the notification position to your liking. For example to change the position to top right:

gameoverlay.styles can be overwritten while Steam is running, allowing you to have game-specific notification positions.

And the #Launch options should be something like:

Steam has built-in support for remote play.

See this Steam Community guide on how to setup a headless streaming server on Linux.

If you use Proton (Steam Play) for launching your games, and still keep a Windows installation for some reason (for example, if some game has problems with anti cheat or if you want to make a comparison tests with Windows), you may want to store your games in a common partition instead of keeping two copies of game one per OS.

To add another folder for library, click on Steam > Settings > Downloads > STEAM LIBRARY FOLDERS, then on the ⊕ (Plus) button.

There are four file systems, that can be read/write by both Windows and Linux.

See Using a NTFS disk with Linux and Windows for more information on how to configure that. To launch games from an NTFS drive, follow the steps from Steam/Troubleshooting#Steam Library in NTFS partition.

Using ntfs has disadvantages. It happens often that shaders cache folder becomes corrupted. Messages saying ntfs3: sdb6 ino=1921f, steamapprun_pipeline_cache Looks like your dir is corrupt. You cannot fix that from linux. You need to boot to Windows and use chkdsk for that.

This filesystem has disadvantage that it is case-insensitive. You will get such message: SteamLibrary has both 'SteamApps' and 'steamapps' directories. This will cause problems. Please fix manually and only keep 'steamapps' See issue #7665

Also it is problematic to create symlinks on exfat, so you cannot use the method of symlinking compatdata as in ntfs method.

#Btrfs has a fairly mature Windows Driver

NTFS can be also converted into Btrfs, see Btrfs#NTFS_to_Btrfs_converson

This filesystem eliminates any potential issues with NTFS and exFAT not supporting filesystem attributes considered normal on Linux, and can be repaired and scrubbed from both system, see Btrfs#Scrub.

When used to share Steam libraries, it's important to setup proper UID/GID mappings to avoid having permission issues.

This filesystem can be used without issue, but to ensure compatibility, it must be formatted to the correct UDF revision. Linux lacks write support for revisions 2.50 and higher. Therefore, revision 2.01 is required for proper functionality.

The UDF block size must match the logical sector size of the partition. This value can be obtained using blockdev(8):

The partition is then formatted to UDF using mkfs.udf(8) provided by udftools. For both HDDs and SSDs, the appropriate media type is hd.

Alternatively, graphical tools like gparted can be used to handle formatting. They correctly manage UDF revision selection to ensure compatibility.

In certain circumstances shader pre-compilation may only use one core, however this can be overridden by the user, example to use 8 cores:

There are compatibility tools other than Proton/Wine.

You can also use protonup-qtAUR to manage them:

Some systems and configurations seem to have issues with HTTP2. Disabling HTTP2 will probably yield faster downloads on those configurations. You can either use the console command @nClientDownloadEnableHTTP2PlatformLinux 0 or set it in steam_dev.cfg like so:

On hybrid graphics laptops, Steam runs games using the integrated GPU by default. See PRIME#PRIME GPU offloading to switch to the more powerful discrete GPU for specific games.

Steam can also be installed with Flatpak as com.valvesoftware.Steam from Flathub. The easiest way to install it for the current user is by using the Flathub repository:

The Flatpak application currently does not support themes. Also you currently cannot run games via optirun/primusrun, see Issue#869 for more details.

Steam installed via Flatpak is not able to access your home directory and overriding this will cause Steam to not run because it is not safe. However, you can freely add directories outside the home directory. If you want to add an external library, run the following command to add it:

Launching Steam with Flatpak might warn you about installing the steam-devices package. This package currently does not exist but game-devices-udevAUR can be installed instead, see Gamepad#Device permissions.

If you are having problem getting Asian fonts to show in game, it is because org.freedesktop.Platform does not include it. First try mounting your local font :

If that does not work, consider this hack: make the fonts available by directly copying the font files into org.freedesktop.Platform's directories, e.g.

After launch, Steam will try to download files and you will see a progress bar. If it crashes, you may try to give additional permissions to the flatpak package:

For an alternative way to control permissions, install flatseal.

This is useful for video cards with a small amount of video memory.

Make a copy of the Steam shortcut:

and change the Exec= and Name= sections in the shortcut copy:

As a result, when launching the Steam Minimal (Runtime) shortcut you will get an ascetic interface, which is still functional enough to install and run games, and when launching the standard Steam (Runtime) shortcut you will get a full-fledged client.

See Steam/Troubleshooting.

**Examples:**

Example 1 (unknown):
```unknown
/etc/resolv.conf
```

Example 2 (unknown):
```unknown
vm.max_map_count
```

Example 3 (unknown):
```unknown
~/.local/share/Steam
```

Example 4 (unknown):
```unknown
~/.steam/root
```

---

## Flyspray

**URL:** https://wiki.archlinux.org/title/Flyspray

**Contents:**
- Installation
  - Apache Setup

Flyspray is a bug tracking system written in PHP. FlySpray was notably used by Arch Linux itself.

Install the flysprayAUR package. Flyspray requires a web server such as Apache HTTP Server with PHP, and an SQL server such as MySQL or PostgreSQL.

You will need to create a configuration file for Apache to find your Flyspray install. Create the following file:

You will then need to edit /etc/webapps/flyspray/.htaccess and change deny from all to allow from all. You should now be able to navigate to the flyspray interface (e.g. http://localhost/flyspray) and it will show a page of pre-installation checks. Any issues here should be resolved before continuing.

**Examples:**

Example 1 (unknown):
```unknown
extension=mysqli
```

Example 2 (unknown):
```unknown
/etc/php/php.ini
```

Example 3 (unknown):
```unknown
/etc/httpd/conf/extra/flyspray.conf
```

Example 4 (unknown):
```unknown
Alias /flyspray "/usr/share/webapps/flyspray"
<Directory "/usr/share/webapps/flyspray">
	AllowOverride All
	Options FollowSymlinks
	Require all granted
	php_admin_value open_basedir "/srv/http/:/tmp/:/usr/share/webapps/flyspray"
</Directory>
```

---

## Rust package guidelines

**URL:** https://wiki.archlinux.org/title/Rust_package_guidelines

**Contents:**
- Package naming
- Source
- Depends
- Prepare
- Build
- Check
- Package
  - Notes about using cargo install
- Complete PKGBUILD template
- Example packages

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

This document covers standards and guidelines on writing PKGBUILDs for software written in Rust.

When packaging Rust projects, the package name should almost always be the same as the name of the generated binary. Note that it does not make any sense to package library crates, so only crates with bins will be packaged. For ones that generate more than one binary, the upstream crate name is usually appropriate. In any event the package name should be entirely lowercase.

Most Rust projects may be built from tarballs, source archives (e.g. source links on GitHub releases), or any other published source.

When other sources are not available, most Rust projects are published on crates.io which provides a stable download URL scheme for use with cargo. The downside of this source is that it usually does not include all the test files, license files, or other assets normally in the other sources. If needed, the PKGBUILD#source can use the following template:

While some Rust projects have external dependencies, most just use Rust ecosystem libraries that are statically embedded in the final binary. As such most projects will not need to specify many depends. The usual exceptions that most Rust binaries do link against glibc libraries, so gcc-libs and glibc are typically dependencies of most Rust packages. There may be more if the build process looks for and links against any system libraries.

For makedepends, the vast majority of Rust projects are designed to be built using the cargo dependency manager, which both orchestrates the download of libraries to satisfy build time dependencies as well as makes all the necessary calls to rustc, the actual Rust compiler. Currently both cargo and rustc are provided by the rust package, but there are also alternative ways of getting both of these together or separately including the rustup package. As such, the tool most PKGBUILDs are going to call is cargo and you should depend directly on it.

If a project requires the use of a nightly version of the Rust tool chain, use:

The rust dependency manager cargo is able to download all the libraries required to build a project ahead of time. Running this fetch in the prepare() stage enables the later build() and other stages to be run entirely offline.

Building a Rust package.

Most Rust projects provide a simple way to run the test suite.

You should also check if the repository is a cargo workspace. Just open up /Cargo.toml and see if it contains a [workspace] section. If so, you should add the --workspace flag to cargo test to ensure that all tests of the workspace members are run too.

Rust builds binaries in target/release and can simply be installed to /usr/bin.

If a package has more than one executable in /usr/bin you can use find command:

Some packages should install more files such as a man page or other assets. In the event that such a package does not have any other way to install these, one can use cargo install. In this case build() is unnecessary because cargo install forces rebuilding even if the package already has been built by using cargo build. The prepare() stage can still be used to fetch sources ahead of time:

The --no-track argument should always be used, otherwise cargo install will create unwanted files such as /usr/.crates.toml or /usr/.crates2.json.

Click Package Actions > Source Files in the package page to see its example PKGBUILD.

**Examples:**

Example 1 (unknown):
```unknown
source=("$pkgname-$pkgver.tar.gz::https://static.crates.io/crates/$pkgname/$pkgname-$pkgver.crate")
```

Example 2 (unknown):
```unknown
makedepends
```

Example 3 (unknown):
```unknown
makedepends=(cargo)
```

Example 4 (unknown):
```unknown
makedepends=(cargo-nightly)
```

---

## Redshift

**URL:** https://wiki.archlinux.org/title/Redshift

**Contents:**
- Installation
  - Front ends
- Usage
  - Quick start
  - Autostart
  - Toggle
- Configuration
  - Specify location manually
  - Automatic location based on GeoClue
  - Automatic location based on GPSD

From the Redshift project web page[dead link 2025-08-16—HTTP 404]:

Install the redshift package. Alternatively, install the redshift-minimalAUR package, for a version with minimal dependencies.

The redshift-gtk command comes with the redshift package and provides a system tray icon for controlling Redshift. See optional dependencies.

Alternatives are redshift-qtAUR or redshiftconfAUR.

Redshift will at least need your location to start (unless -O is used), meaning the latitude and longitude of your location. Redshift employs several routines for obtaining your location. If none of them works (e.g. none of the used helper programs is installed), you need to enter your location manually.

To just get it up and running with a basic setup, issue:

where LATITUDE is the latitude and LONGITUDE is the longitude of your location.

To instantly adjust the color temperature of your screen use:

where TEMPERATURE is the desired color temperature (between 1000 and 25000).

There are several options to have Redshift automatically started:

Redshift will continously update the color temperature at regular intervals. One shot mode can be selected if you only want to do one adjustment. The color adjustments done by Redshift can be temporarily toggled on and off by sending it the USR1 signal:

Redshift reads the configuration file ~/.config/redshift/redshift.conf [2] if it exists. However, Redshift does not create that configuration file, so you may want to create it manually. See redshift.conf.sample.

Redshift calculates the sunrise and sunset times based on geographic coordinates. It can be specified manually by using the manual location-provider, e.g. for Paris:

Redshift uses the geoclue2 location-provider by default. It needs a GeoClue agent running in the background. It is supposed to work without further configuration, but if you experience problems, see #Unable to connect to GeoClue.

You can also use gpsd to automatically determine your GPS location and use it as an input for Redshift. Create the following script and pass $lat and $lon to redshift -l $lat:$lon:

For more information, see this forums thread.

Redshift has a brightness adjustment setting, but it does not work the way most people might expect. In fact it is a fake brightness adjustment obtained by manipulating the gamma ramps, which means that it does not reduce the backlight of the screen. [3][dead link 2025-08-16—HTTP 404]

Changing screen backlight is possible with redshift hooks and acpilightAUR, but please see Backlight#xbacklight as there are some limitations and you may have to find another method of controlling the backlight depending on your hardware.

You need to create a file in ~/.config/redshift/hooks and make it executable. You can use and edit the following example:

Make it executable and restart the redshift.service to apply changes.

Check the service status as it should not contain the following message:

If running $ redshift and you are getting:

Then make sure that a GeoClue agent is running. GNOME Shell provides an agent itself. For other desktop environments, a demo agent (/usr/lib/geoclue-2.0/demos/agent) is autostarted. You can check if GeoClue works properly by checking the output of the /usr/lib/geoclue-2.0/demos/where-am-i command.

If you are using a desktop environment that does not support XDG Autostart, then you have to start the demo agent manually, or you can create a systemd unit file with the following config:

Then start/enable the geoclue-agent.service user unit.

Locate configuration-file "redshift.conf" in your distribution and change "screen 1" to "screen 0".

Install libappindicator. See redshift issue 363 and FS#49971.

Make sure there are not multiple instances of redshift running.

The systemd unit has a line in the redshift.service file that makes the service wait until the display-manager.service unit is started by a display manager before the unit will invoke redshift. If you do not use a display manager, edit the redshift.service user service and delete the After=display-manager.service line. Run a daemon-reload and the service should initialize properly.

Refer to the previous problem and to [4].

If running the $ redshift-gtk command does not start in the system tray, but instead you get the following output

you will need to install python-gobject.

This is a bug with the nvidia drivers. A fix for this is to make the following edit:

For more information, see redshift issue 587 and redshift issue 720.

A workaround is to create a custom hotkey in your desktop environment calling the command pkill -USR1 '^redshift$'.

For more information, see [5].

**Examples:**

Example 1 (unknown):
```unknown
$ redshift -l LATITUDE:LONGITUDE
```

Example 2 (unknown):
```unknown
$ redshift -P -O TEMPERATURE
```

Example 3 (unknown):
```unknown
TEMPERATURE
```

Example 4 (unknown):
```unknown
~/.config/autostart/
```

---

## Nonfree applications package guidelines

**URL:** https://wiki.archlinux.org/title/Nonfree_applications_package_guidelines

**Contents:**
- Rationale
- Common rules
  - Avoid nonfree software when possible
  - Use open source variants where possible
  - Keep it simple
- Package naming
- File placement
- Missing files
  - Files can only be obtained in a distributed archive/installer
    - Scheme to choose

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

This article or section needs expansion.

For many applications (most of which are Windows ones) there are neither sources nor tarballs available. Many of such applications can not be freely distributed because of license restrictions and/or lack of legal ways to obtain installer for no fee.

There are multiple reasons for packaging even non-packageable software:

Yes, it is better to leave this guide and spend some time searching (or maybe even creating) alternatives to an application you wanted to package because:

Many commercial games (some are listed in this Wiki) have open source engines and many old games can be played with emulators such as ScummVM. Using open source engines together with the original game assets gives users access to bug fixes and eliminates several issues caused by binary packages.

If the packaging of some program requires more effort and hacks than buying and using the original version, do the simplest thing—it is Arch!

This article or section needs expansion.

Before naming a package, search the AUR for existing packages of software that you are packaging. Try to use established naming conventions, e.g. do not name your package gish-hb if there are existing packages called aquaria-hib, crayonphysicsdeluxe-hib and uplink-hib. If you are certain there will never be a source-based package, you can omit the suffix -bin. Otherwise, always use this suffix. A user submitting a source-based package of the software would have to ask the maintainer of your package (or, in the worst case, a Package maintainer) to orphan the existing package so that their source-based package could be submitted, and both the original binary package and the new source-based package would end up having their respective PKGBUILDs cluttered with additional replaces and conflicts entries.

Again, analyze existing packages (if present) and decide whether or not you want to conflict with them. Do not place things under /opt unless you want to use some ugly hacks like giving ownership root:games to the package directory (so users in group games running the game can write files in the game's own folder).

For most commercial games there is no way to (legally) download game files, which is the preferable way to get them for normal packages. Even when it is possible to download files after providing a password (like with all Humble Indie Bundle games) asking user for this password and downloading somewhere in build function is not recommended for a variety of reasons (for example, the user may have no Internet access but have all files downloaded and stored locally).

The subsections below provide recommendations for a few situations you may encounter.

The software is only available via that archive/installer file, which must be obtained in order to get the missing files.

Add the required archive/installer to the source array, renaming the source filename so the source's link in the AUR web interface looks different from names of files included in the source tarball:

Also add a pinned comment like the one below to the package page in the AUR, and explain the details in the PKGBUILD:

In case you use the local:// scheme in a source array, makepkg behaves as though no scheme were specified, and the file must be manually placed in the same directory as the PKGBUILD.

In case you use the file:// scheme, you can additionally specify DLAGENTS for the file protocol, so it may be obtained in a special way. See examples below.

However, there are still no clear rules which of these schemes you should use.

The software is only available via an optical disk media (e.g. CD, DVD, Bluray etc.), which must be inserted into the optical disk drive in order get the missing files.

Add an installer script and an .install file to the package contents.

Copying files from disk, downloading from Net or getting from archive during the build phase may look like a good idea but it is not recommended because it limits the user's possibilities and makes package installation interactive (which is generally discouraged and just annoying). Again, a good installer script and .install file can work instead.

Few examples of various strategies for obtaining files required for package:

This article or section needs expansion.

Some software authors aggressively protect their software from automatic downloading: ban certain "User-Agent" strings, create temporary links to files etc. You can still conveniently download these files by using DLAGENTS variable in the PKGBUILD (see makepkg.conf(5)). This is used by some packages in official repositories, for example in previous version of ttf-baekmuk.

Please pay attention, if you want to have a customized user-agent string, if the latter contains spaces, parentheses, or slashes in it (or actually anything that can break parsing), this will not work. There is no workaround, this is the nature of arrays in bash and the way DLAGENTS was designed to be consumed in makepkg. The following example will thus not work:

Shorten it to the following which is working:

And the following allows to extract temporary link to file from download page:

In order to download temporary links to files or get past an interactive download, it is possible to analyze the HTTP request used to create the final download link, and then create a DLAGENTS that emulates this using curl. See for example decklink-sdkAUR or jlink-software-and-documentationAUR.

Alternatively, the DLAGENTS can be used to provide a more informative error message to the user when a file is missing. See for example ttf-ms-win10AUR.

Many proprietary programs are shipped in nasty installers which sometimes do not even run in Wine. The following tools may be of some help:

In order to determine exact type of file run file file_of_unknown_type.

Proprietary software often have no separate icon files, so there is nothing to use in .desktop file creation. Fortunately, .ico files can be easily extracted from executables using programs from the icoutils package. You can even do it on the fly during the build phase, for example:

Non-free software vendors often don’t include a version number in their download source URL:

That will likely cause the release upstream package to change without notice, which is an issue for packaging. Just like in VCS packages, you may want to auto-bump your pkgver to handle that.

For example, some .exe installers have the Product Version field set in their PE. The peres command from the pevAUR package may help you extract and use that value to auto-bump your pkgver:

Sometimes the .exe installer doesn’t carry a meaningful value for Product Version but the main executable does. In that case, you can use the prepare step to extract the nested main executable (see Unpacking for details) and then auto-bump the pkgver:

Sometimes a .deb file doesn’t have a version number in its name but in its control file.

You can use dpkg-deb to extract the version directly from the control file inside the .deb package:

**Examples:**

Example 1 (unknown):
```unknown
$ chmod +x filename$ chown root:root filename# cp filename /usr/bin/
```

Example 2 (unknown):
```unknown
$ makepkg -i
```

Example 3 (unknown):
```unknown
sources=(... "originalname::local://originalname")
```

Example 4 (unknown):
```unknown
Need archive/installer to work.
```

---

## LILO

**URL:** https://wiki.archlinux.org/title/LILO

**Contents:**
- Supported file systems
- Installation
  - Install to partition or partitionless disk
- Configuration
  - Sample setup
  - Using an image as background
- Pacman hook
- Troubleshooting
  - Read write error message whilst booting
  - Devmapper not found error message after kernel upgrade

The LInux LOader, or LILO for short, is a legacy multi-boot loader for Linux systems. In spite of being the standard choice over the course of several years, it has been slowly phased out. As of January 2016, LILO is no longer actively developed.

From upstream's readme:

In practice, the development of LILO has stopped precisely because of some limitations to that approach, e.g. with Btrfs, GPT, RAID.

LILO can be installed with the liloAUR package. LILO only works on BIOS systems.

Running the command lilo (as root) will install LILO to the MBR. Before running the lilo command you should edit /etc/lilo.conf to ensure that the root entry points towards the root partition. If your root partition is on /dev/sda1 then the root entry should look like this: root=/dev/sda1. Remember to change the root line for both the 'arch' and the 'arch-fallback' entries.

Use the -b flag to specify a partition or the whole disk (instead of the implied -M) to install LILO to the volume boot record (VBR) instead of the MBR. See lilo(8) and the answers by Hypnos on the Gentoo forum.

LILO is configured by editing the /etc/lilo.conf file and running lilo afterwards to apply the new configuration.

As a reminder, consider that LILO needs to be run after every kernel upgrade, otherwise the system is likely to be left in an unbootable state.

More help on setting up LILO can be found in the LILO-mini-HOWTO.

A typical LILO setup:

You can use hwinfo --framebuffer to determine what vga modes you can use.

First prepare the background image:

Now edit lilo.conf. There are a few options that can be set for your graphical menu. See man lilo.conf for more information.

Save lilo.conf, run lilo as root, and reboot and see how it looks!

lilo needs to be run after every kernel update. You can use a pacman hook to automate it. See Pacman#Hooks or alpm-hooks(5).

Make the directory /etc/pacman.d/hooks if it does not already exist.

This error message is caused by a change in mkinitcpio which was in response to this systemd commit. The change causes partitions to be fsck'ed twice when mounted read only. To fix this error edit /etc/lilo.conf and change the 'read only' line to 'read write' for both arch entries.

See this forum thread for more information.

It is possible that running the lilo command after a kernel upgrade results in a devmapper not found error. If this is the case run modprobe dm-mod before running lilo after a kernel upgrade.

**Examples:**

Example 1 (unknown):
```unknown
/etc/lilo.conf
```

Example 2 (unknown):
```unknown
root=/dev/sda1
```

Example 3 (unknown):
```unknown
/etc/lilo.conf
```

Example 4 (unknown):
```unknown
/etc/lilo.conf
```

---

## JWM

**URL:** https://wiki.archlinux.org/title/JWM

**Contents:**
- Installation
- Starting
- Configuration
  - Autostart
- Tips and tricks
  - Improve <Tasklist> contrast
  - Logout and refresh
    - Reboot and shutdown
    - Conky
  - Minimal font suggestions

JWM (Joe's Window Manager) is a lightweight window manager for Xorg written in C. It is under active development and maintained by Joe Wingbermuehle.

Install the jwmAUR package.

You can start a JWM session with a display manager. Alternatively, you can run jwm with xinit.

Configuration is done via a single XML file. There is native support for customizable panels and buttons, and a system tray dock. A sample configuration file is located at /etc/system.jwmrc which can be copied to the user configuration ~/.jwmrc:

Edit this file to establish the environment. See JWM Configuration for a complete list of available tags, attributes and values.

Add an StartupCommand section in your configuration file to execute one or more commands at startup. For example:

Change the default <Tasklist> settings to match the improved contrast style of the default <MenuStyle> and active <WindowStyle>:

<Exit/> (Logout) is the menu command to cleanly log out of the current X server.

<Restart/> (Refresh) is the menu command tag which reinitializes the configuration file and updates menus and keybindings accordingly.

<Restart/> and <Exit/> can be bound to the Ctrl+Alt modified keys following the example syntax below:

The Restart and Poweroff menu options can use systemctl commands:

Alternatively, use <Key> to bind the commands to a chosen key.

See Allow users to shutdown#Using systemd-logind for additional information.

Conky can be run within the <StartupCommand> to provide the display of various data streams (e.g. battery life and AC adapter status for notebooks). xfdesktop may conflict with Conky; workarounds include:

Tiling support can be added to JWM with the Poor Man's Tiling Window Manager. Assuming manage.py is part of the local PATH, various tiling actions can be assigned to keys, for example:

If X is not already running on tty1, Ctrl+Alt+F1 will allow you to review standard output errors and messages. See script(1) command for details on how to create a typescript of what is printed to the terminal.

Adjust the window transparency in ~/.jwmrc:

Add a group with the iignore option to ~/.jwmrc, for example:

To check the JWM configuration and return syntax errors (including associated line numbers), if any, run:

**Examples:**

Example 1 (unknown):
```unknown
/etc/system.jwmrc
```

Example 2 (unknown):
```unknown
$ cp -i /etc/system.jwmrc ~/.jwmrc
```

Example 3 (unknown):
```unknown
StartupCommand
```

Example 4 (unknown):
```unknown
<StartupCommand>
feh --randomize --bg-fill ~/backgrounds/*
xterm -geometry 100x30 &
numlockx
</StartupCommand>
```

---

## DKMS package guidelines

**URL:** https://wiki.archlinux.org/title/DKMS_package_guidelines

**Contents:**
- Package name
- Dependencies
- Source location
- Patching
- Module loading automatically in .install
- Example
  - PKGBUILD
  - dkms.conf
  - .install
  - Module blacklist conf

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

Here are some guidelines to follow when creating a DKMS package.

DKMS packages are named by appending "-dkms" to the original package name.

The variable $_pkgname is often used below $pkgname to describe the package name minus the "-dkms" suffix (e.g. _pkgname="${pkgname%-*}")

Add dkms to depends array. This is important because this will provide tools and hooks that will rebuild the kernel driver provided by the -dkms package whenever the kernel is updated.

Do not include linux-headers – or any other Linux header package – to the PKGBUILD. These headers are already listed as optional dependencies of dkms and each kernel package has its own header package, so including header package dependency in the -dkms package is both unnecessarily redundant and restricting.

The package should install the kernel module's source files into:

where PACKAGE_NAME and PACKAGE_VERSION are the kernel module's name and version.

It is highly recommended to set PACKAGE_NAME with the value of $_pkgname (See #Package name), and PACKAGE_VERSION with $pkgver.

The sources can be patched either directly in the PKGBUILD or through dkms.conf.

If patching through dkms.conf, make sure to install the patches into /usr/src/PACKAGE_NAME-PACKAGE_VERSION/patches/ directory and to add a PATCH[number]=patch_filename for each patch to be applied, replacing number with a incremental value starting at 0. See dkms(8) § DKMS.CONF for more information.

Do not use .install file to load or unload modules. Leave it to the user, since there is a possibility a module may crash when loaded.

Also do not call dkms as it is automatically done via pacman hook provided by dkms. This hook runs dkms install and dkms remove leaving no manual task for the package maintainer.

Here is an example package that edits dkms.conf according to the package name and version, and install module blacklist configuration file.

For other example of (real) packages, search -dkms in official repositories and -dkms in AUR.

This example shows a message on post-install and post-upgrade that suggests unloading a conflicting module (example-conflicting-module) and then loading this package's module (example) for immediate use, when the user do not want to reboot the system at this moment.

When it is known that example-conflicting-module conflicts with this package's example module, it should be blacklisted:

**Examples:**

Example 1 (unknown):
```unknown
_pkgname="${pkgname%-*}"
```

Example 2 (unknown):
```unknown
/usr/src/PACKAGE_NAME-PACKAGE_VERSION
```

Example 3 (unknown):
```unknown
PACKAGE_NAME
```

Example 4 (unknown):
```unknown
PACKAGE_VERSION
```

---

## Package Maintainers

**URL:** https://wiki.archlinux.org/title/Package_Maintainers

**Contents:**
- How do I become a Package Maintainer?
- Active Package Maintainers
- Past Package Maintainers

Package Maintainers (previously called Trusted Users) are an official Arch Linux staff role. Package Maintainers fulfill the following tasks:

The generic term "package maintainer" is also used to describe any person maintaining a package, regardless of the repository, as described in Arch terminology#Package maintainer.

The minimum requirements to becoming a Package Maintainer are as follows:

Even though you could become a Package Maintainer by merely fulfilling those minimum requirements, the people judging you during the standard voting procedure might expect more from you. Such as:

If you still feel up to becoming a Package Maintainer after reading these lines, the first step is to find two Package Maintainers who agree to sponsor you. Once sponsored, you should write a witty application signed with your GPG key to the aur-general mailing list.

For more information, see the Package Maintainer Bylaws and Package Maintainer guidelines.

See https://archlinux.org/people/package-maintainers/

See https://archlinux.org/people/package-maintainer-fellows/

---

## Package proxy cache

**URL:** https://wiki.archlinux.org/title/Package_proxy_cache

**Contents:**
- Package cache sharing
  - Read-only cache
  - Overlay mount of read-only cache
  - Distributed read-only cache
  - Read-write cache
  - Two-way with rsync or FTP
  - Synchronize pacman package cache using synchronization programs
- Proxy server
  - Dynamic reverse proxy cache using nginx
  - Squid

If you want to install the same Arch packages over and over —e.g. for testing purposes— it could help if you would not have to get the packages every time from the internet. This article shows you how to share packages so that you can greatly decrease your download times.

Which solution is best depends on your individual use-case. The methods can be grouped into #Package cache sharing of the machines, or deploying a #Proxy server for extra caching on one machine and configuring the machines to use it accordingly.

For all solutions to share the package cache, keep in mind that, by default, pacman -Sc removes package tarballs from the cache that correspond to packages that are not installed on the machine the command was issued on. Because pacman cannot predict what packages are installed on all machines that share the cache, it will end up deleting files that should not be.

To clean up the cache so that only outdated tarballs are deleted:

Pacman 6.1.0 supports cache servers directly. Cache servers will be tried before any non-cache servers, will not be removed from the server pool because of HTTP 404 download errors, and will not be used for database files.

If you are looking for a quick solution, you can simply run a basic temporary webserver which other computers can use as their cache server.

Start serving this directory. For example, with Python http.server module:

Then edit /etc/pacman.d/mirrorlist on each client machine to add this server:

If looking for a more standalone solution, darkhttpd offers a very minimal webserver. Replace the previous python command with e.g.:

You could also run darkhttpd as a systemd service for convenience: see Systemd#Writing unit files.

miniserve, a small web server written in Rust, can also be used:

Then edit /etc/pacman.d/mirrorlist as above with the first url miniserve is available at.

If you are already running a web server for some other purpose, you might wish to reuse that as your local repository server instead. For example, if you already serve a site with nginx, you can add an nginx server block listening on port 8080:

Remember to restart nginx.service after making this change.

It is possible to use one machine on a local network as a read-only package cache by overlay mounting its /var/cache/pacman/pkg directory. Such a configuration is advantageous if this server has installed on it a reasonably comprehensive selection of up-to-date packages which are also used by other boxes. This is useful for maintaining a number of machines at the end of a low bandwidth upstream connection.

As an example, to use this method:

After this, run pacman using the option --cachedir /tmp/pacman_pkg, e.g.:

There are Arch-specific tools for automatically discovering other computers on your network offering a package cache. Try pacredir, pacserve, pkgdistcacheAUR, or paclanAUR. pkgdistcache uses Avahi instead of plain UDP which may work better in certain home networks that route instead of bridge between Wi-Fi and Ethernet.

Historically, there was PkgD and multipkg, but they are no longer maintained.

In order to share packages between multiple computers, simply share /var/cache/pacman/ using any network-based mount protocol. This section shows how to use SSHFS to share a package cache plus the related library-directories between multiple computers on the same local network. Keep in mind that a network shared cache can be slow depending on the file-system choice, among other factors.

First, install any network-supporting filesystem packages: sshfs, curlftpfs, samba or nfs-utils.

Then, to share the actual packages, mount /var/cache/pacman/pkg from the server to /var/cache/pacman/pkg on every client machine.

Another approach in a local environment is rsync. Choose a server for caching and enable the rsync daemon. On clients synchronize two-way with this share via the rsync protocol. Filenames that contain colons are no problem for the rsync protocol.

Draft example for a client, using uname -m within the share name ensures an architecture-dependent sync:

Instead of relying on unencrypted rsync daemon a more secure security option is rsync over ssh, Rsync#Automated backup with SSH gives an overview.

In case rsync is not available in your local environment, a simple ftp service is suitable for the two-way sync as well. lftp provides a --mirror and a --delete option to sync a local with a remote storage.

Use Syncthing or Resilio Sync to synchronize the pacman cache directories (i.e. /var/cache/pacman/pkg).

For proxy server solutions, keep in mind the machines should only use HTTP mirrors, because a proxy server cannot introspect HTTPS connections by default.

nginx can be used to proxy package requests to official upstream mirrors and cache the results to the local disk. All subsequent requests for that package will be served directly from the local cache, minimizing the amount of internet traffic needed to update a large number of computers.

In this example, the cache server will run at http://cache.domain.example:8080/ and store the packages in /srv/http/pacman-cache/.

Install nginx on the computer that is going to host the cache. Create the directory for the cache and adjust the permissions so nginx can write files to it:

Use the nginx pacman cache config as a starting point for /etc/nginx/nginx.conf. Check that the resolver directive works for your needs. In the upstream server blocks, configure the proxy_pass directives with addresses of official mirrors, see examples in the configuration file about the expected format. Once you are satisfied with the configuration file start and enable nginx.

In order to use the cache each Arch Linux computer (including the one hosting the cache) must have the following line at the top of the mirrorlist file:

Squid proxy can be setup to only cache arch packages and can be used with aif/pacman/wget/etc with minimal configuration on the client system.

This is the minimum configuration to get squid cache arch packages.

Before defining these rules, remove/comment (if you do not need them) all the default refresh_patterns

That should define that *.pkg.tar.* gets cached, and anything else should not.

Objects larger than this size will NOT be saved on disk:

Set the cache dir and its maximum size and subdirs:

Time to wait until all active client sockets are closed:

Every time you change the cache_dir path (and after fresh install), you need to (re)create this directory:

and it could be helpful to check the configuration file before running squid:

Just start squid.service or if squid is already running restart it.

It could be helpful to check the configuration file before running:

To see the access to squid:

You should see this for packages that are directed to original host:

and for packages that are delivered from the cache:

On the individual machines, add environment variables for your proxy. To do so for testing:

Now it should use your proxy. Watch the squid logs to verify this. Once it works, add the http_proxy and/or ftp_proxy variables in an appropriate place on the installed system, e.g. in /etc/profile.d/proxy.sh.

If you want all HTTP requests on local machine automagically go through squid, we first need to add an intercepting port for squid:

and iptables rules to redirect all (except the ones from squid) port 80 requests to squid:

Pacoloco is an easy-to-use proxy cache server for pacman repositories. It also allows automatic prefetching of the cached packages.

It can be installed as pacoloco. Open the configuration file and add pacman mirrors:

Restart pacoloco.service and the proxy repository will be available at http://myserver:9129/repo/mycopy.

Flexo is yet another proxy cache server for pacman repositories. Flexo is available as flexo-gitAUR. Once installed, start the flexo.service unit.

Flexo runs on port 7878 by default. Enter Server = http://myserver:7878/$repo/os/$arch to the top of your /etc/pacman.d/mirrorlist so that pacman downloads packages via Flexo.

**Examples:**

Example 1 (unknown):
```unknown
/etc/pacman.conf
```

Example 2 (unknown):
```unknown
[options]
CleanMethod = KeepCurrent
```

Example 3 (unknown):
```unknown
$ python -m http.server -d /var/cache/pacman/pkg/
```

Example 4 (unknown):
```unknown
http.server
```

---

## Snapper

**URL:** https://wiki.archlinux.org/title/Snapper

**Contents:**
- Installation
- Creating a new configuration
- Taking snapshots
  - Automatic timeline snapshots
    - Enable/disable
    - Set snapshot limits
    - Change snapshot and cleanup frequencies
  - Manual snapshots
    - Single snapshots
    - Pre/post snapshots

Snapper is a tool created by openSUSE's Arvin Schnell that helps with managing snapshots of Btrfs subvolumes, thin-provisioned LVM volumes, and (experimentally) Bcachefs subvolumes. It can create and compare snapshots, revert between snapshots, and supports automatic snapshots timelines.

Install the snapper package.

Additionally, GUIs are available with btrfs-assistant, snapper-gui-gitAUR, and snapper-toolsAUR.

Before creating a snapper configuration for a Btrfs subvolume, the subvolume must already exist. If it does not, you should create it before generating a snapper configuration.

To create a new snapper configuration named config for the Btrfs subvolume at /path/to/subvolume, run:

For example, to create a configuration file for the subvolume mounted at /, run:

This procedure is not needed for the suggested Btrfs partition layout from archinstall version 3.0.5 or newer.

At this point, the configuration is active. If your cron daemon is running, snapper will take #Automatic timeline snapshots. If you do not use a cron daemon, you will need to use the systemd service and timer. See #Enable/disable.

See also snapper-configs(5).

A snapshot timeline can be created with a configurable number of hourly, daily, weekly, monthly, and yearly snapshots kept. When the timeline is enabled, by default a snapshot gets created once an hour. Once a day the snapshots get cleaned up by the timeline cleanup algorithm. Refer to the TIMELINE_* variables in snapper-configs(5) for details.

If you have a cron daemon, this feature should start automatically. To disable it, edit the configuration file corresponding with the subvolume you do not want to have this feature and set:

If you do not have a cron daemon, you can use the provided systemd units. Start and enable snapper-timeline.timer to start the automatic snapshot timeline. Additionally, start and enable snapper-cleanup.timer to periodically clean up older snapshots.

The default settings will keep 10 hourly, 10 daily, 10 monthly and 10 yearly snapshots. You may want to change this in the configuration, especially on busy subvolumes like /. See #Preventing slowdowns.

Here is an example section of a configuration named config with only 5 hourly snapshots, 7 daily ones, no monthly and no yearly ones:

If you are using the provided systemd timers, you can edit them to change the snapshot and cleanup frequency.

For example, when editing the snapper-timeline.timer, add the following to make the frequency every five minutes, instead of hourly:

When editing snapper-cleanup.timer, you need to change OnUnitActiveSec. To make cleanups occur every hour instead of every day, add:

See systemd/Timers and systemd#Drop-in files.

By default snapper takes snapshots that are of the single type, having no special relationship to other snapshots.

To take a snapshot of a subvolume manually, do:

The above command does not use any cleanup algorithm, so the snapshot is stored permanently or until deleted.

To set a cleanup algorithm, use the -c flag after create and choose either number, timeline, pre, or post. number sets snapper to periodically remove snapshots that have exceeded a set number in the configuration file. For example, to create a snaphot that uses the number algorithm for cleanup do:

See #Automatic timeline snapshots for how timeline snapshots work and see #Pre/post snapshots on how pre and post work.

The other type of snapshots - pre/post snapshots - are intended to be created as a pair, one before and one after a significant change (such as a system update).

If the significant change is/can be invoked by a single command, then snapper create --command can be used to invoke the command and automatically create pre/post snapshots:

Alternatively, the pre/post snapshots can be created manually.

First create a pre snapshot:

Note the number of the new snapshot (it is required to create the post snapshot).

Now perform the actions that will modify the filesystem (*e.g.*, install a new program, upgrade, etc.).

Finally, create the post snapshot, replacing N with the number of the pre snapshot:

See also #Wrapping pacman transactions in snapshots.

To have snapper take a snapshot of the root configuration, enable snapper-boot.timer. (These snapshots are of type single.)

To list all configurations that have been created do:

To list snapshots taken for a given configuration config do:

A file may be kept as is when restoring a snapshot, either because was not included in the snapshot (e.g. it resides on another subvolume), or because a filter configuration excluded the file.

The factual accuracy of this article or section is disputed.

Some files keep state information of the system, e.g. /etc/mtab. Such files should never be reverted. The default configuration in arch linux ensures this. To help users, snapper allows one to ignore these files. Each line in all files /etc/snapper/filters/*.txt and /usr/share/snapper/filters/*.txt specifies a pattern. When snapper computes the difference between two snapshots it ignores all files and directories matching any of those patterns. Note that filters do not exclude files or directories from being snapshotted. For that, use subvolumes or mount points.

The factual accuracy of this article or section is disputed.

See also the Directories That Are Excluded from Snapshots in the SLES 12 SP5 documentation.

The factual accuracy of this article or section is disputed.

If you are using the default layout of snapper, each snapshot is sub-subvolume in the .snapshots directory of a subvolume, e.g. @home.

The factual accuracy of this article or section is disputed.

To restore /home using one of snapper's snapshots, first boot into a live Arch Linux USB/CD.

Mount btrfs root-volume into /mnt using the UUID:

The factual accuracy of this article or section is disputed.

If the snapper service is running on a running system, stop it. Check if any snapper-unit.timers are running, then stop them.

Move a broken/old subvolume out of the way e.g. @home to @home-backup:

Find the number of the snapshot that you want to recover (there is one line for each snapshot, so you can easily match up number and date of each snapshot):

Create a new snapshot @home from snapshot number number to be restored.

Get the directory .snapshots back to the healthy subvolume, e.g. @home

If subvolid was used for the /home mount entry option in fstab, instead of /path/to/subvolume, change subvolid in the /mnt/@/etc/fstab file (assuming that @ is the subvolume that is mounted as / in the system) to the new subvolid that can be found with btrfs subvolume list /mnt | grep @home$.

Check if your system is working as intended, the delete the old/broken snapshot (e.g. @home-backup) if desired. You should check if it contains useful data that you can get back.

To delete a snapshot number N do:

Multiple snapshots can be deleted at one time. For example, to delete snapshots 65 and 70 of the root configuration do:

To delete a range of snapshots, in this example between snapshots 65 and 70 of the root configuration do:

To free the space used by the snapshot(s) immediately, use --sync:

To delete all snapshots, the .snapshots subvol and the snapper configuration files for a configuration:

Each config is created with the root user, and by default, only root can see and access it.

To be able to list the snapshots for a given config for a specific user, simply change the value of ALLOW_USERS in your /etc/snapper/configs/config file. You should now be able to run snapper -c config list as a normal user.

Eventually, you want to be able to browse the .snapshots directory with a user, but the owner of this directory must stay root. Therefore, you should change the group owner by a group containing the user you are interested in, such as users for example:

To enable a regular user to use snapper (e.g. for /home snapshots), you can use the SYNC_ACL option.

There are a couple of packages used for automatically creating snapshots upon a pacman transaction:

Users who rely on grub-btrfs or snap-pac-grubAUR or limine-snapper-syncAUR should note that by default, Snapper's snapshots are read-only, and there are some inherent difficulties booting into read-only snapshots. Many services, such as a desktop manager, require a writable /var directory, and will fail to start when booted from a read-only snapshot.

To work around this, you can either make the snapshots writable, or use the developer-approved method of booting the snapshots with overlay filesystem, causing the snapshot to behave similar to a live CD environment.

To boot snapshots with overlayfs:

If your /boot partition is on a non Btrfs filesystem (e.g. an ESP) you are not able to do snapper backups with it. See System backup#Snapshots and /boot partition to copy the boot partition automatically on a kernel update to your Btrfs root with a hook. This also plays nice together with snap-pac.

Some tools can use snapper to automate backups. See Btrfs#Incremental backup to external drive.

Here is a suggested file system layout for easily restoring the subvolume @ that is mounted at root to a previous snapshot:

The subvolumes @... are mounted to any other directory that should have its own subvolume.

If you were to restore your system to a previous snapshots of @, these other subvolumes will remain unaffected. For example, this allows you to restore @ to a previous snapshot while keeping your /home unchanged, because of the subvolume that is mounted at /home.

This layout allows the snapper utility to take regular snapshots of /, while at the same time making it easy to restore / from an Arch Live CD if it becomes unbootable.

In this scenario, after the initial setup, snapper needs no changes, and will work as expected.

It is assumed that the subvolume @ is mounted at root /. It is also assumed that /.snapshots is not mounted and does not exist as folder, this can be ensured by the commands:

Then create a new configuration for /. Snapper create-config automatically creates a subvolume .snapshots with the root subvolume @ as its parent, that is not needed for the suggested filesystem layout, and can be deleted.

After deleting the subvolume, recreate the directory /.snapshots.

Now mount @snapshots to /.snapshots. For example, for a file system located on /dev/sda1:

To make this mount permanent, add an entry to your fstab.

Or if you have an existing fstab entry remount the snapshot subvolume:

Give the folder 750 permissions.

This will make all snapshots that snapper creates be stored outside of the @ subvolume, so that @ can easily be replaced anytime without losing the snapper snapshots.

To restore / using one of snapper's snapshots, first boot into a live Arch Linux USB/CD.

Mount the toplevel subvolume (subvolid=5). That is, omit any subvolid or subvol mount flags.

Find the number of the snapshot that you want to recover:

The output should look like so, there is one line for each snapshot, so you can easily match up number and date of each snapshot.

Now, move @ to another location (e.g. /@.broken) to save a copy of the current system. Alternatively, simply delete @ using btrfs subvolume delete /mnt/@.

Create a read-write snapshot of the read-only snapshot snapper took:

Where number is the number of the snapper snapshot you wish to restore.

If subvolid was used for the / mount entry option in fstab, instead of /path/to/subvolume, change subvolid in the /mnt/@/etc/fstab file to the new subvolid that can be found with btrfs subvolume list /mnt | grep @$. Also change the boot loader configuration such as refind_linux.conf, if it contains the subvolid.

Finally, unmount the top-level subvolume (ID=5), then mount @ to /mnt and your ESP or boot partition to the appropriate mount point. Change root to your restored snapshot in order to regenerate your initramfs image.

Your / has now been restored to the previous snapshot. Now just simply reboot.

See #Restore snapshot.

If you want to delete a specific file or folder from past snapshots without deleting the snapshots themselves, snappersAUR is a script that adds this functionality to Snapper. This script can also be used to manipulate past snapshots in a number of other ways that Snapper does not currently support.

If you want to remove a file without using an extra script, you just need to make your snapshot subvolume read-write, which you can do with:

Verify that ro=false:

You can now modify files in /path/to/.snapshots/<snapshot_num>/snapshot like normal. You can use a shell loop to work on your snapshots in bulk.

Keeping many snapshots for a large timeframe on a busy filesystem like /, where many system updates happen over time, can cause serious slowdowns. You can prevent it by:

By default, updatedb (see locate) will also index the .snapshots directory created by snapper, which can cause serious slowdown and excessive memory usage if you have many snapshots. You can prevent updatedb from indexing over it by editing:

There are reports of significant slow downs being caused by quota groups, if for instance snapper ls takes many minutes to return a result this could be the cause. See [5].

To determine whether or not quota groups are enabled use the following command:

Quota groups can then be disabled with:

If disabling quota groups did not help with slow down, it may be helpful to count the number of snapshots, this can be done with:

It is recommended to store directories on their own subvolume, rather than the root subvolume /, if they contain user data e.g. emails, or logs. That way if a snapshot of / is restored, user data and logs will not also be reverted to the previous state. A separate timeline of snapshots can be maintained for user data. It is not recommended to create snapshots of logs in /var/log. This makes it easier to troubleshoot.

Directories can also be skipped during a restore using #Filter configuration. See the SLES documentation for examples and reasons to skip certain paths.

This article or section needs expansion.

Snapper writes all activity to /var/log/snapper.log - check this file first if you think something goes wrong.

If you have issues with hourly/daily/weekly snapshots, the most common cause for this so far has been that the cronie service (or whatever cron daemon you are using) was not running.

If you get an 'IO Error' when trying to create a snapshot please make sure that the .snapshots directory associated to the subvolume you are trying to snapshot is a subvolume by itself.

Another possible cause is that .snapshots directory does not have root as an owner (You will find Btrfs.cc(openInfosDir):219 - .snapshots must have owner root in the /var/log/snapper.log).

It is possible for snapshots to get 'lost', where they still exist on disk but are not tracked by snapper. This can result in a large amount of wasted, unaccounted-for disk space. To check for this, compare the output of

Any subvolume in the second list which is not present in the first is an orphan and can be deleted manually.

**Examples:**

Example 1 (unknown):
```unknown
/path/to/subvolume
```

Example 2 (unknown):
```unknown
# snapper -c config create-config /path/to/subvolume
```

Example 3 (unknown):
```unknown
/etc/snapper/configs/config
```

Example 4 (unknown):
```unknown
/usr/share/snapper/config-templates
```

---

## greetd

**URL:** https://wiki.archlinux.org/title/Greetd

**Contents:**
- Installation
  - Greeters
- Starting greetd
- Greeter configuration
  - agreety
  - gtkgreet
    - Using cage
    - Using sway
  - ReGreet
  - wlgreet

greetd is a minimal, agnostic and flexible login manager daemon which does not make assumptions about what the user wants to launch, should it be console-based or graphical. Any script or program which can be started from the console may be launched by greetd, which makes it particularly suitable for Wayland compositors. It can also launch a greeter to start user sessions, like any other display manager.

Install the greetd or greetd-gitAUR packages.

The default greetd configuration file is located at /etc/greetd/config.toml. PAM-specific configuration is set in /etc/pam.d/greetd.

Greetd has greetd-agreety as its built-in greeter, however this is a minimal implementation. You should consider using one of the several available greeters:

Enable greetd.service so greetd will be started at boot.

See also Display manager#Loading the display manager.

Configuring the greeter run by greetd is done using the command option in the default_session section in /etc/greetd/config.toml. The included agreety greeter will be used if no changes are made. Also see #agreety.

By default, greeters are run as the greeter user. This can be changed by editing the user option in the default_session section of the configuration file and replacing another_user with the chosen user:

Make sure the ownership of the /etc/greetd directory is set accordingly.

This is the default greeter. It is launched by greetd with the configuration file set as follows:

agreety can launch any arbitrary command once a user logs in. For example, in order to start Sway, replace $SHELL in the example above with sway.

In order to run, gtkgreet needs a compositor. For the full experience, a compositor with wlr-layer-shell-unstable support is required but others can work. As such, it is recommended to use sway, but something like cage can also be used. Examples for both cage and sway are provided below.

In order to specify which login environments can be started by gtkgreet, list them in /etc/greetd/environments. For example:

You can also invoke gtkgreet with the -c mycommand parameter, replacing mycommand with the desired program (for example, gtkgreet -c bash or gtkgreet -c sway). Do so in the below compositor examples as desired.

Install cage and set the command option as follows:

The -s argument enables VT switching in cage (0.1.2 and newer only), which is highly recommended to prevent locking yourself out.

Install sway. When using Sway, it must be terminated once the user logs in. For that purpose, a specific configuration file must be created, for example in /etc/greetd/sway-config, with the following content:

Then, greetd must be set to start Sway with the configuration file above. Set the command option as follows:

Similar to gtkgreet, ReGreet needs a compositor. For example, both Cage and Sway can be used just like they are used for gtkgreet, replacing the gtkgreet command with regreet. The config for Sway would thus look like:

ReGreet picks up available sessions from /usr/share/xsession (for X11 sessions) and /usr/share/wayland-sessions (for Wayland sessions). Thus, there is no need to list sessions in /etc/greetd/environments.

ReGreet can be configured through a TOML file in /etc/greetd/regreet.toml. A sample file is provided in /usr/share/doc/greetd-regreet/regreet.sample.toml with all available options. Copy this to /etc/greetd/regreet.toml and make the changes you want, commenting out or deleting the lines you do not need. Any invalid options are ignored.

In order to start wlgreet, a compositor with wlr-layer-shell-unstable is required. Follow the steps required to set up gtkgreet with Sway as described above but use the following for /etc/greetd/sway-config instead:

tuigreet does not require any special setup, just set the command option as follows:

tuigreet --help will display customization options.

ddlm does not require any special setup, just set the command option as follows:

In order to use qtgreet, you need a WLR based compositor (e.g. wayfireAUR, sway).

Install wayfireAUR and set the command option as follows:

The Wayfire configuration file referred to is included with qtgreet.

Set the command option as follows:

Then create /etc/greetd/hyprland.conf as:

In order to use nwg-hello, you either need sway or hyprland.

Install sway and set the command option as follows:

The Sway configuration file referred to is included with nwg-hello.

Install hyprland and set the command option as follows:

The Hyprland configuration file referred to is included with nwg-hello.

If you want a user to be logged in automatically, an initial_session section must be defined in /etc/greetd/config.toml:

The command option may contain the name of any executable file. In the example above, Sway will be started by myuser at boot.

If you do not want to use greetd and always want autologin to be enabled, see autologin.

Add your PATH to ~/.profile, or the DE called by greetd will not be able to run local programs. Greetd will not have access to .bashrc or .zshrc, so do not define the PATH there.

By default greetd does not set environment variables such as XDG_SESSION_TYPE and XDG_CURRENT_DESKTOP, unless the greeter sets them based on the session you chose (for example TUI will set the session type based on the location of the session file chosen). One way to solve this is to use a wrapper script that sets any desired environment variables before running the actual command. For example to start sway:

then use this wrapper script as the command the greeter runs. For example with gtkgreet you could use

or put start-sway in /etc/greetd/environments.

See How to Set XDG_SESSION_TYPE=wayland

The logind session type is set by the XDG_SESSION_TYPE environment variable. However, it must be set before the PAM session is opened. Because of this, setting the variable through ~/.profile or a wrapper script will not work (both happen after session open).

The correct way to achieve this is through the environment variables sent by greeters (these are set before session open). So if your greeter supports it, just make it send the appropriate XDG_SESSION_TYPE=xxx.

If your greeter does not support this, it is also possible to use pam_env under the auth group. The drawback is that all the sessions spawned by greetd will use that session type, which may or may not be problematic depending on your use case.

Here is how one could use the pam_env method to have a Wayland session:

If you are using qtgreet with a compositor such as wayfire and generally need to export variables, such as WLR_NO_HARDWARE_CURSORS=1 to get the mouse cursor working, one solution would be to create a separate executable script and then calling that from /etc/greetd/config.toml.

**Examples:**

Example 1 (unknown):
```unknown
/etc/greetd/config.toml
```

Example 2 (unknown):
```unknown
/etc/pam.d/greetd
```

Example 3 (unknown):
```unknown
greetd.service
```

Example 4 (unknown):
```unknown
default_session
```

---

## Window Maker

**URL:** https://wiki.archlinux.org/title/Window_Maker

**Contents:**
- Installation
- Starting
- Configuration
  - Files
  - Styles
  - HiDPI
  - Keyboard shortcuts
  - Background
- Dock
- Clip

Window Maker is a window manager (WM) for the X Window System. It is designed to emulate the NeXT user interface as an OpenStep-compatible environment, and is characterized by low memory demands and high flexibility. As one of the lighter WMs, it is well suited for machines with modest performance specifications.

Install the windowmakerAUR package. You may also wish to install the windowmaker-extraAUR package which contains a number of extra icons and themes.

Run wmaker with xinit.

All of the settings for Window Maker can be found in the GNUSTEP_USER_ROOT directory, under Default and Library. They are simple text files which can be edited by hand, or you can use the Preferences Utility (WPrefs) GUI application to change the settings; in the default installation WPrefs can be started by double-clicking the icon in the top right corner of the workspace.

Styles are simple text property list files that change the appearance of Window Maker. They have the same layout as the Defaults/WindowMaker file. Whatever settings are in the style file will be applied to the Defaults/WindowMaker file. Here is an example style that gives Window Maker a blue and gray Arch Linux like look:

Styles can also be edited by using the Preferences Utility application.

Window Maker (git HEAD) has rudimentary HiDPI support (WMScaleX/WMScaleY) that scales Window elements according to the metrics of the default font. Open Defaults/WMGLOBAL and multiply the DefaultFontSize value by your current scale factor, i.e. DPI divided by 96.

Window Maker allows keyboard shortcuts to be assigned both to window manager actions and to menu entries.

To assign a keyboard shortcut to a window manager action, start the WPrefs application and navigate to the Keyboard Shortcut Preferences tab. Choose an action, click the Capture button and hit the desired keyboard combination. Then click Save.

You can also assign keyboard shortcuts to menu entries. For instance, if one wishes to use GNOME Screensaver to lock the screen, one could create a Lock Screen menu entry which runs the command gnome-screensaver-command --lock. To then assign a keyboard shortcut to this menu entry, start the WPrefs application and navigate to the Applications Menu Definition tab. In the root menu that appears on screen, click on the Lock Screen entry. In the WPrefs window, click the Capture button, hit the desired keyboard combination and then click Save.

To use an image as a background in Window Maker, copy the image to the ~/GNUstep/Library/WindowMaker/Backgrounds directory. Then, from the root menu, select Appearance -> Background -> Images -> image-name.

Alternatively, use a standalone background setter such as Nitrogen.

The user interface of macOS evolved from the style of user interface that Window Maker uses. There is a "dock" that contains applications icons that are "pinned" to the dock by the user. Also, the dock can hold special small applications called "dockapps", which run only inside the dock. By default, all applications run in Window Maker will have an application icon, which you can use to run a new instance of the application, hide and unhide all windows of the application, or kill the application. The application icon does not represent a window. Instead, if you minimize a window, a small icon representing the window will appear on the desktop.

After starting any application, (for example, from the command line) the application icon will appear on the desktop. You can pin it to the dock by clicking and dragging the icon into the dock area. To remove the application icon from the dock, click and drag the icon away from the dock area. You change settings, such as making an application automatically start when Window Maker starts, by right clicking on the application icon in the dock.

The default action to activate application icons and window icons is to double click them. You can change a setting to allow you to activate them with a single click.

The "clip" is a button that has the image of a paperclip on it. You can change the name of the current workspace by right clicking on the clip. You can change workspaces by clicking the arrows that are on the clip.

The clip also has similar functionality to the dock. Application icons that are added to the dock are visible on all workspaces, while application icons that are attached to the clip are only seen on the workspace where they are attached. This allows you to conveniently associate specific application icons with specific workspaces.

Double click the clip to hide and unhide the application icons that are attached to it.

Dockapps are small applications that run in the dock. They can be useful for showing system information. Some useful dockapps include:

See the Window Maker website for more information about dockapps.

Window Maker does not ship with a system tray; however, a number of standalone trays can be used with it.

Since version 0.8 of stalonetray, basic dockapp support for Window Maker can be enabled using the --dockapp-mode wmaker command line option. The following options should also be used: --slot-size 32 --geometry 2x2 --parent-bg --scrollbars none.

tint2 is compatible with Window Maker. As well as a system tray it has an optional taskbar (duplicating the Window Maker feature) and applets showing the clock and the status of the battery.

wmsystemtrayAUR is a system tray dockapp designed for Window Maker and reported to work well in other desktops.

PeksystrayAUR is a system tray designed for the light window managers that support docking. Peksystray provides a window where icons will automatically add up, according to the requests from the applications. Both the size of the window and the size of the icons can be selected by the user. If the window is full, it can automatically display another window in order to display more icons.

For some applications, you may not want Window Maker to display an application icon or appicon. To disable the appicon for an application, right click on the application's titlebar and choose Attributes... and from the drop down menu choose Application Specific. Tick the No application icon option and then hit Apply and Save.

Delete (but keep a backup) the ~/.fontconfig/ directory and ~/.fonts.conf file, then restart Window Maker.

To correct this issue, right click on any pinned application and, from the Dock position submenu, choose Normal. Then start the WPrefs tool. Under the Window Handling Preferences tab, tick the ...do not cover dock option. This will ensure that maximised applications do not cover the dock but that fullscreen applications do.

Some applications such as Chromium will not display an application icon. For a workaround involving Chromium, see the following bug report.

If you find that window attributes that you have saved for a certain window are not persistent, this is probably because you are trying to override hints set by the application itself that change the way the window manager treats the window. For instance, a window might set a Motif hint requesting that the window manager does not decorate the window with a titlebar. However, when you untick the Disable titlebar option and hit Save in Window Attributes, you find that the window does not have a titlebar when it is next launched.

This problem arises because Window Maker will only write window settings to the settings file that it considers to be non-default. However, Window Maker will not update what it considers to be a default setting to take into account window hints. So for a window that has no titlebar, hitting the Save button after unticking Disable titlebar will do nothing because Window Maker incorrectly considers that to already be the default setting.

To work around this, open the Window Attributes dialogue for the window in question and, without making any changes whatsoever, hit the Save button. This will write the hint set settings that Window Maker considers to be non-default to file. Then, open ~/GNUstep/Defaults/WMWindowAttributes in a text editor and you should find the settings in question for that window written there. You can now change them to your preferred values, for instance: change NoTitlebar = Yes; to NoTitlebar = No;

**Examples:**

Example 1 (unknown):
```unknown
GNUSTEP_USER_ROOT
```

Example 2 (unknown):
```unknown
Preferences Utility
```

Example 3 (unknown):
```unknown
Defaults/WindowMaker
```

Example 4 (unknown):
```unknown
Defaults/WMGLOBAL
```

---

## User:Schard

**URL:** https://wiki.archlinux.org/title/User:Schard

Born in the late '80s, working as systems administrator and web developer (I do full-stack but my strengths lie on the back-end).

I love music. Mostly Alternative Rock and Irish Folk, but also some Classic and Metal. I also play bass guitar and piano.

I use Arch Linux as my daily driver, both at work and at home. I also maintain a few packages in the AUR.

---

## Arch package guidelines/Security

**URL:** https://wiki.archlinux.org/title/Arch_package_guidelines/Security

**Contents:**
- Usage
- RELRO
  - Haskell
  - Go
- Stack canary
- NX
  - C/C++
- PIE
  - C/C++
  - Golang

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

This page describes security packaging guidelines for Arch Linux packages. For C/C++ projects the compiler and linker can apply security hardening options. Arch Linux applies PIE, FORTIFY_SOURCE, stack protector, nx and relro by default.

Hardening protections can be reviewed by running checksec.

RELRO is a generic mitigation technique to harden the data sections of an ELF binary/process. When a program is loaded several ELF memory sections need to be written to by the linker but can be turned read-only before turning control over to the program. This prevents attackers of overriding some ELF sections. There are two different RELRO modes:

If an application reports partial relro, investigate if the build toolchain passes our LDFLAGS or allows overriding LDFLAGS. For Go packages investigate if the build method uses build.go as pure golang Makefile replacement which does not allow passing of LDFLAGS.

For Haskell it is not clear how to achieve Full RELRO at the moment.

See Go package guidelines#Flags and build options.

A stack canary is added by the compiler between the buffer and control data on the stack. If this well known value is corrupted, a buffer overflow occurred and the running program segfaults to prevent possible arbitrary code execution.

The gcc package has it enabled stack protection by default with the --enable-default-ssp compile option.

Executable-space protection marks memory regions as non-executable, such that an attempt to execute machine code in these regions will cause an exception. It makes use of hardware features such as the NX bit (no-execute bit), or in some cases software emulation of those features.

The gcc package has it enabled by default for C/C++ with --enable-default-pie.

Pass the following flags to go build:

Pass the following flag to runhaskell Setup.hs configure:

RUNPATH/RPATH provides further search paths for the object it is listed in (it can be used both for executable and for shared objects).

If the RPATH value contains a path within an attackers control it can possibly execute code by installing a malicious library in that directory for example CVE-2006-1566 CVE-2005-4280. See Debian:RpathIssue.

The RPATH entry is set by the linker by passing for example the following string to LDFLAGS -Wl,-rpath -Wl,/usr/local/lib. To make an RUNPATH entry append --enable-new-dtags to the linker flags.

Fortify source is a macro that adds buffer overflow protection in various functions that perform operations on memory and strings. It checks whether an attacker tries to copy more bytes to overflow a buffer and then stops the execution of the program. This protection is enabled with the default CPPFLAGS:

See makepkg#Configuration.

This article or section is a candidate for moving to systemd/Sandboxing.

If a systemd service file is shipped with the package due to upstream not providing any, look into applying the following systemd service hardening features. Systemd provides a way to analyse security features which are enabled for a service.

A service can be hardened by restricting file system access.

Set up a new file system namespace for the executed process and mounts private /tmp and var/tmp directories inside it that is not shared by processes outside the namespace. Useful for programs which write data to /tmp.

ProtectSystem has three different varieties of mounting directories as read-only for the executed process. The "full" option mounts /usr, /boot and /etc read only. ProtectHome makes /home, /root and /run/user inaccessible to the executed process.

Sets up a new /dev namespace for the executed process and only adds API pseudo devices such as /dev/null, /dev/zero or /dev/random, but not for physical devices or system memory, system ports and others. This is useful to secure the execute process from writing directly to physical devices, systemd also adds a system call filter for calls within the @raw-io set.

These options make the executed process unable to change kernel variables accessible through /proc/sys, /sys, etc. ProtectControlGroups makes the /sys/fs/cgroup hierarchy read-only.

Making file paths inaccessible can be done as following:

More detailed information can be found in systemd.exec(5).

Ensure that the executed process and its children can never gain new privileges through execve(2).

Prohibit attempts to create memory mappings that are both writable and executable, to change mappings to be executable or to create executable shared memory. This sandboxes a process against allowing an attacker to write in to memory which is also executed. Note that enabling this is not compatible with all applications which rely on a JIT.

Locks down the personality(2) system call so that the kernel execution domain can not be changed.

System calls can be restricted in a service as well, systemd can display syscalls to filter on:

Predefined groups are available, e.g. to use the recommended starting point for whitelisting system calls for system services use:

System calls can be restricted by their architecture such as to prevent 32-bit binaries from executing on 64-bit machines (no non-native binaries):

If the running process does not require any network access it can be fully disabled by setting up a new network namespace for the process and only configuration a loopback interface.

If network is required, the type of address families used can be restricted for the socket(2) system call by for example only allowing UNIX sockets.

For when only network to localhost or specific IP ranges is required a process can be restricted by only allowing network access to localhost.

More information about network filtering can be found in systemd.resource-control(5).

Sets up a new UTS namespace for the execute process and disallows changing the hostname or domainname.

**Examples:**

Example 1 (unknown):
```unknown
$ checksec --file=/usr/bin/cat
```

Example 2 (unknown):
```unknown
-Wl,-z,relro
```

Example 3 (unknown):
```unknown
export GOFLAGS='-buildmode=pie'
export CGO_CPPFLAGS="-D_FORTIFY_SOURCE=3"
export CGO_LDFLAGS="-Wl,-z,relro,-z,now"
```

Example 4 (unknown):
```unknown
runhaskell Setup.hs configure
```

---

## Package Maintainer guidelines

**URL:** https://wiki.archlinux.org/title/Package_Maintainer_guidelines

**Contents:**
- TODO list for new Package Maintainers
  - Junior maintainership
- The Package Maintainer and the AUR
  - Rewriting git history
  - Handling AUR requests
- The Package Maintainer and extra, guidelines for package maintenance
  - Rules for packages entering the extra repository
  - Accessing and updating the repository
  - Disowning packages
  - Moving packages from the AUR to extra

Package Maintainers are Arch Linux staff members charged with keeping the AUR in working order. They maintain popular packages (communicating with and sending patches upstream as needed), and vote in administrative matters. A Package Maintainer is elected from active community members by current Package Maintainers in a democratic process. Package Maintainers are the only members who have a final say in the direction of the AUR.

The Package Maintainers are governed using the Package Maintainer bylaws

Since the ratification of RFC 0014, new Package Maintainers will be marked as "junior" for their first two months of packaging. During this time, the new Package Maintainer may only push to the extra-testing repository. Your sponsors can review your packages as-needed and move them to extra.

The Package Maintainers should also make an effort to check package submissions in the AUR for malicious code and good PKGBUILDing standards. In around 80% of cases the PKGBUILDs in the AUR are very simple and can be quickly checked for sanity and malicious code by the Package Maintainer team.

Package Maintainers should also check PKGBUILDs for minor mistakes, suggest corrections and improvements. The Package Maintainer should endeavor to confirm that all packages follow the Arch Packaging Guidelines/Standards and in doing so share their skills with other package builders in an effort to raise the standard of package building across the distribution.

Package Maintainers are also in an excellent position to document recommended practices.

In some cases rewriting the history of an AUR repository is required, for example when a user inadvertently uses their legal name in a published commit. This can be automated with git-filter-branch(1).

To force push the new history, forward the AUR_OVERWRITE=1 environment variable to git-push(1).

In detail this includes adding SendEnv AUR_OVERWRITE to your AUR SSH config and setting the env var on your push command: AUR_OVERWRITE=1 git push --force. See [1] for details.

Install git-filter-repo and run:

Alternatively, use git filter-branch --env-filter with the GIT_AUTHOR_NAME, GIT_AUTHOR_EMAIL, GIT_COMMITTER_NAME and GIT_COMMITTER_EMAIL environment variables. For example:

This article or section needs expansion.

Package Maintainers should periodically check the requests filed on the AUR. For that there are some generic rules what to check for each request type:

If all of the above points are true then you can accept the Orphan Request.

The factual accuracy of this article or section is disputed.

See the packager guide.

If a Package Maintainer cannot or does not want to maintain a package any longer, a notice should be posted to the AUR Mailing List, so another package maintainer can maintain it. A package can still be disowned even if no other Package Maintainer wants to maintain it, but the Package Maintainers should try not to drop many packages (they should not take on more than they have time for). If a package has become obsolete or is not used any longer, it can be removed completely as well.

If a package has been removed completely, it can be uploaded once again (fresh) to the AUR, where a regular user can maintain the package instead of the Package Maintainer.

Follow the normal procedures for adding a package to extra using the instructions in the packager guide, but remember to delete the corresponding package from the AUR!

Remove the package using the instructions in the packager guide and upload your source to the AUR.

Move the package from the extra-testing to the extra repository using the instructions in the packager guide.

Package Maintainers and Developers can connect to build.archlinux.org via SSH to, among others, build packages using the devtools. This has numerous advantages over a local setup:

The process is similar to that of a local setup with devtools. Your GnuPG private is required for signing but you do not want to upload it for obvious security reasons. As such, you will need to forward the GnuPG agent socket from your local machine to the server: this will allow you to sign packages on the build server without communicating your key. This also means that we need to disable the agent on the server before we can run anything.

First, connect to build.archlinux.org and disable

Make sure gpg-agent is not running (systemctl --user stop gpg-agent.service). At this point, make sure that no sockets exist in the folder pointed by gpgconf --list-dir socketdir. If they do, remove them or log out and in again. If you have a custom $GNUPGHOME (eg. to move it to ~/.config/gnupg), you will need to unset that, as it is not possible in gnupg to set the homedir without setting the socketdir. On build.archlinux.org, StreamLocalBindUnlink yes is set in sshd_config, therefore removing the sockets manually on logout is not necessary.

While the PGP private keys remain on your local machine, the public keys must be on the build server. Export your public ring to the build server, e.g. from you local machine

SSH is required to checkout and commit to the Git repository. You can either set up a new SSH key pair on the server (it is highly discouraged to put your local private key on a server for security reasons) or reuse your local keys via socket forwarding. If you opt for the latter, make sure to disable ssh-agent on the build server if you had enabled it previously (it is not running by default).

Configure you build environment on the build server:

Disable passphrase caching with the following settings:

Because we will want to keep our usual GPG agent running with its current settings, we are going to run another GPG agent dedicated to the task at hand. Create a ~/.gnupg-archlinux folder and symlink everything from ~/.gnupg there, except ~/.gnupg/gpg-agent.conf. Configure the new GPG agent:

The gpg-agent-extra.socket will be forwarded to build.archlinux.org.

Start the dedicated agent with

or, if using GnuPG as your SSH agent:

Replace REMOTE_UID and LOCAL_UID by your user identifier as returned by id -u on the build server and locally, respectively. If using ssh-agent, replace REMOTE_SSH_AUTH_SOCK by the path to the SSH socket on the remote host (it can be anything).

You can make the forwarding permanent for that host. For instance with gpg-agent.ssh:

Again, replace REMOTE_UID with the user UID on the build server.

From then on, the procedure should be exactly the same as a local build:

When a Package Maintainer resigns the following list has be followed, these steps do not apply when a Package Maintainer resigns but is still a Developer.

**Examples:**

Example 1 (unknown):
```unknown
@archlinux/package-maintainer/username
```

Example 2 (unknown):
```unknown
@archlinux.org
```

Example 3 (unknown):
```unknown
username@archlinux.org
```

Example 4 (unknown):
```unknown
@archlinux.org
```

---

## pacman/Tips and tricks

**URL:** https://wiki.archlinux.org/title/Pacman_tips

**Contents:**
- Maintenance
  - Listing packages
    - In unused repositories
    - With version
    - With size
      - Individual packages
      - Packages and dependencies
    - By date
    - Not in a specified group, repository or meta package
    - Development packages

For general methods to improve the flexibility of the provided tips or pacman itself, see Core utilities and Bash.

See also System maintenance.

By default, repositories listed in pacman.conf are used for syncing, searching, installing and upgrading from them. This can be changed for more versatility, for example by using some repositories only for searching in them[1]:

See pacman.conf(5) § REPOSITORY SECTIONS.

You may want to get the list of installed packages with their version, which is useful when reporting bugs or discussing installed packages.

Figuring out which packages are largest can be useful when trying to free space on your hard drive. There are two options here: get the size of individual packages, or get the size of packages and their dependencies.

The following command will list all installed packages and their individual sizes:

To list package sizes with their dependencies,

To list the download size of several packages (leave packages blank to list all packages):

To list explicitly installed packages not in the meta package base nor package group xorg with size and description:

To list the packages marked for upgrade with their download size:

To list optional dependencies only:

To list the 20 last installed packages with expac, run:

or, with seconds since the epoch (1970-01-01 UTC):

List explicitly installed packages not in the base meta package:

List explicitly installed packages not in the base meta package or xorg package group:

List all installed packages unrequired by other packages, and which are not in the base meta package or xorg package group:

As above, but with descriptions:

List all installed packages that are not in the specified repository repo_name (multiple repositories can be checked at once):

List all installed packages that are in the repo_name repository (multiple repositories can be checked at once):

List all packages on the Arch Linux ISO that are not in the base meta package:

To list all development/unstable packages, run:

To obtain the list of the dependencies of a package, the simplest solution is reading the output of:

For automation, instead of the error-prone method of parsing pacman output, use expac:

To list explicitly-installed packages with their optional dependencies, run:

Alternatively, with expac:

To list them while omitting optional dependencies you have already installed, run:

To browse all installed packages with an instant preview of each package:

This uses fzf to present a two-pane view listing all packages with package info shown on the right.

Enter letters to filter the list of packages; use arrow keys (or Ctrl-j/Ctrl-k) to navigate; press Enter to see package info under less.

To browse all packages currently known to pacman (both installed and not yet installed) in a similar way, using fzf, use:

The navigational keybindings are the same, although Enter will not work in the same way.

This one might come in handy if you have found that a specific package uses a huge amount of space and you want to find out which files make up the most of that.

If your system has stray files not owned by any package (a common case if you do not use the package manager to install software), you may want to find such files in order to clean them up.

One method is to list all files of interest and check them against pacman:

Most systems will slowly collect several ghost files such as state files, logs, indexes, etc. through the course of usual operation.

pacreport from pacutils can be used to track these files and their associations via /etc/pacreport.conf (see pacreport(1) § FILES).

An example may look something like this (abridged):

Then, when using pacreport --unowned-files as the root user, any unowned files will be listed if the associated package is no longer installed (or if any new files have been created).

Additionally, aconfmgr (aconfmgr-gitAUR) allows tracking modified and orphaned files using a configuration script.

Orphans are packages that were installed as a dependency and are no longer required by any package.

They can accumulate on your system over time either due to uninstalling packages using pacman -R package instead of pacman -Rs package, installing packages as makedepends, or packages removing dependencies in newer versions.

For recursively removing orphans and their configuration files:

If no orphans were found, the output is error: argument '-' specified with empty stdin. This is expected as no arguments were passed to pacman -Rns. The error can be avoided by prefixing the second command with ifne(1) from the moreutils package.

If there is a package listed that you do not want to remove, it can be excluded from the list of orphans by marking it as explicitly installed:

In some cases the method above will not detect all possible unneeded packages. E.g. dependency cycles (also known as "circular dependencies"), excessive dependencies (fulfilled more than once), some non-explicit optionals etc.

To detect such packages:

If you want to remove all packages in the list at once, run the command without --print argument.

Sometimes there may be multiple packages providing same item. For example, there may be multiple packages which provide ttf-font. You may not want all such packages depending your preference.

To detect packages which provide same item:

Check the output and carefully remove redundant package which you do not require.

If it is ever necessary to remove all packages except the essentials packages, one method is to set the installation reason of the non-essential ones as dependency and then remove all unnecessary dependencies.

First, for all the packages "explicitly installed", change their installation reason to "installed as a dependency":

Then, change the installation reason to "explicitly installed" of only the essential packages, those you do not want to remove, in order to avoid targeting them:

Finally, follow the instructions in #Removing unused packages (orphans) to remove all packages that are "installed as a dependency".

Dependencies are alphabetically sorted and doubles are removed.

Alternatively, with expac:

To list configuration files tracked by pacman as susceptible of containing user changes (i.e. files listed in the PKGBUILD backup array) and having received user modifications, use the following command:

Running this command with root permissions will ensure that files readable only by root (such as /etc/sudoers) are included in the output.

This can be used when doing a selective system backup or when trying to replicate a system configuration from one machine to another.

The following command can be used to back up the local pacman database:

Store the backup pacman database file on one or more offline media, such as a USB stick, external hard drive, or CD-R.

The database can be restored by moving the pacman_database.tar.bz2 file into the / directory and executing the following command:

When maintainers update packages, commits are often commented in a useful fashion. Users can quickly check these from the command line by installing pacologAUR. This utility lists recent commit messages for packages from the official repositories or the AUR, by using pacolog package.

Alternative ways of getting and restoring packages.

This article or section is a candidate for merging with #Custom local repository.

To download packages, or groups of packages:

Pacman, which will reference the host installation by default, will not properly resolve and download existing dependencies. In cases where all packages and dependencies are wanted, it is recommended to create a temporary blank DB and reference it with --dbpath:

Then you can burn the "Packages" directory to an optical disc (e.g. CD, DVD) or transfer it to a USB flash drive, external HDD, etc.

For an optical disc drive:

For a USB flash drive, hard disk drive, etc.:

2. Edit pacman.conf and add this repository before the other ones (e.g. extra, core, etc.). This is important. Do not just uncomment the one on the bottom. This way it ensures that the files from the CD/DVD/USB take precedence over those in the standard repositories:

3. Finally, synchronize the pacman database to be able to use the new repository:

Use the repo-add script included with pacman to generate a database for a personal repository. Use repo-add --help for more details on its usage. A package database is a tar file, optionally compressed. Valid extensions are .db or .files followed by an archive extension of .tar, .tar.gz, .tar.bz2, .tar.xz, .tar.zst, or .tar.Z. The file does not need to exist, but all parent directories must exist.

To add a new package to the database, or to replace the old version of an existing package in the database, run:

The database and the packages do not need to be in the same directory when using repo-add, but keep in mind that when using pacman with that database, they should be together. Storing all the built packages to be included in the repository in one directory also allows to use shell glob expansion to add or update multiple packages at once:

If you are looking to support multiple architectures then precautions should be taken to prevent errors from occurring. Each architecture should have its own directory tree:

The repo-add executable checks if the package is appropriate. If this is not the case you will be running into error messages similar to this:

repo-remove is used to remove packages from the package database, except that only package names are specified on the command line.

Once the local repository database has been created, add the repository to pacman.conf for each system that is to use the repository. An example of a custom repository is in pacman.conf. The repository's name is the database filename with the file extension omitted. In the case of the example above the repository's name would simply be repo. Reference the repository's location using a file:// URL, or via HTTP using http://localhost/path/to/directory.

If willing, add the custom repository to the list of unofficial user repositories, so that the community can benefit from it.

See Package proxy cache.

To recreate a package from the file system, use fakepkgAUR. Files from the system are taken as they are, hence any modifications will be present in the assembled package. Distributing the recreated package is therefore discouraged; see ABS and Arch Linux Archive for alternatives.

Keeping a list of all explicitly installed packages can be useful to backup a system or quicken the installation of a new one:

To keep an up-to-date list of explicitly installed packages (e.g. in combination with a versioned /etc/), you can set up a hook. Example:

To install packages from a previously saved list of packages, while not reinstalling previously installed packages that are already up-to-date, run:

However, it is likely foreign packages such as from the AUR or installed locally are present in the list. To filter out from the list the foreign packages, the previous command line can be enriched as follows:

Eventually, to make sure the installed packages of your system match the list and remove all the packages that are not mentioned in it:

If you are suspecting file corruption (e.g. by software/hardware failure), but are unsure if files were corrupted, you might want to compare with the hash sums in the packages. This can be done with pacutils:

For recovery of the database see #Restore pacman's local database. The mtree files can also be extracted as .MTREE from the respective package files.

To reinstall all native packages, use:

Foreign (AUR) packages must be reinstalled separately; you can list them with pacman -Qqm.

Pacman preserves the installation reason by default.

See pacman/Restore local database.

If you have managed to mess up an Arch install with broken packages, it is possible to re-install all the packages and hopefully get it back up and working again (assuming the root of the broken install is mounted in /brokenArch)

paccat is a small utility that finds which package contains a given file, downloads it and then prints the contents. This can be used to read specific files, restore changed files back to their initial state, and extract files without installing the package.

For example, if you want to see the contents of /etc/systemd/logind.conf supplied within the systemd package:

Or if you want to see the contents of archive.h supplied by any package:

bsdtar can also be used to show the contents:

Or you can use vim to browse the archive:

Already running processes do not automatically notice changes caused by updates. Instead, they continue using old library versions. That may be undesirable, due to potential issues related to security vulnerabilities or other bugs, and version incompatibility.

Processes depending on updated libraries may be found using either htop, which highlights the names of the affected programs, or with a snippet based on lsof, which also prints the names of the libraries:

This solution will only detect files, that are normally kept opened by running processes, which basically limits it to shared libraries (.so files). It may miss some dependencies, like those of Java or Python applications.

Many packages install documentation and translations in several languages. Some programs are designed to remove such unnecessary files, such as localepurgeAUR, which runs after a package is installed to delete the unneeded locale files. A more preemptive approach is provided through the NoExtract directive in /etc/pacman.conf, which prevent these files from ever being installed.

To prevent the installation of all translations for help files, except for the C locale, add:

To prevent the installation of all the HTML documentation, add:

To prevent the installation of the various locales, except the required ones, add:

To prevent the installation of the translated man pages, add:

To prevent the installation of the language files in vim-runtime, add:

To prevent the installation of all but English content in Qt applications, add:

To prevent the installation of all but English content in Chromium and Electron applications, add:

To prevent the installation of English help files in LibreOffice, add:

To prevent the installation of all but English content from OnlyOffice, add:

To prevent the installation of all but the English iBus dictionary for emojis, add:

When trying to install a package from a bad connection (e.g. a train using a cell phone), use the --disable-download-timeout option to lessen the chance of receiving errors such as:

When downloading packages pacman uses the mirrors in the order they are in /etc/pacman.d/mirrorlist. The mirror which is at the top of the list by default however may not be the fastest for you. To select a faster mirror, see Mirrors.

Pacman's speed in downloading packages can also be improved by using parallel downloads, a major feature request (FS#20056) added with pacman 6.0.0. It is enabled by default since pacman 7.0.0.

Instead of pacman's built-in file downloader, a separate application can also be used to download packages.

In all cases, make sure you have the latest pacman before doing any modifications.

Powerpill is a pacman wrapper that uses parallel and segmented downloading to try to speed up downloads for pacman.

This is also very handy if you need more powerful proxy settings than pacman's built-in capabilities.

To use wget, first install the wget package then modify /etc/pacman.conf by uncommenting the following line in the [options] section:

Instead of uncommenting the wget parameters in /etc/pacman.conf, you can also modify the wget configuration file directly (the system-wide file is /etc/wgetrc, per user files are $HOME/.wgetrc).

aria2 is a lightweight download utility with support for resumable and segmented HTTP/HTTPS and FTP downloads. aria2 allows for multiple and simultaneous HTTP/HTTPS and FTP connections to an Arch mirror, which should result in an increase in download speeds for both file and package retrieval.

Install aria2, then edit /etc/pacman.conf by adding the following line to the [options] section:

See aria2c(1) § OPTIONS for used aria2c options.

There are other downloading applications that you can use with pacman. Here they are, and their associated XferCommand settings:

**Examples:**

Example 1 (unknown):
```unknown
pacman.conf
```

Example 2 (unknown):
```unknown
/etc/pacman.conf
```

Example 3 (unknown):
```unknown
...
[multilib]
Usage = Sync Search
...
```

Example 4 (unknown):
```unknown
pacman -Sg group
```

---

## Liri

**URL:** https://wiki.archlinux.org/title/Liri

**Contents:**
- Installation
- Starting the desktop
  - Run with a graphical login manager
  - Run from a tty
  - Run with systemd user session
- See also

Liri is a desktop environment with modern design and features. Liri is the merge between Hawaii, Papyros and the Liri Project.

Install the meta package liri-git-metaAUR to get all the LiriOS ecosystem.

Alternatively, it could be installed using flatpak. See Flatpak instructions in LiriOS Download page.

Login managers that support Wayland such as SDDM and GDM can run a Liri session.

Log in to a tty and type:

The session manager automatically detects the hardware and will run the compositor accordingly.

However the mode can be forced, for example to force nested mode and run inside Weston:

First you need to setup D-Bus with systemd user session as explained in systemd/User. Then enable the liri.service user unit.

Every time you want to start a Liri session:

logind integration is known not to work with systemd user session at the moment, hence some features might not be working. systemd user session is pretty new and the developers are testing Liri with it.

**Examples:**

Example 1 (unknown):
```unknown
$ liri-session
```

Example 2 (unknown):
```unknown
$ liri-session -platform wayland
```

Example 3 (unknown):
```unknown
liri.service
```

Example 4 (unknown):
```unknown
$ systemctl --user isolate liri.target
```

---

## Web application package guidelines

**URL:** https://wiki.archlinux.org/title/Web_application_package_guidelines

**Contents:**
- Separate user
- Directory structure

The factual accuracy of this article or section is disputed.

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

This page describes how to package web applications.

For security reasons, every web application should be run as a separate (unprivileged) user (i.e. $pkgname).

Refer to the systemd-sysusers(8), sysusers.d(5), systemd-tmpfiles(8) and tmpfiles.d(5) man pages for details on how to create users and deal with ownership of files and folders for that user in a package.

The layout follows the FHS.

**Examples:**

Example 1 (unknown):
```unknown
/usr/share/$pkgname
```

Example 2 (unknown):
```unknown
/etc/$pkgname
```

Example 3 (unknown):
```unknown
/run/$pkgname
```

Example 4 (unknown):
```unknown
/var/cache/$pkgname
```

---

## Arch Linux Archive

**URL:** https://wiki.archlinux.org/title/Arch_Linux_Archive

**Contents:**
- Location
- Directories
  - /repos
  - /packages
  - /iso
- Frequently asked questions
  - How to downgrade one package
  - How to restore all packages to a specific date
- Historical Archive
  - Finding packages in the Historical Archive

The Arch Linux Archive (a.k.a. ALA), formerly known as Arch Linux Rollback Machine (a.k.a. ARM), stores official repositories snapshots, iso images and bootstrap tarballs across time.

Packages are only kept for a few years, afterwards they are moved to the Arch Linux Historical Archive on archive.org.

The Arch Linux Archive is available at https://archive.archlinux.org/ and mirrors around the globe.

The source code is also available for setting up your own mirror.

The Archive is split into 3 main directories detailed below.

The repos directory contains daily snapshots of official mirror organized by date like in the following example.

Note: The last 3 special directories (last, week and month) which links respectively to the last synced repository, to the last Monday and to the first of the current month.

The packages directory contains all versions of each package with their signatures. One directory by package and package directories are grouped by their first letter.

You can use the magic subdirectory .all to access all packages by their name. It acts as a flat directory containing all versions of every package.

You can download the full package list (there are over a hundred thousand packages) as a compressed index: index.0.xz.

The iso directory contains official ISO images and bootstrap tarballs sorted by release date.

Find the package you want under /packages and let pacman fetch it for installation. For example:

Letting pacman fetch it will automatically download the package's detached .sig file and verify it according to /etc/pacman.conf settings.

Alternatively, download and install the package manually using pacman -U.

See also Downgrading packages#Automation for tools that simplify the process.

To restore all packages to their version at a specific date, let us say 30 March 2014, you have to direct pacman to this date, by editing your /etc/pacman.conf and use the following server directive:

or by replacing your /etc/pacman.d/mirrorlist with the following content:

Then update the database and force downgrade:

If you get errors complaining about corrupted/invalid packages due to PGP signature, try to first update separately archlinux-keyring and ca-certificates. Alternatively, you can decide to temporarily disable signature checking altogether.

Maintaining the Arch Linux Archive consumes significant amount of resources, so old packages are cleaned up from time to time.

Before removing them, old packages are uploaded to a dedicated collection "Arch Linux Historical Archive" on archive.org.

The Historical Archive does not provide a way to access a "snapshot" of Arch packages at a given point in time. However, there is a redirection on archive.archlinux.org so that downloads for old packages are redirected to the Historical Archive on archive.org. There should be no visible impact from the user side, except from the fact that archive.org is generally quite slow for downloading.

The Arch Linux Historical Archive collection has an index of all packages: https://archive.org/details/archlinuxarchive

It is also possible to directly access a package by its identifier. The general pattern for identifiers is archlinux_pkg_sanitized_package_name.

To obtain the sanitized package name, simply replace any @, + or . character in the package name by an underscore _.

For instance, the identifier for lucene++ is archlinux_pkg_lucene__.

You can then access the details page of a package via its identifier, for instance: https://archive.org/details/archlinux_pkg_lucene__.

It is also possible to run searches with the archive.org Python client:

All available package versions (and their signature) can be accessed via the download page of a package: https://archive.org/download/archlinux_pkg_lucene__.

To download, verify and install a package using pacman:

Package verification is controlled by pacman's RemoteFileSigLevel option. Note that if you use pacman, you have to figure out the dependencies yourself.

It is also possible to use the archive.org Python client.

Download a specific version of a package:

Download all x86_64 versions of a package, with signatures:

**Examples:**

Example 1 (unknown):
```unknown
├── iso
├── packages
└── repos
```

Example 2 (unknown):
```unknown
repos
├── 2013
│   ├── 08
│   │   └── 31
│   │       ├── community
│   │       ├── community-staging
│   │       ├── community-testing
│   │       ├── core
│   │       ├── extra
│   │       ├── gnome-unstable
│   │       ├── kde-unstable
│   │       ├── lastsync
│   │       ├── multilib
│   │       ├── multilib-staging
│   │       ├── multilib-testing
│   │       ├── pool
│   │       ├── staging
│   │       └── testing
│   ├── 09
│   │   ├── 01
│   │   ├── 02
│   │   ├── ...
│   │   ├── 21
│   │   └── 22
│   ├── 10
│   │   ├── 01
│   │   ├── 02
│   │   ├── ...
│   │
│   ├── 11
│   └── 12
├── 2014
│   ├── 01
│   │   ├── 01
│   │   ├── 02
│   │   ├── ...
│   │
│   ├── 02
│   ├── 03
│   ├── ...
│   └── 09
│       ├── 01
│       ├── ...
│       └── 28
├── last
├── month
└── week
```

Example 3 (unknown):
```unknown
├── packages
│   ├── a
│   │   ├── awesome
│   │   │   ├── awesome-4.3-2-x86_64.pkg.tar.zst
│   │   │   ├── awesome-4.3-2-x86_64.pkg.tar.zst.sig
│   │   │   ├── awesome-4.3-3-x86_64.pkg.tar.zst
│   │   │   ├── awesome-4.3-3-x86_64.pkg.tar.zst.sig
│   │   │   ├── ...
│   │   │
│   │   ├── ...
│   │   ├── awstats
│   │   └── axel
│   │   
│   ├── b
│   ├── ...
│   └── z
```

Example 4 (unknown):
```unknown
├── packages
│   ├── .all
│   │   ├── awesome-4.3-2-x86_64.pkg.tar.zst
│   │   ├── ...
│   │   ├── zsh-5.8-1-x86_64.pkg.tar.zst
│   │   ├── zsh-5.8.1-1-x86_64.pkg.tar.zst
│   │   └── ...
```

---

## MinGW package guidelines

**URL:** https://wiki.archlinux.org/title/MinGW_package_guidelines

**Contents:**
- Package naming
- Packaging
- Examples
  - Autotools
  - CMake

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

This page explains how to write PKGBUILDs for software running on Windows.

In order to build software for Windows on Linux one needs:

For ix86/x86_64 the typical choice is to use mingw-w64- with GCC/libstdc++ and binutils. This is therefore what AUR packages following the package naming mingw-w64-pkgname use. The rest of this Wiki page focuses on those packages.

There are also AUR packages named llvm-mingw-w64-pkgname that use LLVM/Clang/libc++ and support aarch64 besides just i686 and x86_64. Those packages rely on builds from https://github.com/mstorsjo/llvm-mingw and do not utilize LLVM/Clang provided by Arch Linux. Only a few core packages exist.

There are also packages named mingw-w64-clang-arch-pkgname provided by https://github.com/Martchus/PKGBUILDs. Those packages use llvm, lld and clang as provided by Arch Linux and only provide mingw-w64, the LLVM compiler runtime and libc++ on top of that. Those packages so far only exist for the aarch64 target. They are mainly generated from mingw-w64-pkgname AUR packages via a conversion script to be able to provide more than just the core toolchain without much extra effort. Over 100 mingw-w64-pkgname packages have been converted into mingw-w64-clang-aarch64-pkgname packages so far. They have not been uploaded to the AUR yet as they are generated anyway but the generator and a binary repository can be found on the mentioned GitHub repository.

A package for mingw-w64 should be named mingw-w64-pkgname. If a static variant of the package is being built, suffix the package name with -static (see below for the cases where this is necessary).

Packaging for cross platform packages can be fairly tricky as there are many different build systems and low-level quirks. Take a note of the following things though:

As mentioned above, the files should all be installed into /usr/i686-w64-mingw32 and /usr/x86_64-w64-mingw32. Specifically, all DLLs should be put into /usr/*-w64-mingw32/bin as they are dynamic libraries needed at runtime. Their corresponding .dll.a files should go into /usr/*-w64-mingw32/lib. Please delete any unnecessary documentation and perhaps other files from /usr/share. Cross-compilations packages are not meant for the user but only for the compiler and binary distribution, and as such you should try to make them as small as possible.

Always try to match the pkgver in your mingw-w64 packages to the pkgver of the corresponding regular packages in the official Arch Linux repos (not the testing repos). This ensures that the cross-compiled software works exactly the same way on Windows without any unexpected bugs. If packages in Arch are out-of-date, there usually is a good reason and you should still follow the Arch version instead of using the most recent upstream release. If the corresponding native package is in the AUR, you need not follow this version policy, as many AUR packages are often orphaned or left unmaintained.

The following examples will try to cover some of the most common conventions and build systems.

**Examples:**

Example 1 (unknown):
```unknown
rustup target add x86_64-pc-windows-gnu
```

Example 2 (unknown):
```unknown
mingw-w64-pkgname
```

Example 3 (unknown):
```unknown
llvm-mingw-w64-pkgname
```

Example 4 (unknown):
```unknown
mingw-w64-clang-arch-pkgname
```

---

## Trinity

**URL:** https://wiki.archlinux.org/title/Trinity

**Contents:**
- Installation
  - Binary packages
  - Build from source
- Starting
  - Manually
  - Graphically
- Tips and tricks
  - Trinity "Kicker" panel with other desktop environments
- Troubleshooting
  - TDE Display Manager

From the Trinity Desktop Environment (TDE) project page:

TDE depends on End of Life libraries like Qt 3, which they maintain themselves.

The Trinity applications and applets should also work with other desktop environments.

Install either the tde-tdebase package from the trinity repository for a base Trinity environment, or tde-meta for a more complete one.

If you have any errors during an upgrade, add the 0x8685AD8B key by following pacman/Package signing#Adding unofficial keys.

Trinity Packaging repository contains PKGBUILD files for most Trinity packages in the "arch" folder.

The sources are in a git repository. More info on cloning it is at their GIT information page.

The suggested build order is specified in the How to Build TDE page.

To start Trinity from the Linux console:

tde-tdebase comes with TDE Display Manager. To start it at boot, enable the tdm.service.

To use the Trinity "kicker" Desktop Panel and Applets with another desktop environment, create this script and make it executable. For Plasma5, use System Settings > Startup and Shutdown > Autostart > Add Script.

If you encounter any issues, the default.target may have to be manually configured. See Display manager#Loading the display manager for resolution.

**Examples:**

Example 1 (unknown):
```unknown
$ startx /opt/trinity/bin/starttde
```

Example 2 (unknown):
```unknown
tdm.service
```

Example 3 (unknown):
```unknown
#!/bin/bash
/opt/trinity/bin/tdeinit
/opt/trinity/bin/kicker
/opt/trinity/bin/tdebuildsycoca --noincremental
```

Example 4 (unknown):
```unknown
default.target
```

---

## sSMTP

**URL:** https://wiki.archlinux.org/title/SSMTP

**Contents:**
- Installation
- Forward to a Gmail mail server
- Security
- Sending email
  - Attachments
  - Mail to Local Users
- See also

sSMTP is a program which delivers email from a local computer to a configured mailhost (mailhub). It is not a mail server (like feature-rich mail server sendmail) and does not receive mail, expand aliases or manage a queue. One of its primary uses is for forwarding automated email (like system alerts) off your machine and to an external email address.

Install the package ssmtpAUR.

This article or section is out of date.

To configure sSMTP, you will have to edit its configuration file (/etc/ssmtp/ssmtp.conf) and enter your account settings.

Create aliases for local usernames (optional)

To test whether the Gmail server will properly forward your email:

Change the 'From' text by editing /etc/passwd to receive mail from 'root at myhost' instead of just 'root'.

Which changes /etc/passwd to:

Because your email password is stored as cleartext in /etc/ssmtp/ssmtp.conf, it is important that this file is secure. By default, the entire /etc/ssmtp directory is accessible only by root and the mail group. The /usr/bin/ssmtp binary runs as the mail group and can read this file. There is no reason to add yourself or other users to the mail group.

To send email from the terminal, do:

An alternate method for sending emails is to create a text file and send it with ssmtp or mail

Send the test-mail.txt file

Some users might prefer the syntax of mail from s-nail, mailutils, or other mailx providers instead. For example, mail has options to provide the subject as an argument. mail requires sendmail and can use ssmtpAUR as sendmail.

If you need to be able to add attachments, install and configure Mutt and Msmtp and then go see the tip at nixcraft.

Alternatively, you can attach using uuencode from sharutils. To attach 'file.txt' as 'myfile.txt':

Messages sent to local users (or any other address not ending in @fqdn are treated in one of two ways

This can lead to problems if local users on your system are not also valid users at your rewriteDomain, but are receiving mail from system services, esp if your rewrite domain is a public service like gmail.com.

To work around this, you can use mail from s-nail. The mail command can read aliases defined in /etc/mail.rc. Example:

You can then pipe messages into mail instead of into sendmail.

**Examples:**

Example 1 (unknown):
```unknown
/etc/ssmtp/ssmtp.conf
```

Example 2 (unknown):
```unknown
/etc/ssmtp/ssmtp.conf
```

Example 3 (unknown):
```unknown
# The user that gets all the mails (UID < 1000, usually the admin)
root=username@gmail.com

# The mail server (where the mail is sent to), both port 465 or 587 should be acceptable
# See also https://support.google.com/mail/answer/78799
mailhub=smtp.gmail.com:465

# The address where the mail appears to come from for user authentication.
rewriteDomain=gmail.com

# The full hostname.  Must be correctly formed, fully qualified domain name or GMail will reject connection.
hostname=yourlocalhost.yourlocaldomain.tld

# Use implicit TLS (port 465). When using port 587, change UseSTARTTLS=Yes
TLS_CA_FILE=/etc/ssl/certs/ca-certificates.crt
UseTLS=Yes
UseSTARTTLS=No

# Username/Password
AuthUser=username
AuthPass=password
AuthMethod=LOGIN

# Email 'From header's can override the default domain?
FromLineOverride=yes
```

Example 4 (unknown):
```unknown
/etc/ssmtp/revaliases
```

---

## .SRCINFO

**URL:** https://wiki.archlinux.org/title/.SRCINFO

**Contents:**
- Generation
- Syntax
- Specification

.SRCINFO files (originally called .AURINFO) contain package metadata in a simple, unambiguous format, so that tools such as devtools, the Arch User Repository Web back-end or AUR helpers may retrieve a package metadata without parsing the PKGBUILD directly. See FS#25210, FS#15043, and FS#16394 for examples of the sorts of issues that may arise from attempting to parse shell scripts.

.SRCINFO files may be generated using makepkg:

.SRCINFO files are lists of key = value pairs, separated into sections.

Keys take their names and meanings from PKGBUILD variables; see PKGBUILD(5) § OPTIONS AND DIRECTIVES. Neither keys nor values are quoted. Data that, in a PKGBUILD, would be represented by an array is instead specified multiple times. For instance, the following are equivalent:

The main section of the file is headed by a pkgbase declaration, and contains data applicable to the package as a whole. In a standard PKGBUILD describing a single package, this will be the only section, followed by a pkgname declaration containing the same value as the preceding pkgbase:

In a split PKGBUILD, each section is headed by a pkgname, followed by any data specific to that package.

This article or section needs expansion.

The following fields may appear only once in each .SRCINFO file, in the pkgbase section:

The following fields may appear up to once in any section.

The following fields may be repeated within a section to specify multiple values:

The following fields may, additionally, specify multiple architectures as shown below:

Fields with other names are ignored. Blank lines and comment lines beginning with a hash sign (#) are also ignored. Lines may be indented.

**Examples:**

Example 1 (unknown):
```unknown
$ makepkg --printsrcinfo > .SRCINFO
```

Example 2 (unknown):
```unknown
key = value
```

Example 3 (unknown):
```unknown
arch=(i686 x86_64)
```

Example 4 (unknown):
```unknown
arch = i686
arch = x86_64
```

---

## SDL

**URL:** https://wiki.archlinux.org/title/SDL

**Contents:**
- Installation
- Documentation
- See also

Install the sdl3 package.

In case you need sdl2AUR or sdl12-compat install them accordingly, though it is advised to migrate to SDL3.

SDL2 apps can also use sdl2-compat. An SDL2 compatibility layer that uses SDL3 behind the scenes.

Like SDL3, SDL2 also is modular though the modules are in separate packages. These include sdl2_image, sdl2_mixer, sdl2_ttf, etc. for SDL 2. There are also sdl_image, sdl_mixer, sdl_ttf, etc. for SDL1.2.

The official SDL3 Wiki provides the most essential resources to learn and utilize SDL3. Additionally, SDL3 Examples has a selection of small sample programs.

---

## getty

**URL:** https://wiki.archlinux.org/title/Disable_clearing_of_boot_messages

**Contents:**
- Installation
- Tips and tricks
  - Staircase effect
  - Add additional virtual consoles
  - Automatic login to virtual console
    - Virtual console
    - Serial console
    - Nspawn console
  - Prompt only the password for a default user in virtual console login
  - Have boot messages stay on tty1

A getty is the generic name for a program which manages a terminal line and its connected terminal. Its purpose is to protect the system from unauthorized access. Generally, each getty process is started by systemd and manages a single terminal line.

agetty is the default getty in Arch Linux, as part of the util-linux package.

An alternative is mingettyAUR.

agetty modifies the TTY settings while waiting for a login so that the newlines are not translated to CR-LFs. This tends to cause a "staircase effect" for messages printed to the console.

It is entirely harmless, but in the event it persists once logged, you can fix this behavior with:

See this forums discussion on the subject.

Agetty manages virtual consoles and six of these virtual consoles are provided by default in Arch Linux. They are usually accessible by pressing Ctrl+Alt+F1 through Ctrl+Alt+F6.

Open the file /etc/systemd/logind.conf and set the option NAutoVTs=6 to the number of virtual terminals that you want at boot.

If needed, it is possible to temporarily start a getty@ttyN.service service directly.

Configuration relies on systemd unit drop-in files to override the default parameters passed to agetty.

Configuration differs for virtual versus serial consoles. In most cases, you want to set up automatic login on a virtual console, (whose device name is ttyN, where N is a number). The configuration of automatic login for serial consoles will be slightly different. Device names of the serial consoles look like ttySN, where N is a number.

Create a drop-in file for getty@tty1.service with the following contents:

If you do not want full automatic login, but also do not want to type your username, see #Prompt only the password for a default user in virtual console login.

If you want to use a tty other than tty1, see systemd/FAQ#How do I change the default number of gettys?.

Create a drop-in file:

To configure auto-login for a systemd-nspawn container, override console-getty.service by creating a drop-in file:

If machinectl login my-container method is used to access the container, also adjust the container-getty@.service template that manages pts/[0-9] pseudo ttys:

Getty can be used to login from a virtual console with a default user, typing the password but without needing to insert the username. For instance, to prompt the password for username on tty1:

By default, Arch has the getty@tty1 service enabled. The service file already passes --noclear, which stops agetty from clearing the screen. However systemd clears the screen before starting it. To disable this behavior, create a drop-in file:

This article or section is a candidate for merging with Display Power Management Signaling#Linux console.

When the system is used as a server but has a display connected, the display will be turned on forever. To turn off display after 5 minutes create a drop-in file. On any key press, display will turn back on.

**Examples:**

Example 1 (unknown):
```unknown
$ stty onlcr
```

Example 2 (unknown):
```unknown
Ctrl+Alt+F1
```

Example 3 (unknown):
```unknown
Ctrl+Alt+F6
```

Example 4 (unknown):
```unknown
/etc/systemd/logind.conf
```

---

## Arch package guidelines

**URL:** https://wiki.archlinux.org/title/Arch_package_guidelines

**Contents:**
- Package etiquette
- Package naming
- Package versioning
- Package dependencies
- Package relations
- Package sources
- Working with upstream
- Directories
- Makepkg duties
- Architectures

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

When building packages for Arch Linux, adhere to the package guidelines below, especially if the intention is to contribute a new package to Arch Linux. You should also see the PKGBUILD(5) and makepkg(8) man pages.

Important points listed on this page are not repeated on the other package guideline pages. These specific guidelines are intended as an addition to the standards listed below.

Packages submitted to the Arch User Repository must additionally comply with AUR submission guidelines.

See .proto files in the /usr/share/pacman/ directory as PKGBUILD examples.

The factual accuracy of this article or section is disputed.

It is considered best-practice to work closely with upstream wherever possible. This entails reporting problems about building and testing a package.

It is recommended to track upstream with tools such as nvchecker, nvrsAUR or urlwatch to be informed about new stable releases.

When makepkg is used to build a package, it does the following automatically:

The arch array should contain 'x86_64' if the compiled package is architecture-specific. Otherwise, use 'any' for architecture independent packages.

There are two kinds of licenses regarding an Arch package:

The license field of a PKGBUILD. It lists the packaged software's upstream license. It is NOT the license of the package source. The licenses in this field must be in the SPDX license format. See also PKGBUILD#license for more details.

The license for the package sources themselves. In RFC40, Arch Linux specifies that package sources are to be licensed as 0BSD with RFC52 specifying that REUSE should be used to enforce this.

It boils down to this:

If you have additional files that you need to license, you need to pick a reasonable license for them. This is usually quite straight forward:

See also the Arch Linux Dev blog post introducing pkgctl-license(1).

Arch is working on making all packages reproducible. A packager can check if a package is reproducible with makerepropkg from devtools or repro from archlinux-repro.

If the timestamp is required at build-time, use the environment variable SOURCE_DATE_EPOCH. The format is documented upstream.

**Examples:**

Example 1 (unknown):
```unknown
/usr/share/pacman/
```

Example 2 (unknown):
```unknown
/usr/local/
```

Example 3 (unknown):
```unknown
_customvariable=
```

Example 4 (unknown):
```unknown
/usr/libexec/
```

---

## Open Sound System

**URL:** https://wiki.archlinux.org/title/OSS

**Contents:**
- Installation
- Testing
- Volume control mixer
  - Color definitions
  - Saving mixer levels
  - Other mixers
- Configuring applications for OSS
  - GStreamer-based
  - OpenAL-based
  - Audacity

The Open Sound System (OSS) was the original sound system for Linux.

It was superseded by the Advanced Linux Sound Architecture (ALSA), which has a number of advantages over OSS:

Install the ossAUR package, or the package with non-free drivers oss-nonfreeAUR.

This will install the OSS, run the OSS install script (temporarily disabling the ALSA modules) and install the OSS kernel modules. Since ALSA is enabled by default, you need to disable it so it does not conflict with OSS. You can do this by blacklisting the soundcore module.

After blacklisting the module, you can enable oss.service to start at boot.

To start using OSS without needing to reboot, check if any ALSA modules are still loaded (ALSA modules start with "snd"):

Remove the ALSA modules as follows:

To completely remove ALSA from your system, you can compile a custom kernel and disable ALSA in its configuration. See Gentoo:ALSA#Kernel for the details.

This article or section is out of date.

In case you are not part of the audio group, add yourself and relogin for the changes to take effect:

In case OSS is not able to detect your card when starting it, run:

You should be able to hear music during the test process. If there is no audio, try to adjust the volume or refer to the #Troubleshooting section.

If you want to hear sounds from more than one application simultaneously, you need vmix, OSS's software mixer.

Check that vmix is enabled by running:

You should see a line like vmix0-enable ON|OFF (currently ON). If you do not see any lines beginning with vmix, it probably means that vmix has not been attached to your sound device. To attach vmix, issue the command:

where device is your sound device, e.g. /dev/oss/oss_envy240/pcm0.

To avoid having to issue this command manually in the future, you can add it to /usr/lib/oss/soundon.user, as suggested by the official documentation.

If you get a "Device or resource busy" error, you need to add vmix_no_autoattach=1 to /usr/lib/oss/conf/osscore.conf and then reboot.

See which devices are detected by running:

You should be able to see your devices listed under Device Objects or Audio Devices. If the device that you want to use is not at the top of one of these sections, you have to edit /usr/lib/oss/etc/installed_drivers and place the driver for your device at the very top. It may be required to restart OSS:

If this does not work, comment all drivers listed except the ones for your device.

To control the volume of various devices, mixers levels will need to be set. There are two mixers:

For high definition (HD) audio, ossxmix will color jack configurations by their pre-defined jack colors:

Mixer levels are saved when you shut off your computer. If you want to save the mixer level immediately, execute as root:

savemixer can be used to write mixer levels to a file with the -f switch and restore by the -L switch.

Other mixers that have support for OSS:

If you have problems with applications that use GStreamer for audio, you can try removing pulseaudio and installing the gst-plugins-good package which is needed by oss4sink and oss4src.

By default OpenAL uses ALSA. To change this, simply define the usage of OSS in /etc/openal/alsound.conf:

If Audacity starts, but it complains that it cannot open the device or simply does not play anything, then you may be using vmix which prevents Audacity from having exclusive access to your sound device. To fix this, before running Audacity, run:

You can restore vmix after closing Audacity with:

By default, Gajim uses aplay -q to play a sound. For OSS you can change it to the equivalent ossplay -qq by going to Edit > Preferences > Advanced, opening the Advanced Configuration Editor and modifying the soundplayer variable accordingly.

To use MOC with OSS v4.1 you must change OSSMixerDevice to /dev/ossmix in your configuration file (located in ~/.moc). For issues with the interface try changing the OSSMixerChannel by pressing w in mocp (to change to the sofware mixer).

MPD is configured through /etc/mpd.conf or ~/.mpdconf. Check both of these files, looking for something that looks like:

If you find an uncommented (the lines do not begin with #'s) ALSA configuration like the one above, comment all of it out, or delete it, and add the following:

Further configuration might not be necessary for all users. However, if you experience issues (in that MPD does not work properly after it has been restarted), or if you like having specific (i.e. more user-configured, less auto-configured) configuration files, the audio output for OSS can be more specifically configured by finding the card identifier:

Look for the line that says something similar to /dev/dsp -> /dev/oss/CARD_IDENTIFIER/pcm0. Take note of what your CARD_IDENTIFIER is, and add these lines to your OSS audio_output in your MPD configuration file:

See also: Music Player Daemon#System-wide configuration.

If you are using a GUI (SMplayer, GNOME MPlayer, etc.) you can select OSS as the default output in the settings dialogs. If you use MPlayer from the command-line, you should specify the sound output:

If you do not want to bother typing it over and over again add ao=oss to your configuration file (at ~/.mplayer/config).

See also: MPlayer#Configuration.

You can select OSS as the default output in the audio settings.

To set OSS support in Wine start:

and go to the Audio tab and select the OSS Driver.

See also: Wine#Sound.

This article or section is a candidate for merging with #Keyboard volume control.

The volume lever of ossxmix is very small, making it difficult to finely control the volume.

Run ossmix to find the control you want to control (refer to ossxmix), this example is codec1.jack.green.front.

Bind the following commands to the keyboard shortcuts of the desktop environment.

Increase the volume by 1 (the volume can be between 0 and 100):

Decrease the volume by 1 (The -- is needed on some systems so that the -1 will not be mistaken for a parameter.):

Then you can easily control the volume.

An easy way to mute/unmute and increase/decrease the volume is to use the ossvol script.

Download the script and place it at /usr/bin/ossvol.

Once you installed it, type:

to see the available commands.

If you want to use multimedia keys with ossvol, map the following commands to your volume keys: XF86AudioRaiseVolume, XF86AudioLowerVolume and XF86AudioMute:

To mute/unmute the volume:

Changing the output sample rate is not obvious at first. Sample rates can only be changed by root and vmix must be unused by any programs when a change is requested. Before you follow any of these steps, ensure you are going through a receiver/amplifier and using quality speakers and not simply computer speakers. If you are only using computer speakers, do not bother changing anything here as you will not notice a difference.

By default the sample rate is 48000hz. There are several conditions in which you may want to change this. This all depends on your usage patterns. You want the sample rate you are using to match the media you use the most. If your computer has to change the sampling rate of the media to suit the hardware it is likely, though not guaranteed, that you will have a loss in audio quality. This is most noticeable in down sampling (ie. 96000hz → 48000hz). There is an article about this issue in Stereophile which was discussed on Apple's CoreAudio API mailing list if you wish to learn more about this issue.

This article or section is out of date.

Some example sample rates:

To check what your sample rate is currently set to, run:

You are likely to see vmix0-rate <decimal value> (currently 48000) (Read-only).

This article or section is out of date.

If you do not see a vmix0-rate (or vmix1-rate, etc.) being outputted, then it probably means that vmix is disabled. In that case, OSS will use the rate requested by the program which uses the device, so this section does not apply. Exception to this are Envy24 (and Envy24HT) cards that have a special setting envy24.rate which has a similar function (see the oss_envy24 manpage).

To change your sample rate:

and make it executable.

vmix is a virtual mixer audio that mixes multiple audio streams but can reduce the sound quality. Simply unchecking vmix-things in OSS Mixer GUI does not always work.

Turn off COOKEDMODE to disable format conversions for all applications and devices.

Restart oss.service or your computer ifyou encounter errors.

After that you can still control the volume via ossmix or ossxmix.

Create an application launcher file named ossxmix.desktop in you local application launchers directory (~/.local/share/applications/ with:

To have it autostart with your system, add it to the list in System Settings > System Administration > Startup and Shutdown > Autostart.

As root create a file /usr/local/bin/ossxmix_bg with the following content:

Then go to System > Preferences > Start Up Applications and:

See upstream article on Recording sound output of a program.

OSS does not automatically support suspend, it must be manually stopped prior to suspending or hibernating and restarted afterwards.

OSS provides soundon and soundoff to enable and disable OSS, although they only stop OSS if all processes that use sound are terminated first.

The following script is a rather basic method of automatically unloading OSS prior to suspending and reloading afterwards.

Save the contents of this script (as root) into /usr/lib/systemd/system-sleep/50osssound.sh and make it executable.

With this, all your applications should be fine.

When running osstest, the first test passes for the first channel, but not for the stereo or right channel, it sounds distorted/hisses. If this is what your sound is like, then it is set to the wrong output.

The left sounded good, the right and stereo were the distorted ones.

Let the test continue until you get a working output:

If this passed the test on all left, right and stereo, proceed to next step.

For the command to change the default output see upstream's wiki article. Change it to what works for you, for example:

For surround sound (4.0-7.1) choose dsp_multich, for only 2 channels, dsp is sufficient. See this for all available devices.

This article or section is being considered for removal.

You can instruct alsa-lib to use OSS as its audio output system. This works as a sort of ALSA emulation.

Note, however, that this method may introduce additional latency in your sound output, and that the emulation is not complete and does not work with all applications. It does not work, for example, with programs that try to detect devices using ALSA.

So, as most applications support OSS directly, use this method only as a last resort.

In the future, more complete methods may be available for emulating ALSA, such as libsalsa and cuckoo.

If something is not working, there is a possibility that some of your OSS settings are driver specific or just wrong for your driver.

For example, the setting:

in oss_ich.conf turns on jack-sense (which is responsible for recognizing plugged headphones and muting the speaker). Other settings for jack-sense can be found in hdaudio.conf where you have to change the hdaudio_jacksense variable.

If you have a HD Audio sound device, it is very likely that you will have to adjust some mixer settings before your sound works.

HD Audio devices are very powerful in the sense that they can contain a lot of small circuits (called widgets) that can be adjusted by software at any time. These controls are exposed to the mixer, and they can be used, for example, to turn the earphone jack into a sound input jack instead of a sound output jack.

However, there are also bad side effects, mainly because the HD Audio standard is more flexible than it perhaps should be, and because the vendors often only care to get their official drivers working.

When using HD Audio devices, you often find disorganized mixer controls, that do not work at all by default, and you are forced to try every mixer control combination possible, until it works.

Open ossxmix and try to change every mixer control in the middle area, that contains the sound card specific controls, as explained in the #Volume control mixer section.

You will probably want to setup a program to record/play continuously in the background (e.g. ossrecord - | ossplay - for recording or osstest -lV for playing), while changing mixer settings in ossxmix in the foreground.

If you hear various cracks or strange noises in Totem during playback, you can try using another backend such as FFmpeg. This will not fix the issue that somehow pops up in GStreamer when playing MMS streams but it will give you the option to play it with good sound quality. Playing it in MPlayer is simple:

By default, OSS plays back the microphone through the speakers. To disable this in ossxmix find the "Misc" section and uncheck every "input-mix-mute" box.

The factual accuracy of this article or section is disputed.

OSS provides a "generic" codec driver that should be able to parse 99% of all HDAudio codecs.

If the device are not listed in the oss_hdaudio.c source file, add them to it, recompile and start the drivers.

To find the device/vendor IDs for "Multimedia controller" device class, do the following:

In this example, "Vendor ID" is "8086" and "Device ID" is "a170".

Change 5 lines of code in the source code, taking "the latest source package"(currently "oss-v4.2-build2020-src-gpl.tar.bz2") as an example:

It is better to modify the existing "Controller" ("PCH_C" in this example), appending a new line of code may fail. It does not matter if it is PCH_C.

The last line of code is a bit complicated. This example is an ALC1150 sound card chip. The "Vendor_id" of "ALC1150" is "0x10ec0900", you can get it through a search engine, or try the following:

For sound card chips of different manufacturers, different paragraphs need to be modified. In the example, the paragraph of Realtek manufacturer:

It is very important that on the hardware of this example, modifying the second-to-last line works, but modifying the same code on the first-to-last line fails. You will need to try and modify the same code over and over on different lines to work on your hardware.

For example, try on the 4th last line:

**Examples:**

Example 1 (unknown):
```unknown
oss.service
```

Example 2 (unknown):
```unknown
# lsmod | grep snd
```

Example 3 (unknown):
```unknown
# lsmod | awk ' { print $1 } ' | grep snd | xargs rmmod
```

Example 4 (unknown):
```unknown
# soundoff && soundon
```

---

## getty

**URL:** https://wiki.archlinux.org/title/Getty

**Contents:**
- Installation
- Tips and tricks
  - Staircase effect
  - Add additional virtual consoles
  - Automatic login to virtual console
    - Virtual console
    - Serial console
    - Nspawn console
  - Prompt only the password for a default user in virtual console login
  - Have boot messages stay on tty1

A getty is the generic name for a program which manages a terminal line and its connected terminal. Its purpose is to protect the system from unauthorized access. Generally, each getty process is started by systemd and manages a single terminal line.

agetty is the default getty in Arch Linux, as part of the util-linux package.

An alternative is mingettyAUR.

agetty modifies the TTY settings while waiting for a login so that the newlines are not translated to CR-LFs. This tends to cause a "staircase effect" for messages printed to the console.

It is entirely harmless, but in the event it persists once logged, you can fix this behavior with:

See this forums discussion on the subject.

Agetty manages virtual consoles and six of these virtual consoles are provided by default in Arch Linux. They are usually accessible by pressing Ctrl+Alt+F1 through Ctrl+Alt+F6.

Open the file /etc/systemd/logind.conf and set the option NAutoVTs=6 to the number of virtual terminals that you want at boot.

If needed, it is possible to temporarily start a getty@ttyN.service service directly.

Configuration relies on systemd unit drop-in files to override the default parameters passed to agetty.

Configuration differs for virtual versus serial consoles. In most cases, you want to set up automatic login on a virtual console, (whose device name is ttyN, where N is a number). The configuration of automatic login for serial consoles will be slightly different. Device names of the serial consoles look like ttySN, where N is a number.

Create a drop-in file for getty@tty1.service with the following contents:

If you do not want full automatic login, but also do not want to type your username, see #Prompt only the password for a default user in virtual console login.

If you want to use a tty other than tty1, see systemd/FAQ#How do I change the default number of gettys?.

Create a drop-in file:

To configure auto-login for a systemd-nspawn container, override console-getty.service by creating a drop-in file:

If machinectl login my-container method is used to access the container, also adjust the container-getty@.service template that manages pts/[0-9] pseudo ttys:

Getty can be used to login from a virtual console with a default user, typing the password but without needing to insert the username. For instance, to prompt the password for username on tty1:

By default, Arch has the getty@tty1 service enabled. The service file already passes --noclear, which stops agetty from clearing the screen. However systemd clears the screen before starting it. To disable this behavior, create a drop-in file:

This article or section is a candidate for merging with Display Power Management Signaling#Linux console.

When the system is used as a server but has a display connected, the display will be turned on forever. To turn off display after 5 minutes create a drop-in file. On any key press, display will turn back on.

**Examples:**

Example 1 (unknown):
```unknown
$ stty onlcr
```

Example 2 (unknown):
```unknown
Ctrl+Alt+F1
```

Example 3 (unknown):
```unknown
Ctrl+Alt+F6
```

Example 4 (unknown):
```unknown
/etc/systemd/logind.conf
```

---

## Modprobed-db

**URL:** https://wiki.archlinux.org/title/Modprobed-db

**Contents:**
- Installation
- Usage
  - Populating the database
    - Recommendations
    - Automatic periodic database updates
      - Cron
      - systemd
    - Manually editing the database
      - Recommended modules
  - Building a kernel with modprobed-db

modprobed-db is a utility that populates a list of all the kernel modules that have been loaded on a system while running. This list can then be used to disable all the unused modules when building your own kernel and significantly reduce the compilation time.

Install the modprobed-dbAUR package.

Optionally: add modules in the ignore array that you do *not* want counted, for example modules that get built or that are provided by another package. Some common ones are included by default:

Once the initial database has been created, use modprobed-db list to show the current database modules and modprobed-db store to update the database with the currently loaded kernel modules.

It is recommended to "use" the official Arch kernel, with modprobed-db installed, for a good amount of time to allow the database to grow based on usage and capture everything the system needs before building a kernel without the unneeded modules). Here are some suggested actions to allow appropriate modules to load and get cataloged:

These suggested actions are to be made in parallel with periodically updating the database with modprobed-db store to capture any newly loaded kernel module.

Calls to modprobed-db store can be automated with one of the following methods:

The most convenient method to use modprobed-db is to simply add a crontab entry invoking /usr/bin/modprobed-db store at some regular interval.

Example running the script once every hour:

Instead of cron, enable/start the modprobed-db.service user unit. It will run modprobed-db in store mode once per 6 hours, and at boot and on shutdown.

Like any service and timer, the status of the modprobed-db.service user unit can be queried.

Using the #Automatic periodic database updates or manually running modprobed-db store is not entirely foolproof:

Thankfully, the modprobed.db database file is a simple text file that contains one kernel module name per line: it can be manually edited to add/remove a module. It is then recommended to run modprobed-db store after a manual edit so the modules get automatically reordered.

These modules are recommended to be added to the $XDG_CONFIG_HOME/modprobed.db database file as they are broadly used:

For a ready-made database of commonplace modules, linux-tkg maintains one for each (recent) kernel version: [1]

After the database has been adequately populated, it can be read directly by make localmodconfig.

modprobed-db naturally intervenes in a traditional compilation workflow during the configuration step with the default Arch .config file.

The official Arch kernel PKGBUILD can be modified as shown to do this automatically:

linux-tkg offers a user-friendly kernel build script that also includes extra patches oriented towards improving desktop/gaming performance. In its configuration file, it supports user-provided modprobed-db's database files, but also offers its own "diet" database files: contains the most common modules while still producing a lighter kernel.

Comparisons using kernel version 5.13.1, where a Kernel/Traditional compilation is made with the default Arch configuration.

The main results of the benchmark is that 80% of the build time of a "full" kernel is spent on modules. Given that only a fraction of those modules are needed by any given machine, the build time can be reduced by ~70%. The results will vary from one machine to another but should be similar.

The number of modules can be determined by the following:

The kernel build time is obtained with:

then the modules build time is obtained with:

**Examples:**

Example 1 (unknown):
```unknown
modprobed-db
```

Example 2 (unknown):
```unknown
$XDG_CONFIG_HOME/modprobed-db.conf
```

Example 3 (unknown):
```unknown
modprobed-db store
```

Example 4 (unknown):
```unknown
$XDG_CONFIG_HOME/modprobed.db
```

---

## Unofficial user repositories

**URL:** https://wiki.archlinux.org/title/Unofficial_user_repository

**Contents:**
- Adding your repository to this page
- Signed
  - ada
  - alerque
  - ALHP
  - andontie-aur
  - arcanisrepo
  - arch4edu
  - archlinuxcn
  - archzfs

This article lists binary repositories freely created and shared by the community, often providing pre-built versions of PKGBUILDs found in the Arch User Repository (AUR).

In order to use these repositories, add them to /etc/pacman.conf, as explained in pacman#Repositories and mirrors. If a repository is signed, you must obtain and locally sign the associated key, as explained in pacman/Package signing#Adding unofficial keys.

If you want to create your own custom repository, follow pacman/Tips and tricks#Custom local repository.

If you have your own repository, please add it to this page so that all the other users will know where to find your packages. Please keep the following rules when adding new repositories:

Some repositories may also have packages for architectures besides x86_64. The $arch variable will be set automatically by pacman.

The factual accuracy of this article or section is disputed.

Many of the unofficial Arch Linux repositories are indexed on https://archlinux.pkgs.org/.

It provides repositories browser and packages search.

**Examples:**

Example 1 (unknown):
```unknown
/etc/pacman.conf
```

Example 2 (unknown):
```unknown
pacman.conf
```

Example 3 (unknown):
```unknown
[ada]
Server = http://www.orthanc.site:8080/assets/arch_ada_repo
```

Example 4 (unknown):
```unknown
[alerque]
Server = https://arch.alerque.com/$arch
```

---

## Keybase

**URL:** https://wiki.archlinux.org/title/Keybase

**Contents:**
- Installation
- Signup / Login
- GnuPG Keys
- Keybase Filesystem (KBFS)
- Troubleshooting
  - Keybase GUI starts automatically
  - Tray icon using AppIndicator GNOME Shell extension
- See also

Keybase is provided by the keybaseAUR package. The KBFS filesystem and Keybase GUI can be additionally installed with the kbfsAUR and keybase-guiAUR packages. Alternatively, keybase-binAUR is available on the AUR which includes everything in a single package. See also the install instructions on keybase.io.

If you installed the GUI via keybase-binAUR, it will walk you through signup. These instructions are for the CLI-only keybaseAUR package.

Keybase requires its service to be running so you can interact with it. Start the keybase.service user unit and enable it to run on boot.

Alternatively, run the keybase service manually:

To signup for a Keybase account use, and follow the on-screen prompts:

If you already have a Keybase account you can login with:

During the interactive signup if you already have any GnuPG key pairs on your keyring, Keybase will ask if you wish to use one of them. If you do not have a key pair, you can generate one with:

This will interactively generate a key pair and securely upload the keys.

KBFS uses FUSE to mount the remote cryptographic filesystem. It comes with the keybase-binAUR package, or can be installed separately with kbfsAUR.

Keybase allows users to store up to 250 GB of files in a cloud storage called the Keybase filesystem. The filesystem is divided into three parts: public files, private files, and team files. The filesystem is mounted to /keybase by default if installed through keybase-binAUR.

To configure kbfs if installed via the kbfsAUR package, first ensure the keybase service is running (see instructions above). Then configure the desired mountpoint for the KBFS:

Now the kbfs.service user unit can be started.

Enable this service to have the kbfs mounted on boot.

All files under /path/to/kbfs/public are automatically signed by the client. All files under /path/to/kbfs/private are both encrypted and signed before being uploaded, making them end-to-end encrypted. See the KBFS docs on keybase.io for more information and usage instructions.

By default, keybase-gui add a desktop entry in your autostart. To disable it:

You might find that no icon shows up when Keybase starts, if you are using the gnome-shell-extension-appindicator extension. It seems that Electron needs the libappindicator to be installed, so that it can create and manage those icons.

**Examples:**

Example 1 (unknown):
```unknown
keybase.service
```

Example 2 (unknown):
```unknown
$ keybase service
```

Example 3 (unknown):
```unknown
$ keybase signup
```

Example 4 (unknown):
```unknown
$ keybase login keybase_username
```

---

## Node.js package guidelines

**URL:** https://wiki.archlinux.org/title/Node.js_package_guidelines

**Contents:**
- Package naming
- Source
- Using npm
  - Setting temporary cache
  - Package contains reference to $srcdir/$pkgdir
- Using nvm
  - Example PKGBUILD usage

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

This document covers standards and guidelines on writing PKGBUILDs for Node.js packages.

Package names for Node.js libraries should start with a nodejs- prefix. For standalone applications, just use the program name.

npm provides a stable naming scheme for download URLs. PKGBUILD#source source=() array can use the following URL template:

When installing with npm, add it as a build dependency:

There is also usually no need to extract the tarball:

This is a minimal package function:

When npm processes package.json in order to build a package it downloads dependencies to its default cache folder at $HOME/.npm. To avoid littering user's home folder we can temporarily set a different cache folder with --cache flag.

Download dependencies to ${srcdir}/npm-cache and install them in package directory:

Continue with packaging as usual:

npm unfortunately creates references to the source dir and the pkg dir, this is a known issue. However, you may remove those references manually since they are not used in any way.

All dependencies will contain a reference to $pkgdir, in the _where attribute. You can usually remove those attributes with some sed magic as follows:

Your main package will have some other references too. The easiest way to remove those is to remove all underscored properties, but that is not as easy with sed. Instead, you can use jq for similar results as follows:

Another place where you may find references to $pkgdir is the man attributes of packages. If you do not care about man pages (they will not be installed for dependencies anyway), you may delete them like this:

An example of all three of these techniques can be seen in nodejs-readability-cli's PKGBUILD.

When a node.js-based application requires different version for building or packaging, then nvm can be leveraged.

Add it as a build dependency:

nvm uses NVM_DIR environment variable to look for its prefix, which is set to $HOME/.nvm if not specified before nvm initialization.

You can use the following function to create and isolate your custom prefix from user's location:

This function should be called before interacting with nvm, npm or any other Node.js based programs that should use the specified version.

Alternatively, bare nvm install will look for a version string in .nvmrc file in the current directory.

An example of this usage can be seen in insomniaAUR. See PKGBUILD for more information.

**Examples:**

Example 1 (unknown):
```unknown
_pkgname=${pkgname#nodejs-}
```

Example 2 (unknown):
```unknown
https://registry.npmjs.org/$_pkgname/-/$_pkgname-$pkgver.tgz
```

Example 3 (unknown):
```unknown
npm view @nestjs/cli@10.1.7 dist.tarball
```

Example 4 (unknown):
```unknown
makedepends=('npm')
```

---

## Patching packages

**URL:** https://wiki.archlinux.org/title/Patching_packages

**Contents:**
- Creating patches
- Applying patches
- Using quilt
- See also

This article covers how to create and how to apply patches to packages in the Arch build system (ABS).

A patch describes a set of line changes for one or multiple files. Patches are typically used to automate the changing of source code.

The diff tool compares files line by line. If you save its output you have a patch, e.g. diff --unified --recursive --text foo bar > foobar.patch (which can be shortened to diff -ura). If you pass directories diff will compare the files they contain.

See diff(1) and git-diff(1) for more info.

This section outlines how to apply patches you created or downloaded from the Internet from within a PKGBUILD's prepare() function. Follow these steps:

An example prepare-function:

Alternatively, you can use the --directory/-d flag of patch without having to cd first. The example above would then become:

Run makepkg from the terminal now. If all goes well, the patch will be automatically applied, and your new package will contain whatever changes were included in the patch. If not, you may have to experiment with the --strip/-p option of patch. While experimenting, you might find --dry-run, --reverse or --verbose options usable. Read patch(1) for more information.

Basically it works as follows. If the diff file was created to apply patches to files in myversion/, the diff files will be applied to myversion/file. You are running it from within the yourversion/ directory (because you would cd into that directory in the PKGBUILD), so when patch applies the file, you want it to apply it to the file file, taking off the myversion/ part. -p1 does this, by removing one directory from the path. However, if the developer patched in myfiles/myversion, you need to remove two directories, so you use -p2.

If you do not apply a -p option, it will take off all directory structure. This is OK if all the files are in the base directory, but if the patch was created on myversion/ and one of the edited files was myversion/src/file, and you run the patch without a -p option from within yourversion, it will try to patch a file named yourversion/file.

Most developers create patches from the parent directory of the directory that is being patched, so -p1 will usually be right.

A simpler way to create patches is using quilt which provides better support for managing many patches, such as applying patches, refreshing patches, and reverting patched files to original state. quilt is used on Debian to manage their patches. See Using Quilt for basic information about basic quilt usage to generate, apply patches, and reverting patched files.

**Examples:**

Example 1 (unknown):
```unknown
diff --unified --recursive --text foo bar > foobar.patch
```

Example 2 (unknown):
```unknown
makepkg --nobuild
```

Example 3 (unknown):
```unknown
makepkg --nobuild --nodeps
```

Example 4 (unknown):
```unknown
makepkg -od
```

---

## PKGBUILD

**URL:** https://wiki.archlinux.org/title/Makedepends

**Contents:**
- Package name
  - pkgbase
  - pkgname
- Version
  - pkgver
  - pkgrel
  - epoch
- Generic
  - pkgdesc
  - arch

This article discusses variables definable by the maintainer in a PKGBUILD. For information on the PKGBUILD functions and creating packages in general, refer to Creating packages. Also read PKGBUILD(5).

A PKGBUILD is a Bash script containing the build information required by Arch Linux packages.

Packages in Arch Linux are built using the makepkg utility. When makepkg is run, it searches for a PKGBUILD file in the current directory and follows the instructions therein to either compile or otherwise acquire the files to build a package archive—pkgname.pkg.tar.zst. The resulting package contains binary files and installation instructions, readily installable with pacman.

Mandatory variables are pkgname, pkgver, pkgrel, and arch. license is not strictly necessary to build a package, but is recommended for any PKGBUILD shared with others, as makepkg will produce a warning if not present.

It is a common practice to define the variables in the PKGBUILD in the same order as given here. However, it is not mandatory.

See the .proto files in the /usr/share/pacman/ directory as examples.

When building regular packages, this variable should not be explicitly declared in the PKGBUILD: its value defaults to that of #pkgname.

When building a split package, this variable can be used to explicitly specify the name to be used to refer to the group of packages in the output of makepkg and in the naming of source-only tarballs. The value is not allowed to begin with a hyphen. If not specified, the value will default to the first element in the pkgname array.

All options and directives for split packages default to the global values given in the PKGBUILD. Nevertheless, the following ones can be overridden within each split package’s packaging function: #pkgdesc, #arch, #url, #license, #groups, #depends, #optdepends, #provides, #conflicts, #replaces, #backup, #options, #install, and #changelog.

Either the name of the package, e.g. pkgname=foo, or, for split packages, an array of names, e.g. pkgname=(foo bar). Package names should only consist of lowercase alphanumerics and the following characters: @._+- (at symbol, dot, underscore, plus, hyphen). Names are not allowed to start with hyphens or dots. For the sake of consistency, pkgname should match the name of the source tarball of the software: for instance, if the software is in foobar-2.5.tar.gz, use pkgname=foobar.

The version of the package. This should be the same as the version published by the author of the upstream software. It can contain letters, numbers, periods and underscores, but not a hyphen (-). If the author of the software uses one, replace it with an underscore (_). If the pkgver variable is used later in the PKGBUILD, then the underscore can easily be substituted for a hyphen, e.g. source=("${pkgname}-${pkgver//_/-}.tar.gz").

The release number. This is usually a positive integer number that allows to differentiate between consecutive builds of the same version of a package. As fixes and additional features are added to the PKGBUILD that influence the resulting package, the pkgrel should be incremented by 1. When a new version of the software is released, this value must be reset to 1. In exceptional cases other formats can be found in use, such as major.minor.

Used to force the package to be seen as newer than any previous version with a lower epoch. This value is required to be a non-negative integer; the default is 0. It is used when the version numbering scheme of a package changes (or is alphanumeric), breaking normal version comparison logic. For example:

See pacman(8) for more information on version comparisons.

The description of the package. This is recommended to be 80 characters or less and should not include the package name in a self-referencing way, unless the application name differs from the package name. For example, use pkgdesc='Text editor for X11' instead of pkgdesc='Nedit is a text editor for X11'.

Also it is important to use keywords wisely to increase the chances of appearing in relevant search queries.

An array of architectures that the PKGBUILD is intended to build and work on. Arch officially supports only x86_64, but other projects may support other architectures. For example, Arch Linux 32 provides support for i686 and pentium4, and Arch Linux ARM provides support for armv7h (armv7 hardfloat) and aarch64 (armv8 64-bit).

There are two types of values the array can use:

The target architecture can be accessed with the variable CARCH during a build.

The URL of the official site of the software being packaged.

This article or section is a candidate for merging with Arch package guidelines#licenses.

This article or section needs expansion.

The license under which the software is distributed. Arch Linux uses SPDX license identifiers. Each license must have a corresponding entry in /usr/share/licenses/.

For common licenses (like GPL-3.0-or-later), package licenses delivers all the corresponding files. The package is installed by default, as it is a dependency of base meta package, and the files may be found in /usr/share/licenses/spdx/. Simply refer to the license using its SPDX license identifier from the list of SPDX identifiers.

License families like BSD or MIT are, strictly speaking, not a single license and each instance requires a separate license file. In license variable refer to them using a common SPDX identifier (e.g. BSD-3-Clause or MIT), but then provide the corresponding file as if it was a custom license.

For custom licenses the identifier should be either LicenseRef-license-name or custom:license-name, if they are not covered by the common families mentioned above. The corresponding license text must be placed in directory /usr/share/licenses/pkgname. To install the file a following code snippet may be used in package() section:

Combining multiple licenses or adding exceptions should follow the SPDX syntax. For example a package released under either GNU/GPL 2.0 or GNU/LGPL 2.1 could use 'GPL-2.0-or-later OR LGPL-2.1-or-later', a package released under Apache 2.0 with LLVM exception would use 'Apache-2.0 WITH LLVM-exception' and a package released with part under the BSD 3 clause, others under GNU/LGPL 2.1 and some under GNU/GPL 2.0 would use 'BSD-3-Clause AND LGPL-2.1-or-later AND GPL-2.0-or-later'[2]. Note that this must be a single string, so the entire expression has to be enclosed in quotes. As for November 2023 SPDX list of exceptions is limited, so usually the custom license route must be used.

If issues are encountered with SPDX identifiers, during the transitional period using old identifiers —names of the directories in /usr/share/licenses/common— is acceptable.

See also Nonfree applications package guidelines.

Additional information and perspectives on free and open source software licenses may be found on the following pages:

The group the package belongs in. For instance, when installing plasma, it installs all packages belonging in that group.

An array of packages that must be installed for the software to build and run. Dependencies defined inside the package() function are only required to run the software.

Version restrictions can be specified with comparison operators, e.g. depends=('foobar>=1.8.0'); if multiple restrictions are needed, the dependency can be repeated for each, e.g. depends=('foobar>=1.8.0' 'foobar<2.0.0').

This article or section is a candidate for merging with Arch package guidelines.

The depends array should list all direct first level dependencies even when some are already declared transitively. For instance, if a package foo depends on both bar and baz, and the bar package depends in turn on baz too, it will ultimately lead to undesired behavior if bar stops pulling in baz. Pacman will not enforce the installation of baz on systems which newly install the foo package, or have cleaned up orphans, and foo will crash at runtime or otherwise misbehave.

In some cases this is not necessary and may or may not be listed, for example glibc cannot be uninstalled as every system needs some C library, or python for a package that already depends on another python- module, as the second module must per definition depend on python and cannot ever stop pulling it in as a dependency.

Dependencies should normally include the requirements for building all optional features of a package. Alternatively, any feature whose dependencies are not included should be explicitly disabled via a configure option. Failure to do this can lead to packages with "automagic dependencies" build-time optional features that are unpredictably enabled due to transitive dependencies or unrelated software installed on the build machine, but which are not reflected in the package dependencies.

If the dependency name appears to be a library, e.g. depends=(libfoobar.so), makepkg will try to find a binary that depends on the library in the built package and append the soname version needed by the binary. Manually appending the version disables automatic detection, e.g. depends=('libfoobar.so=2').

An array of packages that are only required to build the package. The minimum dependency version can be specified in the same format as in the depends array. The packages in the depends array are implicitly required to build the package, they should not be duplicated here.

An array of packages that the software depends on to run its test suite, but are not needed at runtime. Packages in this list follow the same format as depends. These dependencies are only considered when the check() function is present and is to be run by makepkg.

An array of packages that are not needed for the software to function, but provide additional features. This may imply that not all executables provided by a package will function without the respective optdepends.[3] If the software works on multiple alternative dependencies, all of them can be listed here, instead of the depends array.

A short description of the extra functionality each optdepend provides should also be noted:

An array of additional packages that the software provides the features of, including virtual packages such as cron or sh and all external shared libraries. Packages providing the same item can be installed side-by-side, unless at least one of them uses a conflicts array.

An array of packages that conflict with, or cause problems with the package, if installed. All these packages and packages providing this item will need to be removed. The version properties of the conflicting packages can also be specified in the same format as the depends array.

Note that conflicts are checked against pkgname as well as names specified in the provides array. Hence, if your package provides a foo feature, specifying foo in the conflicts array will cause a conflict between your package and all other packages that contain foo in their provides array (i.e., there is no need to specify all those conflicting package names in your conflicts array). Let us take a concrete example:

When packages provide the same feature via the provides array, there is a difference between explicitly adding the alternative package to the conflicts array and not adding it. If the conflicts array is explicitly declared the two packages providing the same feature will be considered as alternative; if the conflicts array is missing the two packages providing the same feature will be considered as possibly cohabiting. Packagers should always ignore the content of the provides variable in deciding whether to declare a conflicts variable or not.

An array of obsolete packages that are replaced by the package, e.g. wireshark-qt uses replaces=('wireshark'). When syncing, pacman will immediately replace an installed package upon encountering another package with the matching replaces in the repositories. If providing an alternate version of an already existing package or uploading to the AUR, use the conflicts and provides arrays, which are only evaluated when actually installing the conflicting package.

An array of files that can contain user-made changes and should be preserved during upgrade or removal of a package, primarily intended for configuration files in /etc. If these files are unchanged from how they ship with the package, they will be removed or replaced as normal files during upgrade or removal.

Files in this array should use relative paths without the leading slash (/) (e.g. etc/pacman.conf, instead of /etc/pacman.conf). The backup array does not support empty directories or wildcards such as "*".

When updating, new versions may be saved as file.pacnew to avoid overwriting a file which already exists and was previously modified by the user. Similarly, when the package is removed, user-modified files will be preserved as file.pacsave unless the package was removed with the pacman -Rn command.

See also Pacnew and Pacsave files.

This array allows overriding some of the default behavior of makepkg, defined in /etc/makepkg.conf. To set an option, include the name in the array. To disable an option, place an ! before it.

The full list of the available options can be found in PKGBUILD(5) § OPTIONS AND DIRECTIVES.

The name of the .install script to be included in the package.

pacman has the ability to store and execute a package-specific script when it installs, removes or upgrades a package. The script contains the following functions which run at different times:

Each function is run chrooted inside the pacman install directory. See this thread.

The name of the package changelog. To view changelogs for installed packages (that have this file):

An array of files needed to build the package. It must contain the location of the software source, which in most cases is a full HTTP or FTP URL. The previously set variables pkgname and pkgver can be used effectively here; e.g. source=("https://example.com/${pkgname}-${pkgver}.tar.gz").

Files can also be supplied in the same directory where the PKGBUILD is located, and their names added to this array. Before the actual build process starts, all the files referenced in this array will be downloaded or checked for existence, and makepkg will not proceed if any is missing.

.install files are recognized automatically by makepkg and should not be included in the source array. Files in the source array with extensions .sig, .sign, or .asc are recognized by makepkg as PGP signatures and will be automatically used to verify the integrity of the corresponding source file.

An array of files listed under source, which should not be extracted from their archive format by makepkg. This can be used with archives that cannot be handled by /usr/bin/bsdtar or those that need to be installed as-is. If an alternative unarchiving tool is used (e.g. lrzip), it should be added in the makedepends array and the first line of the prepare() function should extract the source archive manually; for example:

Note that while the source array accepts URLs, noextract is just the file name portion:

To extract nothing, consider the following:

An array of PGP fingerprints. If used, makepkg will only accept signatures from the keys listed here and will ignore the trust values from the keyring. If the source file was signed with a subkey, makepkg will still use the primary key for comparison.

Only full fingerprints are accepted. They must be uppercase and must not contain whitespace characters.

Please read makepkg#Signature checking for more information.

These variables are arrays whose items are checksum strings that will be used to verify the integrity of the respective files in the source array. Insert SKIP for a particular file, and its checksum will not be tested.

The checksum type and values should always be those provided by upstream, such as in release announcements. When multiple types are available, the strongest checksum is to be preferred (in order from most to least preferred): b2, sha512, sha384, sha256, sha224, sha1, md5, ck. This best ensures the integrity of the downloaded files, from upstream announcement to package building.

The values for these variables can be auto-generated by makepkg's -g/--geninteg option, then commonly appended with makepkg -g >> PKGBUILD. The updpkgsums(8) command from pacman-contrib is able to update the variables wherever they are in the PKGBUILD. Both tools will use the variable that is already set in the PKGBUILD, or fall back to sha256sums if none is set.

The file integrity checks to use can be set up with the INTEGRITY_CHECK option in /etc/makepkg.conf. See makepkg.conf(5).

An array of BLAKE2b checksums with digest size of 512 bits.

An array of SHA-2 checksums with digest sizes 512, 384, 256 and 224 bits, respectively. sha256sums is the most common of them.

An array of 160-bit SHA-1 checksums of the files listed in the source array.

An array of 128-bit MD5 checksums of the files listed in the source array.

An array CRC32 checksums (from UNIX-standard cksum) of the files listed in the source array.

**Examples:**

Example 1 (unknown):
```unknown
pkgname.pkg.tar.zst
```

Example 2 (unknown):
```unknown
shellcheck --shell=bash --exclude=SC2034,SC2154,SC2164 PKGBUILD
```

Example 3 (unknown):
```unknown
makepkg.conf
```

Example 4 (unknown):
```unknown
/usr/share/pacman/
```

---

## tmux

**URL:** https://wiki.archlinux.org/title/Tmux

**Contents:**
- Installation
- Configuration
  - Key bindings
    - Copy Mode
  - Browsing URLs
  - Setting the correct term
    - 256 colors
    - 24-bit color
    - xterm-keys
  - Theming

tmux is a "terminal multiplexer: it enables a number of terminals (or windows), each running a separate program, to be created, accessed, and controlled from a single screen. tmux may be detached from a screen and continue running in the background, then later reattached."

tmux is an ISC-licensed alternative to GNU Screen. Although similar, there are many differences between the programs, as noted on the tmux FAQ page.

Install the tmux package. Optionally, install tmux-bash-completion-gitAUR to provide bash completion functions for tmux.

By default, tmux looks for user-specific configuration at $XDG_CONFIG_HOME/tmux/tmux.conf followed by ~/.config/tmux/tmux.conf, as of 3.2. A global configuration file may be provided at /etc/tmux.conf though by default Arch does not ship such a file.

By default, command key bindings are prefixed by Ctrl+b. For example, to vertically split a window type Ctrl+b %.

After splitting a window into multiple panes, a pane can be resized by the hitting prefix key (e.g. Ctrl+b) and, while continuing to hold Ctrl, press Left/Right/Up/Down. Swapping panes is achieved in the same manner, but by hitting o instead of a directional key.

Key bindings may be changed with the bind and unbind commands in tmux.conf. For example, the default prefix binding of Ctrl+b can be changed to Ctrl+a by adding the following commands in your configuration file:

To create a new window you can use Ctrl+b c and move forward one window with Ctrl+b n and backwards one window with Ctrl+b p.

Additional ways to move between windows include the following:

tmux has a find-window option & key binding to ease navigation of many windows:

A tmux window may be in one of several modes. The default permits direct access to the terminal attached to the window; the other is copy mode. Once in copy mode you can navigate the buffer including scrolling the history. Use vi or emacs-style key bindings in copy mode. The default is emacs, unless VISUAL or EDITOR contains ‘vi’

To enter copy mode do the following:

You can navigate the buffer as you would in your default editor.

To quit copy mode, use one of the following keybindings:

To browse URLs inside tmux you must have urlviewAUR installed and configured.

Inside a new terminal:

Or inside a new tmux window (no new terminal needed):

If you are using a 256 color terminal, you will need to set the correct term in tmux: tmux, or tmux-256color. This can set in the configuration file:

Also, if tmux messes up, you can force tmux to assume that the terminal support 256 colors, by adding the following alias in .bashrc:

tmux supports 24-bit color. If your terminal supports this mode (see [1]), add it to the terminal-features setting.

For example, if you use the Alacritty terminal, you would add:

For other terminals, replace alacritty above with the relevant terminal type as stored in $TERM.

See tmux(1) for details about the RGB terminfo flag.

To enable xterm-keys, add the following line in the configuration file:

If you enable xterm-keys in your tmux.conf, then you need to build a custom terminfo to declare the new escape codes or applications will not know about them. Compile the following with tic and you can use "xterm-screen-256color" as your TERM:

To check if your terminal support bce, you can use tic -c:

The file will be compiled and saved in $HOME/.terminfo or in /usr/share/terminfo/ if run as root (and so available system-wide).

Tmux can be themed however in order to do so, first one needs to know the color codes. This can be achieved by executing the below command, which will print the color codes together with a sample of such color:

The color codes printed using the above command can then be used to change the tmux color scheme. The following is an example for how one can change the colors of the status bar:

The panes borders can also be themed as per below example:

To limit the scrollback buffer to 10000 lines:

Mouse can be toggled with

There are some notable advantages to starting a tmux server at startup. Notably, when you start a new tmux session, having the service already running reduces any delays in the startup.

Furthermore, any customization attached to your tmux session will be retained and your tmux session can be made to persist even if you have never logged in, if you have some reason to do that (like a heavily scripted tmux configuration or shared user tmux sessions).

The service below starts tmux for the specified user (i.e. start/enable with tmux@username.service):

Alternatively, you can place this file within your systemd/User directory (without User=%I and by replacing multi-user.target with default.target in WantedBy), for example ~/.config/systemd/user/tmux.service. This way the tmux service will start when you log in, unless you also enable systemd/User#Automatic start-up of systemd user instances. The user service will stay active on logout due to the default explained in systemd/User#Kill user processes on logout for this method.

A different way to start tmux through systemd is this pair of units:

(Or plop them into ~/.config/systemd/user.) This creates a tmux process per service instance, each with a separate socket. tmux -D starts a non-forking tmux server, which is correctly passed the activation FD; but this process will not execute the configuration file directives. tmux start runs a transient client which forces the server to execute the session, if any.

To enable just the activation, run systemctl --user enable tmux@NAME.socket; start the client normally, with tmux -L NAME (just tmux when NAME is default). Socket activation alone simply ensures that the tmux server is moved into its own slice (tmux.slice/tmux-NAME.slice). This is equivalent to what systemd devs suggest (see systemd-run(1) § EXAMPLES, under screen), and prevents it from being killed by the session-cleanup mechanism. This also allows acting on the whole group, e.g. systemctl --user freeze tmux-NAME.slice.

To enable the server startup, run systemctl --user enable tmux@NAME.service. If your user systemd instance is lingering, this runs tmux on boot; otherwise, on login. To have the server initialise and run programs, define sessions in your tmux config file.

Note that tmux started this way inherits your systemd environment; unless spawning login shells for every pane, consult Systemd/User#Environment_variables on how to populate it.

To change the configuration file for a single instance, use a drop-in:

You can have tmux open a session with preloaded windows by including those details in your ~/.tmux.conf:

To start a session with split windows (multiple panes), include the splitw command below the neww you would like to split; thus:

would open 2 windows, the second of which would be named foo/bar and would be split vertically in half (50%) with foo running above bar. Focus would be in window 2 (foo/bar), top pane (foo).

To manage multiple sessions, source separate session files from your configuration file:

It is possible to copy a tmux selection to the display server clipboard (both primary/secondary selections), and paste from it into tmux. The following tmux configuration file snippets integrate X11 and Wayland clipboard/selection with the current tmux selection.

The first possibility is using xsel:

xclip could also be used for this purpose. Unlike xsel, it works better when printing a raw bitstream that does not fit the current locale. Nevertheless, it is neater to use xsel because xclip does not close STDOUT after it has read from the tmux buffer. As such, tmux does not know that the copy task has completed, and continues to wait for xclip to terminate, thereby rendering tmux unresponsive. A workaround is to redirect STDOUT to /dev/null:

Make sure to have wl-clipboard installed.

There is an unofficial perl extension (mentioned in the official FAQ) to enable copying/pasting in and out of urxvt with tmux via Middle Mouse Clicking.

First, you will need to download the perl script and place it into urxvts perl lib:

You will also need to enable that perl script in your .Xdefaults:

Next, you want to tell tmux about the new function and enable mouse support (if you have not already):

That's it. Be sure to end all instances of tmux before trying the new MiddleClick functionality.

While in tmux, Shift+MiddleMouseClick will paste the clipboard selection while just MiddleMouseClick will paste your tmux buffer. Outside of tmux, just use MiddleMouseClick to paste your tmux buffer and your standard Ctrl+c to copy.

Session managers like tmuxinator and tmuxp make it easy to manage common session configurations.

For tmuxinator, install tmuxinatorAUR. Test your installation with

Start tmux as usual and configure your windows and panes layout as you like. When finished, get the current layout values by executing (while you are still within the current tmux session)

The output may look like this (two windows with 3 panes and 2 panes layout)

The Interesting part you need to copy for later use begins after [layout... and excludes ... ] @2 (active). For the first window layout you need to copy e.g. 20a0,274x83,0,0{137x83,0,0,3,136x83,138,0[136x41,138,0,5,136x41,138,42,6]}

Knowing this, you can exit the current tmux session. Following this, you create your default tmux session layout by editing tmuxinator's configuration file (Do not copy the example, get your layout values as described above)

The example defines two windows named "default" and "remote". With your determined layout values. For each pane you have to use at least one - line. Within the first window panes you start the commandline "clear" in pane one, "vim" in pane two and "clear && emacs -nw" executes two commands in pane three on each tmux start. The second window layout has two panes without defining any start commmands.

Test the new default layout with:

If you like to start your terminal session with your default tmux session layout edit

Instead of using the above method, one can just write a bash script that when run, will create the default session and attach to it. Then you can execute it from a terminal to get the pre-designed configuration in that terminal

Use this command to start urxvt with a started tmux session. I use this with the exec command from my .ratpoisonrc file.

What the above snippet does is the following:

If you are using systemd as a user to keep a session alive, you can replace the command inside the if-block with the following commands to attach to that session and detach all the other connected clients:

tmux starts a login shell by default, which may result in multiple negative side effects:

To disable this behaviour, add to ~/.tmux.conf:

The following settings added to ~/.tmux.conf allow to use tmux windows like tabs, such as those provided by the reference of these hotkeys — urxvt's tabbing extensions. An advantage thereof is that these virtual “tabs” are independent of the terminal emulator.

Of course, those should not overlap with other applications' hotkeys, such as the terminal's. Given that they substitute terminal tabbing that might as well be deactivated, though.

It can also come handy to supplement the EOT hotkey Ctrl+d with one for tmux's detach:

In Practical Tmux, Brandur Leach writes:

The tmx script below implements this — the version here is slightly modified to execute tmux new-window if 1 is its second parameter. Invoked as tmx base_session_name [1], it launches the base session if necessary. Otherwise a new "client" session linked to the base, optionally add a new window and attach, setting it to kill itself once it turns "zombie". Do not forget to make it executable.

A useful setting for this is

added to ~/.tmux.conf. It causes tmux to resize a window based on the smallest client actually viewing it, not on the smallest one attached to the entire session.

An alternative is to put the following ~/.bashrc:

Instead of setting a fixed TERM variable in tmux, it is possible to set the proper TERM (either screen or screen-256color) according to the type of your terminal emulator:

By default tmux reads ~/.tmux.conf only if it was not already running. To have tmux load a configuration file afterwards, execute:

This can be added to ~/.tmux.conf as e. g.:

You can also do ^: and type :

This script checks for a program presumed to have been started by a previous run of itself. Unless found it creates a new tmux session and attaches to a window named after and running the program. If however the program was found it merely attaches to the session and selects the window.

A derived version to run irssi with the nicklist plugin can be found on its ArchWiki page.

If you SSH into a host in a tmux window, you will notice the window title of your terminal emulator remains to be user@localhost rather than user@server. To allow the title bar to adapt to whatever host you connect to, set the following in ~/.tmux.conf

For set-titles-string, #T will display user@host:~ and change accordingly as you connect to different hosts.

When creating new splits or destroying older ones the currently selected layout is not applied. To fix that, add following binds which will apply the currently selected layout to new or remaining panes:

See the following if your vim colorscheme is not loading in tmux: [2] [3]

See [4] for a configuration friendly to vim users.

The default key-binding for splitting a pane vertically is Ctrl+b % and for splitting a pane horizontally is Ctrl+b ". That can be difficult to type depending of your keyboard layout and it is also hard to remember.

A more friendly key-binding is to use Ctrl+b h for splitting horizontally and Ctrl+b v for splitting a pane vertically, it is also very convenient to remember.

To make this change, add these lines in ~/.tmux.conf:

If tmux hangs when connected from another device because the host goes to sleep, run session's shell command with an inhibition lock:

In case of trouble scrolling in the terminal with Shift-Page Up/Down, the following will disable the smcup and rmcup capabilities for any term that reports itself as anything beginning with xterm:

This tricks the terminal emulator into thinking tmux is a full screen application like pico or mutt[5], which will make the scrollback be recorded properly. Beware however, it will get a bit messed up when switching between windows/panes. Consider using tmux's native scrollback instead.

If you want to scroll with your mouse wheel, ensure mode-mouse is on in .tmux.conf

You can set scroll History with:

For mouse wheel scrolling as from tmux 2.1 try adding one or both of these to ~/.tmux.conf

Though the above will only scroll one line at a time, add this solution to scroll an entire page instead

When the terminal emulator does not support the UTF-8 mouse events and the mouse on tmux option is set, left-clicking inside the terminal window might paste strings like [M# or [Ma into the promt.

To solve this issue set:

See Midnight Commander#Broken shortcuts.

**Examples:**

Example 1 (unknown):
```unknown
$XDG_CONFIG_HOME/tmux/tmux.conf
```

Example 2 (unknown):
```unknown
~/.config/tmux/tmux.conf
```

Example 3 (unknown):
```unknown
/etc/tmux.conf
```

Example 4 (unknown):
```unknown
unbind C-b
set -g prefix C-a
bind C-a send-prefix
```

---

## DeveloperWiki:Building in a clean chroot

**URL:** https://wiki.archlinux.org/title/DeveloperWiki:Building_in_a_clean_chroot

**Contents:**
- Convenience way
- Classic way
  - Setting up a chroot
    - Custom pacman.conf
  - Building in the chroot
    - Pre-install required packages
    - Passing arguments to makepkg
- Handling major rebuilds
- Tips and tricks
  - Build in tmpfs

Building in a clean chroot prevents missing dependencies in packages, whether due to unwanted linking or packages missing in the depends array in a PKGBUILD file. It also allows users to build a package for the stable repositories (core, extra) while having packages from core-testing or extra-testing installed.

To quickly build a package in a clean chroot without any further tinkering, one can use the helper scripts from the devtools package.

These helper scripts—for example, pkgctl build—should be called in the same directory where the PKGBUILD file is, just like with makepkg. For instance, extra-x86_64-build automatically sets up a chroot from a clean chroot matrix in /var/lib/archbuild, updates it, and builds a package for the extra repository. For multilib builds there is just multilib-build without an architecture. Consult the table below for information on which script to use when building for a specific repository and architecture.

The -c parameter resets the chroot matrix, which can be useful in case of breakage. It is not needed for building in a clean chroot.

The devtools package provides tools for creating and building within clean chroots. Install it if not done already.

To make a clean chroot, create a directory in which the chroot will reside. For example, $HOME/chroot.

Define the CHROOT variable:

Now create the chroot (the sub directory root is required because the $CHROOT directory will get other sub directories for clean working copies):

Edit ~/.makepkg.conf to set the packager name and any makeflags. Also adjust the mirrorlist in $CHROOT/root/etc/pacman.d/mirrorlist and enable the testing repositories in $CHROOT/root/etc/pacman.conf, if desired.

Alternatively, provide a custom pacman.conf and makepkg.conf with the following:

Firstly, make sure the base chroot ($CHROOT/root) is up to date:

Then, build a package by calling makechrootpkg in the directory containing its PKGBUILD file:

To build a package with dependencies unavailable from the repositories enabled in $CHROOT/root/pacman.conf, pre-install them to the working chroot with -I package:

To pass arguments to makepkg, list them after an end-of-options marker[dead link 2025-08-16—domain name not resolved]; e.g., to force a check():

The cleanest way to handle a major rebuild is to use the staging repositories. Build the first package against extra and push it to staging. Then rebuild all following packages against staging and push them there.

If you cannot use staging, you can build against custom packages using a command like this:

You can specify more than one package to be installed using multiple -I arguments.

A simpler, but dirtier way to handle a major rebuild is to install all built packages in the chroot, never cleaning it. Build the first package using:

And build all following packages using:

Running namcap (the -n argument) implies installing the package in the chroot. *-build also does this by default.

If the system has enough RAM, it is possible to specify a tmpfs for the devtools build scripts:

Just delete the chroot directory and its corresponding .lock file.

**Examples:**

Example 1 (unknown):
```unknown
pkgctl build
```

Example 2 (unknown):
```unknown
extra-x86_64-build
```

Example 3 (unknown):
```unknown
/var/lib/archbuild
```

Example 4 (unknown):
```unknown
multilib-build
```

---

## pacman/Tips and tricks

**URL:** https://wiki.archlinux.org/title/Improve_pacman_performance

**Contents:**
- Maintenance
  - Listing packages
    - In unused repositories
    - With version
    - With size
      - Individual packages
      - Packages and dependencies
    - By date
    - Not in a specified group, repository or meta package
    - Development packages

For general methods to improve the flexibility of the provided tips or pacman itself, see Core utilities and Bash.

See also System maintenance.

By default, repositories listed in pacman.conf are used for syncing, searching, installing and upgrading from them. This can be changed for more versatility, for example by using some repositories only for searching in them[1]:

See pacman.conf(5) § REPOSITORY SECTIONS.

You may want to get the list of installed packages with their version, which is useful when reporting bugs or discussing installed packages.

Figuring out which packages are largest can be useful when trying to free space on your hard drive. There are two options here: get the size of individual packages, or get the size of packages and their dependencies.

The following command will list all installed packages and their individual sizes:

To list package sizes with their dependencies,

To list the download size of several packages (leave packages blank to list all packages):

To list explicitly installed packages not in the meta package base nor package group xorg with size and description:

To list the packages marked for upgrade with their download size:

To list optional dependencies only:

To list the 20 last installed packages with expac, run:

or, with seconds since the epoch (1970-01-01 UTC):

List explicitly installed packages not in the base meta package:

List explicitly installed packages not in the base meta package or xorg package group:

List all installed packages unrequired by other packages, and which are not in the base meta package or xorg package group:

As above, but with descriptions:

List all installed packages that are not in the specified repository repo_name (multiple repositories can be checked at once):

List all installed packages that are in the repo_name repository (multiple repositories can be checked at once):

List all packages on the Arch Linux ISO that are not in the base meta package:

To list all development/unstable packages, run:

To obtain the list of the dependencies of a package, the simplest solution is reading the output of:

For automation, instead of the error-prone method of parsing pacman output, use expac:

To list explicitly-installed packages with their optional dependencies, run:

Alternatively, with expac:

To list them while omitting optional dependencies you have already installed, run:

To browse all installed packages with an instant preview of each package:

This uses fzf to present a two-pane view listing all packages with package info shown on the right.

Enter letters to filter the list of packages; use arrow keys (or Ctrl-j/Ctrl-k) to navigate; press Enter to see package info under less.

To browse all packages currently known to pacman (both installed and not yet installed) in a similar way, using fzf, use:

The navigational keybindings are the same, although Enter will not work in the same way.

This one might come in handy if you have found that a specific package uses a huge amount of space and you want to find out which files make up the most of that.

If your system has stray files not owned by any package (a common case if you do not use the package manager to install software), you may want to find such files in order to clean them up.

One method is to list all files of interest and check them against pacman:

Most systems will slowly collect several ghost files such as state files, logs, indexes, etc. through the course of usual operation.

pacreport from pacutils can be used to track these files and their associations via /etc/pacreport.conf (see pacreport(1) § FILES).

An example may look something like this (abridged):

Then, when using pacreport --unowned-files as the root user, any unowned files will be listed if the associated package is no longer installed (or if any new files have been created).

Additionally, aconfmgr (aconfmgr-gitAUR) allows tracking modified and orphaned files using a configuration script.

Orphans are packages that were installed as a dependency and are no longer required by any package.

They can accumulate on your system over time either due to uninstalling packages using pacman -R package instead of pacman -Rs package, installing packages as makedepends, or packages removing dependencies in newer versions.

For recursively removing orphans and their configuration files:

If no orphans were found, the output is error: argument '-' specified with empty stdin. This is expected as no arguments were passed to pacman -Rns. The error can be avoided by prefixing the second command with ifne(1) from the moreutils package.

If there is a package listed that you do not want to remove, it can be excluded from the list of orphans by marking it as explicitly installed:

In some cases the method above will not detect all possible unneeded packages. E.g. dependency cycles (also known as "circular dependencies"), excessive dependencies (fulfilled more than once), some non-explicit optionals etc.

To detect such packages:

If you want to remove all packages in the list at once, run the command without --print argument.

Sometimes there may be multiple packages providing same item. For example, there may be multiple packages which provide ttf-font. You may not want all such packages depending your preference.

To detect packages which provide same item:

Check the output and carefully remove redundant package which you do not require.

If it is ever necessary to remove all packages except the essentials packages, one method is to set the installation reason of the non-essential ones as dependency and then remove all unnecessary dependencies.

First, for all the packages "explicitly installed", change their installation reason to "installed as a dependency":

Then, change the installation reason to "explicitly installed" of only the essential packages, those you do not want to remove, in order to avoid targeting them:

Finally, follow the instructions in #Removing unused packages (orphans) to remove all packages that are "installed as a dependency".

Dependencies are alphabetically sorted and doubles are removed.

Alternatively, with expac:

To list configuration files tracked by pacman as susceptible of containing user changes (i.e. files listed in the PKGBUILD backup array) and having received user modifications, use the following command:

Running this command with root permissions will ensure that files readable only by root (such as /etc/sudoers) are included in the output.

This can be used when doing a selective system backup or when trying to replicate a system configuration from one machine to another.

The following command can be used to back up the local pacman database:

Store the backup pacman database file on one or more offline media, such as a USB stick, external hard drive, or CD-R.

The database can be restored by moving the pacman_database.tar.bz2 file into the / directory and executing the following command:

When maintainers update packages, commits are often commented in a useful fashion. Users can quickly check these from the command line by installing pacologAUR. This utility lists recent commit messages for packages from the official repositories or the AUR, by using pacolog package.

Alternative ways of getting and restoring packages.

This article or section is a candidate for merging with #Custom local repository.

To download packages, or groups of packages:

Pacman, which will reference the host installation by default, will not properly resolve and download existing dependencies. In cases where all packages and dependencies are wanted, it is recommended to create a temporary blank DB and reference it with --dbpath:

Then you can burn the "Packages" directory to an optical disc (e.g. CD, DVD) or transfer it to a USB flash drive, external HDD, etc.

For an optical disc drive:

For a USB flash drive, hard disk drive, etc.:

2. Edit pacman.conf and add this repository before the other ones (e.g. extra, core, etc.). This is important. Do not just uncomment the one on the bottom. This way it ensures that the files from the CD/DVD/USB take precedence over those in the standard repositories:

3. Finally, synchronize the pacman database to be able to use the new repository:

Use the repo-add script included with pacman to generate a database for a personal repository. Use repo-add --help for more details on its usage. A package database is a tar file, optionally compressed. Valid extensions are .db or .files followed by an archive extension of .tar, .tar.gz, .tar.bz2, .tar.xz, .tar.zst, or .tar.Z. The file does not need to exist, but all parent directories must exist.

To add a new package to the database, or to replace the old version of an existing package in the database, run:

The database and the packages do not need to be in the same directory when using repo-add, but keep in mind that when using pacman with that database, they should be together. Storing all the built packages to be included in the repository in one directory also allows to use shell glob expansion to add or update multiple packages at once:

If you are looking to support multiple architectures then precautions should be taken to prevent errors from occurring. Each architecture should have its own directory tree:

The repo-add executable checks if the package is appropriate. If this is not the case you will be running into error messages similar to this:

repo-remove is used to remove packages from the package database, except that only package names are specified on the command line.

Once the local repository database has been created, add the repository to pacman.conf for each system that is to use the repository. An example of a custom repository is in pacman.conf. The repository's name is the database filename with the file extension omitted. In the case of the example above the repository's name would simply be repo. Reference the repository's location using a file:// URL, or via HTTP using http://localhost/path/to/directory.

If willing, add the custom repository to the list of unofficial user repositories, so that the community can benefit from it.

See Package proxy cache.

To recreate a package from the file system, use fakepkgAUR. Files from the system are taken as they are, hence any modifications will be present in the assembled package. Distributing the recreated package is therefore discouraged; see ABS and Arch Linux Archive for alternatives.

Keeping a list of all explicitly installed packages can be useful to backup a system or quicken the installation of a new one:

To keep an up-to-date list of explicitly installed packages (e.g. in combination with a versioned /etc/), you can set up a hook. Example:

To install packages from a previously saved list of packages, while not reinstalling previously installed packages that are already up-to-date, run:

However, it is likely foreign packages such as from the AUR or installed locally are present in the list. To filter out from the list the foreign packages, the previous command line can be enriched as follows:

Eventually, to make sure the installed packages of your system match the list and remove all the packages that are not mentioned in it:

If you are suspecting file corruption (e.g. by software/hardware failure), but are unsure if files were corrupted, you might want to compare with the hash sums in the packages. This can be done with pacutils:

For recovery of the database see #Restore pacman's local database. The mtree files can also be extracted as .MTREE from the respective package files.

To reinstall all native packages, use:

Foreign (AUR) packages must be reinstalled separately; you can list them with pacman -Qqm.

Pacman preserves the installation reason by default.

See pacman/Restore local database.

If you have managed to mess up an Arch install with broken packages, it is possible to re-install all the packages and hopefully get it back up and working again (assuming the root of the broken install is mounted in /brokenArch)

paccat is a small utility that finds which package contains a given file, downloads it and then prints the contents. This can be used to read specific files, restore changed files back to their initial state, and extract files without installing the package.

For example, if you want to see the contents of /etc/systemd/logind.conf supplied within the systemd package:

Or if you want to see the contents of archive.h supplied by any package:

bsdtar can also be used to show the contents:

Or you can use vim to browse the archive:

Already running processes do not automatically notice changes caused by updates. Instead, they continue using old library versions. That may be undesirable, due to potential issues related to security vulnerabilities or other bugs, and version incompatibility.

Processes depending on updated libraries may be found using either htop, which highlights the names of the affected programs, or with a snippet based on lsof, which also prints the names of the libraries:

This solution will only detect files, that are normally kept opened by running processes, which basically limits it to shared libraries (.so files). It may miss some dependencies, like those of Java or Python applications.

Many packages install documentation and translations in several languages. Some programs are designed to remove such unnecessary files, such as localepurgeAUR, which runs after a package is installed to delete the unneeded locale files. A more preemptive approach is provided through the NoExtract directive in /etc/pacman.conf, which prevent these files from ever being installed.

To prevent the installation of all translations for help files, except for the C locale, add:

To prevent the installation of all the HTML documentation, add:

To prevent the installation of the various locales, except the required ones, add:

To prevent the installation of the translated man pages, add:

To prevent the installation of the language files in vim-runtime, add:

To prevent the installation of all but English content in Qt applications, add:

To prevent the installation of all but English content in Chromium and Electron applications, add:

To prevent the installation of English help files in LibreOffice, add:

To prevent the installation of all but English content from OnlyOffice, add:

To prevent the installation of all but the English iBus dictionary for emojis, add:

When trying to install a package from a bad connection (e.g. a train using a cell phone), use the --disable-download-timeout option to lessen the chance of receiving errors such as:

When downloading packages pacman uses the mirrors in the order they are in /etc/pacman.d/mirrorlist. The mirror which is at the top of the list by default however may not be the fastest for you. To select a faster mirror, see Mirrors.

Pacman's speed in downloading packages can also be improved by using parallel downloads, a major feature request (FS#20056) added with pacman 6.0.0. It is enabled by default since pacman 7.0.0.

Instead of pacman's built-in file downloader, a separate application can also be used to download packages.

In all cases, make sure you have the latest pacman before doing any modifications.

Powerpill is a pacman wrapper that uses parallel and segmented downloading to try to speed up downloads for pacman.

This is also very handy if you need more powerful proxy settings than pacman's built-in capabilities.

To use wget, first install the wget package then modify /etc/pacman.conf by uncommenting the following line in the [options] section:

Instead of uncommenting the wget parameters in /etc/pacman.conf, you can also modify the wget configuration file directly (the system-wide file is /etc/wgetrc, per user files are $HOME/.wgetrc).

aria2 is a lightweight download utility with support for resumable and segmented HTTP/HTTPS and FTP downloads. aria2 allows for multiple and simultaneous HTTP/HTTPS and FTP connections to an Arch mirror, which should result in an increase in download speeds for both file and package retrieval.

Install aria2, then edit /etc/pacman.conf by adding the following line to the [options] section:

See aria2c(1) § OPTIONS for used aria2c options.

There are other downloading applications that you can use with pacman. Here they are, and their associated XferCommand settings:

**Examples:**

Example 1 (unknown):
```unknown
pacman.conf
```

Example 2 (unknown):
```unknown
/etc/pacman.conf
```

Example 3 (unknown):
```unknown
...
[multilib]
Usage = Sync Search
...
```

Example 4 (unknown):
```unknown
pacman -Sg group
```

---

## AUR helpers

**URL:** https://wiki.archlinux.org/title/AUR_helper

**Contents:**
- Legend
- Comparison tables
  - Search and download
  - Search and build
  - Pacman wrappers
- Graphical
- Maintenance
- Other
- See also

AUR helpers automate usage of the Arch User Repository. In particular, they may automate the following tasks:

Pacman only handles updates for pre-built packages in its repositories. AUR packages are redistributed in form of PKGBUILDs and need an AUR helper to automate the re-build process. However, keep in mind that a rebuild of a package may be required when its shared library dependencies are updated, not only when the package itself is updated.

The #Comparison tables columns have the following meaning:

---

## PKGBUILD

**URL:** https://wiki.archlinux.org/title/Optdepends

**Contents:**
- Package name
  - pkgbase
  - pkgname
- Version
  - pkgver
  - pkgrel
  - epoch
- Generic
  - pkgdesc
  - arch

This article discusses variables definable by the maintainer in a PKGBUILD. For information on the PKGBUILD functions and creating packages in general, refer to Creating packages. Also read PKGBUILD(5).

A PKGBUILD is a Bash script containing the build information required by Arch Linux packages.

Packages in Arch Linux are built using the makepkg utility. When makepkg is run, it searches for a PKGBUILD file in the current directory and follows the instructions therein to either compile or otherwise acquire the files to build a package archive—pkgname.pkg.tar.zst. The resulting package contains binary files and installation instructions, readily installable with pacman.

Mandatory variables are pkgname, pkgver, pkgrel, and arch. license is not strictly necessary to build a package, but is recommended for any PKGBUILD shared with others, as makepkg will produce a warning if not present.

It is a common practice to define the variables in the PKGBUILD in the same order as given here. However, it is not mandatory.

See the .proto files in the /usr/share/pacman/ directory as examples.

When building regular packages, this variable should not be explicitly declared in the PKGBUILD: its value defaults to that of #pkgname.

When building a split package, this variable can be used to explicitly specify the name to be used to refer to the group of packages in the output of makepkg and in the naming of source-only tarballs. The value is not allowed to begin with a hyphen. If not specified, the value will default to the first element in the pkgname array.

All options and directives for split packages default to the global values given in the PKGBUILD. Nevertheless, the following ones can be overridden within each split package’s packaging function: #pkgdesc, #arch, #url, #license, #groups, #depends, #optdepends, #provides, #conflicts, #replaces, #backup, #options, #install, and #changelog.

Either the name of the package, e.g. pkgname=foo, or, for split packages, an array of names, e.g. pkgname=(foo bar). Package names should only consist of lowercase alphanumerics and the following characters: @._+- (at symbol, dot, underscore, plus, hyphen). Names are not allowed to start with hyphens or dots. For the sake of consistency, pkgname should match the name of the source tarball of the software: for instance, if the software is in foobar-2.5.tar.gz, use pkgname=foobar.

The version of the package. This should be the same as the version published by the author of the upstream software. It can contain letters, numbers, periods and underscores, but not a hyphen (-). If the author of the software uses one, replace it with an underscore (_). If the pkgver variable is used later in the PKGBUILD, then the underscore can easily be substituted for a hyphen, e.g. source=("${pkgname}-${pkgver//_/-}.tar.gz").

The release number. This is usually a positive integer number that allows to differentiate between consecutive builds of the same version of a package. As fixes and additional features are added to the PKGBUILD that influence the resulting package, the pkgrel should be incremented by 1. When a new version of the software is released, this value must be reset to 1. In exceptional cases other formats can be found in use, such as major.minor.

Used to force the package to be seen as newer than any previous version with a lower epoch. This value is required to be a non-negative integer; the default is 0. It is used when the version numbering scheme of a package changes (or is alphanumeric), breaking normal version comparison logic. For example:

See pacman(8) for more information on version comparisons.

The description of the package. This is recommended to be 80 characters or less and should not include the package name in a self-referencing way, unless the application name differs from the package name. For example, use pkgdesc='Text editor for X11' instead of pkgdesc='Nedit is a text editor for X11'.

Also it is important to use keywords wisely to increase the chances of appearing in relevant search queries.

An array of architectures that the PKGBUILD is intended to build and work on. Arch officially supports only x86_64, but other projects may support other architectures. For example, Arch Linux 32 provides support for i686 and pentium4, and Arch Linux ARM provides support for armv7h (armv7 hardfloat) and aarch64 (armv8 64-bit).

There are two types of values the array can use:

The target architecture can be accessed with the variable CARCH during a build.

The URL of the official site of the software being packaged.

This article or section is a candidate for merging with Arch package guidelines#licenses.

This article or section needs expansion.

The license under which the software is distributed. Arch Linux uses SPDX license identifiers. Each license must have a corresponding entry in /usr/share/licenses/.

For common licenses (like GPL-3.0-or-later), package licenses delivers all the corresponding files. The package is installed by default, as it is a dependency of base meta package, and the files may be found in /usr/share/licenses/spdx/. Simply refer to the license using its SPDX license identifier from the list of SPDX identifiers.

License families like BSD or MIT are, strictly speaking, not a single license and each instance requires a separate license file. In license variable refer to them using a common SPDX identifier (e.g. BSD-3-Clause or MIT), but then provide the corresponding file as if it was a custom license.

For custom licenses the identifier should be either LicenseRef-license-name or custom:license-name, if they are not covered by the common families mentioned above. The corresponding license text must be placed in directory /usr/share/licenses/pkgname. To install the file a following code snippet may be used in package() section:

Combining multiple licenses or adding exceptions should follow the SPDX syntax. For example a package released under either GNU/GPL 2.0 or GNU/LGPL 2.1 could use 'GPL-2.0-or-later OR LGPL-2.1-or-later', a package released under Apache 2.0 with LLVM exception would use 'Apache-2.0 WITH LLVM-exception' and a package released with part under the BSD 3 clause, others under GNU/LGPL 2.1 and some under GNU/GPL 2.0 would use 'BSD-3-Clause AND LGPL-2.1-or-later AND GPL-2.0-or-later'[2]. Note that this must be a single string, so the entire expression has to be enclosed in quotes. As for November 2023 SPDX list of exceptions is limited, so usually the custom license route must be used.

If issues are encountered with SPDX identifiers, during the transitional period using old identifiers —names of the directories in /usr/share/licenses/common— is acceptable.

See also Nonfree applications package guidelines.

Additional information and perspectives on free and open source software licenses may be found on the following pages:

The group the package belongs in. For instance, when installing plasma, it installs all packages belonging in that group.

An array of packages that must be installed for the software to build and run. Dependencies defined inside the package() function are only required to run the software.

Version restrictions can be specified with comparison operators, e.g. depends=('foobar>=1.8.0'); if multiple restrictions are needed, the dependency can be repeated for each, e.g. depends=('foobar>=1.8.0' 'foobar<2.0.0').

This article or section is a candidate for merging with Arch package guidelines.

The depends array should list all direct first level dependencies even when some are already declared transitively. For instance, if a package foo depends on both bar and baz, and the bar package depends in turn on baz too, it will ultimately lead to undesired behavior if bar stops pulling in baz. Pacman will not enforce the installation of baz on systems which newly install the foo package, or have cleaned up orphans, and foo will crash at runtime or otherwise misbehave.

In some cases this is not necessary and may or may not be listed, for example glibc cannot be uninstalled as every system needs some C library, or python for a package that already depends on another python- module, as the second module must per definition depend on python and cannot ever stop pulling it in as a dependency.

Dependencies should normally include the requirements for building all optional features of a package. Alternatively, any feature whose dependencies are not included should be explicitly disabled via a configure option. Failure to do this can lead to packages with "automagic dependencies" build-time optional features that are unpredictably enabled due to transitive dependencies or unrelated software installed on the build machine, but which are not reflected in the package dependencies.

If the dependency name appears to be a library, e.g. depends=(libfoobar.so), makepkg will try to find a binary that depends on the library in the built package and append the soname version needed by the binary. Manually appending the version disables automatic detection, e.g. depends=('libfoobar.so=2').

An array of packages that are only required to build the package. The minimum dependency version can be specified in the same format as in the depends array. The packages in the depends array are implicitly required to build the package, they should not be duplicated here.

An array of packages that the software depends on to run its test suite, but are not needed at runtime. Packages in this list follow the same format as depends. These dependencies are only considered when the check() function is present and is to be run by makepkg.

An array of packages that are not needed for the software to function, but provide additional features. This may imply that not all executables provided by a package will function without the respective optdepends.[3] If the software works on multiple alternative dependencies, all of them can be listed here, instead of the depends array.

A short description of the extra functionality each optdepend provides should also be noted:

An array of additional packages that the software provides the features of, including virtual packages such as cron or sh and all external shared libraries. Packages providing the same item can be installed side-by-side, unless at least one of them uses a conflicts array.

An array of packages that conflict with, or cause problems with the package, if installed. All these packages and packages providing this item will need to be removed. The version properties of the conflicting packages can also be specified in the same format as the depends array.

Note that conflicts are checked against pkgname as well as names specified in the provides array. Hence, if your package provides a foo feature, specifying foo in the conflicts array will cause a conflict between your package and all other packages that contain foo in their provides array (i.e., there is no need to specify all those conflicting package names in your conflicts array). Let us take a concrete example:

When packages provide the same feature via the provides array, there is a difference between explicitly adding the alternative package to the conflicts array and not adding it. If the conflicts array is explicitly declared the two packages providing the same feature will be considered as alternative; if the conflicts array is missing the two packages providing the same feature will be considered as possibly cohabiting. Packagers should always ignore the content of the provides variable in deciding whether to declare a conflicts variable or not.

An array of obsolete packages that are replaced by the package, e.g. wireshark-qt uses replaces=('wireshark'). When syncing, pacman will immediately replace an installed package upon encountering another package with the matching replaces in the repositories. If providing an alternate version of an already existing package or uploading to the AUR, use the conflicts and provides arrays, which are only evaluated when actually installing the conflicting package.

An array of files that can contain user-made changes and should be preserved during upgrade or removal of a package, primarily intended for configuration files in /etc. If these files are unchanged from how they ship with the package, they will be removed or replaced as normal files during upgrade or removal.

Files in this array should use relative paths without the leading slash (/) (e.g. etc/pacman.conf, instead of /etc/pacman.conf). The backup array does not support empty directories or wildcards such as "*".

When updating, new versions may be saved as file.pacnew to avoid overwriting a file which already exists and was previously modified by the user. Similarly, when the package is removed, user-modified files will be preserved as file.pacsave unless the package was removed with the pacman -Rn command.

See also Pacnew and Pacsave files.

This array allows overriding some of the default behavior of makepkg, defined in /etc/makepkg.conf. To set an option, include the name in the array. To disable an option, place an ! before it.

The full list of the available options can be found in PKGBUILD(5) § OPTIONS AND DIRECTIVES.

The name of the .install script to be included in the package.

pacman has the ability to store and execute a package-specific script when it installs, removes or upgrades a package. The script contains the following functions which run at different times:

Each function is run chrooted inside the pacman install directory. See this thread.

The name of the package changelog. To view changelogs for installed packages (that have this file):

An array of files needed to build the package. It must contain the location of the software source, which in most cases is a full HTTP or FTP URL. The previously set variables pkgname and pkgver can be used effectively here; e.g. source=("https://example.com/${pkgname}-${pkgver}.tar.gz").

Files can also be supplied in the same directory where the PKGBUILD is located, and their names added to this array. Before the actual build process starts, all the files referenced in this array will be downloaded or checked for existence, and makepkg will not proceed if any is missing.

.install files are recognized automatically by makepkg and should not be included in the source array. Files in the source array with extensions .sig, .sign, or .asc are recognized by makepkg as PGP signatures and will be automatically used to verify the integrity of the corresponding source file.

An array of files listed under source, which should not be extracted from their archive format by makepkg. This can be used with archives that cannot be handled by /usr/bin/bsdtar or those that need to be installed as-is. If an alternative unarchiving tool is used (e.g. lrzip), it should be added in the makedepends array and the first line of the prepare() function should extract the source archive manually; for example:

Note that while the source array accepts URLs, noextract is just the file name portion:

To extract nothing, consider the following:

An array of PGP fingerprints. If used, makepkg will only accept signatures from the keys listed here and will ignore the trust values from the keyring. If the source file was signed with a subkey, makepkg will still use the primary key for comparison.

Only full fingerprints are accepted. They must be uppercase and must not contain whitespace characters.

Please read makepkg#Signature checking for more information.

These variables are arrays whose items are checksum strings that will be used to verify the integrity of the respective files in the source array. Insert SKIP for a particular file, and its checksum will not be tested.

The checksum type and values should always be those provided by upstream, such as in release announcements. When multiple types are available, the strongest checksum is to be preferred (in order from most to least preferred): b2, sha512, sha384, sha256, sha224, sha1, md5, ck. This best ensures the integrity of the downloaded files, from upstream announcement to package building.

The values for these variables can be auto-generated by makepkg's -g/--geninteg option, then commonly appended with makepkg -g >> PKGBUILD. The updpkgsums(8) command from pacman-contrib is able to update the variables wherever they are in the PKGBUILD. Both tools will use the variable that is already set in the PKGBUILD, or fall back to sha256sums if none is set.

The file integrity checks to use can be set up with the INTEGRITY_CHECK option in /etc/makepkg.conf. See makepkg.conf(5).

An array of BLAKE2b checksums with digest size of 512 bits.

An array of SHA-2 checksums with digest sizes 512, 384, 256 and 224 bits, respectively. sha256sums is the most common of them.

An array of 160-bit SHA-1 checksums of the files listed in the source array.

An array of 128-bit MD5 checksums of the files listed in the source array.

An array CRC32 checksums (from UNIX-standard cksum) of the files listed in the source array.

**Examples:**

Example 1 (unknown):
```unknown
pkgname.pkg.tar.zst
```

Example 2 (unknown):
```unknown
shellcheck --shell=bash --exclude=SC2034,SC2154,SC2164 PKGBUILD
```

Example 3 (unknown):
```unknown
makepkg.conf
```

Example 4 (unknown):
```unknown
/usr/share/pacman/
```

---

## List of games

**URL:** https://wiki.archlinux.org/title/List_of_games

**Contents:**
- Action and adventure
- Arcade
- Casual games
- Chess simulators
- Digital collectible card game (DCCG)
- Education
- Interactive fiction
- Massively multiplayer online games (MMO)
- Minecraft and Minecraft-like
- Platformer

This page strives to list all games which have a package available in the official repositories or the AUR. There are many more Linux games available, which are not packaged. See Gaming#Getting games for ways to obtain them.

For more about running games, related system configuration tips, see Gaming. For an up to date selection of games available in the AUR, try checking the AUR 'game' keyword.

See also Wikipedia:Interactive fiction#Development systems.

See also Wikipedia:List of massively multiplayer online games and Wikipedia:Comparison of massively multiplayer online role-playing games.

See also Wikipedia:Chronology of roguelike video games.

---

## Init package guidelines

**URL:** https://wiki.archlinux.org/title/Init_package_guidelines

**Contents:**
- Package naming
- Architecture
- Depends
- Example packages

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

This document covers standards and guidelines on writing PKGBUILDs for init scripts. eg openrcAUR

For init scripts, use modulename-init.

example bluetooth-openrcAUR jellyfin-runitAUR

A init script should be architecture-independent.

all scripts should depend on it's init ie apparmor-openrcAUR requires openrc for it to work

**Examples:**

Example 1 (unknown):
```unknown
modulename-init
```

---

## Lisp package guidelines

**URL:** https://wiki.archlinux.org/title/Lisp_package_guidelines

**Contents:**
- Directory structure and naming
- ASDF
- Lisp-specific packaging
- Things you, the reader, can do

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

At the moment, there are relatively few Lisp packages available in the Arch repositories. This means that at some point or another, more will likely appear. It is useful, therefore, to figure out now, while there are few packages, how they should be packaged.

There is at least one package in the base repository (libgpg-error) that includes lisp files, which are placed in /usr/share/common-lisp/source/gpg-error. In keeping with this, other lisp packages should also place their files in /usr/share/common-lisp/source/pkgname.

The package directory should be the name of the lisp package, not what it is called in Arch's official repositories (or AUR). This applies even to single-file packages.

For example, a Lisp package called "cl-ppcre" should be called cl-ppcre in AUR and reside in /usr/share/common-lisp/source/cl-ppcre. A Lisp package called "alexandria" should be called cl-alexandria in AUR and reside in /usr/share/common-lisp/source/alexandria.

Try to avoid the usage of Lisp's ASDF-Install as a means of installing these system-wide packages.

ASDF itself may be necessary or helpful as a means of compiling and/or loading packages. In that case, it is suggested that the directory used for the central registry (the location of all of the symlinks to *.asd) be /usr/share/common-lisp/systems/.

However, I have observed problems with doing the compilation with asdf as a part of the package compilation process. However, it does work during an install, through use of a package.install file. Such a file might look like this:

Of course, for this example to work, there needs to be a symlink to package.asd in the asdf system directory. During package compilation, a stanza such as this will do the trick...

where $_lispdir is $pkgdir/usr/share/common-lisp. By linking to a relative, rather than an absolute, path, it is possible to guarantee that the link will not break post-install.

When possible, do not make packages specific to a single lisp implementation; try to be as cross-platform as the package itself will allow. If, however, the package is specifically designed for a single lisp implementation (i.e., the developers have not gotten around to adding support for others yet, or the package's purpose is specifically to provide a capability that is built in to another lisp implementation), it is appropriate to make your Arch package lisp-specific.

If the package is implementation-independent, it should depend on common-lisp. If the package supports multiple but not all implementations, you could (a) not make your package depend on *any* lisp and include a statement in the package.install file telling folks to make sure they have a supported lisp installed (not ideal), or (b) Take direction from the sbcl PKGBUILD and include a conditional statement to figure out which lisp is needed (which is hackish and, again, far from ideal). Other ideas are welcome.

Also note that if ASDF is needed to install/compile/load the package, things could potentially get awkward as far as dependencies go. SBCL and CMUCL come with asdf installed, but clisp does not (but there is an AUR package).

People currently maintaining lisp-specific packages that do not need to be lisp-specific should consider doing at least one of the following:

**Examples:**

Example 1 (unknown):
```unknown
/usr/share/common-lisp/source/gpg-error
```

Example 2 (unknown):
```unknown
/usr/share/common-lisp/source/pkgname
```

Example 3 (unknown):
```unknown
/usr/share/common-lisp/source/cl-ppcre
```

Example 4 (unknown):
```unknown
cl-alexandria
```

---

## Open Sound System

**URL:** https://wiki.archlinux.org/title/Open_Sound_System

**Contents:**
- Installation
- Testing
- Volume control mixer
  - Color definitions
  - Saving mixer levels
  - Other mixers
- Configuring applications for OSS
  - GStreamer-based
  - OpenAL-based
  - Audacity

The Open Sound System (OSS) was the original sound system for Linux.

It was superseded by the Advanced Linux Sound Architecture (ALSA), which has a number of advantages over OSS:

Install the ossAUR package, or the package with non-free drivers oss-nonfreeAUR.

This will install the OSS, run the OSS install script (temporarily disabling the ALSA modules) and install the OSS kernel modules. Since ALSA is enabled by default, you need to disable it so it does not conflict with OSS. You can do this by blacklisting the soundcore module.

After blacklisting the module, you can enable oss.service to start at boot.

To start using OSS without needing to reboot, check if any ALSA modules are still loaded (ALSA modules start with "snd"):

Remove the ALSA modules as follows:

To completely remove ALSA from your system, you can compile a custom kernel and disable ALSA in its configuration. See Gentoo:ALSA#Kernel for the details.

This article or section is out of date.

In case you are not part of the audio group, add yourself and relogin for the changes to take effect:

In case OSS is not able to detect your card when starting it, run:

You should be able to hear music during the test process. If there is no audio, try to adjust the volume or refer to the #Troubleshooting section.

If you want to hear sounds from more than one application simultaneously, you need vmix, OSS's software mixer.

Check that vmix is enabled by running:

You should see a line like vmix0-enable ON|OFF (currently ON). If you do not see any lines beginning with vmix, it probably means that vmix has not been attached to your sound device. To attach vmix, issue the command:

where device is your sound device, e.g. /dev/oss/oss_envy240/pcm0.

To avoid having to issue this command manually in the future, you can add it to /usr/lib/oss/soundon.user, as suggested by the official documentation.

If you get a "Device or resource busy" error, you need to add vmix_no_autoattach=1 to /usr/lib/oss/conf/osscore.conf and then reboot.

See which devices are detected by running:

You should be able to see your devices listed under Device Objects or Audio Devices. If the device that you want to use is not at the top of one of these sections, you have to edit /usr/lib/oss/etc/installed_drivers and place the driver for your device at the very top. It may be required to restart OSS:

If this does not work, comment all drivers listed except the ones for your device.

To control the volume of various devices, mixers levels will need to be set. There are two mixers:

For high definition (HD) audio, ossxmix will color jack configurations by their pre-defined jack colors:

Mixer levels are saved when you shut off your computer. If you want to save the mixer level immediately, execute as root:

savemixer can be used to write mixer levels to a file with the -f switch and restore by the -L switch.

Other mixers that have support for OSS:

If you have problems with applications that use GStreamer for audio, you can try removing pulseaudio and installing the gst-plugins-good package which is needed by oss4sink and oss4src.

By default OpenAL uses ALSA. To change this, simply define the usage of OSS in /etc/openal/alsound.conf:

If Audacity starts, but it complains that it cannot open the device or simply does not play anything, then you may be using vmix which prevents Audacity from having exclusive access to your sound device. To fix this, before running Audacity, run:

You can restore vmix after closing Audacity with:

By default, Gajim uses aplay -q to play a sound. For OSS you can change it to the equivalent ossplay -qq by going to Edit > Preferences > Advanced, opening the Advanced Configuration Editor and modifying the soundplayer variable accordingly.

To use MOC with OSS v4.1 you must change OSSMixerDevice to /dev/ossmix in your configuration file (located in ~/.moc). For issues with the interface try changing the OSSMixerChannel by pressing w in mocp (to change to the sofware mixer).

MPD is configured through /etc/mpd.conf or ~/.mpdconf. Check both of these files, looking for something that looks like:

If you find an uncommented (the lines do not begin with #'s) ALSA configuration like the one above, comment all of it out, or delete it, and add the following:

Further configuration might not be necessary for all users. However, if you experience issues (in that MPD does not work properly after it has been restarted), or if you like having specific (i.e. more user-configured, less auto-configured) configuration files, the audio output for OSS can be more specifically configured by finding the card identifier:

Look for the line that says something similar to /dev/dsp -> /dev/oss/CARD_IDENTIFIER/pcm0. Take note of what your CARD_IDENTIFIER is, and add these lines to your OSS audio_output in your MPD configuration file:

See also: Music Player Daemon#System-wide configuration.

If you are using a GUI (SMplayer, GNOME MPlayer, etc.) you can select OSS as the default output in the settings dialogs. If you use MPlayer from the command-line, you should specify the sound output:

If you do not want to bother typing it over and over again add ao=oss to your configuration file (at ~/.mplayer/config).

See also: MPlayer#Configuration.

You can select OSS as the default output in the audio settings.

To set OSS support in Wine start:

and go to the Audio tab and select the OSS Driver.

See also: Wine#Sound.

This article or section is a candidate for merging with #Keyboard volume control.

The volume lever of ossxmix is very small, making it difficult to finely control the volume.

Run ossmix to find the control you want to control (refer to ossxmix), this example is codec1.jack.green.front.

Bind the following commands to the keyboard shortcuts of the desktop environment.

Increase the volume by 1 (the volume can be between 0 and 100):

Decrease the volume by 1 (The -- is needed on some systems so that the -1 will not be mistaken for a parameter.):

Then you can easily control the volume.

An easy way to mute/unmute and increase/decrease the volume is to use the ossvol script.

Download the script and place it at /usr/bin/ossvol.

Once you installed it, type:

to see the available commands.

If you want to use multimedia keys with ossvol, map the following commands to your volume keys: XF86AudioRaiseVolume, XF86AudioLowerVolume and XF86AudioMute:

To mute/unmute the volume:

Changing the output sample rate is not obvious at first. Sample rates can only be changed by root and vmix must be unused by any programs when a change is requested. Before you follow any of these steps, ensure you are going through a receiver/amplifier and using quality speakers and not simply computer speakers. If you are only using computer speakers, do not bother changing anything here as you will not notice a difference.

By default the sample rate is 48000hz. There are several conditions in which you may want to change this. This all depends on your usage patterns. You want the sample rate you are using to match the media you use the most. If your computer has to change the sampling rate of the media to suit the hardware it is likely, though not guaranteed, that you will have a loss in audio quality. This is most noticeable in down sampling (ie. 96000hz → 48000hz). There is an article about this issue in Stereophile which was discussed on Apple's CoreAudio API mailing list if you wish to learn more about this issue.

This article or section is out of date.

Some example sample rates:

To check what your sample rate is currently set to, run:

You are likely to see vmix0-rate <decimal value> (currently 48000) (Read-only).

This article or section is out of date.

If you do not see a vmix0-rate (or vmix1-rate, etc.) being outputted, then it probably means that vmix is disabled. In that case, OSS will use the rate requested by the program which uses the device, so this section does not apply. Exception to this are Envy24 (and Envy24HT) cards that have a special setting envy24.rate which has a similar function (see the oss_envy24 manpage).

To change your sample rate:

and make it executable.

vmix is a virtual mixer audio that mixes multiple audio streams but can reduce the sound quality. Simply unchecking vmix-things in OSS Mixer GUI does not always work.

Turn off COOKEDMODE to disable format conversions for all applications and devices.

Restart oss.service or your computer ifyou encounter errors.

After that you can still control the volume via ossmix or ossxmix.

Create an application launcher file named ossxmix.desktop in you local application launchers directory (~/.local/share/applications/ with:

To have it autostart with your system, add it to the list in System Settings > System Administration > Startup and Shutdown > Autostart.

As root create a file /usr/local/bin/ossxmix_bg with the following content:

Then go to System > Preferences > Start Up Applications and:

See upstream article on Recording sound output of a program.

OSS does not automatically support suspend, it must be manually stopped prior to suspending or hibernating and restarted afterwards.

OSS provides soundon and soundoff to enable and disable OSS, although they only stop OSS if all processes that use sound are terminated first.

The following script is a rather basic method of automatically unloading OSS prior to suspending and reloading afterwards.

Save the contents of this script (as root) into /usr/lib/systemd/system-sleep/50osssound.sh and make it executable.

With this, all your applications should be fine.

When running osstest, the first test passes for the first channel, but not for the stereo or right channel, it sounds distorted/hisses. If this is what your sound is like, then it is set to the wrong output.

The left sounded good, the right and stereo were the distorted ones.

Let the test continue until you get a working output:

If this passed the test on all left, right and stereo, proceed to next step.

For the command to change the default output see upstream's wiki article. Change it to what works for you, for example:

For surround sound (4.0-7.1) choose dsp_multich, for only 2 channels, dsp is sufficient. See this for all available devices.

This article or section is being considered for removal.

You can instruct alsa-lib to use OSS as its audio output system. This works as a sort of ALSA emulation.

Note, however, that this method may introduce additional latency in your sound output, and that the emulation is not complete and does not work with all applications. It does not work, for example, with programs that try to detect devices using ALSA.

So, as most applications support OSS directly, use this method only as a last resort.

In the future, more complete methods may be available for emulating ALSA, such as libsalsa and cuckoo.

If something is not working, there is a possibility that some of your OSS settings are driver specific or just wrong for your driver.

For example, the setting:

in oss_ich.conf turns on jack-sense (which is responsible for recognizing plugged headphones and muting the speaker). Other settings for jack-sense can be found in hdaudio.conf where you have to change the hdaudio_jacksense variable.

If you have a HD Audio sound device, it is very likely that you will have to adjust some mixer settings before your sound works.

HD Audio devices are very powerful in the sense that they can contain a lot of small circuits (called widgets) that can be adjusted by software at any time. These controls are exposed to the mixer, and they can be used, for example, to turn the earphone jack into a sound input jack instead of a sound output jack.

However, there are also bad side effects, mainly because the HD Audio standard is more flexible than it perhaps should be, and because the vendors often only care to get their official drivers working.

When using HD Audio devices, you often find disorganized mixer controls, that do not work at all by default, and you are forced to try every mixer control combination possible, until it works.

Open ossxmix and try to change every mixer control in the middle area, that contains the sound card specific controls, as explained in the #Volume control mixer section.

You will probably want to setup a program to record/play continuously in the background (e.g. ossrecord - | ossplay - for recording or osstest -lV for playing), while changing mixer settings in ossxmix in the foreground.

If you hear various cracks or strange noises in Totem during playback, you can try using another backend such as FFmpeg. This will not fix the issue that somehow pops up in GStreamer when playing MMS streams but it will give you the option to play it with good sound quality. Playing it in MPlayer is simple:

By default, OSS plays back the microphone through the speakers. To disable this in ossxmix find the "Misc" section and uncheck every "input-mix-mute" box.

The factual accuracy of this article or section is disputed.

OSS provides a "generic" codec driver that should be able to parse 99% of all HDAudio codecs.

If the device are not listed in the oss_hdaudio.c source file, add them to it, recompile and start the drivers.

To find the device/vendor IDs for "Multimedia controller" device class, do the following:

In this example, "Vendor ID" is "8086" and "Device ID" is "a170".

Change 5 lines of code in the source code, taking "the latest source package"(currently "oss-v4.2-build2020-src-gpl.tar.bz2") as an example:

It is better to modify the existing "Controller" ("PCH_C" in this example), appending a new line of code may fail. It does not matter if it is PCH_C.

The last line of code is a bit complicated. This example is an ALC1150 sound card chip. The "Vendor_id" of "ALC1150" is "0x10ec0900", you can get it through a search engine, or try the following:

For sound card chips of different manufacturers, different paragraphs need to be modified. In the example, the paragraph of Realtek manufacturer:

It is very important that on the hardware of this example, modifying the second-to-last line works, but modifying the same code on the first-to-last line fails. You will need to try and modify the same code over and over on different lines to work on your hardware.

For example, try on the 4th last line:

**Examples:**

Example 1 (unknown):
```unknown
oss.service
```

Example 2 (unknown):
```unknown
# lsmod | grep snd
```

Example 3 (unknown):
```unknown
# lsmod | awk ' { print $1 } ' | grep snd | xargs rmmod
```

Example 4 (unknown):
```unknown
# soundoff && soundon
```

---

## Package Maintainer guidelines

**URL:** https://wiki.archlinux.org/title/AUR_Package_Maintainer_guidelines

**Contents:**
- TODO list for new Package Maintainers
  - Junior maintainership
- The Package Maintainer and the AUR
  - Rewriting git history
  - Handling AUR requests
- The Package Maintainer and extra, guidelines for package maintenance
  - Rules for packages entering the extra repository
  - Accessing and updating the repository
  - Disowning packages
  - Moving packages from the AUR to extra

Package Maintainers are Arch Linux staff members charged with keeping the AUR in working order. They maintain popular packages (communicating with and sending patches upstream as needed), and vote in administrative matters. A Package Maintainer is elected from active community members by current Package Maintainers in a democratic process. Package Maintainers are the only members who have a final say in the direction of the AUR.

The Package Maintainers are governed using the Package Maintainer bylaws

Since the ratification of RFC 0014, new Package Maintainers will be marked as "junior" for their first two months of packaging. During this time, the new Package Maintainer may only push to the extra-testing repository. Your sponsors can review your packages as-needed and move them to extra.

The Package Maintainers should also make an effort to check package submissions in the AUR for malicious code and good PKGBUILDing standards. In around 80% of cases the PKGBUILDs in the AUR are very simple and can be quickly checked for sanity and malicious code by the Package Maintainer team.

Package Maintainers should also check PKGBUILDs for minor mistakes, suggest corrections and improvements. The Package Maintainer should endeavor to confirm that all packages follow the Arch Packaging Guidelines/Standards and in doing so share their skills with other package builders in an effort to raise the standard of package building across the distribution.

Package Maintainers are also in an excellent position to document recommended practices.

In some cases rewriting the history of an AUR repository is required, for example when a user inadvertently uses their legal name in a published commit. This can be automated with git-filter-branch(1).

To force push the new history, forward the AUR_OVERWRITE=1 environment variable to git-push(1).

In detail this includes adding SendEnv AUR_OVERWRITE to your AUR SSH config and setting the env var on your push command: AUR_OVERWRITE=1 git push --force. See [1] for details.

Install git-filter-repo and run:

Alternatively, use git filter-branch --env-filter with the GIT_AUTHOR_NAME, GIT_AUTHOR_EMAIL, GIT_COMMITTER_NAME and GIT_COMMITTER_EMAIL environment variables. For example:

This article or section needs expansion.

Package Maintainers should periodically check the requests filed on the AUR. For that there are some generic rules what to check for each request type:

If all of the above points are true then you can accept the Orphan Request.

The factual accuracy of this article or section is disputed.

See the packager guide.

If a Package Maintainer cannot or does not want to maintain a package any longer, a notice should be posted to the AUR Mailing List, so another package maintainer can maintain it. A package can still be disowned even if no other Package Maintainer wants to maintain it, but the Package Maintainers should try not to drop many packages (they should not take on more than they have time for). If a package has become obsolete or is not used any longer, it can be removed completely as well.

If a package has been removed completely, it can be uploaded once again (fresh) to the AUR, where a regular user can maintain the package instead of the Package Maintainer.

Follow the normal procedures for adding a package to extra using the instructions in the packager guide, but remember to delete the corresponding package from the AUR!

Remove the package using the instructions in the packager guide and upload your source to the AUR.

Move the package from the extra-testing to the extra repository using the instructions in the packager guide.

Package Maintainers and Developers can connect to build.archlinux.org via SSH to, among others, build packages using the devtools. This has numerous advantages over a local setup:

The process is similar to that of a local setup with devtools. Your GnuPG private is required for signing but you do not want to upload it for obvious security reasons. As such, you will need to forward the GnuPG agent socket from your local machine to the server: this will allow you to sign packages on the build server without communicating your key. This also means that we need to disable the agent on the server before we can run anything.

First, connect to build.archlinux.org and disable

Make sure gpg-agent is not running (systemctl --user stop gpg-agent.service). At this point, make sure that no sockets exist in the folder pointed by gpgconf --list-dir socketdir. If they do, remove them or log out and in again. If you have a custom $GNUPGHOME (eg. to move it to ~/.config/gnupg), you will need to unset that, as it is not possible in gnupg to set the homedir without setting the socketdir. On build.archlinux.org, StreamLocalBindUnlink yes is set in sshd_config, therefore removing the sockets manually on logout is not necessary.

While the PGP private keys remain on your local machine, the public keys must be on the build server. Export your public ring to the build server, e.g. from you local machine

SSH is required to checkout and commit to the Git repository. You can either set up a new SSH key pair on the server (it is highly discouraged to put your local private key on a server for security reasons) or reuse your local keys via socket forwarding. If you opt for the latter, make sure to disable ssh-agent on the build server if you had enabled it previously (it is not running by default).

Configure you build environment on the build server:

Disable passphrase caching with the following settings:

Because we will want to keep our usual GPG agent running with its current settings, we are going to run another GPG agent dedicated to the task at hand. Create a ~/.gnupg-archlinux folder and symlink everything from ~/.gnupg there, except ~/.gnupg/gpg-agent.conf. Configure the new GPG agent:

The gpg-agent-extra.socket will be forwarded to build.archlinux.org.

Start the dedicated agent with

or, if using GnuPG as your SSH agent:

Replace REMOTE_UID and LOCAL_UID by your user identifier as returned by id -u on the build server and locally, respectively. If using ssh-agent, replace REMOTE_SSH_AUTH_SOCK by the path to the SSH socket on the remote host (it can be anything).

You can make the forwarding permanent for that host. For instance with gpg-agent.ssh:

Again, replace REMOTE_UID with the user UID on the build server.

From then on, the procedure should be exactly the same as a local build:

When a Package Maintainer resigns the following list has be followed, these steps do not apply when a Package Maintainer resigns but is still a Developer.

**Examples:**

Example 1 (unknown):
```unknown
@archlinux/package-maintainer/username
```

Example 2 (unknown):
```unknown
@archlinux.org
```

Example 3 (unknown):
```unknown
username@archlinux.org
```

Example 4 (unknown):
```unknown
@archlinux.org
```

---

## pacman/Tips and tricks

**URL:** https://wiki.archlinux.org/title/Custom_local_repository

**Contents:**
- Maintenance
  - Listing packages
    - In unused repositories
    - With version
    - With size
      - Individual packages
      - Packages and dependencies
    - By date
    - Not in a specified group, repository or meta package
    - Development packages

For general methods to improve the flexibility of the provided tips or pacman itself, see Core utilities and Bash.

See also System maintenance.

By default, repositories listed in pacman.conf are used for syncing, searching, installing and upgrading from them. This can be changed for more versatility, for example by using some repositories only for searching in them[1]:

See pacman.conf(5) § REPOSITORY SECTIONS.

You may want to get the list of installed packages with their version, which is useful when reporting bugs or discussing installed packages.

Figuring out which packages are largest can be useful when trying to free space on your hard drive. There are two options here: get the size of individual packages, or get the size of packages and their dependencies.

The following command will list all installed packages and their individual sizes:

To list package sizes with their dependencies,

To list the download size of several packages (leave packages blank to list all packages):

To list explicitly installed packages not in the meta package base nor package group xorg with size and description:

To list the packages marked for upgrade with their download size:

To list optional dependencies only:

To list the 20 last installed packages with expac, run:

or, with seconds since the epoch (1970-01-01 UTC):

List explicitly installed packages not in the base meta package:

List explicitly installed packages not in the base meta package or xorg package group:

List all installed packages unrequired by other packages, and which are not in the base meta package or xorg package group:

As above, but with descriptions:

List all installed packages that are not in the specified repository repo_name (multiple repositories can be checked at once):

List all installed packages that are in the repo_name repository (multiple repositories can be checked at once):

List all packages on the Arch Linux ISO that are not in the base meta package:

To list all development/unstable packages, run:

To obtain the list of the dependencies of a package, the simplest solution is reading the output of:

For automation, instead of the error-prone method of parsing pacman output, use expac:

To list explicitly-installed packages with their optional dependencies, run:

Alternatively, with expac:

To list them while omitting optional dependencies you have already installed, run:

To browse all installed packages with an instant preview of each package:

This uses fzf to present a two-pane view listing all packages with package info shown on the right.

Enter letters to filter the list of packages; use arrow keys (or Ctrl-j/Ctrl-k) to navigate; press Enter to see package info under less.

To browse all packages currently known to pacman (both installed and not yet installed) in a similar way, using fzf, use:

The navigational keybindings are the same, although Enter will not work in the same way.

This one might come in handy if you have found that a specific package uses a huge amount of space and you want to find out which files make up the most of that.

If your system has stray files not owned by any package (a common case if you do not use the package manager to install software), you may want to find such files in order to clean them up.

One method is to list all files of interest and check them against pacman:

Most systems will slowly collect several ghost files such as state files, logs, indexes, etc. through the course of usual operation.

pacreport from pacutils can be used to track these files and their associations via /etc/pacreport.conf (see pacreport(1) § FILES).

An example may look something like this (abridged):

Then, when using pacreport --unowned-files as the root user, any unowned files will be listed if the associated package is no longer installed (or if any new files have been created).

Additionally, aconfmgr (aconfmgr-gitAUR) allows tracking modified and orphaned files using a configuration script.

Orphans are packages that were installed as a dependency and are no longer required by any package.

They can accumulate on your system over time either due to uninstalling packages using pacman -R package instead of pacman -Rs package, installing packages as makedepends, or packages removing dependencies in newer versions.

For recursively removing orphans and their configuration files:

If no orphans were found, the output is error: argument '-' specified with empty stdin. This is expected as no arguments were passed to pacman -Rns. The error can be avoided by prefixing the second command with ifne(1) from the moreutils package.

If there is a package listed that you do not want to remove, it can be excluded from the list of orphans by marking it as explicitly installed:

In some cases the method above will not detect all possible unneeded packages. E.g. dependency cycles (also known as "circular dependencies"), excessive dependencies (fulfilled more than once), some non-explicit optionals etc.

To detect such packages:

If you want to remove all packages in the list at once, run the command without --print argument.

Sometimes there may be multiple packages providing same item. For example, there may be multiple packages which provide ttf-font. You may not want all such packages depending your preference.

To detect packages which provide same item:

Check the output and carefully remove redundant package which you do not require.

If it is ever necessary to remove all packages except the essentials packages, one method is to set the installation reason of the non-essential ones as dependency and then remove all unnecessary dependencies.

First, for all the packages "explicitly installed", change their installation reason to "installed as a dependency":

Then, change the installation reason to "explicitly installed" of only the essential packages, those you do not want to remove, in order to avoid targeting them:

Finally, follow the instructions in #Removing unused packages (orphans) to remove all packages that are "installed as a dependency".

Dependencies are alphabetically sorted and doubles are removed.

Alternatively, with expac:

To list configuration files tracked by pacman as susceptible of containing user changes (i.e. files listed in the PKGBUILD backup array) and having received user modifications, use the following command:

Running this command with root permissions will ensure that files readable only by root (such as /etc/sudoers) are included in the output.

This can be used when doing a selective system backup or when trying to replicate a system configuration from one machine to another.

The following command can be used to back up the local pacman database:

Store the backup pacman database file on one or more offline media, such as a USB stick, external hard drive, or CD-R.

The database can be restored by moving the pacman_database.tar.bz2 file into the / directory and executing the following command:

When maintainers update packages, commits are often commented in a useful fashion. Users can quickly check these from the command line by installing pacologAUR. This utility lists recent commit messages for packages from the official repositories or the AUR, by using pacolog package.

Alternative ways of getting and restoring packages.

This article or section is a candidate for merging with #Custom local repository.

To download packages, or groups of packages:

Pacman, which will reference the host installation by default, will not properly resolve and download existing dependencies. In cases where all packages and dependencies are wanted, it is recommended to create a temporary blank DB and reference it with --dbpath:

Then you can burn the "Packages" directory to an optical disc (e.g. CD, DVD) or transfer it to a USB flash drive, external HDD, etc.

For an optical disc drive:

For a USB flash drive, hard disk drive, etc.:

2. Edit pacman.conf and add this repository before the other ones (e.g. extra, core, etc.). This is important. Do not just uncomment the one on the bottom. This way it ensures that the files from the CD/DVD/USB take precedence over those in the standard repositories:

3. Finally, synchronize the pacman database to be able to use the new repository:

Use the repo-add script included with pacman to generate a database for a personal repository. Use repo-add --help for more details on its usage. A package database is a tar file, optionally compressed. Valid extensions are .db or .files followed by an archive extension of .tar, .tar.gz, .tar.bz2, .tar.xz, .tar.zst, or .tar.Z. The file does not need to exist, but all parent directories must exist.

To add a new package to the database, or to replace the old version of an existing package in the database, run:

The database and the packages do not need to be in the same directory when using repo-add, but keep in mind that when using pacman with that database, they should be together. Storing all the built packages to be included in the repository in one directory also allows to use shell glob expansion to add or update multiple packages at once:

If you are looking to support multiple architectures then precautions should be taken to prevent errors from occurring. Each architecture should have its own directory tree:

The repo-add executable checks if the package is appropriate. If this is not the case you will be running into error messages similar to this:

repo-remove is used to remove packages from the package database, except that only package names are specified on the command line.

Once the local repository database has been created, add the repository to pacman.conf for each system that is to use the repository. An example of a custom repository is in pacman.conf. The repository's name is the database filename with the file extension omitted. In the case of the example above the repository's name would simply be repo. Reference the repository's location using a file:// URL, or via HTTP using http://localhost/path/to/directory.

If willing, add the custom repository to the list of unofficial user repositories, so that the community can benefit from it.

See Package proxy cache.

To recreate a package from the file system, use fakepkgAUR. Files from the system are taken as they are, hence any modifications will be present in the assembled package. Distributing the recreated package is therefore discouraged; see ABS and Arch Linux Archive for alternatives.

Keeping a list of all explicitly installed packages can be useful to backup a system or quicken the installation of a new one:

To keep an up-to-date list of explicitly installed packages (e.g. in combination with a versioned /etc/), you can set up a hook. Example:

To install packages from a previously saved list of packages, while not reinstalling previously installed packages that are already up-to-date, run:

However, it is likely foreign packages such as from the AUR or installed locally are present in the list. To filter out from the list the foreign packages, the previous command line can be enriched as follows:

Eventually, to make sure the installed packages of your system match the list and remove all the packages that are not mentioned in it:

If you are suspecting file corruption (e.g. by software/hardware failure), but are unsure if files were corrupted, you might want to compare with the hash sums in the packages. This can be done with pacutils:

For recovery of the database see #Restore pacman's local database. The mtree files can also be extracted as .MTREE from the respective package files.

To reinstall all native packages, use:

Foreign (AUR) packages must be reinstalled separately; you can list them with pacman -Qqm.

Pacman preserves the installation reason by default.

See pacman/Restore local database.

If you have managed to mess up an Arch install with broken packages, it is possible to re-install all the packages and hopefully get it back up and working again (assuming the root of the broken install is mounted in /brokenArch)

paccat is a small utility that finds which package contains a given file, downloads it and then prints the contents. This can be used to read specific files, restore changed files back to their initial state, and extract files without installing the package.

For example, if you want to see the contents of /etc/systemd/logind.conf supplied within the systemd package:

Or if you want to see the contents of archive.h supplied by any package:

bsdtar can also be used to show the contents:

Or you can use vim to browse the archive:

Already running processes do not automatically notice changes caused by updates. Instead, they continue using old library versions. That may be undesirable, due to potential issues related to security vulnerabilities or other bugs, and version incompatibility.

Processes depending on updated libraries may be found using either htop, which highlights the names of the affected programs, or with a snippet based on lsof, which also prints the names of the libraries:

This solution will only detect files, that are normally kept opened by running processes, which basically limits it to shared libraries (.so files). It may miss some dependencies, like those of Java or Python applications.

Many packages install documentation and translations in several languages. Some programs are designed to remove such unnecessary files, such as localepurgeAUR, which runs after a package is installed to delete the unneeded locale files. A more preemptive approach is provided through the NoExtract directive in /etc/pacman.conf, which prevent these files from ever being installed.

To prevent the installation of all translations for help files, except for the C locale, add:

To prevent the installation of all the HTML documentation, add:

To prevent the installation of the various locales, except the required ones, add:

To prevent the installation of the translated man pages, add:

To prevent the installation of the language files in vim-runtime, add:

To prevent the installation of all but English content in Qt applications, add:

To prevent the installation of all but English content in Chromium and Electron applications, add:

To prevent the installation of English help files in LibreOffice, add:

To prevent the installation of all but English content from OnlyOffice, add:

To prevent the installation of all but the English iBus dictionary for emojis, add:

When trying to install a package from a bad connection (e.g. a train using a cell phone), use the --disable-download-timeout option to lessen the chance of receiving errors such as:

When downloading packages pacman uses the mirrors in the order they are in /etc/pacman.d/mirrorlist. The mirror which is at the top of the list by default however may not be the fastest for you. To select a faster mirror, see Mirrors.

Pacman's speed in downloading packages can also be improved by using parallel downloads, a major feature request (FS#20056) added with pacman 6.0.0. It is enabled by default since pacman 7.0.0.

Instead of pacman's built-in file downloader, a separate application can also be used to download packages.

In all cases, make sure you have the latest pacman before doing any modifications.

Powerpill is a pacman wrapper that uses parallel and segmented downloading to try to speed up downloads for pacman.

This is also very handy if you need more powerful proxy settings than pacman's built-in capabilities.

To use wget, first install the wget package then modify /etc/pacman.conf by uncommenting the following line in the [options] section:

Instead of uncommenting the wget parameters in /etc/pacman.conf, you can also modify the wget configuration file directly (the system-wide file is /etc/wgetrc, per user files are $HOME/.wgetrc).

aria2 is a lightweight download utility with support for resumable and segmented HTTP/HTTPS and FTP downloads. aria2 allows for multiple and simultaneous HTTP/HTTPS and FTP connections to an Arch mirror, which should result in an increase in download speeds for both file and package retrieval.

Install aria2, then edit /etc/pacman.conf by adding the following line to the [options] section:

See aria2c(1) § OPTIONS for used aria2c options.

There are other downloading applications that you can use with pacman. Here they are, and their associated XferCommand settings:

**Examples:**

Example 1 (unknown):
```unknown
pacman.conf
```

Example 2 (unknown):
```unknown
/etc/pacman.conf
```

Example 3 (unknown):
```unknown
...
[multilib]
Usage = Sync Search
...
```

Example 4 (unknown):
```unknown
pacman -Sg group
```

---

## Sawfish

**URL:** https://wiki.archlinux.org/title/Sawfish

**Contents:**
- Installation
- Starting
- Customization
  - Themes
    - Adding new
  - Menus
    - Menu example
- Additional resources

Sawfish is a highly customizable window manager. Formerly it has been the standard Window manager of the GNOME desktop, but because of a change of maintainership this is no longer true. This article will show you how to install and configure it for standalone use (without GNOME).

Install the sawfishAUR package.

Start sawfish with xinit.

Out-of-the box Sawfish provides a menu accessible by clicking Mouse-2 (middle button) on the root window. From there, you can launch the customization app.

If you change any settings, they are stored in ~/.sawfish/custom.

You can select a window theme from the customization app. There is a small bug: if the theme is parametrizable, its configuration window will only appear after you restart the customization app.

Create the directory ~/.sawfish/themes/ and drop there any theme files. You do not need to uncompress them. There are 500+ themes to choose from in the Sawfish site.

Arch does not provide an automatic menu generator for Sawfish, but you can generate the menus using the XFCE4 ones. Here are the necessary steps:

Create the directory ~/.sawfish/lisp/. This is where custom Sawfish scripts are stored; the menu will be one of them. Install libxslt, copy the xslt stylesheet example, paste it into a file named xfce4-menu-to-sawfish.xslt. Now you need a XFCE4 menu. You may have one already or you can generate one with menumaker or xdg_menu.

Now you have a script ~/.sawfish/lisp/arch-menu.jl that defines a variable arch-menu with a list of your applications. You need to link to it from the root menu. You need to write the code for that to happen in ~/.sawfishrc. So, start your favorite editor, create ~/.sawfishrc, and type:

Restart Sawfish to effect the changes.

**Examples:**

Example 1 (unknown):
```unknown
~/.sawfish/custom
```

Example 2 (unknown):
```unknown
~/.sawfish/themes/
```

Example 3 (unknown):
```unknown
~/.sawfish/lisp/
```

Example 4 (unknown):
```unknown
xfce4-menu-to-sawfish.xslt
```

---

## PKGBUILD

**URL:** https://wiki.archlinux.org/title/Dependency

**Contents:**
- Package name
  - pkgbase
  - pkgname
- Version
  - pkgver
  - pkgrel
  - epoch
- Generic
  - pkgdesc
  - arch

This article discusses variables definable by the maintainer in a PKGBUILD. For information on the PKGBUILD functions and creating packages in general, refer to Creating packages. Also read PKGBUILD(5).

A PKGBUILD is a Bash script containing the build information required by Arch Linux packages.

Packages in Arch Linux are built using the makepkg utility. When makepkg is run, it searches for a PKGBUILD file in the current directory and follows the instructions therein to either compile or otherwise acquire the files to build a package archive—pkgname.pkg.tar.zst. The resulting package contains binary files and installation instructions, readily installable with pacman.

Mandatory variables are pkgname, pkgver, pkgrel, and arch. license is not strictly necessary to build a package, but is recommended for any PKGBUILD shared with others, as makepkg will produce a warning if not present.

It is a common practice to define the variables in the PKGBUILD in the same order as given here. However, it is not mandatory.

See the .proto files in the /usr/share/pacman/ directory as examples.

When building regular packages, this variable should not be explicitly declared in the PKGBUILD: its value defaults to that of #pkgname.

When building a split package, this variable can be used to explicitly specify the name to be used to refer to the group of packages in the output of makepkg and in the naming of source-only tarballs. The value is not allowed to begin with a hyphen. If not specified, the value will default to the first element in the pkgname array.

All options and directives for split packages default to the global values given in the PKGBUILD. Nevertheless, the following ones can be overridden within each split package’s packaging function: #pkgdesc, #arch, #url, #license, #groups, #depends, #optdepends, #provides, #conflicts, #replaces, #backup, #options, #install, and #changelog.

Either the name of the package, e.g. pkgname=foo, or, for split packages, an array of names, e.g. pkgname=(foo bar). Package names should only consist of lowercase alphanumerics and the following characters: @._+- (at symbol, dot, underscore, plus, hyphen). Names are not allowed to start with hyphens or dots. For the sake of consistency, pkgname should match the name of the source tarball of the software: for instance, if the software is in foobar-2.5.tar.gz, use pkgname=foobar.

The version of the package. This should be the same as the version published by the author of the upstream software. It can contain letters, numbers, periods and underscores, but not a hyphen (-). If the author of the software uses one, replace it with an underscore (_). If the pkgver variable is used later in the PKGBUILD, then the underscore can easily be substituted for a hyphen, e.g. source=("${pkgname}-${pkgver//_/-}.tar.gz").

The release number. This is usually a positive integer number that allows to differentiate between consecutive builds of the same version of a package. As fixes and additional features are added to the PKGBUILD that influence the resulting package, the pkgrel should be incremented by 1. When a new version of the software is released, this value must be reset to 1. In exceptional cases other formats can be found in use, such as major.minor.

Used to force the package to be seen as newer than any previous version with a lower epoch. This value is required to be a non-negative integer; the default is 0. It is used when the version numbering scheme of a package changes (or is alphanumeric), breaking normal version comparison logic. For example:

See pacman(8) for more information on version comparisons.

The description of the package. This is recommended to be 80 characters or less and should not include the package name in a self-referencing way, unless the application name differs from the package name. For example, use pkgdesc='Text editor for X11' instead of pkgdesc='Nedit is a text editor for X11'.

Also it is important to use keywords wisely to increase the chances of appearing in relevant search queries.

An array of architectures that the PKGBUILD is intended to build and work on. Arch officially supports only x86_64, but other projects may support other architectures. For example, Arch Linux 32 provides support for i686 and pentium4, and Arch Linux ARM provides support for armv7h (armv7 hardfloat) and aarch64 (armv8 64-bit).

There are two types of values the array can use:

The target architecture can be accessed with the variable CARCH during a build.

The URL of the official site of the software being packaged.

This article or section is a candidate for merging with Arch package guidelines#licenses.

This article or section needs expansion.

The license under which the software is distributed. Arch Linux uses SPDX license identifiers. Each license must have a corresponding entry in /usr/share/licenses/.

For common licenses (like GPL-3.0-or-later), package licenses delivers all the corresponding files. The package is installed by default, as it is a dependency of base meta package, and the files may be found in /usr/share/licenses/spdx/. Simply refer to the license using its SPDX license identifier from the list of SPDX identifiers.

License families like BSD or MIT are, strictly speaking, not a single license and each instance requires a separate license file. In license variable refer to them using a common SPDX identifier (e.g. BSD-3-Clause or MIT), but then provide the corresponding file as if it was a custom license.

For custom licenses the identifier should be either LicenseRef-license-name or custom:license-name, if they are not covered by the common families mentioned above. The corresponding license text must be placed in directory /usr/share/licenses/pkgname. To install the file a following code snippet may be used in package() section:

Combining multiple licenses or adding exceptions should follow the SPDX syntax. For example a package released under either GNU/GPL 2.0 or GNU/LGPL 2.1 could use 'GPL-2.0-or-later OR LGPL-2.1-or-later', a package released under Apache 2.0 with LLVM exception would use 'Apache-2.0 WITH LLVM-exception' and a package released with part under the BSD 3 clause, others under GNU/LGPL 2.1 and some under GNU/GPL 2.0 would use 'BSD-3-Clause AND LGPL-2.1-or-later AND GPL-2.0-or-later'[2]. Note that this must be a single string, so the entire expression has to be enclosed in quotes. As for November 2023 SPDX list of exceptions is limited, so usually the custom license route must be used.

If issues are encountered with SPDX identifiers, during the transitional period using old identifiers —names of the directories in /usr/share/licenses/common— is acceptable.

See also Nonfree applications package guidelines.

Additional information and perspectives on free and open source software licenses may be found on the following pages:

The group the package belongs in. For instance, when installing plasma, it installs all packages belonging in that group.

An array of packages that must be installed for the software to build and run. Dependencies defined inside the package() function are only required to run the software.

Version restrictions can be specified with comparison operators, e.g. depends=('foobar>=1.8.0'); if multiple restrictions are needed, the dependency can be repeated for each, e.g. depends=('foobar>=1.8.0' 'foobar<2.0.0').

This article or section is a candidate for merging with Arch package guidelines.

The depends array should list all direct first level dependencies even when some are already declared transitively. For instance, if a package foo depends on both bar and baz, and the bar package depends in turn on baz too, it will ultimately lead to undesired behavior if bar stops pulling in baz. Pacman will not enforce the installation of baz on systems which newly install the foo package, or have cleaned up orphans, and foo will crash at runtime or otherwise misbehave.

In some cases this is not necessary and may or may not be listed, for example glibc cannot be uninstalled as every system needs some C library, or python for a package that already depends on another python- module, as the second module must per definition depend on python and cannot ever stop pulling it in as a dependency.

Dependencies should normally include the requirements for building all optional features of a package. Alternatively, any feature whose dependencies are not included should be explicitly disabled via a configure option. Failure to do this can lead to packages with "automagic dependencies" build-time optional features that are unpredictably enabled due to transitive dependencies or unrelated software installed on the build machine, but which are not reflected in the package dependencies.

If the dependency name appears to be a library, e.g. depends=(libfoobar.so), makepkg will try to find a binary that depends on the library in the built package and append the soname version needed by the binary. Manually appending the version disables automatic detection, e.g. depends=('libfoobar.so=2').

An array of packages that are only required to build the package. The minimum dependency version can be specified in the same format as in the depends array. The packages in the depends array are implicitly required to build the package, they should not be duplicated here.

An array of packages that the software depends on to run its test suite, but are not needed at runtime. Packages in this list follow the same format as depends. These dependencies are only considered when the check() function is present and is to be run by makepkg.

An array of packages that are not needed for the software to function, but provide additional features. This may imply that not all executables provided by a package will function without the respective optdepends.[3] If the software works on multiple alternative dependencies, all of them can be listed here, instead of the depends array.

A short description of the extra functionality each optdepend provides should also be noted:

An array of additional packages that the software provides the features of, including virtual packages such as cron or sh and all external shared libraries. Packages providing the same item can be installed side-by-side, unless at least one of them uses a conflicts array.

An array of packages that conflict with, or cause problems with the package, if installed. All these packages and packages providing this item will need to be removed. The version properties of the conflicting packages can also be specified in the same format as the depends array.

Note that conflicts are checked against pkgname as well as names specified in the provides array. Hence, if your package provides a foo feature, specifying foo in the conflicts array will cause a conflict between your package and all other packages that contain foo in their provides array (i.e., there is no need to specify all those conflicting package names in your conflicts array). Let us take a concrete example:

When packages provide the same feature via the provides array, there is a difference between explicitly adding the alternative package to the conflicts array and not adding it. If the conflicts array is explicitly declared the two packages providing the same feature will be considered as alternative; if the conflicts array is missing the two packages providing the same feature will be considered as possibly cohabiting. Packagers should always ignore the content of the provides variable in deciding whether to declare a conflicts variable or not.

An array of obsolete packages that are replaced by the package, e.g. wireshark-qt uses replaces=('wireshark'). When syncing, pacman will immediately replace an installed package upon encountering another package with the matching replaces in the repositories. If providing an alternate version of an already existing package or uploading to the AUR, use the conflicts and provides arrays, which are only evaluated when actually installing the conflicting package.

An array of files that can contain user-made changes and should be preserved during upgrade or removal of a package, primarily intended for configuration files in /etc. If these files are unchanged from how they ship with the package, they will be removed or replaced as normal files during upgrade or removal.

Files in this array should use relative paths without the leading slash (/) (e.g. etc/pacman.conf, instead of /etc/pacman.conf). The backup array does not support empty directories or wildcards such as "*".

When updating, new versions may be saved as file.pacnew to avoid overwriting a file which already exists and was previously modified by the user. Similarly, when the package is removed, user-modified files will be preserved as file.pacsave unless the package was removed with the pacman -Rn command.

See also Pacnew and Pacsave files.

This array allows overriding some of the default behavior of makepkg, defined in /etc/makepkg.conf. To set an option, include the name in the array. To disable an option, place an ! before it.

The full list of the available options can be found in PKGBUILD(5) § OPTIONS AND DIRECTIVES.

The name of the .install script to be included in the package.

pacman has the ability to store and execute a package-specific script when it installs, removes or upgrades a package. The script contains the following functions which run at different times:

Each function is run chrooted inside the pacman install directory. See this thread.

The name of the package changelog. To view changelogs for installed packages (that have this file):

An array of files needed to build the package. It must contain the location of the software source, which in most cases is a full HTTP or FTP URL. The previously set variables pkgname and pkgver can be used effectively here; e.g. source=("https://example.com/${pkgname}-${pkgver}.tar.gz").

Files can also be supplied in the same directory where the PKGBUILD is located, and their names added to this array. Before the actual build process starts, all the files referenced in this array will be downloaded or checked for existence, and makepkg will not proceed if any is missing.

.install files are recognized automatically by makepkg and should not be included in the source array. Files in the source array with extensions .sig, .sign, or .asc are recognized by makepkg as PGP signatures and will be automatically used to verify the integrity of the corresponding source file.

An array of files listed under source, which should not be extracted from their archive format by makepkg. This can be used with archives that cannot be handled by /usr/bin/bsdtar or those that need to be installed as-is. If an alternative unarchiving tool is used (e.g. lrzip), it should be added in the makedepends array and the first line of the prepare() function should extract the source archive manually; for example:

Note that while the source array accepts URLs, noextract is just the file name portion:

To extract nothing, consider the following:

An array of PGP fingerprints. If used, makepkg will only accept signatures from the keys listed here and will ignore the trust values from the keyring. If the source file was signed with a subkey, makepkg will still use the primary key for comparison.

Only full fingerprints are accepted. They must be uppercase and must not contain whitespace characters.

Please read makepkg#Signature checking for more information.

These variables are arrays whose items are checksum strings that will be used to verify the integrity of the respective files in the source array. Insert SKIP for a particular file, and its checksum will not be tested.

The checksum type and values should always be those provided by upstream, such as in release announcements. When multiple types are available, the strongest checksum is to be preferred (in order from most to least preferred): b2, sha512, sha384, sha256, sha224, sha1, md5, ck. This best ensures the integrity of the downloaded files, from upstream announcement to package building.

The values for these variables can be auto-generated by makepkg's -g/--geninteg option, then commonly appended with makepkg -g >> PKGBUILD. The updpkgsums(8) command from pacman-contrib is able to update the variables wherever they are in the PKGBUILD. Both tools will use the variable that is already set in the PKGBUILD, or fall back to sha256sums if none is set.

The file integrity checks to use can be set up with the INTEGRITY_CHECK option in /etc/makepkg.conf. See makepkg.conf(5).

An array of BLAKE2b checksums with digest size of 512 bits.

An array of SHA-2 checksums with digest sizes 512, 384, 256 and 224 bits, respectively. sha256sums is the most common of them.

An array of 160-bit SHA-1 checksums of the files listed in the source array.

An array of 128-bit MD5 checksums of the files listed in the source array.

An array CRC32 checksums (from UNIX-standard cksum) of the files listed in the source array.

**Examples:**

Example 1 (unknown):
```unknown
pkgname.pkg.tar.zst
```

Example 2 (unknown):
```unknown
shellcheck --shell=bash --exclude=SC2034,SC2154,SC2164 PKGBUILD
```

Example 3 (unknown):
```unknown
makepkg.conf
```

Example 4 (unknown):
```unknown
/usr/share/pacman/
```

---

## Labwc

**URL:** https://wiki.archlinux.org/title/Labwc

**Contents:**
- Installation
- Starting
- Configuration
  - Autostart
  - Keymap
  - Statusbar
  - Outputs
    - Wallpaper
  - Custom keybindings
    - Workspaces

Labwc stands for Lab Wayland Compositor[1]. According to the official website:

Labwc can be installed with the packages labwc or labwc-gitAUR.

The default terminal emulator is alacritty. Before starting labwc it is advisable to either install it or set a new terminal in the configuration.

Like all wlroots-based compositors, for access to your seat, labwc requires Polkit to be installed when using systemd-logind(8), or seatd service to be enabled with your user added to the seat user group.

You can start labwc in the Linux console, use a Wayland-compatible Display manager.

By default, you can press Super (usually a key with a Window icon) with Enter to launch alacritty. See 6. Usage for the default keybindings.

This article or section needs language, wiki syntax or style improvements. See Help:Style for reference.

Following files can be used for configuration:

Example files are provided in /usr/share/doc/labwc/. Especially, /usr/share/doc/labwc/rc.xml.all contains all the default configurations.

See labwc-config(5) for further details.

~/.config/labwc/autostart contains a shell script executed when launching labwc. For example:

The keyboard layout can be configured by setting environment variables in ~/.config/labwc/environment. For example:

See xkeyboard-config(7) for details.

Use external tools like waybar and sfwbarAUR can be used to show status bars. For example:

Use external tools like wlr-randr and kanshi can be used to manage outputs. For example:

Use external tools like swaybg, wpaperd and wbgAUR can be used to show backgrounds. For example:

Keybindings are configured by adding <keyboard><keybind> sections with <action>. For example:

Workspaces are configured in <desktops> section and switched with keybindings. For example:

Labwc follows Openbox's syntax for menu configuration in ~/.config/labwc/menu.xml. For example:

Also, you can use menu generators for Openbox like archlinux-xdg-menu and obmenu-generatorAUR.

See labwc-menu(5) for details.

Labwc loosely follows Openbox 3 theme specification. You can install themes to the following directories:

These directories contain themerc which defines the theme colors and geometries, and button icon files like close-active.svg and close-inactive.svg. XBM, SVG and PNG formats are supported for icon files.

Additionally, you can override the theme entries with ~/.config/themerc-override.

labwc-artwork provides some themes for labwc.

See labwc-theme(5) for details.

xorg-xwayland starts automatically if Xwayland support is enabled at build time. To force disable it, set:

To use another renderer such as vulkan, see Wayland#Use another renderer for wlroots based compositor.

**Examples:**

Example 1 (unknown):
```unknown
~/.config/labwc/rc.xml
```

Example 2 (unknown):
```unknown
~/.config/labwc/menu.xml
```

Example 3 (unknown):
```unknown
~/.config/labwc/autostart
```

Example 4 (unknown):
```unknown
~/.config/labwc/shutdown
```

---

## Haskell package guidelines

**URL:** https://wiki.archlinux.org/title/Haskell_package_guidelines

**Contents:**
- Package naming
- Architecture
- Source
- Creating packages
- Updating packages
  - Identifying required changes
  - Package rebuilds
- PKGBUILD library example

This article or section needs expansion.

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

This document aims to cover standards and guidelines for producing good Haskell packages on Arch.

Until this document is written, contact User:Felixonmars.

For Haskell libraries, use haskell-libraryname usually the same name as on hackage.

Every Haskell library or program is architecture-dependent.

The preferred source of a Haskell program or library is from hackage. PKGBUILD#source source=() array should use the following URL template:

Note that a custom _hkgname variable is used instead of pkgname since Haskell packages are generally prefixed with haskell-. This variable can generically be defined as follows:

arch-hs is provided to automate PKGBUILD generation and maintenance.

To generate a series of PKGBUILDs for a Hackage package (and its unpackaged dependencies):

When a Haskell library changes its build flags or is updated, all dependent packages and their transitive dependents, including makedepends and checkdepends, need to be rebuilt. See the subsections below for determining the correct rebuild order.

Moreover, in the Haskell ecosystem, the latest releases of libraries frequently do not work together. It is therefore advisable to upgrade packages incrementally, in small steps, and read upstream changelogs to identify potential upstream issues. This holds in particular for packages with a non-negligible number of packages in their reverse dependency chain. Sometimes, an incompatibility may only be discovered during the rebuilds and may turn out to be non-trivial to fix; in such cases, it may be best to revert changes and document the incompatibility in the relevant bumpbuddy ticket.

To compare dependencies and other packaging metadata for updating an existing package:

To compare Arch [extra] package versions and their corresponding Hackage package versions:

Note that arch-hs uses cabal-install to maintain Hackage databases, so please update your cabal-install database regularly to keep them fresh:

The genrebuild tool can be used to find out what needs rebuilding and how.

Packaging a Haskell library is different from packaging a Haskell program, the libraries packaged in Arch Linux are meant to be used by packaged Haskell programs.

**Examples:**

Example 1 (unknown):
```unknown
haskell-libraryname
```

Example 2 (unknown):
```unknown
https://hackage.haskell.org/packages/archive/$_hkgname/$pkgver/$_hkgname-$pkgver.tar.gz
```

Example 3 (unknown):
```unknown
_hkgname=stm-delay
```

Example 4 (unknown):
```unknown
$ arch-hs -o /path/to/workdir library_name
```

---

## awesome

**URL:** https://wiki.archlinux.org/title/Awesome

**Contents:**
- Installation
- Starting
  - With GNOME
  - XFCE
- Configuration
  - Creating the configuration file
    - Examples
  - Extensions
  - Autostart
  - Changing keyboard layout

From the awesome website:

Install the awesome package.

Run awesome with xinit. To use the included xsession file, see Display manager.

You can set up GNOME to use awesome as the visual interface, but have GNOME work in the background. See awesome-gnomeAUR.

See Xfce#Use a different window manager.

The lua based configuration file is at ~/.config/awesome/rc.lua.

First, run the following to create the directory needed in the next step:

Whenever compiled, awesome will attempt to use whatever custom settings are contained in ~/.config/awesome/rc.lua. This file is not created by default, so we must copy the template file first:

The API for the configuration often changes when awesome updates. So, remember to repeat the command above when you get something strange with awesome, or you want to modify the configuration.

For more information about configuring awesome, check out the configuration section at awesome docs

Some good examples of rc.lua would be as follows:

Several extensions are available for awesome:

To implement the XDG Autostart specification, install xorg-xrdb and dex and add the following lines to ~/.config/awesome/rc.lua:

Especially for daemons without tray icon, systemd user units using an autostart target are an interesting alternative as they can be configured to be kept running, that is, monitored and restarted after an unexpected halt.

Finally, one can also create autorun.sh and insert the following:

Then, make it executable.

To add programs to autostart, simply append run "program [some arguments]" to autorun.sh. The run function checks whether there already is an instance of program with the same arguments and only runs program if there is none. You can check your autorun.sh by running it:

If everything is fine, add the following line to your rc.lua:

Alternatively, add the commands you wish to run (including setting environment variables) to xinitrc (or xprofile when a display manager is being used).

There are multiple ways to configure keyboard layers.

The default configuration of awesome already has the layout widget activated.

To set multiple layers temporary, run

Clicking on the widget should toggle the layout. If you want a keycombo to change the layout, you may append -option "grp:alt_shift_toggle". This for example will let you change the layout by pressing Shift+Alt. So the complete command would be:

To setup EN and RU layouts with phonetic variant:

If using LightDM to start session, then add the command above into .xprofile file.

You can use awesome itself to switch (from v.4). To change the layout by pressing Shift+Alt, add these two lines to globalkeys:

This requires you to set up the keyboard layouts you want to be able to switch between either by the setxkbmap command or in X configuration files.

Once you have found the appropriate command to setup your layouts, add it to #Autostart.

Alternatively, see Keyboard configuration in Xorg.

Beautiful is a Lua library that allows you to theme awesome using an external file, it becomes very easy to dynamically change your whole awesome colours and wallpaper without changing your rc.lua.

The default theme is at /usr/share/awesome/themes/default. Copy it to ~/.config/awesome/themes/default (optionally copy them all) and change rc.lua:

If you also copied the other themes you can replace "default" with e.g. "sky", "gtk", "zenburn" etc to change themes easily and the local copy of the themes can be studied, modified and used for testing. See also [1] for additional theming options. To add a useless gap for example, add

At the bottom of the theming section in your rc.lua.

Beautiful can handle your wallpaper, thus you do not need to set it up in your .xinitrc or .xsession files. This allows you to have a specific wallpaper for each theme.

There are two ways to specify the wallpaper:

For a random background image, add [2] to rc.lua (v3.5+). To automatically fetch images from a given directory, use [3] instead.

To show the wibox (or perform other actions) only while the ModKey is pressed is not possible from within awesome, but there is a python script that does that: autohidewibox.

See Keyboard input to ensure the PrtSc button is assigned correctly. Then install a screen capturing program such as scrot

Add to the globalkeys array:

This function saves screenshots inside ~/screenshots/, edit as needed.

As of awesome 3.4, it is possible to remove the small gaps between windows; in the awful.rules.rules table there is a properties section, add to it

See composite manager.

In awesome 3.5, window transparency can be set dynamically using signals. For example, rc.lua could contain the following:

This article or section is a candidate for merging with Conky.

If using conky, you must set it to create its own window instead of using the desktop. To do so, edit ~/.conkyrc to contain

Otherwise strange behavior may be observed, such as all windows becoming fully transparent. Note also that since conky will be creating a transparent window on your desktop, any actions defined in awesome's rc.lua for the desktop will not work where conky is.

There is built-in pseudo-transparency for wiboxes. To enable it, append 2 hexadecimal digits to the colors in your theme file (e.g. ~/.config/awesome/themes/default/theme.lua, which is usually a copy of /usr/share/awesome/themes/default/theme.lua), like shown here:

where "AA" is the transparency value.

To change transparency for the actual selected window by pressing Modkey + PgUp/PgDown you can also use transset-dfAUR and the following modification to your rc.lua:

The default rc.lua places widgets including keyboard layout and clock in a wibox with little spacing. It is possible to add extra spacing between widgets using the spacing property:

This article or section is a candidate for merging with Composite manager.

You may have problems if you set your wallpaper with imagemagick's display command. It does not work well with xcompmgr. Please note that awsetbg may be using display if it does not have any other options. Installing habak, feh, hsetroot or whatever should fix the problem (grep -A 1 wpsetters /usr/bin/awsetbg to see your options).

You can easily send text to an awesome widget. Just create a new widget:

To update the text from an external source, use awesome-client:

Do not forget to add the widget to your wibox.

If you like awesome's lightweightness and functionality but do not like the way its default panel looks, you can install a different panel, for example xfce4-panel.

Then add it to the autorun section of your rc.lua. You may also comment out the section which creates wiboxes for each screen (starting from mywibox[s] = awful.wibox({ position = "top", screen = s })) but it is not necessary. Do not forget to check your rc.lua for errors by typing:

You should also change your modkey+R keybinding, in order to start some other application launcher instead of built in awesome. See List of applications/Other#Application launchers for examples. Do not forget to add:

awesome includes menubar. By default, pressing Mod+p will open a dmenu-like applications menu at the top of the screen. This menu searches for .desktop files in $XDG_DATA_DIRS/applications/ and $XDG_DATA_HOME/applications/.

You can extend or replace these directories by modifying menubar.menu_gen.all_menu_dirs:

Note that the .desktop files are re-read each time awesome starts, thereby slowing down the startup. If you prefer other means of launching programs, the menubar can be disabled in rc.lua by removing local menubar = require("menubar") and other references to the menubar variable.

There is a simple menu by default since awesome 3, simplifying custom menus. [4] If you want a freedesktop.org menu, you could take a look at awesome-freedesktop.

If you prefer to use an external applications menu when you click on the Awesome icon, or right-click on an empty area of the desktop, you can follow the instructions in Xdg-menu#Awesome. However this menu is not updated when you add or remove programs. So, be sure to run the command to update your menu. It may look something like:

It is easy to enable titlebars in awesome by simply setting the variable titlebars_enabled to true in the configuration file. （in rules area）

However, you may want to be able to toggle the titlebar on or off. You can do this by simply adding something like this to your key bindings: (in clientkeys of Key bindings. And do not put the code to the end of the clientkeys area)

Then you may want to initially hide the titlebars. To do that just add this immediately after the title bar is created (inside the "manage" signal handler):

See this blog post for a simple battery notification to add to rc.lua. Note that it needs naughty for the notifications (installed by default in version 3.5). Other examples are available at awesome wiki.

It is possible to control both volume and media playback via a combination of amixer(1) (available via the alsa-utils package) and playerctl. The following can be added to the relevant key binding section of your rc.lua configuration file:

The on screen Steam Keyboard that can be activated by the Steam Controller appears to freeze after trying to type one character. This is because the client that is supposed to receive the input has to be focused to receive it and the keyboard will wait until this input is successfully send. Manually focusing another client will send the input to this client and unfreeze the keyboard again until the next character is entered.

The trick to getting the keyboard to work correctly is to prevent it ever receiving focus. Add the following signal to your configuration (or merge with an existing client focus signal):

This will return the focus to the last client whenever the keyboard receives focus. As the input to the keyboard is handled by the Steam client and as such does not need focus, inputting text will now work correctly.

Xephyr allows you to run X nested in another X's client window. This allows you to debug rc.lua without breaking your current desktop. Start by copying rc.lua into a new file (e.g. rc.lua.new), and modify it as needed. Then run new instance of awesome in Xephyr, supplying rc.lua.new as a configuration file like this:

The advantage of this approach is that if you introduce bugs you do not break your current awesome desktop, potentially crashing X applications and losing work. Once you are happy with the new configuration, copy rc.lua.new to rc.lua and restart awesome.

In addition to the method above, you can use inotify-tools in order to automatically reload the Awesome instance inside Xephyr when updating any configuration file inside the ~/.config/awesome directory:

awmttAUR (Awesome WM Testing Tool) is an easy to use wrapper script around Xephyr. By default, it will use ~/.config/awesome/rc.lua.test. If it cannot find that test file, it will use your actual rc.lua. You can also specify the location of the configuration file you want to test:

When you are done testing, close the window with:

Or immediately see the changes you are doing to the configuration file by issuing:

aawmttAUR (Another Awesome WM Testing Tool) is an alternative implementation of awmttAUR, which includes Live-Reload by default. It is similar to awmtt-ng, but includes some fixes for the XOrg Display detection which does not work on some machines with awmtt-ng. It differs from awmtt in that it does not try to run a test file first, but just runs the default config.

To simply open a Xephyr window with awesome loaded, run:

The output of awesome will now be printed to your terminal and upon changing any files in your configuration folder, awesomewm will be reloaded.

In case you want to modify the directory that is watched for file changes, or the location of your configuration file, simply run:

The directory that is watched for changes defaults to the parent directory of your config file, so by default it would be "~/.config/awesome".

If you are using LightDM, awesome will log errors to `$HOME/.xsession-errors`. If you use .xinitrc to start awesome, the entry "Where are logs, error messages or something?" in the FAQ may be a helpful resource.

This article or section is a candidate for merging with Configuring_keyboard_layouts_in_X.

Awesome recommends to remap mod4, which by default should be the Super or "Windows" key. If for some reason it is not mapped to mod4, use xmodmap to find out what is. To change the mapping, use xev to find the keycode and name of the key to be mapped. Then add something like the following to ~/.xinitrc

The problem in this case is that some xorg installations recognize keycode 115, but incorrectly as the 'Select' key. The above command explictly remaps keycode 115 to the correct 'Super_L' key.

To remap mod4 with setxkbmap (conflict with xmodmap) see:

To set the caps lock key as mod4 add the following to ~/.xinitrc:

See Java#Gray window, applications not resizing with WM, menus immediately closing and [5].

If you get stuck and cannot move or resize the main window (using mod4 + left/right mouse button) edit the workbench.xml and set fullscreen/maximized to false (if set) and reduce the width and height to numbers smaller than your single screen desktop area.

workbench.xml can be found in eclipse_workspace/.metadata/.plugins/org.eclipse.ui.workbench/. Edit the line:

If you have two displays and use code-prediction (Ctrl + Space) in Netbeans, the code-predictions might appear on the wrong screen. This fixed it for me:

This article or section is out of date.

See GitHub issue #2204.

This fixed it for me:

When using scrot, you may have problems at assigning a keyboard shortcut to the mouse selection option (formally scrot -s). To fix it, add the following line to your rc.lua:

Note that nil is passed to the press argument of awful.key. Instead, the callback function is passed as fourth argument, which is the argument named release.

If YouTube videos appear underneath your web browser when in fullscreen mode, or underneath the panel with controls hidden, add this to rc.lua

In your rc.lua, change the Mouse Bindings section to the following:

Xdg-menu will generate duplicate entries if you copy desktop-files from /usr/share/applications to ~/.local/share/applications even though it might be preferable to simply override the originals, for example using a different theme for a specific application. One solution to the problem is to filter the generated output trough awk to remove entries with a name identical to the previous entry.

for Overlapping keys like "Super L" or Key Combinations which should be run by Awesome

Some users experience memory leaks even without activity. When using a lot of widgets leaks can occur at a rate up to 5 MB/min. To mitigate this you can enforce more frequent garbage collection by adding this to your ~/.config/awesome/rc.lua:

**Examples:**

Example 1 (unknown):
```unknown
~/.config/awesome/rc.lua
```

Example 2 (unknown):
```unknown
$ mkdir -p ~/.config/awesome/
```

Example 3 (unknown):
```unknown
$ cp /etc/xdg/awesome/rc.lua ~/.config/awesome/
```

Example 4 (unknown):
```unknown
~/.config/awesome/rc.lua
```

---

## Sway

**URL:** https://wiki.archlinux.org/title/Sway

**Contents:**
- Installation
- Starting
  - Manually
  - Automatically on TTY login
  - From a display manager
- Configuration
  - Keymap
  - Typematic delay and rate
  - Statusbar
  - Outputs

Sway (contracted from SirCmpwn's Wayland compositor [1]) is a compositor for Wayland designed to be fully compatible with i3. According to the official website:

If you are interested in eye-candy, swayfxAUR exists as a fork of sway with popular eye-candy effects.

sway-scroll-gitAUR is another fork of sway with a scrolling layout like PaperWM or niri. It also supports animations, window content scaling and several overview modes.

Sway can be installed with the sway package. Always update wlroots when you update sway, due to tight dependencies.

You may also install swaylock, swayidle, and swaybg to lock your screen, set up an idle manager, and set wallpapers, respectively.

The default application launcher is wmenu and the default terminal emulator is foot. Before starting sway it is advisable to either install them or set a new launcher and terminal in the configuration. For other Wayland-compatible versions of some useful i3 packages you can look at the migration guide on the Sway wiki.

Before Sway can be started, it needs access to your hardware devices such as your keyboard, mouse, and graphics card. The collection of these hardware devices is called a seat, as mentioned in sd-login(3) § DEFINITION OF TERMS。

On Arch Linux, Sway can get access to your seat using either

If polkit is already installed on your system, Sway should automatically get access to your seat.

Alternatively, if polkit is not installed on your system and you want to use seatd instead, add yourself to the seat user group and enable/start seatd.service, then re-log.

You can pick one of the following methods to start Sway.

To start Sway, simply type sway in the Linux console.

Similarly to X, Sway can be started by adding the following to your shell initialization file (see Command-line shell#Login shell):

For more details, see Xinit#Autostart X at login

The sway session is located at /usr/share/wayland-sessions/sway.desktop. It is automatically recognized by modern display managers like GDM and SDDM.

It is also possible to start sway as a systemd user service through the display manager.

Also you can use text-based session manager, see Display manager#Console.

If you already use i3, you may copy your i3 configuration to ~/.config/sway/config and it should work out of the box. Otherwise, copy the sample configuration file located at /etc/sway/config to ~/.config/sway/config. See sway(5) for information on the configuration.

By default, sway starts with the US QWERTY keymap. To configure per-input:

More details are available in xkeyboard-config(7) and sway-input(5).

The keymap can also be configured using environment variables (XKB_DEFAULT_LAYOUT, XKB_DEFAULT_VARIANT, etc.) when starting sway. The configuration options take precedence over environment variables.

To change typematic delay and rate, you can add the following lines to your input section:

Sway ships with a default status bar in the form of swaybar which runs in a pure Wayland environment. swaybar can call a shell script or other program to show information in the status bar. See sway-bar(5) and swaybar-protocol(7) for details.

Installing i3status is an option to obtain a practical, default status bar under Wayland. All you have to do is add the following snippet at the end of your sway config:

If you want to enable colored output for i3status, you need to adjust the following part in the i3status configuration:

The output command in sway allows for the detailed configuration of different display outputs. This includes settings for wallpaper, scale factor, position, and more. You can combine multiple output commands into one line, as needed.

Outputs can be specifically addressed by employing their designated output names, by universally matching all outputs with "*", or through utilizing the distinct names of the displays (a string consisting of the make, model and serial). For example:

You can get a list of output names and additional information using the command:

For a deeper dive into configurations and additional options, consult sway-output(5).

The displaying of a wallpaper in sway is handled by a dedicated program. The simplest example is swaybg, which sway can manage directly. swaybg must be installed if needed in order to run the output ... bg command.

The following line, which can be included anywhere in sway's configuration file, sets a background image on all displays:

Of course /path/to/image should be replaced with the path to an existing image file.

Solid colors may be set as follows:

See the Sway wiki for additional tools and utilities for wallpaper management.

Sway automatically applies integer scaling by default. If the following conditions hold: [3]

then Sway will use 2x scaling. Some devices, such as the Framework Laptop 16, have a DPI that is close to (but not quite) 192. In these cases, you may want to manually configure fractional scaling.

Set your displays scale factor with the output command in your configuration file. The scale factor can be fractional, but it is usually 2 for HiDPI screens.

You can find your display name with the following command:

By default, sway will synchronize frame updates (vsync) to make frame-perfect output without tearing, at the cost of latency. But in some cases it is useful to disable vsync to make output more smooth (e.g. video games):

It is possible to tweak specific input device configurations. For example, to enable tap-to-click and natural scrolling for all touchpads:

To set the configuration for a particular touchpad, use swaymsg -t get_inputs to obtain a device identifier and use it instead of type:touchpad.

More documentation and options like acceleration profiles or disabling input entirely can be found in sway-input(5).

If you use a graphics tablet, see Graphics tablet#Sway.

Touch input targets for touch displays used in a multi-display environment can be mapped to only that touch display.

Special keys on your keyboard can be used to execute commands, for example to control volume, monitor brightness or media players:

For details and alternative utilities, see:

To allow a keybinding to be executed while the lockscreen is active add the --locked parameter to bindsym.

It is often desirable to have the current level of some percentage-valued setting, such as brightness or volume, be indicated by a graphical bar when it is adjusted. A good option for providing this facility in Sway is wob (alternatively wob-gitAUR), which provides a subset of the functionality of the popular X tool xobAUR but as a native Wayland utility implementing the layer-shell protocol. See the project website for usage examples.

If you are using a lot of workspaces with a lot of windows and cannot follow what is where any more, then sovAUR can come in handy. It is an overlay that shows schemas for all workspaces to make navigation in sway easier. It shows program names, window titles, supports multi-output setup. See the project page for more information.

Sway has a dedicated idle management daemon named swayidle to handle idling sessions. There are different ways to start and parameterize the daemon. The simplest is to use the configuration of sway itself. swayidle accepts a multitude of arguments to configure events like timeout (a.k.a. idling), resume (not idle anymore, after a timeout), before-sleep etc. See swayidle(1) for more details and further explanations of the events. Each event can then be assigned an action. To assign multiple actions to an event simply repeat the trigger.

The following instructs swayidle to lock the screen after 30 minutes and turn it off five seconds after:

To turn off a locked screen much sooner e.g. after 10 seconds, grep the process list for your locking manager and execute swaymsg "output * power off" accordingly like so:

In order to lock the screen before suspending and pause any playing media, append the following instruction to the swayidle command:

If you do not want swaylock to trigger while videos are playing in Firefox, Chrome or VLC, you can use idlehack-gitAUR to listen for dbus screensaver inhibit requests and invoke swayidle-inhibit. Programs like Firefox, Chrome and VLC emit these events to prevent the system from going idle.

Using before-sleep swaylock, might cause screen content to be briefly shown upon resume. To mitigate this, you can let logind to ignore lid events and use sway to handle lid and power button events.

We use --locked option for suspending the system when the lid is toggled during lock screen. If you are using clamshell mode, you can unset the lid binding with unbindswitch lid:toggle. pgrep swaylock is for suspending the computer again during accidental wake-ups.

logind integration is considered buggy and is hard to maintain. See also [4].

To enable floating windows or window assignments, open the application and then use the app_id, the class, the instance and the title attributes to enable floating windows/window assignments. The following command will list the properties of all the open windows.

To get only the app_id's of all open windows use:

To get the app_id of the focused window use:

X11 windows do not have an app_id property. However, you can use attributes like class, window_type, window_role and/or the instance to match them. You can search the output of swaymsg -t get_tree and create fine grained rules for your windows.

This is similar to using xorg-xprop to find the class or wm_name attributes in X11.

When using multiple monitors, the floating scratchpad window can get too large, covering more than one monitor. This command centers and resizes the floating window to 80% of the current monitor's size:

This article or section is a candidate for merging with Clipboard.

The clipboard content in Wayland is maintained by the program that copied it. If the program closes, the copied content becomes unavailable.

To persist clipboard content, use a "clipboard manager", it maintains its own copy of the clipboard content.

One example of a clipboard manager, designed for Wayland, is clipman, which can be installed from clipmanAUR or clipman-gitAUR.

To start clipman with Sway, add the following line to your configuration file:

Copy ~/.Xresources to ~/.Xdefaults to use them in Sway.

See Wayland#Xwayland for details and an overview of available packages.

The use of Xwayland is enabled by default.

If you would like to disable Xwayland entirely and run a "pure" Wayland session, set the following to deactivate the use of Xwayland:

If you would like to be able to tell at a glance which windows are using Xwayland, set the following:

To use another renderer such as Vulkan, see Wayland#Use another renderer for wlroots based compositor.

See i3#Autostart, adjusting the configuration file name for sway.

By default, sway initially disables the CapsLock and NumLock keys on startup. To instead enable them on startup, set the xkb_capslock and/or xkb_numlock input configurations to enable for your keyboards. For example, to do so on all keyboards, add the following lines to your sway configuration:

In either case, the CapsLock and NumLock keys may be toggled by pressing the relevant keys on a keyboard.

The current keyboard layout can be retrieved as follows, where kbd_identifier needs to be replaced with your keyboard's identifier:

To set up PrintScreen as the compose key:

The available key combinations can be looked up as shown in Xorg/Keyboard configuration#Configuring compose key. The combinations for the compose key can also be configured in the XCompose file. Applications need to be restarted for this change to take effect.

To turn off (and on) your displays with a key (e.g. Pause) bind the following script in your Sway config:

Or you can use the toggle option directly, but you need to specify an output explicitly if you have multiple monitors:

See Screen capture#Wayland.

See Backlight#Wayland.

It is possible to use a color profile by adding the following line to your config file:

Swaynag, the default warning/prompt program shipped with sway, only supports user interaction with the mouse. A helper program such as swaynagmodeAUR may be used to enable interaction via keyboard shortcuts.

Swaynagmode works by first launching swaynag, then listening for signals which trigger actions such as selecting the next button, dismissing the prompt, or accepting the selected button. These signals are sent by launching another instance of the swaynagmode script itself with a control argument, such as swaynagmode --select right or swaynagmode --confirm.

Swaynagmode by default triggers the sway mode nag upon initialization, followed by default on exit. This makes it easy to define keybindings in your sway configuration:

Note that, beginning in sway version 1.2, mode names are case-sensitive.

You can configure sway to use swaynagmode with the configuration command swaynag_command swaynagmode.

To set the cursor theme and size:

Where my_cursor_theme can be set to or replaced by a specific value like default, Adwaita or Simple-and-Soft, and my_cursor_size a value like 48.

You can inspect their values with echo $XCURSOR_SIZE and echo $XCURSOR_THEME.

Note that you need to restart the application to see the changes.

Systemd provides a graphical-session.target which is a user unit which is active whenever any graphical session is running, whether Xorg or Wayland. User services which should run in all graphical environments can be bound to that target. It also allows for a window-manager-specific target to be bound to graphical-session.target to start and stop services which should run only under that window manager. See systemd.special(7)

Users may want to start some services/daemons (such as swayidle or kanshi) only when the current window manager is Sway, and they may also want these services to stop when Sway stops. Additionally, users who are running systemd-oomd.service(8) may want to have the services be in separate cgroups so that a single memory-hungry service does not take down the whole Sway session (see the Fedora bug report).

Some or all of this functionality is provided by Arch Sway packages. For example, both sway and sway-gitAUR provide a 50-systemd-user.conf drop-in file (see #Configuration).

If you intend to provide functionality using the roll-your-own method described below or by using a specialist package such as sway-systemd-gitAUR, sway-services-gitAUR or uwsm, you should consider removing files that provide the same functionality.

This functionality can be provided on a roll-your-own basis by creating a sway-session.target and let those daemons/services wanted by sway-session.target. This systemd target should be a user target (see systemd/User). For example:

Then, add the following line to Sway's configuration file (for example, append the line to ~/.config/sway/config, or add a new file to /etc/sway/config.d/):

With the above line in the configuration file, whenever Sway starts, it also activates sway-session.target.

Finally, link the desired services to sway-session.target. You can find an example at kanshi#Manage kanshi with systemd.

When this user unit is enabled, it is only activated when Sway is running and deactivated when Sway stops.

The creation of the sway-session.target file and the importing of the environment can also be accomplished by installing sway-systemd-gitAUR. In addition to separating services into cgroups, sway-systemd also places each GUI application in its own cgroup. This enables imposition of per-cgroup resource constraints on individual application. See the sway-systemd README. Alternatively, a more comprehensive solution is provided by uwsm.

You can use the graphical programs nwg-displays, wdisplaysAUR, swayrandr-gitAUR or the terminal program wlr-randr to change the resolution, rotate and arrange displays or set the scaling factor.

Create outputs not related to a physical video interface, HEADLESS-1, HEADLESS-2, etc.:

Print a description of the new output:

Configure the new output with the output command, for example:

To change the modifier key to CapsLock and keep the Super key functional on a US keyboard layout, create ~/.config/xkb/symbols/custom with contents

For other languages, edit the second and third lines. Then include this keyboard layout in your sway config near the top of the file:

The following code can, for example, be run over SSH to start a headless Sway session and access it remotely over VNC.

wayvnc is a VNC server for wlroots-based Wayland compositors and can serve a headless Sway session.

Start a headless Sway session by setting WLR_BACKENDS to headless and (optionally) WLR_LIBINPUT_NO_DEVICES to 1 (see the FAQ of wayvnc):

Now, run wayvnc to serve the VNC server:

If you want to do something when an output is connected or disconnected, look at kanshi.

dmenu functions relatively well in Sway, but runs under Xwayland and suffers from an issue where it can become unresponsive if the cursor is moved to a native Wayland window. The reason for this issue is that Wayland clients/windows do not have access to input devices unless they have focus of the screen. The Xwayland server is itself a client to the Wayland compositor, so one of its Xwayland clients must have focus for it to access user input. However, once one of its clients has focus, it can gather input and make it available to all Xwayland clients through the X11 protocol. Hence, moving the cursor to an Xwayland window and pressing Escape should fix the issue, and sometimes running pkill does too.

bemenu is a native Wayland dmenu replacement. Both can optionally be combined with j4-dmenu-desktop to provide a Wayland-native combination for launching desktop files (as i3-dmenu-desktop does). For example:

You may need to set BEMENU_BACKEND environment variable to "wayland" if you choose not to disable Xwayland.

You can also build your own with a floating terminal and fzf as discussed in a GitHub issue.

Also krunner binary provided by plasma-workspace package can serve as launcher, offering both Xwayland and native Wayland support.

rofi now works in Wayland while still supporting an X11 session.

wofi is a command launcher, that provides some of the same features as rofi but running under Wayland. wofi lacks some features from rofi like an SSH mode and a window-switching mode. It is based on wlroots0.19 library and use GTK3 for rendering. It works pretty well with sway.

fuzzel is an application launcher for wlroots based Wayland compositors, similar to rofi's drun mode.

Sway works with both VirtualBox and VMware ESXi.

For Sway to work in QEMU, QEMU must be started with -vga qxl. See also QEMU#qxl.

For ESXi, you need to enable 3D support under the Hardware Configuration > Video card settings. See also VMware#Enable 3D graphics on Intel, Optimus and AMD.

When using certain graphics drivers (e.g. the VMSVGA graphics controller or the proprietary NVIDIA driver), the cursor is invisible. This can be fixed by using software cursors as discussed in [5]:

Using a swaymsg argument, such as swaymsg -t get_outputs, will sometimes return the message:

when run inside a terminal multiplexer (such as GNU Screen or tmux). This means swaymsg could not connect to the socket provided in your SWAYSOCK.

To view what the current value of SWAYSOCK is, type:

To work around this problem, you may try attaching to a socket based on the running sway process:

To avoid this error, run the command outside of a multiplexer.

Tmux creates local environment variables for each session (to see them type: tmux show-environment). Therefore, if you re-attach to a previous tmux session with tmux-resurrect or tmux-continuum, or your tmux server runs before sway starts, the environment variables are outdated.

You can use update-environment to instruct tmux to update them whenever you attach to the session by adding the following to your .tmux.conf:

Requesting messages from swaymsg -t on a tty may return the following message:

SWAYSOCK environment variable is set after launching Sway, therefore a workaround to this error is to request swaymsg -t [message] in a terminal inside Sway.

By default, if you are using more than one keyboard layout, e.g. input * xkb_layout "us,ru", bindings may become broken when you switch on some secondary layout.

Thanks to https://github.com/swaywm/sway/pull/3058, all you need is to add --to-code key to sensitive bindsym lines like this:

Alternatively you can create a variable set $mybind bindsym --to-code and then replace all instances of bindsym with $mybind like so: $mybind $mod+w thing

Some Java-based applications will display blank screen when opened, for example any JetBrains editor such as IntelliJ, CLion, or PyCharm. To mitigate this, the application can be started with the _JAVA_AWT_WM_NONREPARENTING environment variable set to 1.

If you start the application from a launcher like rofi or dmenu, you might want to modify the application desktop entry as shown in Desktop entries#Modify environment variables.

Some issues with Java applications have been fixed in OpenJDK 11 and Sway 1.5. However, certain applications require additional configuration to use newer versions of OpenJDK, in the case of Android Studio you must set STUDIO_JDK=/usr/lib/jvm/java-11-openjdk/. [6]

The JRE has a hardcoded list of known window managers in which Sway is not present. If you experience grey panels, mislocated menus, or improperly resized windows, see Java#Impersonate another window manager.

If using the mouse scroll wheel on an application's border crashes sway, you could use border none for the app_id (e.g. Firefox).

If a program crashes on start with the error message "cannot open display", it is likely that the program you are using is an X11 program. You can use the Xwayland compatibility layer to run X11 programs under Wayland, see #Xwayland for details.

When running programs, WINE expects a primary monitor to be set, which can cause issues (such as clicks not registering) as Wayland has no concept of a primary monitor. Instead, you can specify a primary monitor for Xwayland to use via xrandr by adding this line to your Sway configuration:

For this to work your display position offset needs to be 0,0 because of a bug [7] in sway.

Note that XWAYLAND0 (or any XWAYLAND display name) may not represent your monitor, and may be susceptible to change in different sessions. Instead, you can specify the first XWAYLAND display using this line instead:

You may need to adjust these lines to suit your needs. You can find out which displays are mapped to what names by using the xrandr command with no arguments.

Although proprietary graphics drivers like NVIDIA are officially not supported, it is possible to use them, even for gaming. If you choose to do so, you may encounter flickering on the upper half of the screen, which can be worked around by replacing wlroots0.19 with wlroots-nvidiaAUR, or manually compiling your own version with the patch.

**Examples:**

Example 1 (unknown):
```unknown
--unsupported-gpu
```

Example 2 (unknown):
```unknown
seatd.service
```

Example 3 (unknown):
```unknown
if [ -z "$WAYLAND_DISPLAY" ] && [ -n "$XDG_VTNR" ] && [ "$XDG_VTNR" -eq 1 ] ; then
    exec sway
fi
```

Example 4 (unknown):
```unknown
/usr/share/wayland-sessions/sway.desktop
```

---

## VCS package guidelines

**URL:** https://wiki.archlinux.org/title/VCS_package_guidelines

**Contents:**
- Package naming
- Versioning
- Conflicts and dependencies
- Authentication and security
- VCS sources
- The pkgver() function
  - Bazaar
  - Git
  - Mercurial
  - Subversion

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

Version control systems can be used for retrieval of source code for usual statically versioned packages, and the latest (trunk) version of a development branch.

Suffix pkgname with -bzr, -cvs, -darcs, -git, -hg, -svn, etc., unless the package fetches a specific release.

If the resulting package is different after changing e.g. the dependencies, URL or sources — update pkgver to the latest version. If pkgver has not changed since the last update to the PKGBUILD, increase pkgrel instead.

It is recommended to have following version format: RELEASE.rREVISION, where REVISION is a monotonically increasing number that uniquely identifies the source tree (VCS revisions do this). If there are no public releases and no repository tags then zero could be used as a release number or you can drop RELEASE completely and use version number that looks like rREVISION. If there are public releases but repository has no tags then the developer should get the release version somehow e.g. by parsing the project files.

The revision number delimiter — r right before REVISION — is important. This delimiter allows to avoid problems in case if upstream decides to make its first release or uses versions with different number of components. E.g. if at revision 455 upstream decides to release version 0.1, then the revision delimiter preserves version monotonicity: 0.1.r456 > r454. Without the delimiter monotonicity fails: 0.1.456 < 454.

The VCS sources should be specified in the source array and will be treated like any other source. makepkg will clone/checkout/branch the repository into $SRCDEST — same as $startdir if not set in makepkg.conf(5), and copy it to $srcdir (in a specific way to each VCS). The local repository is left untouched, thus invalidating the need for a -build directory.

The general format of a source array is:

An example Git source array:

The pkgver autobump is now achieved via a dedicated pkgver() function. This allows for better control over the pkgver, and maintainers should favor a pkgver that makes sense. To use pkgver(), you still need to declare the pkgver variable with the most recent value. makepkg will invoke function pkgver(), and update variable pkgver accordingly.

Using the most recent annotated tag reachable from the last commit:

Using the most recent un-annotated tag reachable from the last commit:

In case if the git-tag(1) does not contain dashes then one can use simpler sed(1) expression sed 's/-/.r/;s/-/./'.

If tag contains a prefix, like v or project name then it should be cut off:

If there are no tags then use number of revisions since beginning of the history:

Version and only commit/revision number (SHA-1 omitted; however, without a SHA-1 quick referencing of an exact revision is lost if not mindful of versioning):

Both methods can also be combined, to support repositories that start without a tag but get tagged later on (uses a bashism):

In case no satisfactory pkgver can be extracted from the repository, the current date(1) can be used:

Git submodules are a little tricky to do. The idea is to add the URLs of the submodules themselves directly to the sources array and then reference them during prepare().

Downstream project developers may not name their submodule as the same name as the upstream module's repository. To view the name of the Git submodules, go to the .gitmodules file in the project's repository and preview it. For example, a repository named lib-dependency by the upstream developers may be registered as a submodule named libs/libdep in .gitmodules downstream.

Git LFS needs a bit of extra setup:

This also works when the LFS is used in submodules:

When referencing stable git tags or specific commits as a source via git+https://domain.invalid/repository.git#tag=v1.0.0, it is possible to specify their checksum in the PKGBUILD. To do so, simply use makepkg -g or updpkgsums to generate them as you would for any other non-git source.

**Examples:**

Example 1 (unknown):
```unknown
/usr/share/pacman/PKGBUILD-vcs.proto
```

Example 2 (unknown):
```unknown
RELEASE.rREVISION
```

Example 3 (unknown):
```unknown
0.1.r456 > r454
```

Example 4 (unknown):
```unknown
0.1.456 < 454
```

---

## OpenRC

**URL:** https://wiki.archlinux.org/title/OpenRC

**Contents:**
- Installation
  - Booting
- Configuration
  - Services
  - Network
  - Boot logs
  - Hostname
  - Kernel modules
  - Locale
- Usage

OpenRC is a service manager maintained by the Gentoo developers. OpenRC is dependency based and works with the system provided init program, normally SysVinit.

For details on init components, see Init.

Install the openrcAUR package.

From version 0.25 onward, OpenRC provides its own init at /usr/bin/openrc-init. Optionally, you can use other inits from, e.g., busybox. Note that when openrc-init is used, it must be paired with openrc-shutdown, and not the shutdown or reboot commands from other packages, otherwise you will encounter errors.

A basic set of service files are available from the openrc-arch-services-gitAUR package. Other packages may have service files provided outside this package; a search on the AUR is recommended.

To maintain compatibility with historical init scripts, configuration files are installed to /etc/openrc/.

For booting with OpenRC, set the init option in the kernel parameters.

To use OpenRC's built-in init, set init=/usr/bin/openrc-init.

Note that when using openrc-init, the /etc/inittab file is not used.

The /etc/openrc/conf.d directory, and the /etc/openrc/rc.d file is used for configuration.

For general information on configuring OpenRC, see:

For instructions when migrating from systemd, see Init#Configuration.

OpenRC services are enabled by issuing rc-update add service_name runlevel as root. It is recommended to at least enable the following services:

If necessary, create services for each wanted getty by creating symbolic links to /etc/openrc/init.d/getty. E.g. for /dev/tty1:

This article or section is a candidate for moving to Init#Configuration.

To prevent PAM from attempting to register with systemd after logging into the tty (which can sometimes cause problems, it is safe to remove or comment out the lines mentioning systemd in /etc/pam.d/system-auth.

See also Gentoo:Systemd#Native services.

The network is configured through newnet [2]. Modify the /etc/openrc/conf.d/network file; both the ip (iproute2) and the ifconfig (net-tools) commands are supported. Below is an example configuration using ip.

The network service is added to the boot runlevel by default, so no further action is required. See Network configuration for general networking information.

To enable boot logging, uncomment the rc_logger="YES" line in /etc/openrc/rc.conf. When enabled, boot logs are stored in /var/log/rc.log.

OpenRC sets the hostname from /etc/openrc/conf.d/hostname. The file looks as follows:

OpenRC uses /etc/openrc/conf.d/modules instead of /etc/modules-load.d. For example:

Keyboard layout can be configured via /etc/openrc/conf.d/keymaps and /etc/openrc/conf.d/consolefont. You can also configure the settings through the /etc/locale.conf file, which is sourced via /etc/profile.d/locale.sh.

See Gentoo:Localization/Guide#Keyboard layout for the console and Locale for details.

This section draws a parallel between systemd and other init systems.

You can omit the .service and .target extensions, especially if temporarily editing the kernel parameters.

To hide boot messages from OpenRC, you can edit /etc/inittab and add --quiet to every openrc command. For further information check with $ openrc -h.

When shutting the system down, you might get an error message such as

This can be fixed by adding

to /etc/openrc/conf.d/localmount

One option is to add:

in a file with a .conf extension under /etc/openrc/sysctl.d

If the above happens, edit the /etc/openrc/init.d/mount-ro file and put:

after the following line:

By default, sysctl --system is called to load the sysctl configuration. [3] This includes the /etc/sysctl.conf file, which was removed from Arch. [4]

To prevent a missing file error, create the file:

On booting openrc, you may see lines like these :

This is caused by /usr/lib/tmpfiles.d/journal-nocow.conf using options that are only valid if journal is on a btrfs filesystem.

See https://github.com/OpenRC/opentmpfiles/issues/2 for details

A workaround is to create an empty /etc/tmpfiles.d/journal-nocow.conf to override the settings.

Reverting to systemd should be straightforward in most cases. It is essentially the reversal of migrating to OpenRC, with care placed on the following:

**Examples:**

Example 1 (unknown):
```unknown
/usr/bin/openrc-init
```

Example 2 (unknown):
```unknown
openrc-init
```

Example 3 (unknown):
```unknown
openrc-shutdown
```

Example 4 (unknown):
```unknown
/etc/openrc/
```

---

## Language Server Protocol

**URL:** https://wiki.archlinux.org/title/Language_Server_Protocol

**Contents:**
- See also

Language Server Protocol (LSP) defines the protocol used between an editor or IDE and a language server that provides language features like auto complete, go to definition, find all references.

Language servers can be installed natively using the following packages. If your programming language is not in the list, search in the Arch official repositories or in the AUR.

This article or section needs language, wiki syntax or style improvements. See Help:Style for reference.

tailwindcss-language-server

fortran-language-serverAUR

nodejs-intelephenseAUR

jedi-language-server,

sql-language-serverAUR

---

## Downgrading packages

**URL:** https://wiki.archlinux.org/title/Downgrading_packages

**Contents:**
- Return to an earlier package version
  - Using the pacman cache
  - Downgrading the kernel
  - Arch Linux Archive
  - Rebuild the package
  - Automation
- Return from [testing]

Before downgrading a single or multiple packages, consider why you wish to do so. If it is due to a bug, follow the bug reporting guidelines. I.e. search the Arch Linux Bugtracker for existing tasks and if there is none, add a new task. It is better to correct bugs, or at least warn other users of possible issues.

If a package was installed at an earlier stage, and the pacman cache was not cleaned, install an earlier version from /var/cache/pacman/pkg/.

This process will remove the current package and install the older version. Dependency changes will be handled, but pacman will not handle version conflicts. If a library or other package needs to be downgraded with the packages, please be aware that you will have to downgrade this package yourself as well.

Once the package is reverted and confirmed to work, to make pacman -Syu temporarily ignore updates, add the package to the IgnorePkg section of pacman.conf, until the difficulty with the updated package is resolved.

In case of issue with a new kernel, the Linux packages can be downgraded to the last working ones #Using the pacman cache. Go into the directory /var/cache/pacman/pkg and downgrade at least linux, linux-headers and any kernel modules. For example:

The Arch Linux Archive is a daily snapshot of the official repositories. It can be used to install a previous package version, or restore the system to an earlier date.

If the package is unavailable, find the correct PKGBUILD and rebuild it with makepkg.

For packages from the official repositories, retrieve the PKGBUILD with ABS and change the software version. Alternatively, find the package on the Packages website, click "View Changes", and navigate to the desired version. The necessary files can then be downloaded from the directory so that the package can be rebuilt.

See also Arch build system#Using the pkgctl tool.

Old AUR packages can be built by checking out an old commit in the AUR package Git repository. For pre-2015 AUR3 PKGBUILDs, see Arch User Repository#Git repositories for AUR3 packages.

See Official repositories#Disabling testing repositories.

**Examples:**

Example 1 (unknown):
```unknown
/var/cache/pacman/pkg/
```

Example 2 (unknown):
```unknown
# pacman -U file:///var/cache/pacman/pkg/package-old_version.pkg.tar.zst
```

Example 3 (unknown):
```unknown
pacman -Syu
```

Example 4 (unknown):
```unknown
pacman.conf
```

---

## Cross-compiling tools package guidelines

**URL:** https://wiki.archlinux.org/title/Cross-compiling_tools_package_guidelines

**Contents:**
- Important note
- Version compatibility
- Building a cross compiler
- Package naming
- File placement
- Example
- Hows and whys
  - Why not installing into /opt
  - What is that "out-of-path executables" thing?
- Troubleshooting

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

This page describes how to create packages for cross-compiler toolchains. Another method to cross-compile makes use of distcc on mixed architectures. See Distcc#Cross compiling with distcc.

This page describes the new way of doing things, inspired by the following packages:

The following strategies allows you to select compatible versions of gcc, binutils, kernel and C library:

The general approach to building a cross compiler is:

The source of the headers and libc will vary across platforms.

The package name shall not be prefixed with the word cross- (it was previously proposed, but was not adopted in official packages, probably due to additional length of names), and shall consist of the package name, prefixed by GNU triplet without vendor field or with "unknown" in vendor field; example: arm-linux-gnueabihf-gcc. If shorter naming convention exists (e.g. mips-gcc), it may be used, but this is not recommended.

Latest versions of gcc and binutils use non-conflicting paths for sysroot and libraries. Executables shall be placed into /usr/bin/, to prevent conflicts here, prefix all of them with architecture name.

Typically, ./configure would have at least following parameters:

where your_target can be, e.g., "i686-pc-mingw32".

This is PKGBUILD for binutils for MinGW. Things worth noticing are:

This weird thing allows easier cross-compiling. Sometimes, project Makefiles do not use CC & co. variables and instead use gcc directly. If you just want to try to cross-compile such project, editing the Makefile could be a very lengthy operation. However, changing the $PATH to use "our" executables first is a very quick solution. You would then run PATH=/usr/arch/bin/:$PATH make instead of make.

For error, occurred during running configure, read $srcdir/pkgname-build/config.log. For error, occurred during compilation, scroll console log up or search for word "error".

Most probably you made some of non-obvious errors:

Various methods of running generic make install line results in different results. For example, some make targets may not provide DESTDIR support and instead require install_root usage. The same for tooldir, prefix and other similar arguments. Sometimes providing parameters as arguments instead of environment variables, e.g

and vice versa may result in different outcomes (often caused by recursive self-invocation of configure/make).

**Examples:**

Example 1 (unknown):
```unknown
mingw-w64-*
```

Example 2 (unknown):
```unknown
arm-none-eabi-*
```

Example 3 (unknown):
```unknown
arm-wince-cegcc-*
```

Example 4 (unknown):
```unknown
--enable-kernel
```

---

## pkgfile

**URL:** https://wiki.archlinux.org/title/Pkgfile

**Contents:**
- Installation
- Usage
- Command not found
- Automatic updates

pkgfile is a tool for searching files from packages in the official repositories.

Install the pkgfile package.

The pkgfile database can then be synced with:

To search for a package that owns the file makepkg:

To list all files provided by archlinux-keyring:

Latter is comparable to pacman -Ql (see pacman#Querying package databases), except it applies to remote packages.

See Bash#Command not found, Zsh#pkgfile "command not found" handler and Fish#The "command not found" hook.

pkgfile ships with a systemd service and timer for automatically synchronizing the pkgfile database. To activate automatic updates enable pkgfile-update.timer.

By default, pkgfile will be updated daily. To change this schedule, edit the unit file.

**Examples:**

Example 1 (unknown):
```unknown
# pkgfile -u
```

Example 2 (unknown):
```unknown
$ pkgfile makepkg
```

Example 3 (unknown):
```unknown
core/pacman
```

Example 4 (unknown):
```unknown
$ pkgfile -l archlinux-keyring
```

---

## Downgrading packages

**URL:** https://wiki.archlinux.org/title/Downgrade

**Contents:**
- Return to an earlier package version
  - Using the pacman cache
  - Downgrading the kernel
  - Arch Linux Archive
  - Rebuild the package
  - Automation
- Return from [testing]

Before downgrading a single or multiple packages, consider why you wish to do so. If it is due to a bug, follow the bug reporting guidelines. I.e. search the Arch Linux Bugtracker for existing tasks and if there is none, add a new task. It is better to correct bugs, or at least warn other users of possible issues.

If a package was installed at an earlier stage, and the pacman cache was not cleaned, install an earlier version from /var/cache/pacman/pkg/.

This process will remove the current package and install the older version. Dependency changes will be handled, but pacman will not handle version conflicts. If a library or other package needs to be downgraded with the packages, please be aware that you will have to downgrade this package yourself as well.

Once the package is reverted and confirmed to work, to make pacman -Syu temporarily ignore updates, add the package to the IgnorePkg section of pacman.conf, until the difficulty with the updated package is resolved.

In case of issue with a new kernel, the Linux packages can be downgraded to the last working ones #Using the pacman cache. Go into the directory /var/cache/pacman/pkg and downgrade at least linux, linux-headers and any kernel modules. For example:

The Arch Linux Archive is a daily snapshot of the official repositories. It can be used to install a previous package version, or restore the system to an earlier date.

If the package is unavailable, find the correct PKGBUILD and rebuild it with makepkg.

For packages from the official repositories, retrieve the PKGBUILD with ABS and change the software version. Alternatively, find the package on the Packages website, click "View Changes", and navigate to the desired version. The necessary files can then be downloaded from the directory so that the package can be rebuilt.

See also Arch build system#Using the pkgctl tool.

Old AUR packages can be built by checking out an old commit in the AUR package Git repository. For pre-2015 AUR3 PKGBUILDs, see Arch User Repository#Git repositories for AUR3 packages.

See Official repositories#Disabling testing repositories.

**Examples:**

Example 1 (unknown):
```unknown
/var/cache/pacman/pkg/
```

Example 2 (unknown):
```unknown
# pacman -U file:///var/cache/pacman/pkg/package-old_version.pkg.tar.zst
```

Example 3 (unknown):
```unknown
pacman -Syu
```

Example 4 (unknown):
```unknown
pacman.conf
```

---

## LibreOffice

**URL:** https://wiki.archlinux.org/title/LibreOffice

**Contents:**
- Installation
- Theme
- Extension management
- Fonts
- Language aids
  - Spell checking
  - Bidirectional support
  - Hyphenation rules
  - Thesaurus
  - Grammar checking with LanguageTool

From LibreOffice website:

Install one of the following packages:

Check the optional dependencies pacman displays. If you use HSQLDB Embedded in LibreOffice Base, you must install a Java Runtime Environment. You may need hsqldb2-javaAUR to use some modules in LibreOffice Base.

LibreOffice includes support for GTK and Qt theme integration. See also Uniform look for Qt and GTK applications.

LibreOffice will try to auto detect the most suitable VCL interface based on your desktop environment. To force the use of a certain VCL interface, e.g. "gtk4" set the environment variables SAL_USE_VCLPLUGIN=gtk4. For more user interface options see /etc/profile.d/libreoffice-fresh.sh or /etc/profile.d/libreoffice-still.sh, where the variables are listed and can be uncommented.

The following additional extensions are available:

For more extensions, check the AUR, the built-in LibreOffice Extension manager, or libreplanet.

The Document Foundation wiki mentions various fonts that are packaged by default with LibreOffice on Windows and macOS. On Arch, the following packages may be installed for the fonts:

Also see Fonts#Font packages.

For spell checking, make sure hunspell and a language dictionary for it are installed. Then enable the Writing aids by selecting the check-box in Tools > Options > Language Settings > Writing Aids > Hunspell SpellChecker after restarting LibreOffice.

Unlike other languages, Finnish spellchecking and grammar checking are based on Voikko. For LibreOffice voikko-libreofficeAUR should be installed.

Project Orthos provides more complete Greek spell checkers as Libreoffice extensions. Package libreoffice-extension-orthos-greek-dictionaryAUR provides a Greek-only spelling dictionary, while libreoffice-extension-orthos-greek-english-dictionaryAUR provides one that bundles Greek and US English.

To enable Bidi support, select the check-box for Complex Text Layout (CTL) from: Tools > Options... > Languages and Locales > General > Default Languages for Documents, then choose the appropriate language. Language alignment can then be forced by RCtrl + RShift and LCtrl + LShift. There's a known issue that switches text direction when paragraph style changes.

For hyphenation rules, you will need hyphen and a language hyphen rule set (hyphen-en for English, hyphen-de for German, etc).

For the thesaurus option, you will need libmythes and a mythes language thesaurus (like mythes-en for English, mythes-de for German, etc).

For Greek, instead of mythes-elAUR you may want to try out libreoffice-extension-orthos-greek-thesaurusAUR, which includes more words.

For grammar checking, several tools are available. The most common is languagetool. Instructions on how to use it depend on which version of LibreOffice you have.

Since version 7.4, LibreOffice supports LanguageTool natively, no extensions are needed:

See LanguageTool page for more information.

libreoffice-still and libreoffice-fresh provide the offline help files for en-US. Help files for different locales is provided by the appropriate libreoffice language package, (i.e., libreoffice-fresh-en-za provides the help files for en-ZA locales).

The factual accuracy of this article or section is disputed.

If you intend to use macros, you must have a Java Runtime Environment enabled.

The default path for macros in Arch Linux is different from most Linux distributions. Its location is: ~/.config/libreoffice/4/user/Scripts/.

Base can be used as a frontend to a database like PostgreSQL. It cannot edit the tables but It gives a very nice overview of the columns and rows of a table with the possibility of hiding columns for better overview of the relevant data. It can also filter the data and enables deletion of multiple rows by selecting them and easy editing of single cells.

It can also help construct SQL queries with the help of a query GUI.

Document conversion can be done by libreoffice directly if called with the --headless command line option. For example, to convert a .odt into .pdf file, you can issue:

Another option is to use the command line tool unoconv, which is an automated conversion and styling tool that uses LibreOffice. Even though it requires more work [4], it is still very useful as it is. It either connects to a running LibreOffice, starts one for its own usage, or connects to a running instance that was started explicitly for its usage. A running X server is not required.

Some user actions like closing LibreOffice with an unsaved document will bring up the "Save Document?" popup window together with a notification sound. Enabling/disabling notification sounds can be tried by changing the GTK configuration option gtk-enable-event-sounds, see GTK#Examples.

A general way to track down problems is the safe mode in LibreOffice:

In case the document uses a font that is not installed in the system, LibreOffice will use an alternative font to render the document. This is called "font substitution".

LibreOffice uses fontconfig to resolve fonts.

To find out which font is the substitute for a missing font, you can issue:

If the result is something like My Font.otf, it means the font is correctly installed. If the result is something different, it means that "My Font" is not installed and is being substituted by something else.

Note that LibreOffice will not issue any errors or messages when it substitutes a font with another. It just puts the name of the font on the toolbar in italics, which mean the font is missing and is being substituted.

Substitution proposed by fontconfig can be overridden with LibreOffice. To override a fontconfig substitution, proceed as follows.

From the drop-down menu, select Tools > Options > LibreOffice > Fonts. Check the box that says Apply Replacement Table. Type the name of your font, for example My Font, in the font box and choose your desired font for the Replace with option. When done, click the checkmark. Then choose the Always and Screen only options in the box below. Click OK.

This article or section is a candidate for merging with Font configuration.

To make the change persistent, add Xft.lcdfilter: lcddefault to your ~/.Xresources file, and make sure to run $ xrdb -merge ~/.Xresources (source). See X resources for more details.

If this does not work, you can also try adding Xft.lcdfilter: lcddefault to your ~/.Xdefaults. If you do not have this file, you will have to create it.

If LibreOffice hangs when trying to open or save a document located on a NFSv3 share, try prepending the following lines with a # in /usr/lib/libreoffice/program/soffice:

To avoid overwriting on update you can copy /usr/lib/libreoffice/program/soffice in /usr/local/bin. Original post here.

See the official documentation.

The only solution is to rename the .pps file to .ppt.

Add the following script to your home directory and use it to open every .pps file. Very useful to open .pps files received by email without the need to save them.

If embedded videos are just gray boxes, make sure to have installed the GStreamer plugins required.

If the default paper size in blank Writer and Draw documents is persistently incorrect for your locale, try installing the libpaper optional dependency and either updating /etc/papersize (for a system-wide change) or creating ~/.config/papersize (for a user change) with your preferred paper size. See paper(1) and paper --no-size --all.

If expected default AutoText behaviour is not present (for example, typing fn in a document in Writer and then pressing the F3 key does not result in the automatic insertion of a numbered function) when the system locale is not en_US you need to add the default en_US AutoText templates to your AutoText path. To do this, go to Tools > AutoText..., then click on Path... and add the following path to the list: /usr/lib/libreoffice/share/autotext/en-US. AutoText should now work as expected by default.

Disable OpenCL and/or OpenGL by setting the environment variable SAL_DISABLE_OPENCL=1 and/or SAL_DISABLEGL=1. The LibreOffice safe mode also offers the option to disable both.

If LibreOffice is freezing or failing to start with the message "Application Error" but works fine when OpenCL is disabled, try installing an OpenCL runtime.

To work around issues with scaling UI elements in Wayland on HiDPI screens, try to specify a VCL interface (e.g., gtk3 or qt6). See #Theme.

Multiple screens with different scaling are affected by a bug preventing proper scaling on all screens. As a workaround start LibreOffice in Xwayland-mode (e.g. WAYLAND_DISPLAY= libreoffice).

To ensure LibreOffice always falls back on kio-fuse for remote files (instead of its internal webdav implementation and password store), remove ,webdav,webdavs from the X-KDE-Protocols key in all libreoffice*.desktop files.

Users of KDE Plasma 6 and 5 and some users testing with GNOME have reported issues of terrible lag while scrolling through documents as reported in [5]. Running LibreOffice through X11 can solve the issue (There are reports that the issue is not resolved in GNOME when using the GTK3 backend). This can be done individually by the setting the environment variable QT_QPA_PLATFORM=xcb libreoffice while in KDE Plasma (QT) or GDK_BACKEND=x11 libreoffice while in GNOME (GTK). Each .desktop file can be edited to permanently apply the change until a fix is found. Users can also switch back to X11 to mediate the issue.

**Examples:**

Example 1 (unknown):
```unknown
SAL_USE_VCLPLUGIN=gtk4
```

Example 2 (unknown):
```unknown
/etc/profile.d/libreoffice-fresh.sh
```

Example 3 (unknown):
```unknown
/etc/profile.d/libreoffice-still.sh
```

Example 4 (unknown):
```unknown
https://api.languagetool.org/v2
```

---

## PKGBUILD

**URL:** https://wiki.archlinux.org/title/PKGBUILD

**Contents:**
- Package name
  - pkgbase
  - pkgname
- Version
  - pkgver
  - pkgrel
  - epoch
- Generic
  - pkgdesc
  - arch

This article discusses variables definable by the maintainer in a PKGBUILD. For information on the PKGBUILD functions and creating packages in general, refer to Creating packages. Also read PKGBUILD(5).

A PKGBUILD is a Bash script containing the build information required by Arch Linux packages.

Packages in Arch Linux are built using the makepkg utility. When makepkg is run, it searches for a PKGBUILD file in the current directory and follows the instructions therein to either compile or otherwise acquire the files to build a package archive—pkgname.pkg.tar.zst. The resulting package contains binary files and installation instructions, readily installable with pacman.

Mandatory variables are pkgname, pkgver, pkgrel, and arch. license is not strictly necessary to build a package, but is recommended for any PKGBUILD shared with others, as makepkg will produce a warning if not present.

It is a common practice to define the variables in the PKGBUILD in the same order as given here. However, it is not mandatory.

See the .proto files in the /usr/share/pacman/ directory as examples.

When building regular packages, this variable should not be explicitly declared in the PKGBUILD: its value defaults to that of #pkgname.

When building a split package, this variable can be used to explicitly specify the name to be used to refer to the group of packages in the output of makepkg and in the naming of source-only tarballs. The value is not allowed to begin with a hyphen. If not specified, the value will default to the first element in the pkgname array.

All options and directives for split packages default to the global values given in the PKGBUILD. Nevertheless, the following ones can be overridden within each split package’s packaging function: #pkgdesc, #arch, #url, #license, #groups, #depends, #optdepends, #provides, #conflicts, #replaces, #backup, #options, #install, and #changelog.

Either the name of the package, e.g. pkgname=foo, or, for split packages, an array of names, e.g. pkgname=(foo bar). Package names should only consist of lowercase alphanumerics and the following characters: @._+- (at symbol, dot, underscore, plus, hyphen). Names are not allowed to start with hyphens or dots. For the sake of consistency, pkgname should match the name of the source tarball of the software: for instance, if the software is in foobar-2.5.tar.gz, use pkgname=foobar.

The version of the package. This should be the same as the version published by the author of the upstream software. It can contain letters, numbers, periods and underscores, but not a hyphen (-). If the author of the software uses one, replace it with an underscore (_). If the pkgver variable is used later in the PKGBUILD, then the underscore can easily be substituted for a hyphen, e.g. source=("${pkgname}-${pkgver//_/-}.tar.gz").

The release number. This is usually a positive integer number that allows to differentiate between consecutive builds of the same version of a package. As fixes and additional features are added to the PKGBUILD that influence the resulting package, the pkgrel should be incremented by 1. When a new version of the software is released, this value must be reset to 1. In exceptional cases other formats can be found in use, such as major.minor.

Used to force the package to be seen as newer than any previous version with a lower epoch. This value is required to be a non-negative integer; the default is 0. It is used when the version numbering scheme of a package changes (or is alphanumeric), breaking normal version comparison logic. For example:

See pacman(8) for more information on version comparisons.

The description of the package. This is recommended to be 80 characters or less and should not include the package name in a self-referencing way, unless the application name differs from the package name. For example, use pkgdesc='Text editor for X11' instead of pkgdesc='Nedit is a text editor for X11'.

Also it is important to use keywords wisely to increase the chances of appearing in relevant search queries.

An array of architectures that the PKGBUILD is intended to build and work on. Arch officially supports only x86_64, but other projects may support other architectures. For example, Arch Linux 32 provides support for i686 and pentium4, and Arch Linux ARM provides support for armv7h (armv7 hardfloat) and aarch64 (armv8 64-bit).

There are two types of values the array can use:

The target architecture can be accessed with the variable CARCH during a build.

The URL of the official site of the software being packaged.

This article or section is a candidate for merging with Arch package guidelines#licenses.

This article or section needs expansion.

The license under which the software is distributed. Arch Linux uses SPDX license identifiers. Each license must have a corresponding entry in /usr/share/licenses/.

For common licenses (like GPL-3.0-or-later), package licenses delivers all the corresponding files. The package is installed by default, as it is a dependency of base meta package, and the files may be found in /usr/share/licenses/spdx/. Simply refer to the license using its SPDX license identifier from the list of SPDX identifiers.

License families like BSD or MIT are, strictly speaking, not a single license and each instance requires a separate license file. In license variable refer to them using a common SPDX identifier (e.g. BSD-3-Clause or MIT), but then provide the corresponding file as if it was a custom license.

For custom licenses the identifier should be either LicenseRef-license-name or custom:license-name, if they are not covered by the common families mentioned above. The corresponding license text must be placed in directory /usr/share/licenses/pkgname. To install the file a following code snippet may be used in package() section:

Combining multiple licenses or adding exceptions should follow the SPDX syntax. For example a package released under either GNU/GPL 2.0 or GNU/LGPL 2.1 could use 'GPL-2.0-or-later OR LGPL-2.1-or-later', a package released under Apache 2.0 with LLVM exception would use 'Apache-2.0 WITH LLVM-exception' and a package released with part under the BSD 3 clause, others under GNU/LGPL 2.1 and some under GNU/GPL 2.0 would use 'BSD-3-Clause AND LGPL-2.1-or-later AND GPL-2.0-or-later'[2]. Note that this must be a single string, so the entire expression has to be enclosed in quotes. As for November 2023 SPDX list of exceptions is limited, so usually the custom license route must be used.

If issues are encountered with SPDX identifiers, during the transitional period using old identifiers —names of the directories in /usr/share/licenses/common— is acceptable.

See also Nonfree applications package guidelines.

Additional information and perspectives on free and open source software licenses may be found on the following pages:

The group the package belongs in. For instance, when installing plasma, it installs all packages belonging in that group.

An array of packages that must be installed for the software to build and run. Dependencies defined inside the package() function are only required to run the software.

Version restrictions can be specified with comparison operators, e.g. depends=('foobar>=1.8.0'); if multiple restrictions are needed, the dependency can be repeated for each, e.g. depends=('foobar>=1.8.0' 'foobar<2.0.0').

This article or section is a candidate for merging with Arch package guidelines.

The depends array should list all direct first level dependencies even when some are already declared transitively. For instance, if a package foo depends on both bar and baz, and the bar package depends in turn on baz too, it will ultimately lead to undesired behavior if bar stops pulling in baz. Pacman will not enforce the installation of baz on systems which newly install the foo package, or have cleaned up orphans, and foo will crash at runtime or otherwise misbehave.

In some cases this is not necessary and may or may not be listed, for example glibc cannot be uninstalled as every system needs some C library, or python for a package that already depends on another python- module, as the second module must per definition depend on python and cannot ever stop pulling it in as a dependency.

Dependencies should normally include the requirements for building all optional features of a package. Alternatively, any feature whose dependencies are not included should be explicitly disabled via a configure option. Failure to do this can lead to packages with "automagic dependencies" build-time optional features that are unpredictably enabled due to transitive dependencies or unrelated software installed on the build machine, but which are not reflected in the package dependencies.

If the dependency name appears to be a library, e.g. depends=(libfoobar.so), makepkg will try to find a binary that depends on the library in the built package and append the soname version needed by the binary. Manually appending the version disables automatic detection, e.g. depends=('libfoobar.so=2').

An array of packages that are only required to build the package. The minimum dependency version can be specified in the same format as in the depends array. The packages in the depends array are implicitly required to build the package, they should not be duplicated here.

An array of packages that the software depends on to run its test suite, but are not needed at runtime. Packages in this list follow the same format as depends. These dependencies are only considered when the check() function is present and is to be run by makepkg.

An array of packages that are not needed for the software to function, but provide additional features. This may imply that not all executables provided by a package will function without the respective optdepends.[3] If the software works on multiple alternative dependencies, all of them can be listed here, instead of the depends array.

A short description of the extra functionality each optdepend provides should also be noted:

An array of additional packages that the software provides the features of, including virtual packages such as cron or sh and all external shared libraries. Packages providing the same item can be installed side-by-side, unless at least one of them uses a conflicts array.

An array of packages that conflict with, or cause problems with the package, if installed. All these packages and packages providing this item will need to be removed. The version properties of the conflicting packages can also be specified in the same format as the depends array.

Note that conflicts are checked against pkgname as well as names specified in the provides array. Hence, if your package provides a foo feature, specifying foo in the conflicts array will cause a conflict between your package and all other packages that contain foo in their provides array (i.e., there is no need to specify all those conflicting package names in your conflicts array). Let us take a concrete example:

When packages provide the same feature via the provides array, there is a difference between explicitly adding the alternative package to the conflicts array and not adding it. If the conflicts array is explicitly declared the two packages providing the same feature will be considered as alternative; if the conflicts array is missing the two packages providing the same feature will be considered as possibly cohabiting. Packagers should always ignore the content of the provides variable in deciding whether to declare a conflicts variable or not.

An array of obsolete packages that are replaced by the package, e.g. wireshark-qt uses replaces=('wireshark'). When syncing, pacman will immediately replace an installed package upon encountering another package with the matching replaces in the repositories. If providing an alternate version of an already existing package or uploading to the AUR, use the conflicts and provides arrays, which are only evaluated when actually installing the conflicting package.

An array of files that can contain user-made changes and should be preserved during upgrade or removal of a package, primarily intended for configuration files in /etc. If these files are unchanged from how they ship with the package, they will be removed or replaced as normal files during upgrade or removal.

Files in this array should use relative paths without the leading slash (/) (e.g. etc/pacman.conf, instead of /etc/pacman.conf). The backup array does not support empty directories or wildcards such as "*".

When updating, new versions may be saved as file.pacnew to avoid overwriting a file which already exists and was previously modified by the user. Similarly, when the package is removed, user-modified files will be preserved as file.pacsave unless the package was removed with the pacman -Rn command.

See also Pacnew and Pacsave files.

This array allows overriding some of the default behavior of makepkg, defined in /etc/makepkg.conf. To set an option, include the name in the array. To disable an option, place an ! before it.

The full list of the available options can be found in PKGBUILD(5) § OPTIONS AND DIRECTIVES.

The name of the .install script to be included in the package.

pacman has the ability to store and execute a package-specific script when it installs, removes or upgrades a package. The script contains the following functions which run at different times:

Each function is run chrooted inside the pacman install directory. See this thread.

The name of the package changelog. To view changelogs for installed packages (that have this file):

An array of files needed to build the package. It must contain the location of the software source, which in most cases is a full HTTP or FTP URL. The previously set variables pkgname and pkgver can be used effectively here; e.g. source=("https://example.com/${pkgname}-${pkgver}.tar.gz").

Files can also be supplied in the same directory where the PKGBUILD is located, and their names added to this array. Before the actual build process starts, all the files referenced in this array will be downloaded or checked for existence, and makepkg will not proceed if any is missing.

.install files are recognized automatically by makepkg and should not be included in the source array. Files in the source array with extensions .sig, .sign, or .asc are recognized by makepkg as PGP signatures and will be automatically used to verify the integrity of the corresponding source file.

An array of files listed under source, which should not be extracted from their archive format by makepkg. This can be used with archives that cannot be handled by /usr/bin/bsdtar or those that need to be installed as-is. If an alternative unarchiving tool is used (e.g. lrzip), it should be added in the makedepends array and the first line of the prepare() function should extract the source archive manually; for example:

Note that while the source array accepts URLs, noextract is just the file name portion:

To extract nothing, consider the following:

An array of PGP fingerprints. If used, makepkg will only accept signatures from the keys listed here and will ignore the trust values from the keyring. If the source file was signed with a subkey, makepkg will still use the primary key for comparison.

Only full fingerprints are accepted. They must be uppercase and must not contain whitespace characters.

Please read makepkg#Signature checking for more information.

These variables are arrays whose items are checksum strings that will be used to verify the integrity of the respective files in the source array. Insert SKIP for a particular file, and its checksum will not be tested.

The checksum type and values should always be those provided by upstream, such as in release announcements. When multiple types are available, the strongest checksum is to be preferred (in order from most to least preferred): b2, sha512, sha384, sha256, sha224, sha1, md5, ck. This best ensures the integrity of the downloaded files, from upstream announcement to package building.

The values for these variables can be auto-generated by makepkg's -g/--geninteg option, then commonly appended with makepkg -g >> PKGBUILD. The updpkgsums(8) command from pacman-contrib is able to update the variables wherever they are in the PKGBUILD. Both tools will use the variable that is already set in the PKGBUILD, or fall back to sha256sums if none is set.

The file integrity checks to use can be set up with the INTEGRITY_CHECK option in /etc/makepkg.conf. See makepkg.conf(5).

An array of BLAKE2b checksums with digest size of 512 bits.

An array of SHA-2 checksums with digest sizes 512, 384, 256 and 224 bits, respectively. sha256sums is the most common of them.

An array of 160-bit SHA-1 checksums of the files listed in the source array.

An array of 128-bit MD5 checksums of the files listed in the source array.

An array CRC32 checksums (from UNIX-standard cksum) of the files listed in the source array.

**Examples:**

Example 1 (unknown):
```unknown
pkgname.pkg.tar.zst
```

Example 2 (unknown):
```unknown
shellcheck --shell=bash --exclude=SC2034,SC2154,SC2164 PKGBUILD
```

Example 3 (unknown):
```unknown
makepkg.conf
```

Example 4 (unknown):
```unknown
/usr/share/pacman/
```

---

## JACK Audio Connection Kit

**URL:** https://wiki.archlinux.org/title/JACK_Audio_Connection_Kit

**Contents:**
- Installation
- Configuration
  - Latency
  - Realtime scheduling and additional resources
  - Realtime kernel and advanced modifications
- Starting the audio graph
  - Jack
  - Jack2
  - Pipewire-jack
- Comparison of JACK implementations

From Wikipedia:JACK Audio Connection Kit:

There are three different implementations of the JACK API: jackAUR, jack2 and pipewire-jack. For an overview, refer to #Comparison of JACK implementations.

Install one of the above packages. For 32-bit application support, also install the lib32-jack2 or lib32-pipewire-jack package (respectively) from the multilib repository.

For the official JACK example-clients and tools install jack-example-tools.

For an alternative ALSA MIDI support in jack2 install a2jmidid.

For dbus support with jack2 install jack2-dbus.

Depending on your use-case and hardware, the system may need further configuration, to allow a JACK implementation to use additional resources or to function properly.

The latency of a running JACK instance (i.e. how much time is spent processing one block of audio) is defined by its frames per period/sample rate ratio.

When looking at jackd(1) § ALSA_BACKEND_OPTIONS as an example, these parameters are defined by the -p and -r flags (respectively).

All JACK implementations may make use of elevated realtime scheduling priority, which allows them to make use of the CPU cycles more often than other applications (see e.g. -P in jackd(1) § OPTIONS).

The realtime-privileges package provides the realtime system group, which is permitted elevated rtprio and unlimited memlock with a sysctl drop-in configuration file and is permitted to alter the system's /dev/cpu_dma_latency file, which may be used by applications to prevent the CPU to use higher C states.

Install the realtime-privileges package and add your user to the realtime group to be able to use realtime scheduling priority that is higher than the default.

A realtime kernel (such as linux-rt or linux-rt-lts) may be used in situations where very low latencies are required. Refer to professional audio for further information and other advanced modifications.

The different JACK implementations have varying ways of starting the audio graph.

Jack1 only supports starting via the jackd(1) executable or by using one of the graphical frontends, that support starting via the library interface.

Jack2 supports starting via the jackd(1) executable, the jack_control script (provided by the jack2-dbus package), the jack@.service systemd user service (refer to /etc/jack/example.conf for configuration documentation) or by using one of the graphical frontends, that support starting via the library or dbus interface.

Pipewire's JACK implementation does not provide the jackd(1) executable or dbus integration. The audio graph is started by the pipewire.service systemd user service.

The following table lists the current implementations of the JACK API and their differing feature sets.

The following table lists control GUIs for JACK and their differing features and levels of support towards the JACK implementations.

This article or section needs expansion.

JACK can handle one soundcard very well, and an arbitrary number of MIDI devices (connected e.g. via USB). If you start JACK and want to use a MIDI keyboard or a synthesizer or some other pure MIDI device, you have to start JACK with a proper soundcard (one that actually outputs or inputs PCM sound). As soon you have done that, you can connect the MIDI device. E.g. with QjackCtl (qjackctl), you click on the connect button and you will find your device listed under JACK-MIDI or ALSA-MIDI, depending on the driver.

For JACK-MIDI, you may want to set the MIDI Driver to seq or raw in QjackCtl Setup > Settings. This should make your MIDI device appear under the MIDI tab. You can also change the name of the client (from a generic "midi_capture_1" to something more descriptive), if you enable Setup > Display > Enable client/port aliases and then Enable client/port aliases editing (rename).

For ALSA-MIDI, make sure to turn on Enable ALSA Sequencer support in QjackCtl Setup > Misc. This will add the ALSA tab in QjackCtl Connect window where your MIDI controller will show up.

For bridging ALSA-MIDI to JACK-MIDI, you may consider using a2jmidid (a2jmidid). The following command will export all available ALSA MIDI ports to JACK MIDI ports:

They will be visible in QjackCtl under the MIDI tab labelled "a2j" client. You can automate starting of a2jmidid by adding to QjackCtl Setup > Options > Execute script after Startup: /usr/bin/a2j_control --ehw && /usr/bin/a2j_control --start

To install some M-Audio MIDI keyboards, you will need the firmware package midisport-firmwareAUR. Also, the snd_usb_audio module has to be available.

See USBMidiDevices article for more information about specific USB MIDI devices.

JACK2 can be directly launched with the jackd executable, or controlled with the D-Bus-based jack_control binary. jack_control makes it easy to start and configure JACK2 via a shell script. Note that you must install the jack2-dbus package to use jack_control. For the a2j_control commands you also need a2jmidid installed (see #Using MIDI devices for more information).

Create a shell script that can be executed at X login:

The above will start a working JACK instance which other programs can then utilize. Details of each line follow. When discovering your own best configuration, it is helpful to do trial and error using QjackCtl's GUI with a non-D-Bus JACK2 version.

Starts JACK if it is not already started.

Sets JACK to use the ALSA driver set.

Sets JACK to use ALSA-compatible sound card named HD2. One can find the names with cat /proc/asound/cards. Most ALSA tutorials and default configurations use card numbers, but this can get confusing when external MIDI devices are in use; names make it easier.

Sets JACK to use 48000 khz sampling. Happens to work very well with this card. Some cards only do 44100, many will go much higher. The higher you go, the lower your latency, but the better your card and your CPU have to be, and software has to support this as well.

Sets JACK to use 2 periods. 2 is right for motherboard, PCI, PCI-X, etc.; 3 for USB.

Sets JACK to use 64 frames per period. Lower is less latency, but the setting in this script gives 2.67 ms latency, which is nicely low without putting too much stress on the particular hardware this example was built for. If a USB sound system were in use it might be good to try 32. Anything less than 3-4 ms should be fine for realtime synthesis and/or FX, 5 ms is the smallest a human being can detect. QjackCtl will tell you how you are doing; at no-load, which means no clients attached, you will want a max of 3-5% CPU usage, and if you cannot get that without xruns (the red numbers which mean the system cannot keep up with the demands), you will have to improve your hardware.

Wait for the above to settle.

Start the ALSA-to-JACK MIDI bridge. Good for mixing in applications which take MIDI input through ALSA but not JACK.

Wait for the above to settle.

Load QjackCtl. GUI configuration tells it to run in the system tray. It will pick up the JACK session started by D-Bus just fine, and very smoothly too. It maintains the patchbay, the connections between these applications and any other JACK-enabled applications to be started manually. The patchbay is set up using manual GUI, but connections pre-configured in the patchbay are automatically created by QjackCtl itself when applications are started.

This example setup utilizes a more GUI focused configuration and management of JACK

If you use JACK for demanding tasks, but every now and then, it is possible to suspend a running PulseAudio session with QjackCtl just when you are using it. On a virgin config, modify the Server prefix option in the Settings > Advanced submenu, so that it states :

The PulseAudio session should resume fine after you close QjackCtl. Tip courtesy of this post.

To allow ALSA programs to play while jack is running you must install the jack plugin for ALSA with alsa-plugins.

And enable it by editing (or creating) /etc/asound.conf (system wide settings) to have these lines if you have a simple 2-channel setup:

If you have a different number of output/input channels or your first two channels are not the ones you wish to route audio to, you cannot use the predefined jack pcm source from /etc/alsa/conf.d/50-jack.conf, but rather something like:

You need not restart your computer or anything. Just edit the ALSA configuration files, start up jack, and there you go...

Remember to start it as a user. If you start it with jackd -d alsa as user X, it will not work for user Y.

For another (more robust but definitely more complex) approach, is to configure and use an ALSA loopback device, by loading the snd-aloop kernel module, as is described in this article. This snd-aloop approach can also be used to bridge Wine's ALSA output to JACK as explained in [3].

GStreamer requires the gst-plugins-good package to work with JACK, which contains the jackaudiosink plugin that adds JACK playback support.

Further information (outdated): https://jackaudio.org/faq/gstreamer_via_jack.html

If you need to keep PulseAudio installed (in the event it is required by other packages, like gnome-settings-daemon), you may want to prevent it from spawning automatically with X and taking over from JACK.

Edit /etc/pulse/client.conf, uncomment "autospawn" and set it to "no":

If you want both to play along, see: PulseAudio/Examples#PulseAudio through JACK

Cadence and other JACK GUI applications are known to write values to ~/.pulse/daemon.conf. These values override any system-wide defaults enabling unexpected behavior (e.g. flat volumes). Refer to PulseAudio#Configuration on how to update these configurations.

In order to prevent ALSA from messing around with your firewire devices you have to blacklist all firewire related kernel modules. This also prevents PulseAudio from using IEEE 1394. Create the following file:

The list of modules is the most recent available at the time of writing at ALSA Firewire Improve Repository.

Now you can unload your loaded firewire modules or reboot.

This article or section is out of date.

JACK can be configured to send audio data over a network to a "master" machine, which then outputs the audio to a physical device. This can be useful to mix audio from a number of "slave" computers without requiring additional cables or hardware mixers, and keeping the audio path digital for as long as possible (as hardware mixers with digital inputs are very rare).

The configuration is very simple, however it requires a network that supports multicast traffic (i.e. IGMP snooping must be enabled on managed network switches), and it requires all machines be running the same JACK major version (JACK1 or JACK2) as the protocols are not interoperable between versions. For JACK2, the netmanager module must be loaded:

The -i -c option tells the netmanager to automatically map any incoming connections to the default audio device. Without this, each incoming connection would have to be manually mapped on each connection. You can use -i -h instead to see all available options, however note that the options are printed in the jackd server output, the jack_load command will not show anything.

On the client, JACK must be started in network mode:

The two machines will connect and on the master the new audio source will be visible:

If you passed the -c option to jack_load as above, then the remote system will now be able to play audio.

See Realtime process management#Configuring PAM and ensure that the user is in the realtime user group.

Still having the "Cannot allocate memory" and/or "Cannot connect to server socket err = No such file or directory" error(s) when pressing qjackctl's start button?

Please delete ~/.jackdrc, ~/.config/jack/conf.xml, ~/.config/rncbc.org/QjackCtl.conf. Kill jackdbus and restart from scratch :) (Thanks to nedko)

and check the resulting PID's with

This will hopefully show the conflicting programs.

Change ALSA input and output channels from 1 to 2

Your CPU or sound card is too weak to handle your settings for JACK. Lower the bitrate, lower the frame size, and raise the frame period in small increments until crackling stops. You can also try changing the sampling rate to 44100 or whatever is natively supported. This allows jack to send audio to the system without having to resample. In jack2 with jack_control, this is accomplished with

If everything appears to be working - you can visually "see" sound in Jack and other things such as PulseAudio can emit sound, check the maximum sample size supported by your sound card. If your card only supports 16 bit samples then you will hear nothing until you tell Jack not to use large samples:

If you install jack-example-tools then you can run jack_simple_client to send a test tone to Jack's output.

Run VLC and change the following menu options:

**Examples:**

Example 1 (unknown):
```unknown
frames per period
```

Example 2 (unknown):
```unknown
sample rate
```

Example 3 (unknown):
```unknown
frames per period
```

Example 4 (unknown):
```unknown
/dev/cpu_dma_latency
```

---

## Downgrading packages

**URL:** https://wiki.archlinux.org/title/Downgrading

**Contents:**
- Return to an earlier package version
  - Using the pacman cache
  - Downgrading the kernel
  - Arch Linux Archive
  - Rebuild the package
  - Automation
- Return from [testing]

Before downgrading a single or multiple packages, consider why you wish to do so. If it is due to a bug, follow the bug reporting guidelines. I.e. search the Arch Linux Bugtracker for existing tasks and if there is none, add a new task. It is better to correct bugs, or at least warn other users of possible issues.

If a package was installed at an earlier stage, and the pacman cache was not cleaned, install an earlier version from /var/cache/pacman/pkg/.

This process will remove the current package and install the older version. Dependency changes will be handled, but pacman will not handle version conflicts. If a library or other package needs to be downgraded with the packages, please be aware that you will have to downgrade this package yourself as well.

Once the package is reverted and confirmed to work, to make pacman -Syu temporarily ignore updates, add the package to the IgnorePkg section of pacman.conf, until the difficulty with the updated package is resolved.

In case of issue with a new kernel, the Linux packages can be downgraded to the last working ones #Using the pacman cache. Go into the directory /var/cache/pacman/pkg and downgrade at least linux, linux-headers and any kernel modules. For example:

The Arch Linux Archive is a daily snapshot of the official repositories. It can be used to install a previous package version, or restore the system to an earlier date.

If the package is unavailable, find the correct PKGBUILD and rebuild it with makepkg.

For packages from the official repositories, retrieve the PKGBUILD with ABS and change the software version. Alternatively, find the package on the Packages website, click "View Changes", and navigate to the desired version. The necessary files can then be downloaded from the directory so that the package can be rebuilt.

See also Arch build system#Using the pkgctl tool.

Old AUR packages can be built by checking out an old commit in the AUR package Git repository. For pre-2015 AUR3 PKGBUILDs, see Arch User Repository#Git repositories for AUR3 packages.

See Official repositories#Disabling testing repositories.

**Examples:**

Example 1 (unknown):
```unknown
/var/cache/pacman/pkg/
```

Example 2 (unknown):
```unknown
# pacman -U file:///var/cache/pacman/pkg/package-old_version.pkg.tar.zst
```

Example 3 (unknown):
```unknown
pacman -Syu
```

Example 4 (unknown):
```unknown
pacman.conf
```

---

## Free Pascal package guidelines

**URL:** https://wiki.archlinux.org/title/Free_Pascal_package_guidelines

**Contents:**
- Free Pascal
  - Package naming
  - Helpful snippets
  - Packaging
    - Cross compiling

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

This page explains on how to write PKGBUILDs for software built with the Free Pascal Compiler (FPC). Compiling for x86_64 Arch Linux requires the fpc package.

The project name alone is usually sufficient. However, in the case of cross-compiling, the package should be prefixed with fpc32- when targeting i686 Linux from multilib and named in the format of fpc-cpu-system-pkgname when targeting non-Arch Linux systems.

Determine FPC's version and the CPU and OS of the units to output:

Please adhere to the following when making an FPC-based package:

**Examples:**

Example 1 (unknown):
```unknown
fpc-cpu-system-pkgname
```

Example 2 (unknown):
```unknown
_unitdir=`fpc -iSP`-`fpc -iSO`
_fpcver=`fpc -iV`
```

Example 3 (unknown):
```unknown
makedepends
```

Example 4 (unknown):
```unknown
/usr/lib/fpc/$_fpcver/units/$arch-linux
```

---

## namcap

**URL:** https://wiki.archlinux.org/title/Namcap

**Contents:**
- Installation
- Usage
- Creating a module

Namcap is an Arch Linux tool to check binary packages and source PKGBUILDs for common packaging mistakes.

Install the namcap package.

To run namcap on a file, where filename is PKGBUILD or the name of a package binary package_name.tar.zst:

If you want to see extra informational messages, then invoke namcap with the --info (-i) flag:

Namcap uses a system of tags of three types to classify the output:

Normally namcap prints a human-readable explanation (sometimes with suggestions on how to fix the problem). If you want output which can be easily parsed by a program, then pass the --machine-readable (-m) flag to namcap.

The tag file /usr/share/namcap/namcap-tags (online source) consists of lines specifying the human-readable form of the hyphenated tags used in the namcap code. A line beginning with a # is treated as a comment:

See namcap(1), README and NEWS for more information.

The main namcap program namcap.py takes as parameters the filename of a package or a PKGBUILD and makes a pkginfo object, which it passes to a list of rules defined in __tarball__ and __pkgbuild__. Once your module is finalized, remember to add it to the appropriate array:

A sample namcap module is like this:

Each namcap module must have the following methods:

**Examples:**

Example 1 (unknown):
```unknown
package_name.tar.zst
```

Example 2 (unknown):
```unknown
$ namcap filename
```

Example 3 (unknown):
```unknown
$ namcap --info filename
```

Example 4 (unknown):
```unknown
--machine-readable
```

---

## Reflector

**URL:** https://wiki.archlinux.org/title/Reflector

**Contents:**
- Installation
- Usage
  - Examples
- Automation
  - systemd service
  - systemd timer
  - pacman hook
- See also

Reflector is a Python script which can retrieve the latest mirror list from the Arch Linux Mirror Status page, filter the most up-to-date mirrors, sort them by speed and overwrite the file /etc/pacman.d/mirrorlist.

Install the reflector package.

To see all of the available options, run the following command:

See reflector(1) § EXAMPLES.

Reflector ships with reflector.service, which runs Reflector using the options specified in /etc/xdg/reflector/reflector.conf. The default options in that file provide a good starting point and example.

Enable reflector.service to run Reflector on boot. To run it immediately, start the service.

Reflector provides a systemd timer (reflector.timer) that starts the #systemd service reflector.service weekly. The schedule can be changed by editing reflector.timer.

For changing the default options that reflector.service gets started with, edit the configuration file as described in #systemd service. Then, start and enable reflector.timer.

To refresh the mirrorlist ahead of schedule, start reflector.service.

pacman-mirrorlist is not updated regularly, invoking reflector because a mirror in some part of the globe was added or removed is not relevant; use the #systemd timer approach instead. If you do not want mirrorlist.pacnew to be installed at all, use NoExtract in /etc/pacman.conf.

**Examples:**

Example 1 (unknown):
```unknown
/etc/pacman.d/mirrorlist
```

Example 2 (unknown):
```unknown
$ reflector --help
```

Example 3 (unknown):
```unknown
/etc/pacman.d/mirrorlist
```

Example 4 (unknown):
```unknown
reflector.service
```

---

## Mirrors

**URL:** https://wiki.archlinux.org/title/Mirror

**Contents:**
- Official mirrors
  - IPv6-ready mirrors
- Enabling a specific mirror
  - Force pacman to refresh the package lists
- Sorting mirrors
  - List by speed
    - Ranking an existing mirror list
    - Fetching and ranking a live mirror list
  - Server-side ranking
  - Client-side ranking

This page is a guide to selecting and configuring your mirrors, and a listing of current available mirrors.

The official Arch Linux mirror list is available from the pacman-mirrorlist package. To get an even more up-to-date list of mirrors, use the Pacman Mirrorlist Generator page.

Check the status of the mirrors by visiting the Mirror Status page. It is recommended to only use mirrors that are up to date, i.e. not out of sync.

If you want your mirror to be added to the official list, see DeveloperWiki:NewMirrors. In the meantime, add it to the Unofficial mirrors article.

The Pacman Mirrorlist Generator can also be used to find a list of current IPv6 mirrors.

To enable mirrors, edit /etc/pacman.d/mirrorlist and locate your geographic region. Uncomment mirrors you would like to use.

See #Sorting mirrors for tools that help choosing mirrors.

It is also possible to specify mirrors in /etc/pacman.conf. For the core repository, the default setup is:

To use the kernel.org mirror as a default mirror, add it before the Include line:

pacman will now try to connect to this mirror first. Proceed to do the same for core-testing, extra, and extra-testing, if applicable.

Mirrors can be out of sync and the package list from the old mirror may not correspond to the package list of the new mirror, even though the dates of the lists may suggest that they do.

After creating/editing /etc/pacman.d/mirrorlist, issue the following command:

Passing two --refresh/-y flags forces pacman to refresh all package lists even if they are considered to be up to date.

This is not necessary when using successfully syncing mirrors or checking timestamp of mirror's lastsync file to ensure package lists are up to date.

When downloading packages, pacman uses the mirrors in the order they are listed in /etc/pacman.d/mirrorlist, i.e. the order servers appear in the list sets their priority. If a package download fails (e.g. file not found, connection timeout), the next list entry is used.

It is not optimal to only rank mirrors based on speed since the fastest servers might be out-of-sync. Instead, make a list of mirrors sorted by their speed, then remove those from the list that are out of sync according to their status.

It is recommended to regularly repeat this process to keep the list of mirrors up-to-date.

The pacman-contrib package provides a Bash script, /usr/bin/rankmirrors, which can be used to rank the mirrors according to their connection and opening speeds to take advantage of using the fastest local mirror.

Back up the existing /etc/pacman.d/mirrorlist:

To prepare mirrorlist.backup for ranking with rankmirrors, the following actions can be carried out:

In order to start with a shortlist of up-to-date mirrors based in some countries and feed it to rankmirrors one can fetch the list from the Pacman Mirrorlist Generator. The command below pulls the up-to-date mirrors in either France or the United Kingdom which support the https protocol, it uncomments the servers in the list and then ranks them and outputs the 5 fastest.

The official Pacman Mirrorlist Generator provides an easy way to obtain a ranked list of mirrors. Because all ranking is done on a single server that takes multiple factors into account, the amount of load on the mirrors and the clients is significantly lower compared to ranking on each individual client.

Other popular alternatives are:

In case you encounter the following error:

Get the mirrorlist directly from the website:

Be sure to uncomment a preferred mirror as described in #Enabling a specific mirror.

Alternatively, use one of the methods for generating a mirrorlist listed under #Sorting mirrors.

If you are certain a mirror is not operating properly and that is not reflected on the mirrors status page, change the mirror and consider opening a bug report. For mirrors the issue should be opened in the arch-mirrors project at the Arch Linux GitLab. You may also send a mail to mirrors@archlinux.org.

See Pacman#Packages cannot be retrieved on installation first. If that doesn't help, use a HTTPS mirror.

**Examples:**

Example 1 (unknown):
```unknown
/etc/pacman.d/mirrorlist
```

Example 2 (unknown):
```unknown
## Worldwide
#Server = https://geo.mirror.pkgbuild.com/$repo/os/$arch
#Server = http://mirror.rackspace.com/archlinux/$repo/os/$arch
Server = https://mirror.rackspace.com/archlinux/$repo/os/$arch
```

Example 3 (unknown):
```unknown
/etc/pacman.conf
```

Example 4 (unknown):
```unknown
[core]
Include = /etc/pacman.d/mirrorlist
```

---

## Suricata

**URL:** https://wiki.archlinux.org/title/Suricata

**Contents:**
- Installation
- Configuration
- Web interface
- Starting Suricata
  - Manual startup
  - systemd service configuration

This article or section needs language, wiki syntax or style improvements. See Help:Style for reference.

From the project home page:

Install the suricataAUR package.

The main configuration file is /etc/suricata/suricata.yaml.

You should change the following parts of the configuration in order to make it run:

You may use Scirius CE [1] or SELKS [2] as web interface for rule management, log analysis, and other sensor management options.

You may start the suricata service manually with: # /usr/bin/suricata -c /etc/suricata/suricata.yaml -i eth0

To start Suricata automatically at system boot, enable suricata.service.

**Examples:**

Example 1 (unknown):
```unknown
/etc/suricata/suricata.yaml
```

Example 2 (unknown):
```unknown
default-log-dir: /var/log/suricata/     # where you want to store log files
  classification-file: /etc/suricata/classification.config
  reference-config-file: /etc/suricata/reference.config
  HOME_NET: "[10.0.0.0/8]"                # your local network
  host-os-policy:   ..                    # according to the OS running the ips
  magic-file: /usr/share/file/misc/magic.mgc
```

Example 3 (unknown):
```unknown
# /usr/bin/suricata -c /etc/suricata/suricata.yaml -i eth0
```

Example 4 (unknown):
```unknown
suricata.service
```

---

## pacman/Pacnew and Pacsave

**URL:** https://wiki.archlinux.org/title/Pacnew_and_Pacsave_files

**Contents:**
- Why these files are created
- Package backup files
- Types explained
  - .pacnew
  - .pacsave
- Locating .pac* files
- Managing .pac* files
  - pacdiff
  - Third-party utilities
- See also

When pacman removes a package that has a configuration file, it normally creates a backup copy of that configuration file and appends .pacsave to the name of the file. Likewise, when pacman upgrades a package which includes a new configuration file created by the maintainer differing from the currently installed file, it saves a .pacnew file with the new configuration. pacman provides notice when these files are written.

A .pacnew file may be created during a package upgrade (pacman -Syu, pacman -Su or pacman -U) to avoid overwriting a file which already exists and was previously modified by the user. When this happens, a message like the following will appear in the output of pacman:

A .pacsave file may be created during a package removal (pacman -R), or by a package upgrade (the package must be removed first). When the pacman database has a record that a certain file owned by the package should be backed up, it will create a .pacsave file. When this happens pacman outputs a message like the following:

These files require manual intervention from the user and it is good practice to handle them right after every package upgrade or removal. If left unhandled, improper configurations can result in improper function of the software or the software being unable to run altogether.

A package's PKGBUILD file specifies which files should be preserved or backed up when the package is upgraded or removed. For example, the PKGBUILD for pulseaudio contains the following line:

After installation, this list can be queried from the pacman database using pacman -Qii package_name.

To prevent any package from overwriting a certain file, see Pacman#Skip file from being upgraded.

For each of the #Package backup files being upgraded, pacman cross-compares three md5sums generated from the file's contents: one sum for the version originally installed by the package, one for the version currently in the filesystem, and one for the version in the new package. If the version of the file currently in the filesystem has been modified from the version originally installed by the package, pacman cannot know how to merge those changes with the new version of the file. Therefore, instead of overwriting the modified file when upgrading, pacman saves the new version with a .pacnew extension and leaves the modified version untouched.

Going into further detail, the 3-way MD5 sum comparison results in one of the following outcomes:

Rarely, when an upgraded package includes a backup file the previous version did not, the situation is correctly handled as X/Y/Y or X/Y/Z, with X being a non-existant value.

If the user has modified one of the files specified in backup then that file will be renamed with a .pacsave extension and will remain in the filesystem after the rest of the package is removed.

Pacman does not deal with .pacnew files automatically: you must maintain these yourself. A few tools are presented in the next section. To do this manually, you will first need to locate them. When upgrading or removing a large number of packages, updated .pac* files may be missed. To discover whether any .pac* files have been installed, use one of the following:

pacman-contrib provides the simple pacdiff(8) tool for managing .pac* files.

It will search for .pacnew, .pacsave and .pacorig files, and will then prompt to take action upon them.

It uses --pacmandb by default, to search using the backup array information from currently installed packages. If this is not sufficient for your use case, you can specify --find or --locate instead, for a more thorough search.

It uses vimdiff by default, but you may specify a different tool with DIFFPROG=your_editor pacdiff. See List of applications/Utilities#Comparison, diff, merge for other common comparison tools.

A few third-party utilities providing various levels of automation for these tasks are available:

**Examples:**

Example 1 (unknown):
```unknown
pacman -Syu
```

Example 2 (unknown):
```unknown
warning: /etc/pam.d/usermod installed as /etc/pam.d/usermod.pacnew
```

Example 3 (unknown):
```unknown
warning: /etc/pam.d/usermod saved as /etc/pam.d/usermod.pacsave
```

Example 4 (unknown):
```unknown
backup=(etc/pulse/{daemon.conf,default.pa,system.pa})
```

---

## DeveloperWiki:NewMirrors

**URL:** https://wiki.archlinux.org/title/DeveloperWiki:NewMirrors

**Contents:**
- Adding a new mirror
- Notes about private mirrors
- 2-tier mirroring scheme
- For the mirror administrator
  - Tier 2 requirements
  - Tier 1 requirements
  - rsync over TLS
  - Create a feature-request
  - Contact info and mailing lists
- The Arch Linux side

This text should outline the procedure for adding a new mirror for Arch packages.

Due to the high load and bandwidth limits Arch Linux uses 2-tier mirroring scheme.

There are few tier 1 mirrors that sync directly from archlinux.org every hour.

All other mirrors should sync from one of tier 1 mirrors. Syncing from archlinux.org is not allowed.

You can use rsync directly or the syncrepo-template.sh script as a starting point. Please note that the script tries to minimize load and bandwidth used (about 3 MiB of metadata for each rsync run as of 2018-03-01) in case there are no changes. Feel free to remove this check if you do not sync very often or your upstream mirror does not provide the lastupdate file.

If you wish to use rsync over TLS, Arch Linux is offering endpoints with rsync over TLS via the geo mirrors and the T0 for T1 mirrors to sync from. You can use rsync-ssl(1) which is a wrapper for rsync(1). The port is exposed at 874 which rsync-ssl uses by default.

To set up rsync over TLS for your mirror you may follow the same patterns as it was implemented by Arch Linux which is by fronting the rsync daemon with nginx using TLS. Using tcp load balancing, supported by nginx-mod-stream , nginx connects to the rsync socket and forwards the requests. rsync needs use proxy = on feature enabled in its configuration to work and the SSL certificates are presented by nginx. For further implementation the changes that were done on the Arch Linux side can be viewed on the Arch Linux GitLab. Another way to produce a similar result would be by using stunnel.

Go to https://gitlab.archlinux.org/archlinux/arch-mirrors/-/issues and create a feature-request containing the following information:

The contact email(s) will be used by Arch Linux staff to contact the mirror administrator if they have questions regarding the mirror or if there are problems with the mirror. If a contact email is not provided, the mirror listing may be removed at any time, especially if problems occur, without prior contact to the admin.

If the mirror administrator is adding or modifying a URL to an already existing mirror, they can specify so in the request with the link to the existing mirror.

Feel free to join the arch-mirrors mailing list which can be used for general discussion about our mirrors. If you want to inform our users about downtime of your mirror please use the arch-mirrors-announce mailing list. You do not need to subscribe to be able to post to arch-mirrors-announce.

If you want to reach the Arch Linux staff for questions, you can either use the arch-mirrors list, you can open a bug report on our tracker or you can send a mail to mirrors@archlinux.org. There is also the #archlinux-mirrors IRC channel for any discussions or questions.

To give you an impression how much space will be needed for a mirror here are some numbers (as of 2023-05-23):

Most mirrors do not sync archive, other and sources directories, but sync everything else (including temporary repositories), so usually you will need about 70 GiB reserved for Arch Linux mirror.

However, note that the required space may temporarily increase when a big rebuild happens and thus many packages exist twice in different versions. Please plan in a buffer of 30 GiB to 50 GiB on top of the above mentioned values.

**Examples:**

Example 1 (unknown):
```unknown
-rlptH --safe-links --delete-delay --delay-updates
```

Example 2 (unknown):
```unknown
use proxy = on
```

Example 3 (unknown):
```unknown
gen_rsyncd.conf.pl
```

---

## Unofficial user repositories

**URL:** https://wiki.archlinux.org/title/Unofficial_user_repositories

**Contents:**
- Adding your repository to this page
- Signed
  - ada
  - alerque
  - ALHP
  - andontie-aur
  - arcanisrepo
  - arch4edu
  - archlinuxcn
  - archzfs

This article lists binary repositories freely created and shared by the community, often providing pre-built versions of PKGBUILDs found in the Arch User Repository (AUR).

In order to use these repositories, add them to /etc/pacman.conf, as explained in pacman#Repositories and mirrors. If a repository is signed, you must obtain and locally sign the associated key, as explained in pacman/Package signing#Adding unofficial keys.

If you want to create your own custom repository, follow pacman/Tips and tricks#Custom local repository.

If you have your own repository, please add it to this page so that all the other users will know where to find your packages. Please keep the following rules when adding new repositories:

Some repositories may also have packages for architectures besides x86_64. The $arch variable will be set automatically by pacman.

The factual accuracy of this article or section is disputed.

Many of the unofficial Arch Linux repositories are indexed on https://archlinux.pkgs.org/.

It provides repositories browser and packages search.

**Examples:**

Example 1 (unknown):
```unknown
/etc/pacman.conf
```

Example 2 (unknown):
```unknown
pacman.conf
```

Example 3 (unknown):
```unknown
[ada]
Server = http://www.orthanc.site:8080/assets/arch_ada_repo
```

Example 4 (unknown):
```unknown
[alerque]
Server = https://arch.alerque.com/$arch
```

---

## Git

**URL:** https://wiki.archlinux.org/title/Git

**Contents:**
- Installation
  - Graphical front-ends
- Configuration
- Usage
  - Getting a Git repository
  - Recording changes
  - Viewing change history
  - Undoing things
  - Working with remotes
  - Branching

Git is the version control system (VCS) designed and developed by Linus Torvalds, the creator of the Linux kernel. Git is now used to maintain AUR packages, as well as many other projects, including sources for the Linux kernel.

Install the git package. For the development version, install the git-gitAUR package. Check the optional dependencies when using tools such as git svn, git gui and gitk.

See also git GUI Clients.

In order to use Git you need to set at least a name and email:

See Getting Started - First-Time Git Setup.

See #Tips and tricks for more settings.

A Git repository is contained in a .git directory, which holds the revision history and other metadata. The directory tracked by the repository, by default the parent directory, is called the working directory. Changes in the working tree need to be staged before they can be recorded (committed) to the repository. Git also lets you restore, previously committed, working tree files.

See Getting a Git Repository - Git Basics

See Recording Changes to the Repository - Git Basics

See Viewing the Commit History - Git Basics

See Undoing Things - Git Basics

See Working with Remotes - Git Basics

See Branching in a Nutshell - Git Branching

See Basic Branching and Merging - Git Branching

See Branch Management - Git Branching

See Branching Workflows - Git Branching

See Remote Branches - Git Branching

See Rebasing - Git Branching

See Distributed Workflows - Distributed Git

See Contributing to a Project - Distributed Git

See Maintaining a Project - Distributed Git

See Revision Selection - Git Tools

See Interactive Staging - Git Tools

See Stashing and Cleaning - Git Tools

See Signing Your Work - Git Tools

See Searching - Git Tools

See Rewriting History - Git Tools

See Reset Demystified - Git Tools

See Advanced Merging - Git Tools

See Rerere - Git Tools

See Debugging with Git - Git Tools

See Submodules - Git Tools

See Bundling - Git Tools

See Replace - Git Tools

See Credential Storage - Git Tools

Git reads its configuration from four INI-type configuration files:

These files can be edited directly, but the usual method is to use git config, as shown in the examples below.

List the currently set variables:

Set the default editor from vim to nano:

Set the default push action:

Set a different tool for git difftool (meld by default):

See git-config(1) and Git Configuration for more information.

Since v1.7.10 in 2012, Git is able to build a configuration file that is split into multiple configuration files using the include keyword inside the gitconfig file.

You may wish to avoid the hassle of authenticating interactively at every push to the Git server.

Git may fetch your credentials from an org.freedesktop.secrets compatible keyring like GNOME Keyring, KeePassXC or KDE Wallet. Therefore set up one compatible keyring and check if a keyring is registered to dbus using:

Git can read the netrc file to access credentials. First, direct Git to the netrc helper script:

Then, create a .netrc file:

The credential helper also supports gpg-encrypted files (~/.netrc.gpg) if you like to keep your secrets safe.

If you are running a multiplexed SSH connection as shown above, Git over SSH might be faster than HTTPS. Also, some servers (like the AUR) only allow pushing via SSH. For example, the following configuration will set Git over SSH for any repository hosted on the AUR.

In order to enable Bash completion, source /usr/share/git/completion/git-completion.bash in a Bash startup file. Alternatively, install bash-completion.

The Git package comes with a prompt script. To enable it, source the /usr/share/git/completion/git-prompt.sh and set a custom prompt with the %s parameter:

Note that the command substitution must be escaped, see Bash/Prompt customization#Embedding commands for details. See Command-line shell#Configuration files for persistent configuration.

When changing to a directory of a Git repository, the prompt will change to show the branch name. Extra details can be set to be shown by the prompt by setting the corresponding environment variable:

The full documentation for the environment variables is available in the comments of the script.

Alternatively, you can use one of git shell prompt customization packages from AUR such as bash-git-promptAUR or gittifyAUR.

To get an idea of the amount of work done:

git log with forking representation:

git log graph alias (i.e. git graph will show a decorated version):

Reset to previous commit (very dangerous, erases all tracked files to the specified commit):

If a repository address gets changed, its remote location will need to be updated:

Alternatively, edit .git/config with the new location.

Signed-off-by line append (a name-email signature is added to the commit which is required by some projects):

Signed-off-by automatically append to patches (when using git format-patch commit):

Commit specific parts of files that have changed. This is useful if there are a large number of changes made that would be best split into several commits:

Git allows commits and tags to be signed using GnuPG, see Signing Your Work.

To configure Git to automatically sign commits:

Occasionally a maintainer will ask that work be done on a branch. These branches are often called devel or testing. Begin by cloning the repository.

To enter another branch beside master (git clone only shows master branch but others still exist, git branch -a to show):

Now edit normally; however to keep the repository tree in sync be sure to use both:

If you want to send patches directly to a mailing list, you have to install the following packages: perl-authen-sasl and perl-io-socket-ssl.

Make sure you have configured your username and e-mail address, see #Configuration.

Configure your e-mail settings:

Now you should be able to send the patch to the mailing list (see also OpenEmbedded: Sending the Patches via Email and git-send-email.io):

When working with a large remote repository, a significant amount of data has to be fetched. The following examples use the Linux kernel to illustrate how to work with such codebases.

The easiest solution is to get the entire repository:

You can update your repository by git pull.

To limit your local repository to a smaller subset of the origin, say after v4.14 to bisect a bug, use a shallow clone:

You will get v4.14 and later, but not v4.13 and older.

If you only want the latest snapshot, ignoring all history. (If a tarball is available and it suffices, choose that. Downloading from a git repository needs more bandwidth.) You can get it with:

You can later obtain older commits, as the two following examples show:

Scalar, formerly Virtual File System for Git (VFS for Git), allows to access git repositories without a local instance.

Your local repository tracks, in the above example, only the mainline kernel, i.e. in which the latest development is done. Suppose you want the latest LTS, for example the up-to-date 4.14 branch. You can get it by:

The last line is not mandatory, but probably wanted. (To know the name of the branch you want, there is no general rule. You can guess one by seeing the "ref" link in the gitweb interface.)

For the snapshot of linux-4.14.y, do

Or to extract it in another directory,

As usual, do git pull to update your snapshot.

Occasionally, software may keep plain-text passwords in configuration files, as opposed to hooking into a keyring. In these cases, git clean-filters may be handy to avoid accidentally commiting confidential information. E. g., the following file assigns a filter to the file “some-dotfile”:

Whenever the file “some-dotfile” is checked into git, git will invoke the filter “remove-pass” on the file before checking it in. The filter must be defined in the git-configuration file, e. g.:

The git help documentation is also available in HTML form by installing git-htmldocsAUR. After installing, the HTML docs can be accessed by passing the -w flag. For example:

The HTML documentation can be loaded by default by setting a git config option:

**Examples:**

Example 1 (unknown):
```unknown
LC_MESSAGES
```

Example 2 (unknown):
```unknown
$ git config --global user.name  "John Doe"
$ git config --global user.email "johndoe@example.com"
```

Example 3 (unknown):
```unknown
/etc/gitconfig
```

Example 4 (unknown):
```unknown
~/.gitconfig
```

---

## USBGuard

**URL:** https://wiki.archlinux.org/title/USBGuard

**Contents:**
- Installation
- Configuration
  - Rules
- Usage
  - CLI
    - Allow Bluetooth controllers
  - GNOME integration
    - Grant GNOME access to the USBGuard daemon
    - Turn GNOME USB Protection on
    - Block all USB devices by default

USBGuard offers a white/black-listing mechanism for USB-devices. Inspiration for this is drawn from exploits like BadUSB. It makes use of a device blocking infrastructure included in the Linux kernel and consists of a daemon and some front-ends.

Install the usbguard package.

The official Qt applet was removed from USBGuard and substituted with usbguard-notifierAUR. An unofficial, forked version of the Qt applet is available as usbguard-qtAUR.

The main configuration file is found in /etc/usbguard/usbguard-daemon.conf.

If you want to control the daemon via IPC, be sure to add your username to IPCAllowedUsers or your group to IPCAllowedGroups to make rules persistent. In most cases, you want this.

By default, the PresentDevicePolicy is set to apply-policy so that USBGuard evaluates the ruleset for every connected device. This is the most secure setting, which ensures security even when the daemon hits a restart. Alternatively, the key may be set to allow in order to block all newly connected devices but leave devices connected before daemon as is. To temporary allow new devices use usbguard set-parameter ImplicitPolicyTarget allow.

With the key ImplicitPolicyTarget you can configure the default treatment of devices, if no rules match. The most secure option here is block.

For an in-depth documentation of configuration see the very well commented configuration file.

To configure USBGuard to your needs, you can edit /etc/usbguard/rules.conf. However manual editing of the rules is normally not necessary. You can generate a ruleset based on your currently attached USB devices by executing usbguard generate-policy > /etc/usbguard/rules.conf as root.

The rules syntax is formally explained here. An example for a hp printer connected via USB can look like this:

A rule begins with a policy. allow whitelists a device, block stops the device from being processed now and reject removes the device from the system. Then follows a set of attributes with their options, as detailed below.

USBGuard has a core daemon, a CLI, a DBUS interface and an API via libusbguard.

If you want to use the Qt GUI or another program communicating via DBUS (which includes the GNOME integration), enable and start usbguard-dbus.service.

If you only want to communicate via API (with the CLI tool or another software using libusbguard) enable and start usbguard.service.

The CLI is available via usbguard.

See the according man pages for more info.

If USBGuard is set to block all USB devices by default, it will also block btusb controllers by default since they communicate using a USB bus. Since many motherboards' Bluetooth cards are btusb controllers, it may not be obvious that Bluetooth is blocked by USBGuard. For Bluetooth to work, you need to set USBGuard to allow these btusb controllers.

Find and display information about the USB buses in the system using lsusb (part of usbutils). This should display something like

We are interested in the Bluetooth device. Note its ID (in this case, 0000:0002, but this may vary) and set USBGuard to allow this ID:

GNOME has had USBGuard support baked in since 3.36. It requires polkit rule configuration to grant GNOME access, and dconf modification to always block devices as the default is set to allow and only block on lockscreen.

The factual accuracy of this article or section is disputed.

Authorize GNOME Shell running under users with the wheel group assigned access to USBGuard, by creating the following file:

Changes to polkit rules are picked up automatically by the polkit daemon itself.

If the USBGuard service is present and this setting is enabled, USB devices will be protected as configured in the usb-protection-level setting. Enable it by running the command below:

If set to lockscreen, only when the lock screen is present new USB devices will be rejected; if set to always, all new USB devices will always be rejected. Reject all new USB devices by running the command below:

**Examples:**

Example 1 (unknown):
```unknown
/etc/usbguard/usbguard-daemon.conf
```

Example 2 (unknown):
```unknown
IPCAllowedUsers
```

Example 3 (unknown):
```unknown
IPCAllowedGroups
```

Example 4 (unknown):
```unknown
PresentDevicePolicy
```

---

## Bisecting bugs with Git

**URL:** https://wiki.archlinux.org/title/Bisect

**Contents:**
- Reverting to an older release
- Building package from git
- Setting up the bisect
- Bisecting
- Speeding up builds
  - Ccache
- Restoring package
- See also

Often when reporting bugs encountered with projects such as Mesa or Linux kernel, a user may be asked to bisect between the last known version that worked for them and the newer version which is causing them problems in order to see what is the troublesome commit. On Arch this can be done fairly trivially thanks to the functionality of the AUR.

It might be useful to confirm that it is the new package release that is causing the problem. Downgrading packages on Arch can be accomplished trivially as long as an older version of the package is still stored as cache on your system, or you can use Arch Linux Archive.

In order to bisect we are going to need to build a version of package from git. This can be accomplished by building the -git package from the AUR.

Once package is successfully built you need to change into the git root directory in the src/ directory. The name of the git root directory is often the same as pkgname (or without the -git suffix):

From there you can start the process of bisecting:

The following command will show you all the tags you can use to specify where to bisect:

Following on from the earlier example, we will assume that the version oldver worked for us while newver did not:

Now that we have our good and bad versions tagged we can proceed to test commits.

Change back into the directory with the PKGBUILD. If you are still in the directory mentioned in the previous section this can be accomplished like so:

You can now rebuild and install the specific revision of the package:

Once the new package is installed you can test for your previously discovered error. Return to the directory you were in the previous section:

If you encountered your problem, tell that the revision was bad:

If you did not encounter your problem, tell that the revision it was good:

Then do as described at the beginning of this section again and repeat until git bisect names the troublesome commit.

If you are bisecting a large project built using gcc, it might be possible to reduce build times by enabling ccache. It may take several build iterations before you start to see benefits from the cache, however. The likelihood of cache hits generally increases as the distance between bisection points decreases.

Reverting to an original version of the package can be done by installing the package from repositories with pacman.

**Examples:**

Example 1 (unknown):
```unknown
$ cd src/git_root
```

Example 2 (unknown):
```unknown
$ git bisect start
```

Example 3 (unknown):
```unknown
$ git bisect good oldver
$ git bisect bad newver
```

Example 4 (unknown):
```unknown
$ makepkg -efsi
```

---

## Aurweb RPC interface

**URL:** https://wiki.archlinux.org/title/Aurweb_RPC_interface

**Contents:**
- API usage
  - Query types
    - search
    - info
  - Return types
    - return data
    - error
    - search
    - info
  - jsonp

The Aurweb RPC interface is a lightweight RPC interface for the AUR. Queries are sent as HTTP GET requests and the server responds with JSON.

There are two query types:

Package searches can be performed by issuing requests of the form:

where keyword is the search argument and field is one of the following values:

The by parameter can be skipped and defaults to name-desc. Possible return types are search and error.

If a maintainer search is performed and the search argument is left empty, a list of orphan packages is returned.

Search for packages maintained by user:

Search for packages that have package as `makedepends`:

Search with callback:

Package information can be retrieved by issuing requests of the form:

where pkg1, pkg2, … are the exact matches of names of packages to retrieve package details for.

Possible return types are multiinfo and error.

Info for a single package:

Info for multiple packages:

The return payload is of one format and currently has three main types. The response will always return a type so that the user can determine if the result of an operation was an error or not.

The format of the return payload is:

ReturnType is a string, and the value is one of:

The type of ReturnData is an array of dictionary objects for the search and multiinfo ReturnType, and an empty array for error ReturnType.

For the ReturnType search, ReturnData may contain the following fields:

For the ReturnType info and multiinfo, ReturnData may additionally contain the following fields:

Fields that a package does not contain will be omitted from the output.

The error type has an error response string as the return value. An error response can be returned from either a search or an info query type.

Example of ReturnType error:

The search type is the result returned from a search request operation.

Example of ReturnType search:

The info type is the result returned from an info request operation.

Example of ReturnType multiinfo:

If you are working with a javascript page, and need a JSON callback mechanism, you can do it. You just need to provide an additional callback variable. This callback is usually handled via the javascript library, but here is an example.

This would automatically call the JavaScript function jsonp1192244621103 with the parameter set to the results of the RPC call.

Sometimes things are easier to understand with examples. A few reference implementations (jQuery, python2, ruby) for old specification and without specifying "v" parameter are available here.

The new path-based version of the /rpc v5 API implementation on python 3.12 is available here.

API documentation: https://aur.archlinux.org/rpc/swagger

**Examples:**

Example 1 (unknown):
```unknown
/rpc/v5/search/keyword?by=field
```

Example 2 (unknown):
```unknown
makedepends
```

Example 3 (unknown):
```unknown
checkdepends
```

Example 4 (unknown):
```unknown
https://aur.archlinux.org/rpc/v5/search/package
```

---

## Wine package guidelines

**URL:** https://wiki.archlinux.org/title/Wine_package_guidelines

**Contents:**
- Things to check outright
  - License
  - Installer
  - Portability and cleanness
- The guideline in short
  - Installing
  - The /usr/bin script
  - UnionFsFuse
- One example
- Gecko and Mono

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

Many Windows programs may still be useful in Linux and so we may want to have a package for them. The differences between the two operating systems make this task a little complex. In this guideline we will talk about Win32 binaries, since projects where source is available usually are ported to Linux.

Here we mean a program is portable if it never writes in the registry or outside its directory; we mean a program is clean if it never writes in its directory, but it may write its settings in the user folder. A program can be also both (e.g., it never writes settings) or neither (e.g., it writes in its directory, it writes around, it writes in the registry...)

Usually licenses are in a text file in the install directory. If you cannot find it, try following the screens during installation. If nothing is said about repackaging, go on. The author does not care. Otherwise the license usually does not allow removing files or does not allow repackaging at all. In the former case just be careful that the makepkg process does not lose any file, you may delete unneeded files (e.g., uninstallers) in the post_install phase; in the latter case all the installing process must be done in the post_install phase. The build phase will only be for copying the install files.

It is much easier to work with compressed files like .zip than with Windows installers. If you have no choice, since the author insists on distributing its program with an installer, search the Internet for if it is possible to silently install the software. MSFN is usually a good place to search. If you cannot find a way, try to open the installer with different unpacking utilities; it may work.

A portable program does not need its own Wine emulated file system, so check in Portable Freeware if the program you are packaging is portable.

The idea behind packaging a Windows program is to use the program's files as mere data that Wine will interpret, just like JVM and Java bytecode.

So we will install the program in /usr/share/"$pkgname" and the program will write all what it needs in "$HOME"/."$pkgname". Everything will be prepared by a small script saved in /usr/bin/"$pkgname" that will create the folder, prepare it if needed, and finally start the program.

In the next sections we will talk about every step.

This way every user will have their own settings and their decisions will not bother other users.

If the program has no installer, the installation is a mere decompression of a file; unpack it to "$pkgdir"/usr/share/$pkgname, making sure that the permissions are correct. These commands will do:

If the program cannot be installed the easy way, you need to create a Wine environment:

We have not discussed portability yet, but if your program does not need the registry keys it modified, you can just copy the directory from the:

Otherwise you need to copy all the registry files too and eventually the files the program installed around. The "$srcdir"/tmp/local will contains menu icons and desktop files, you may want to copy them in the package. If there does not exist a way to install the program silently... Maybe you can make a .tar.gz file and upload it somewhere? If nothing automated is possible, force the user to follow the installer and hope they do not mess up the installation, write some checks before blindly copying a folder that may not exist (e.g. the user pressed 'Cancel').

This script prepares the settings folder and starts the program. If your program is portable, it will look like this:

If it is clean, it will look like this:

As you can see, in the second case there is no environment preparation. In fact a clean application will be started directly from /usr/share since it will not need to write in its folder, so its settings will be written somewhere in the emulated file system.

If the application is neither clean neither portable the two ideas must be combined.

If the application does not write settings at all, skip the if and start it from /usr/share.

The task of preparing the environment may differ greatly between applications, but follow these rules of thumb: If the program:

Of course the minimum is just starting WINEDEBUG=-all wine /usr/share/programname "$@".

Usually the environment will be made by symlinking between the "$HOME"/.programname directory and the /usr/share/programname files. But since some Windows programs are very fickle about their paths, you may need to symlink directly in the "$HOME"/.programname/wine/drive_c/Program\ Files/programname directory.

Of course those are just ideas to integrate Win32 applications in the Linux environment, do not forget your intelligence and gumption.

As example, μTorrent is by default a clean application, but with a easy step can be used as a portable one. Since it is a single file and it is pretty small creating its wine environment (about 5MB) it is probably an overkill. It is better to symlink the executable, create the empty settings.dat in order to use it portable in the $HOME/.utorrent directory. With the added advantage that just visiting the .utorrent directory, a user can see a copy of the .torrent files they downloaded.

You can consider using the UnionFsFuse program available as unionfs-fuseAUR. UnionFsFuse allows to keep the base directory in /usr/share and put a copy of the files the application needed to write inside $HOME/.programname almost automatically.

Using UnionFsFuse means an additional dependency and it requires the fuse module that not all users might load. Yet, it might be worthwhile if the application would need lots of symlinking or if it is unclear exactly what it needs to be written. Just ensure to mount and unmount the UnionFs correctly.

To see examples of AUR packages that depends on wine, see https://aur.archlinux.org/rpc/v5/search/wine?by=depends

This article or section is out of date.

We will make a package for eMule. According to Portable Freeware, eMule is not completely portable since it writes some (useless) keys in the registry.

On the other hand, it is not clean either since it writes its configuration files and puts its downloads in its installation folder.

Luckily there is an installer-less version available.

So we make our PKGBUILD; the only dependency is wine. The md5sums should be added.

Now we make our emule file, which according to build, will be copied and made executable in /usr/bin.

If you want to be more precise, you may add a message in the .install file telling the user that they should disable search history since wine messes up that menu. You may even provide a default configuration file with the best settings. And that's it... run $ makepkg, check the package folder to be sure, and install.

Unless you know for sure, that software require browser of .NET runtime (packages wine-gecko and wine-mono), default wine installation prompts for Gecko/Mono are undesirable.

To disable HTML rendering, bytecode support and the dialogs, you need to use a dlloverride in your script. For Gecko:

You can also disable them via winecfg: just set mscoree/mshtml to Disable.

**Examples:**

Example 1 (unknown):
```unknown
post_install
```

Example 2 (unknown):
```unknown
post_install
```

Example 3 (unknown):
```unknown
/usr/share/"$pkgname"
```

Example 4 (unknown):
```unknown
"$HOME"/."$pkgname"
```

---

## CDM

**URL:** https://wiki.archlinux.org/title/CDM

**Contents:**
- Installation
- Configuration
  - Menu items
  - Theming
  - Starting X
- Custom commands for power operations
- See also

CDM is a minimalistic, yet full-featured replacement for display managers like SLiM, SDDM and GDM that provides a fast, dialog-based login system without the overhead of the X Window System. Written in pure bash, CDM has almost no dependencies, yet supports multiple users/sessions and can start virtually any desktop environment or window manager.

Install the cdmAUR package.

Now ensure no other display managers get started by disabling their systemd services.

For example, if you were using GDM, you would disable gdm.service.

There is no need to enable a systemd service for CDM. Rather, a script called zzz-cdm.sh will be placed into /etc/profile.d. This script (along with the rest of the scripts in /etc/profile.d) is run when you login to a login shell. However, in order to prevent a scenario where a broken configuration prevents a user from accessing both their desktop and a virtual terminal, the script checks to see which virtual terminal it is being run on, and will by default only run on tty1.

Since the script is placed in the global /etc/profile.d directory, CDM will be run for all users who login on tty1. If you would rather it only run for you, take away executable permissions from /etc/profile.d/zzz-cdm.sh and copy the contents of that file into your ~/.bash_profile for bash, or ~/.zprofile for zsh.

You can configure CDM by editing /etc/cdmrc. It is fully documented and should be relatively easy to figure out. You can also have user specific configuration files by copying /etc/cdmrc to $HOME/.cdmrc.

Menu items are configured using three arrays: binlist, namelist and flaglist. Order of items in these arrays is important, items with the same index describe the same menu item. binlist contains commands which are executed, namelist contains names which are shown in the menu and flaglist contains type of the programs specified in binlist, either 'X' for X sessions or 'C' for console programs. Basically X sessions are started using startx (the item in binlist is argument of startx command) and console programs are started using exec.

There is a sample configuration:

Themes are located in /usr/share/cdm/themes, all you have to do is to pass the full path of the theme file to the dialogrc variable:

The theme syntax is fairly self explanatory, the best way to create a new theme would be to duplicate and edit an existing theme.

You can affect the process of starting an X server in several ways - you can specify on which tty the X server will be started (specify either number or 'keep' if you want to run the X server on current tty), and finally you can specify custom X server arguments.

If you want to add entries for power operations, like shutdown or reboot, you can include them in the binlist array. See systemd#Power management for details.

**Examples:**

Example 1 (unknown):
```unknown
gdm.service
```

Example 2 (unknown):
```unknown
/etc/profile.d
```

Example 3 (unknown):
```unknown
/etc/profile.d
```

Example 4 (unknown):
```unknown
/etc/profile.d
```

---

## ConsoleKit

**URL:** https://wiki.archlinux.org/title/ConsoleKit

**Contents:**
- Installation
- Configuration
  - ck-launch-session
  - No display manager
  - Desktop environments
- Tips and tricks
  - Use D-Bus for power operations
- Troubleshooting
  - Running several applications from ~/.xinitrc
  - Consolekit blocks active TTY

ConsoleKit2 is a framework for defining and tracking users, login sessions, and seats. Its function is to support multiuser setups. It also works for a single user, but offers no benefits compared to existing methods. [3]

Install the consolekitAUR and polkit-consolekitAUR packages.

To launch an X session with ConsoleKit, append the following to the exec statement in ~/.xinitrc e.g.:

This starts Openbox with proper environment variables so it and its children are able to use ConsoleKit.

Display managers like GDM, LXDM and SLiM start ConsoleKit automatically with each X session.

If you are not using a display manager and ConsoleKit is not working (i.e. ck-list-sessions command showing active = FALSE), you should start your window manager using the bash_profile method: Xinit#Autostart X at login.

LightDM can be used as a login manager.

The factual accuracy of this article or section is disputed.

Hibernate (suspend to disk):

Hybrid Sleep (suspend + hibernate):

This method assumes that you are given permission to shut the system down via PolicyKit. The default group for this is wheel. To change this, edit /etc/polkit-1/localauthority.conf.d/50-localauthority.conf as root.

If several applications are to be executed from ~/.xinitrc, not all of these will have ConsoleKit environment variables set. In the following example, only children of Compiz will be able to properly use ConsoleKit, but children of xterm will not.

Typically, this can be an issue when for example using Compiz standalone and some other application launchers, (gnome-do, kupfer, gmrun, xbindkeys, etc.) since children of the application launcher will not be able to use ConsoleKit. A dirty workaround is to have the entire session started by a second script, e.g. ~/.xstart. Do not forget dbus-launch, it is likely that you will need it too:

Do not forget to make ~/.xstart executable.

To see whether everything is started correctly:

It should show at least one session like this one:

Configure init to start ConsoleKit on an unused TTY, for example:

Specify the keeptty flag to startx or xinit [5], for example:

See also Xorg#Session log redirection.

Remove references to ck-launch-session from ~/.xinitrc.

See Session to check the status of your user session.

**Examples:**

Example 1 (unknown):
```unknown
exec ck-launch-session dbus-launch --sh-syntax --exit-with-session openbox-session
```

Example 2 (unknown):
```unknown
ck-launch-session
```

Example 3 (unknown):
```unknown
ck-list-sessions
```

Example 4 (unknown):
```unknown
active = FALSE
```

---

## Laptop Mode Tools

**URL:** https://wiki.archlinux.org/title/Laptop_Mode_Tools

**Contents:**
- Installation
- Configuration
  - Hard disks
    - Solid state drives
  - CPU frequency
  - Device and bus
    - Intel SATA
    - USB autosuspend
  - Display and graphics
    - LCD brightness

Laptop Mode Tools is a laptop power saving package for Linux systems. It is the primary way to enable the Laptop Mode feature of the Linux kernel, which lets your hard drive spin down. In addition, it allows you to tweak a number of other power-related settings using a simple configuration file.

Combined with acpid and CPU frequency scaling, LMT provides most users with a complete notebook power management suite.

Install the laptop-mode-toolsAUR package.

Configuration is handled through:

Each module can be explicitly enabled, disabled, or set to auto by changing the CONTROL_* argument of any file in conf.d/. LMT will attempt to enable any modules where CONTROL_* is set to auto if ENABLE_AUTO_MODULES is set in /etc/laptop-mode/laptop-mode.conf. There are two exceptions to the above rule: auto-hibernate.conf and battery-level-polling.conf use an ENABLE_* variable instead of CONTROL_*.

To quickly check which modules are enabled, disabled or auto, run:

Finally, enable laptop-mode.service.

For this you need to have hdparm and/or sdparm installed. See Hdparm.

Spinning down the hard drive through hdparm -S values saves power and makes everything a lot more quiet. LMT can also establish hdparm -B values. The maximum hard drive power saving is 1 and the minimum is 254. For example, set this value to 254 when on AC and 20 when on battery. If you find that normal activity hangs often while waiting for the disk to spin up, it might be a good idea to set it to a higher value (e.g. 128) which will make it spin down less often. hdparm -S and hdparm -B values are configured in /etc/laptop-mode/laptop-mode.conf.

With the CONTROL_MOUNT_OPTIONS variable (default on), laptop-mode-tools automatically remounts your partitions, appending commit=600,noatime in the mount options. This keeps the journaling program jbd2 from accessing your disk every few seconds, instead the disk journal gets updated every 10 minutes.

From the official, upstream FAQ:

Question: I have a solid-state disk (SSD) in my machine. Should I enable any of the disk-related parts of laptop-mode-tools, or are they irrelevant?

Answer: They may be relevant, because (a) laptop mode will reduce the number of writes, which improves the lifetime of an SSD, and (b) laptop mode makes writes bursty, which enables power saving mechanisms like ALPM to kick in. However, your mileage may vary depending on the specific hardware involved. For some hardware, you will get no gain at all, for some the gain may be substantial.

For this you need to have a CPU frequency driver installed. See CPU frequency scaling.

Enable the Intel SATA AHCI controller Aggressive Link Power Management feature to set the disk link into a very low power mode in the absence of disk IO.

Available brightness values for certain laptops can be obtained by running following command:

For ThinkPad T40/T42 notebooks, minimum and maximum brightness values can be obtained by running:

For ThinkPad T60 notebooks, minimum and maximum brightness values can be obtained by running:

For most (probably all) Asus ROG & TUF notebooks with Intel CPUs, a maximum brightness value can be obtained by running:

Asus notebooks talk to the kernel though an Asus specific module and as such standard keyboard brightness commands will not work. A maximum brightness levels can be obtained by running:

Wireless interface power management settings are hardware-dependent, and thus a bit trickier to configure. Depending on the wireless chipset, the settings are managed in one of the following three files:

Note that activating the three of them should not be much of a problem, since LMT detects the module used by the interface and acts accordingly.

The supported modules for each configuration file, indicated above, are taken directly from LMT. However, this seems to be a bit out-of-date, since the current 2.6.34 kernel does not provide the ipw3945 and iwl4965 modules anymore (3945 chipset uses iwl3945 instead, and 4965 uses the generic module iwlagn). This is only brought here for information, as this does not (or should not) affect the way LMT works.

There is a known issue with some chipsets running with the iwlagn module (namely, the 5300 chipset, and maybe others). On those chipsets, the following settings of /etc/laptop-mode/conf.d/wireless-iwl-power.conf:

are ignored, because the /sys/class/net/wlan*/device/power_level file does not exist. Instead, the standard method (with iwconfig wlan0 power on/off) is automatically used.

Install acpid and enable acpid.service.

If that does not help, go through the laptop-mode configuration files and make sure that the service you want to enable is set to 1. Many services (including cpufreq control) are by default set to "auto", which may not enable them.

Issues with bluetooth not working when booting up with battery are fixed with disabling runtime-pm.

First find the ID of your device (it should look like 046d:c534):

Put this value into the AUTOSUSPEND_DEVID_BLACKLIST variable in /etc/laptop-mode/conf.d/runtime-pm.conf, for example:

Multiple IDs can be seperated with spaces.

When laptop mode is enabled, KDE fails to start. The reason is that the default KDE display manager (SDDM) starts before the NVIDIA driver. To prevent this from happening you need to remove the nomodeset kernel parameter.

As described before, laptop-mode-tools affects the NVIDIA driver. Adding the nvidia-drm.modeset=1 kernel parameter reduces boot time dramatically.

**Examples:**

Example 1 (unknown):
```unknown
/etc/laptop-mode/laptop-mode.conf
```

Example 2 (unknown):
```unknown
/etc/laptop-mode/conf.d/*
```

Example 3 (unknown):
```unknown
ENABLE_AUTO_MODULES
```

Example 4 (unknown):
```unknown
/etc/laptop-mode/laptop-mode.conf
```

---

## Java package guidelines

**URL:** https://wiki.archlinux.org/title/Java_package_guidelines

**Contents:**
- Introduction
- Structure of a typical Java application
- Java packaging on Arch Linux
  - Multiple API implementations
  - Example directory structure
  - Dependencies

32-bit – CLR – CMake – Cross – DKMS – Eclipse – Electron – Font – Free Pascal – GNOME – Go – Haskell – Java – KDE – Kernel modules – Lisp – Meson – MinGW – Node.js – Nonfree – OCaml – Perl – PHP – Python – R – Ruby – Rust - Security – Shell – VCS – Web – Wine

This document defines a proposed standard for packaging Java programs under Arch Linux. Java programs are notoriously difficult to package cleanly without overlapping dependencies. This document describes a way to remedy this situation. These guidelines are flexible in order to cover the many different scenarios that arise when dealing with Java applications.

Arch Linux packagers cannot seem to agree on how to handle Java packages. Various methods are used in PKGBUILDs across the official and unofficial repositories and in the AUR. These solutions include placing the whole mess in /opt with shell scripts in /usr/bin or profiles placed in /etc/profile. Others are placed in directories in /usr/share with scripts placed in /usr/bin. Many add unnecessary files to the system CLASSPATH and PATH.

Most Desktop Java applications have a similar structure. They are installed from a system-independent (but package dependent!) installer. This usually installs everything in a single directory with subdirectories called bin, lib, jar, conf, etc. There is usually a main jar file containing the main executable classes. A shell script is usually provided to run the main class so users do not have to invoke the Java interpreter directly. This shell script is usually quite complex, as it is generic across distributions and often includes special cases for different systems (e.g., Cygwin).

The lib directory often contains bundled jar files that satisfy dependencies of the Java application. This makes it simple for a user to install the program (all dependencies included), but is a package developer's nightmare. It is a waste of space when several packages bundle the same dependency. This was not a big issue in the past when there were fewer desktop Java applications and libraries, and those that existed tended to be very large anyway. Things are different now...

Other files necessary to run the program are usually stored in the same folder as the main jar file, or a subdirectory thereof. Since Java programs do not know where their classes were loaded from, they usually need to be run from within this directory (i.e. the shell script should cd into the directory), or an environment variable is set to indicate the directory's location.

Packaging Java applications in Arch is going to take quite a bit more work for packagers than it currently does. The effort will be worth it, however, resulting in a cleaner filesystem and fewer bundled dependencies (as more and more Java libraries are refactored into their own packages, packaging will become easier). The following guidelines should be followed in creating an Arch Linux Java package:

If your package distributes commonly used API implementation(like jdbc driver) you should place the library under /usr/share/java/apiname. So that applications that allow user to select from various implementations will know where to look for them. Use this location only for raw library packages. If such a implementation is part of distribution of application, do not place this jar file under common location but use ordinary package structure.

To clarify, here is an example directory structure for a hypothetical program called foo. Since foo is a common name, the package is named java-foo, but notice this is not reflected in the directory structure:

Java packages might specify java-runtime or java-environment as dependency, based on what they need. For most packages, java-runtime (Java Runtime Environment) is what is needed to simply run software written in Java. java-environment (Java Development Toolkit) is needed by packages that will need to compile Java source code into bytecode.

See Java for more information.

**Examples:**

Example 1 (unknown):
```unknown
/etc/profile
```

Example 2 (unknown):
```unknown
/usr/share/java/myprogram
```

Example 3 (unknown):
```unknown
archlinux-java
```

Example 4 (unknown):
```unknown
/usr/bin/java
```

---

## AUR helpers

**URL:** https://wiki.archlinux.org/title/AUR_helpers

**Contents:**
- Legend
- Comparison tables
  - Search and download
  - Search and build
  - Pacman wrappers
- Graphical
- Maintenance
- Other
- See also

AUR helpers automate usage of the Arch User Repository. In particular, they may automate the following tasks:

Pacman only handles updates for pre-built packages in its repositories. AUR packages are redistributed in form of PKGBUILDs and need an AUR helper to automate the re-build process. However, keep in mind that a rebuild of a package may be required when its shared library dependencies are updated, not only when the package itself is updated.

The #Comparison tables columns have the following meaning:

---

## pacman/Package signing

**URL:** https://wiki.archlinux.org/title/Pacman-key

**Contents:**
- Setup
  - Configuring pacman
  - Initializing the keyring
- Managing the keyring
  - Verifying the master keys
  - Adding developer keys
  - Adding unofficial keys
  - Debugging with gpg
- Tips and tricks
  - Upgrade system regularly

To determine if packages are authentic, pacman uses OpenPGP keys in a web of trust model. The current Master Signing Keys are found here. At least three of these Master Signing Keys are used to sign the Developers' and Package Maintainers' own keys. They are then used to sign their packages. Each user also has a unique OpenPGP key, which is generated when you configure pacman-key(8). It is this web of trust that links the user's key to the master keys.

Examples of webs of trust:

The SigLevel option in /etc/pacman.conf determines the level of trust required to install a package with pacman -S. For a detailed explanation of SigLevel, see pacman.conf(5) § PACKAGE AND DATABASE SIGNATURE CHECKING, and the file comments. One can set signature checking globally, or per repository. If SigLevel is set globally in the [options] section, all packages installed with pacman -S will require signing. With the LocalFileSigLevel setting from the default pacman.conf, any packages you build, and install with pacman -U, will not need to be signed using makepkg.

For remote packages, the default configuration will only support the installation of packages signed by trusted keys:

TrustedOnly is a default compiled-in pacman parameter. The default configuration is identical to using the global option of:

The above can be achieved too on a repository level further below in the configuration, e.g.:

explicitly adds signature checking for the packages of the repository, but does not require the database to be signed. Optional here would turn off a global Required for this repository.

To initialize the pacman keyring run:

The initial setup of keys is achieved using:

Take time to verify the Master Signing Keys when prompted as these are used to co-sign (and therefore trust) all other packager's keys.

OpenPGP keys are too large (2048 bits or more) for humans to work with, so they are usually hashed to create a 40-hex-digit fingerprint which can be used to check by hand that two keys are the same. The last eight digits of the fingerprint serve as a name for the key known as the '(short) key ID' (the last sixteen digits of the fingerprint would be the 'long key ID').

The official Developers' and Package Maintainers' keys are signed by the master keys, so you do not need to use pacman-key to sign them yourself. Whenever pacman encounters a key it does not recognize, it will prompt you to download it from a keyserver configured in /etc/pacman.d/gnupg/gpg.conf (or by using the --keyserver option on the command line). Wikipedia maintains a list of keyservers.

Once you have downloaded a developer key, you will not have to download it again, and it can be used to verify any other packages signed by that developer.

This article or section needs expansion.

This method can be utilized to add a key to the pacman keyring, or to enable signed unofficial user repositories.

First, get the key ID (keyid) from its owner. Then add it to the keyring using one of the two methods:

It is recommended to verify the fingerprint, as with any master key or any other key you are going to sign:

Finally, you must locally sign the imported key:

You now trust this key to sign packages.

For debugging purposes, you can access pacman's keyring directly with gpg, e.g.:

Upgrading the system regularly via pacman#Upgrading packages prevents most signing errors. If delay is unavoidable and system upgrade gets delayed for an extended period, manually sync the package database and upgrade the archlinux-keyring package before system upgrade:

This command is not considered a partial upgrade since it syncs the package database and upgrades the keyring package first. Both must be processed just before starting system upgrade to ensure signatures of all upgraded packages can be properly verified.

When the system time is faulty, signing keys could be considered expired (or invalid) and signature checks on packages will fail. Synchronize the system clock regularly by using the Network Time Protocol daemon.

pacman-key depends on system time. If your system clock is not synchronized, system installation/upgrade may fail with:

If using ntpd, correct the system time (as root) with ntpd -qg followed by hwclock -w.

Other NTP clients can be used. See time synchronization.

If correction of the system clock does not resolve the failure, try one of the following approaches:

Some packages could be corrupted or may be unsigned, causing failure. Remove each offending package from the system cache rm /var/cache/pacman/pkg/pkgname so it gets freshly downloaded, or clear the entire cache.

Remove or reset all the keys installed in your system by removing the /etc/pacman.d/gnupg directory (as root) and by rerunning pacman-key --init followed by pacman-key --populate to re-add the default keys.

If you are not concerned about package signing, you can disable OpenPGP signature checking completely. Edit /etc/pacman.conf to have the following lines under [options]:

You need to comment out any repository-specific SigLevel settings because they override the global settings. This will result in no signature checking, which was the behavior before pacman 4. If you do this, you do not need to set up a keyring with pacman-key. You can change those options later if you decide to enable package verification.

This article or section needs language, wiki syntax or style improvements. See Help:Style for reference.

There are multiple possible sources of this problem:

You might be stuck because of an outdated archlinux-keyring package when doing an upgrade synchronization.

Below are a few solutions that could work depending on your case.

See if upgrading the system can fix it first.

If you suspect that something is not working right with the keyserver, you could try to switch to the Ubuntu keyserver. To do this, edit /etc/pacman.d/gnupg/gpg.conf and change the keyserver line to:

If you suspect that your pacman cache at /var/cache/pacman/pkg/ might contain unsigned packages, try cleaning the cache manually or run:

which removes all cached packages that have not been installed.

Sometimes when running pacman -Syu you might encounter this error:

This occurs because the packager's key used in the package package-name is not present and/or not trusted in the local pacman-key gpg database. Pacman does not seem to always be able to check if the key was received and marked as trusted before continuing. This could also be because a key has expired since it was added to your keychain.

The last two options above break the chain of trust, and should be used with care.

In order to use a proxy when updating keys the honor-http-proxy option must be set in both /etc/gnupg/dirmngr.conf and /etc/pacman.d/gnupg/dirmngr.conf. See GnuPG#Use a keyserver for more information.

**Examples:**

Example 1 (unknown):
```unknown
/etc/pacman.conf
```

Example 2 (unknown):
```unknown
LocalFileSigLevel
```

Example 3 (unknown):
```unknown
pacman.conf
```

Example 4 (unknown):
```unknown
DatabaseOptional
```

---

## Dynamic Kernel Module Support

**URL:** https://wiki.archlinux.org/title/DKMS

**Contents:**
- Installation
- Upgrades
- Usage
  - List modules
  - Rebuild modules
  - Remove modules
- DKMS package creation
- See also

This means that a user does not have to wait for a company, project, or package maintainer to release a new version of the module. Since the introduction of pacman hooks, the rebuild of the modules is handled automatically when a kernel is upgraded.

Install the dkms package and the headers for the target kernel/kernels. For example, for the default linux kernel this would be linux-headers. Other kernels have their own respective headers packages.

A good number of modules that lie outside the kernel source tree have a DKMS variant; a few are hosted in the official repositories, most are found in the AUR.

Though the rebuild of the DKMS modules is usually seamless during a kernel upgrade, it may still happen that the rebuild fails. You should pay extra attention to the pacman output. This applies in particular if the system relies on the DKMS module to boot successfully and/or if you use DKMS with a custom kernel not in the official repositories.

To deal with changes in the kernel, fix bugs, or add necessary features consider upgrading the DKMS package before rebooting.

Usage for invoking DKMS manually.

Tab-completion is available by doing:

To list the current status of modules, versions and kernels within the tree:

Rebuild all modules for the currently running kernel:

or for a specific kernel:

To build a specific module for the currently running kernel:

To build a module for all kernels:

To remove a module (old ones are not automatically removed):

If the package dkms is removed the information regarding previous module build files is lost. If this is the case, go through /usr/lib/modules/kernel_release and /var/lib/dkms/package_name and delete all files and directories no longer in use.

See DKMS package guidelines.

**Examples:**

Example 1 (unknown):
```unknown
# source /usr/share/bash-completion/completions/dkms
```

Example 2 (unknown):
```unknown
# dkms status
```

Example 3 (unknown):
```unknown
# dkms autoinstall
```

Example 4 (unknown):
```unknown
# dkms autoinstall -k 3.16.4-1-ARCH
```

---

## pacman/Rosetta

**URL:** https://wiki.archlinux.org/title/Pacman/Rosetta

**Contents:**
- Basic operations
- Querying specific packages
- Querying package lists
- Querying package dependencies
- Installation sources management
- Overrides
- Verification and repair
- Using package files and building packages
- Log file rotation
- See also

This page uses a table to display the correspondence of package management commands among some of the most popular Linux distributions. The original inspiration was given by openSUSE's Software Management Command Line Comparison.

or emerge --searchdesc (-S)

By default, Arch Linux does not rotate pacman.log. See, for example, FS#11272 and FS#20428#comment66480. This is in contrast to the default policy of most other Linux distributions. Some distributions, notably Gentoo, hardly write log files by default.

**Examples:**

Example 1 (unknown):
```unknown
zypper search
```

Example 2 (unknown):
```unknown
zypper se [-s]
```

Example 3 (unknown):
```unknown
emerge --search
```

Example 4 (unknown):
```unknown
emerge --searchdesc
```

---

## Chromium

**URL:** https://wiki.archlinux.org/title/Chromium

**Contents:**
- Installation
- Configuration
  - Default applications
  - Certificates
  - Making flags persistent
  - Force GPU acceleration
  - Hardware video acceleration
    - Vulkan
    - Tips and tricks
  - KDE integration

Chromium is an open-source graphical web browser based on the Blink rendering engine. It is the basis for the proprietary Google Chrome browser.

See this page for an explanation of the differences between Chromium and Google Chrome. Additionally:

Consider switching to xbrowsersync for bookmarks syncing as long term solution.

See List of applications/Internet#Blink-based for other browsers based on Chromium.

Install the chromium package, which tracks the google-chromeAUR releases.

This article or section is a candidate for merging with #Tips and tricks.

To set Chromium as the default browser and to change which applications Chromium launches when opening downloaded files, see default applications.

Chromium uses Network Security Services for certificate management. Certificates can be managed in chrome://certificate-manager.

The "Local certificates" tab manages server certificates. Certificates added in the "Custom" section are per-profile, and stored in the ServerCertificate SQLite database in the profile directory. Certificates in the "Linux" section are read from the NSS Shared DB at ~/.pki/nssdb, and cannot be modified in this UI. To add to NSS Shared DB, use another tool such as certutil. See #SSL certificates for usage examples.

The "Your certificates" tab manages client certificates. Certificates added here are stored in the NSS Shared DB.

You can put your flags in a chromium-flags.conf file under $HOME/.config/ (or under $XDG_CONFIG_HOME if you have configured that environment variable) or /etc/ for global.

No special syntax is used; flags are defined as if they were written in a terminal.

Below is an example chromium-flags.conf file that defines the flags --start-maximized --incognito:

Since at least Chromium 110, GPU acceleration is enabled by default for most systems. You may have to append the following flags to persistent configuration if your system configuration is matched by the block list:

If you have confirmed working VA-API support by checking the output of vainfo (see Hardware video acceleration#Verifying VA-API), you might first try the following flag alone:

--enable-features=AcceleratedVideoDecodeLinuxZeroCopyGL.

Otherwise, continue reading.

To enable accelerated encoding in Chromium:

To enable VA-API support:

When using Vulkan, the following flags are required and might also be sufficient on Chromium 126 and Mesa 24.1:

without any of the additional flags mentioned above.

This article or section is out of date.

To check if it is working play a video which is using a codec supported by your VA-API driver (vainfo tells you which codecs are supported, but Chromium will only support VP9 and h264):

Test on a large enough video. Starting with version 86, Chromium on desktop will only accelerate videos larger than 720p.

To reduce CPU usage while watching YouTube where VP8/VP9 hardware decoding is not available use the h264ify, enhanced-h264ify or Not yet, AV1[7] extension.

On some systems (especially on Xwayland) you might need to #Force GPU acceleration. Only --ignore-gpu-blocklist is enough for our purposes.

This article or section needs expansion.

You might need to disable the Skia renderer, as it is currently not compatible with video decode acceleration: --disable-features=UseSkiaRenderer

For integration into Plasma install plasma-browser-integration. See KDE Plasma Browser Integration for more details.

Chromium and Google Chrome are bundled with the Chromium PDF Viewer plugin. If you do not want to use this plugin, check Download PDFs in chrome://settings/content/pdfDocuments.

If you are using NVIDIA's proprietary driver, running Chromium on Xwayland may cause the GPU process to occasionally crash. To prevent the GPU process from crashing, add the following flags:

Chromium 140 supports Wayland by default. For old versions, you can use

See #Making flags persistent for a permanent configuration. The flag is also available via browser flags menu.

This will select wayland Ozone backend when in wayland session, so you can use a single desktop entry if you switch between X11 and Wayland often.

Additionally, if you are having trouble with input methods you may also want to force newer GTK:

If a AltGr/Compose key stops working, adding this workaround might fix it:

If you are using Fcitx5 and not work properly when using the above flags, try using the --enable-wayland-ime flag instead of --gtk-version=4. [8]

To enable two finger swipe to go back and forward through your history, use the following flags:

This article or section is a candidate for merging with HiDPI#Chromium / Google Chrome.

To force a scale factor on native Wayland, use the following flags [9]:

The following tips and tricks should work for both Chromium and Chrome unless explicitly stated.

A number of tweaks can be accessed via Chrome URLs. See chrome://chrome-urls for a complete list.

An automatically updated, complete listing of Chromium switches (command line parameters) is available here.

Shift+ESC can be used to bring up the browser task manager wherein memory, CPU, and network usage can be viewed.

If you enabled syncing with a Google Account, then Chromium will override any direct edits to the Preferences file found under ~/.config/chromium/Default/Preferences. To work around this, start Chromium with the --disable-sync-preferences switch:

If Chromium is started in the background when you login in to your desktop environment, make sure the command your desktop environment uses is:

Make sites like wiki.archlinux.org and wikipedia.org easily searchable by first executing a search on those pages, then going to Settings > Search and click the Manage search engines.. button. From there, "Edit" the Wikipedia entry and change its keyword to w (or some other shortcut you prefer). Now searching Wikipedia for "Arch Linux" from the address bar is done simply by entering "w arch linux".

To limit Chromium from writing its cache to a physical disk, one can define an alternative location via the --disk-cache-dir flag:

Cache should be considered temporary and will not be saved after a reboot or hard lock. Another option is to setup the space in /etc/fstab:

Alternatively create a symbolic link to /tmp. Make sure to delete Chromium's cache folder before you run the command:

Relocate the browser profile to a tmpfs filesystem, including /tmp, or /dev/shm for improvements in application response as the entire profile is now stored in RAM.

Use an active profile management tool such as profile-sync-daemon for maximal reliability and ease of use. It symlinks or bind mounts and syncs the browser profile directories to RAM. For more, see Profile-sync-daemon.

When you launch the browser, it first checks if another instance using the same data directory is already running. If there is one, the new window is associated with the old instance. If you want to launch an independent instance of the browser, you must specify separate directory using the --user-data-dir parameter:

By default, Chromium downloads *.torrent files directly and you need to click the notification from the bottom-left corner of the screen in order for the file to be opened with your default torrent client. This can be avoided with the following method:

See xdg-open to change the default assocation.

You may need to specify which touch device to use. Find your touchscreen device with xinput list then launch Chromium with the --touch-devices=x parameter, where "x" is the id of your device.

By default, Chromium uses a separate OS process for each instance of a visited web site. [10] However, you can specify command-line switches when starting Chromium to modify this behaviour.

For example, to share one process for all instances of a website:

To use a single process model:

In addition, you can suspend or store inactive Tabs with extensions such as Tab Suspender and OneTab.

The User Agent can be arbitrarily modified at the start of Chromium's base instance via its --user-agent="[string]" parameter.

Chromium has a similar reader mode to Firefox. In this case it is called DOM Distiller, which is an open source project. It is disabled by default, but can be enabled using the chrome://flags/#enable-reader-mode flag, which you can also make persistent. Not only does DOM Distiller provide a better reading experience by distilling the content of the page, it also simplifies pages for print. Even though the latter checkbox option has been removed from the print dialog, you can still print the distilled page, which basically has the same effect.

After enabling the flag, you will find a new "Enter reader mode" menu item and corresponding icon in the address bar when Chromium thinks the website you are visiting could do with some distilling.

In multi-GPU systems, Chromium automatically detects which GPU should be used for rendering (discrete or integrated). This works 99% of the time, except when it does not - if an unavailable GPU is picked (for example, discrete graphics on VFIO GPU passthrough-enabled systems), chrome://gpu will complain about not being able to initialize the GPU process. On the same page below Driver Information there will be multiple GPUs shown (GPU0, GPU1, ...). There is no way to switch between them in a user-friendly way, but you can read the device/vendor IDs present there and configure Chromium to use a specific GPU with flags:

...where 0x8086 and 0x1912 is replaced by the IDs of the GPU you want to use (as shown on the chrome://gpu page).

To ease the transition, you can import bookmarks from Firefox into Chromium.

Navigate Chromium to chrome://settings/importData

If Firefox is already installed on your computer, you can directly import bookmarks as well as many other things from Firefox.

Make sure Mozilla Firefox is selected. Optionally, you can uncheck some unwanted items here. Click the Import and then Done. You are done with it.

If you import bookmarks from another PC, you have to export bookmarks from Firefox first.

Ctrl+Shift+o Import and Backup > Export Bookmarks To HTML in Firefox.

The procedure is pretty much the same. You need to go to chrome://settings/importData. However, this time, in the From drop-down menu, select Bookmarks HTML File and click the Choose File button and upload the desired bookmark file.

Go to chrome://flags#enable-system-notifications and select Enabled.

The autoscroll is still an experimental feature [12]. It is intended to be disabled by default if Chromium or Chromium-based browsers are not a development build and is running on a Linux environment. [13]

To enable this feature, launch your browser with the --enable-features=MiddleClickAutoscroll flag. In case you want to make the option persistent, see #Making flags persistent.

Install libfido2 library. This provides the udev rules required to enable access to the U2F key as a user. U2F keys are by default only accessible by root, and without these rules Chromium will give an error.

You can make Chromium use your current GTK theme for browser menus and controls. Simply press Use GTK in chrome://settings/appearance.

Since Chromium 114, XDG Desktop Portal is used to automatically determine the user's preferred appearance (issue), thereby dissociating dark mode enablement from the user's GTK theme. This preference will be applied to prefers-color-scheme in CSS, JavaScript, Settings and Dev-Tools.

The way to change the preferred appearance depends on your XDG Desktop Portal backend. For instance, many desktop environments have a switch in their appearance settings. Or when using e.g. xdg-desktop-portal-gtk, set the preferred mode to prefer-light, prefer-dark or default with:

You can query the current preferred appearance using dbus-send in dbus (documentation):

To enable dark mode and enable the dark theme (normally used for incognito mode) append the following flag to persistent configuration:

The Side Panel can be enabled through chrome://flags. You can enable or disable Side panel, and change options such as Side panel border and Side panel drag and drop.

Chromium uses SQLite databases to manage history and the like. Sqlite databases become fragmented over time and empty spaces appear all around. But, since there are no managing processes checking and optimizing the database, these factors eventually result in a performance hit. A good way to improve startup and some other bookmarks- and history-related tasks is to defragment and trim unused space from these databases.

profile-cleaner and browser-vacuumAUR do just this.

At the cost of reduced performance, you can disable just-in-time compilation of JavaScript to native code, which is responsible for roughly half of the security vulnerabilities in the JS engine, using the flag --js-flags=--jitless.

WebRTC is a communication protocol that relies on JavaScript that can leak one's actual IP address and hardware hash from behind a VPN. While some software may prevent the leaking scripts from running, it is probably a good idea to block this protocol directly as well, just to be safe. As of October 2016, there is no way to disable WebRTC on Chromium on desktop, there are extensions available to disable local IP address leak, one is this extension.

One can test WebRTC via https://browserleaks.com/webrtc.

See #Certificates for general information.

Grab the CAcerts and create an nssdb, if one does not already exist. To do this, first install the nss package, then complete these steps:

Now users may manually import a self-signed certificate.

Below is a simple script that will extract and add a certificate to the user's nssdb:

Syntax is advertised in the commented lines.

The firefox browser can be used to save the certificate to a file for manual import into the database.

Now import the certificate for use in Chromium:

Canvas fingerprinting is a technique that allows websites to identify users by detecting differences when rendering to an HTML5 canvas. This information can be made inaccessible by using the --disable-reading-from-canvas flag.

To confirm this is working run this test and make sure "hash of canvas fingerprint" is reported as undetermined in the full results.

See Browser extensions#Privacy.

To enable Do Not Track, visit chrome://settings, scroll down to Advanced and under Privacy and security, check Send a "Do Not Track" request with your browsing traffic.

Chromium uses a password store to store your passwords and the Chromium Safe Storage key, which is used to encrypt cookie values. [14]

By default Chromium auto-detects which password store to use, which can lead to you apparently losing your passwords and cookies when switching to another desktop environment or window manager.

You can force Chromium to use a specific password store by launching it with the --password-store flag with one of following the values [15]:

For example, to force Chromium to use Gnome Keyring in another desktop or WM use --password-store=gnome-libsecret, see #Making flags persistent for making it permanent.

When using a password store of another desktop environment you probably also want to unlock it automatically. See GNOME/Keyring#Using the keyring and KDE Wallet#Unlock KDE Wallet automatically on login.

Chromium supports the hybrid post-quantum key exchange X25519Kyber768 for TLS 1.3 since version 155 [16]. This feature is disabled by default, but can be enabled using the chrome://flags/#enable-tls13-kyber flag.

You can open any website in a tabless window intended for Progressive Web Apps:

You need to use a correct full URL. This could be combined with --user-data-dir to split configs. Local html file is also used at native application with --allow-file-access-from-files --app=file://*.

You can force offline state by --proxy-server=dummy for security when you use local html file from Chromium.

Chromium has --enable-parallel-downloading flag for parallel downloading without extensions.

Chromium will use the GTK settings as described in GTK#Configuration. When configured, Chromium will use the gtk-font-name setting for tabs (which may mismatch window font size). To override these settings, use --force-device-scale-factor=1.0.

Since Chrome Refresh 2023 became default, GNOME users with Cantarell font may notice some characters (like lowercase g) cut off in the tab title. See the issue on chromium.org.

Until the issue resolved, a workaround is to replace Cantarell with another font using a configuration based on Font configuration#Set default or fallback fonts, e.g.

This configuration will apply only if process name chromium matches. You can use chrome for Google Chrome.

There is the possibility that your graphics card has been blacklisted by Chromium. See #Force GPU acceleration.

If you are using Chromium with Bumblebee, WebGL might crash due to GPU sandboxing. In this case, you can disable GPU sandboxing with optirun chromium --disable-gpu-sandbox.

Visit chrome://gpu/ for debugging information about WebGL support.

Chromium can save incorrect data about your GPU in your user profile (e.g. if you use switch between an Nvidia card using Optimus and Intel, it will show the Nvidia card in chrome://gpu even when you are not using it or primusrun/optirun). Running using a different user directory, e.g, chromium --user-data-dir=$(mktemp -d) may solve this issue. For a persistent solution you can reset the GPU information by deleting ~/.config/chromium/Local\ State.

Chromium will automatically scale for a HiDPI display, however, this may cause an incorrect rendered GUI.

The flag --force-device-scale-factor=1 may be used to overrule the automatic scaling factor.

When native Wayland support is enabled, Chromium will automatically scale based on the configured scale of each monitor.

See GNOME/Keyring#Passwords are not remembered.

If synchronization is not working for password only (you can check it on chrome://sync-internals/) delete profile login data:

See Google Chrome Help forum for details.

If you see the message Failed to decrypt token for service AccountId-* in the terminal when you start Chromium, it might try to use the wrong password storage backend. This might happen when you switch between Desktop Environments.

See #Force a password store.

Try launching Chrome with --password-store=basic or another appropriate password store.

See #Force a password store.

If you are using KDE and have once set Firefox as the default browser (by clicking the button inside Firefox), you might find Chromium asks to be set as the default browser every time it starts, even if you click the "set as default" button.

Chromium checks for this status by running xdg-settings check default-web-browser chromium.desktop. If the output is "no", it is not considering itself to be the default browser. The script xdg-settings checks for the following MIME associations and expect all of them to be chromium.desktop:

To fix it, go to System settings > Applications > Default applications > Web browser and choose Chromium. Then, set the MIME association for text/html:

Finally, update the MIME database:

As of 2020.04.20 if you run chromium with --remote-debugging-port=9222 flag for web development, you cannot log in to your Google account. Temporarily disable this flag to login and then you can enable it back.

Upstream bug report about the general issue which may contain some additional workarounds can be found here, and a sister issue about mixed refresh rates here.

When using displays with mixed refresh rates(for example 60Hz and 144Hz), Chromium might render for the lower Hz display.

There is a suitable workaround for this issue, append the following flags to persistent configuration:

This should make Chromium run at 144 FPS when used on a 144Hz display, assuming your compositor is also refreshing at 144 FPS. Keep in mind it might be a little choppy due to FS#67035, but it is way better than being stuck at 60 FPS.

There seem to be Wayland compositor-specific problems that trigger this issue. Notably, Plasma 5 seems to only ever render on 60Hz no matter the setup, but Plasma 6(rc1, at the time of writing) makes Chromium work flawlessly on high refresh rates.

A workaround may be to switch to the XWayland backend if all else fails.

Mouse whell scrolling in chromium and electron based applications may be too slow for daily usage. Here are some solutions.

Libinput#Mouse wheel scrolling speed scaling injects libinput_event_pointer_get_axis_value function in libinput and provides an interface to change scale factor. This is not an application level injection, so an addition script for application specific scale factor tuning is needed. Note that scroll on chromium's small height developer tools may be too fast when scale factor is big enough.

IMWheel increases scroll distance by replaying X wheel button event for multiple times. However, chromium assumes the real scroll and the replayed ones as two events. There is a small but noticeable delay between them, so one mouse wheel scroll leads to twice page jumps. Also, touchpad scroll needs additional care.

Linux Scroll Speed Fix and SmoothScroll are two chromium extensions with support for scroll distance modification. Upon wheel scroll in a web page, the closest scrollable ancestor of current focused node will be found, then a scroll method with given pixel distance will be called on it, even if it has been scrolled to bottom. So once you scroll into a text editor or any scrollable element, you can never scroll out of it, except moving mouse. Also, extension based methods can not be used outside chromium.

This article or section is out of date.

This may be a PulseAudio issue. See the suggested fix in PulseAudio/Troubleshooting#Browsers (firefox) load videos but do no play.

The stored password database can become corrupted and in need of getting rebuilt. Doing so will destroy all data therein/lose stored passwords.

Launch chromium from a terminal and look for output like:

Exit chromium and then delete these three database files: ~/.config/chromium/Default/Login Data*

Launching chromium again should re-create them.

See KDE#Plasma cursor sometimes shown incorrectly.

Due to a bug, chromium 124 must be started with the explicit command line flag --ozone-platform=wayland.

Due to a bug, you may see the below in your log when launching from terminal, especially with hardware acceleration enabled on Wayland:

Workaround for now is adding this flag:

Chromium does not support Advanced Linux Sound Architecture#Addressing hardware directly. Set output devices pcm.dmixer and pcm.dsnooper as seen in the page and use -alsa-output-device=pcm.dmixer -alsa-input-device=pcm.dsnooper flags.

Due to extensions which define global shortcuts (such as obsidian web clipper), the gnome "Global Shortcuts" appears at startup. This is described in https://github.com/brave/brave-browser/issues/44886 and can be fixed by adding this flag:

Due to a bug the "Compose" key does not work in recent versions of chromium. This becomes apparent when user tries to type in special characters such as `@` or umlauts anywhere in the browser. The special key combinations utilizing the compose key (for example `ALT GR`) work in all applications except chromium. This issue is most likely related to gtk and cannot be resolved by switching between Wayland and X11. It is described at https://issues.chromium.org/issues/327158031 and can be fixed by adding this flag:

**Examples:**

Example 1 (unknown):
```unknown
chrome://certificate-manager
```

Example 2 (unknown):
```unknown
ServerCertificate
```

Example 3 (unknown):
```unknown
~/.pki/nssdb
```

Example 4 (unknown):
```unknown
chromium-flags.conf
```

---

## VMware

**URL:** https://wiki.archlinux.org/title/VMware

**Contents:**
- Installation
- Usage
- Tips and tricks
  - Entering the Workstation Pro license key
    - From terminal
    - From GUI
  - Extracting the VMware BIOS
  - Extracting the installer
    - Using the modified BIOS
  - Enable 3D graphics on Intel, Optimus and AMD

This article is about the latest major VMware versions, meaning VMware Workstation Pro and Player 17, 16, 15, 14 and 12.5.

You may also be interested in /Install Arch Linux as a guest.

Install the vmware-workstationAUR package.

It is also necessary to install the appropriate headers package(s) for your installed kernel(s): for example linux-headers or linux-lts-headers.

Start vmware-networks-configuration.service first to generate /etc/vmware/networking.

Then, as desired, enable some of the following services:

Lastly, load the VMware modules:

If it loads for too long without response, try #Cannot load module vmmon.

To open VMware Workstation Pro:

Where XXXXX-XXXXX-XXXXX-XXXXX-XXXXX is your license key.

If the above does not work, you can try:

To view the contents of the installer .bundle:

If and when you decide to modify the extracted BIOS you can make your virtual machine use it by moving it to ~/vmware/Virtual_machine_name:

then adding the name to the Virtual_machine_name.vmx file:

Some graphics drivers are blacklisted by default, due to poor and/or unstable 3D acceleration. After enabling Accelerate 3D graphics, the log may show something like:

The configuration file where you can set this setting is ~/.vmware/preferences.

VMware Workstation 16.2 switched from OpenGL to Vulkan, so the setting is a bit different. If your driver is unsupported, you might see a message like this in the log:

If your Vulkan driver is blacklisted, you might have to add mks.vk.allowUnsupportedDevices = "TRUE" to ~/.vmware/preferences or switch to a supported driver - check vmware.log in the VM's directory if unsure.

When using Vulkan with multiple graphics adapters (GPUs) a specific device can be chosen by examining mksSandbox.log to retrieve the correct adapter string then placing it into the VM's .vmx file. Example from mksSandbox.log:

Then to the VM's .vmx file we would add:

Create an executable file:

See also Power management/Suspend and hibernate#Hooks in /usr/lib/systemd/system-sleep, suspend all virtual machines with vmrun and Support for hibernation.

See also Improving performance.

This article or section is a candidate for merging with Improving performance.

If you notice the guest and/or the host frequently freezing when running a VM, you may want to disable transparent hugepages. To disable them for the current session, run (on the host):

To make the change persistent across boots, add the kernel parameter transparent_hugepage=never.

You can also use madvise instead of never to still allow applications that are optimized for transparent hugepages to obtain the performance benefits[1]. This does the same for vmware as above.

By default, VMware writes a running guest system's RAM to a file on disk. If you are certain you have enough spare memory, you can ensure the guest OS writes its memory directly to the host's RAM by adding the following to the VM's .vmx:

To improve the performance of your virtual machine, try the following tips:

VMware Paravirtual SCSI (PVSCSI) adapters are high-performance storage adapters for VMware ESXi that can result in greater throughput and lower CPU utilization. PVSCSI adapters are best suited for environments, where hardware or applications drive a very high amount of I/O throughput.

The SCSI adapter type VMware Paravirtual is available in the Virtual Machine settings.

If these settings are not in the virtual machine's configuration, the paravirtual SCSI adapter can still be enabled. Ensure that the paravirtual SCSI adapter is included in the kernel image by modifying the mkinitcpio.conf:

Regenerate the initramfs.

Shut down the virtual machine and change the SCSI adapter: set the .vmx to the following:

VMware offers multiple network adapters for the guest OS. The default adapter used is usually the e1000 adapter, which emulates an Intel 82545EM Gigabit Ethernet NIC. This Intel adapter is generally compatible with the built-in drivers across most operating systems, including Arch.

For more performance and additional features (such as multiqueue support), the VMware native vmxnet3 network adapter can be used.

Arch has the vmxnet3 kernel module available with a default install. Once enabled in mkinitcpio (or if it is auto-detected; check by running lsmod | grep vmxnet3 to see if it is loaded), shut down and change the network adapter type in the .vmx file to the following:

After changing network adapters, the network and dhcpcd settings will need to be updated to use the new adapter name and MAC address.

The new interface name can be obtained by running ip link.

These settings could help improve the responsiveness of the virtual machine by reducing disk I/O, at the expense of using more host memory. Vmware's KB1008885 provides the following optimizations:

The following settings can also be set in the configuration dialog of VMware Workstation(Edit -> Preferences... -> Memory/Priority).

Install the headers (linux-headers).

As VMware Comunity explained, please disable Secure Boot to use vmmon to load the VMware module.

VMware Workstation provides the possibility to remotely manage Shared VMs through the vmware-workstation-server service. However, this will fail with the error "incorrect username/password" due to incorrect PAM configuration of the vmware-authd service. To fix it, edit /etc/pam.d/vmware-authd like this:

and restart the vmware systemd service.

Now you can connect to the server with the credentials provided during the installation.

To fix sound quality issues or enabling proper HD audio output, first run:

If interested in playing 5.1 surround sound from the guest, look for surround51:CARD=vendor_name,DEV=num, if experiencing quality issues, look for front:CARD=vendor_name,DEV=num. Finally put the name in the .vmx:

OSS emulation should also be disabled.

To disable KVM on boot, you can use something like:

VMWare Player/Workstation 17.5 (and older) have issues discussed here.

To allow the user interface to capture the keyboard:

As an alternative, you can use the following keyboard shortcuts in Windows:

This means that at least the vmmon module is not loaded. Enable the services (see #Installation) for automatic loading.

Another possible reason is Indirect Branch Tracking on 11th Gen and later Intel processors and starting from kernel 5.18.

Add ibt=off to your kernel command line. See [2] for more details.

First, try to manually load the modules

Try to recompile VMware kernel modules with:

Version 14 has stricter CPU requirements than version 12. If you try to start a virtual machine with an affected CPU, the following message will appear:

The solution is to uninstall version 14 and install version 12 (vmware-workstation12AUR).

When VMware was usable and this error suddenly appears it could be due to a warm/soft boot or after suspending the system. Please try a cold boot (shutting the system down and starting it again).

Old Intel microcode may result in the following kind of segmentation fault at startup:

See Microcode for how to update the microcode.

On systems with librsvg version 2:2.44.0 and above, the log files (located in /tmp/vmware-<id>) show several instances of the following error:

A workaround is to downgrade librsvg to earlier version, or more preferably, force VMware to use its own shipped version of librsvg:

VMware also has a VMWARE_USE_SHIPPED_LIBS variable:

As per [3] the temporary workaround is to downgrade the package libpng to version 1.6.28-1 and keep it in the IgnorePkg parameter in /etc/pacman.conf.

An easier workaround is to make VMWare use the system's version of zlib instead of its own one:

It seems to be a problem with the file /usr/lib/vmware/lib/libstdc++.so.6/libstdc++.so.6, missing CXXABI_1.3.8.

If the system have installed gcc-libs, that library is already installed. Therefore, it is possible to remove that file and vmplayer will use the one provided by gcc-libs instead. As root do:

Also there is a workaround:

Registered bug at Mageia, but it seems that there are no error messages shown in terminal with arch. When inspecting the logs, which are in /tmp/vmware-<id>, there are VMWARE_SHIPPED_LIBS_LIST is not set, VMWARE_SYSTEM_LIBS_LIST is not set, VMWARE_USE_SHIPPED_LIBS is not set, VMWARE_USE_SYSTEM_LIBS is not set issues. Process simply terminates with Unable to execute /usr/lib/vmware/bin/vmware-modconfig. after vmware or vmplayer is executed. Solution is the same, as root do:

Also there is a workaround:

Despite setting the VMWARE_USE_SHIPPED_LIBS variable, VMWare may still fail to find certain libraries. An example is the libfontconfig.so.1 library. Check vmware logs in the tmp directory to see which libraries are still not found. Copy them to the appropriate path with libraries existing on the system:

Instead of copying all these files manually, you may want to try exporting an additional setting:

On systems with fontconfig version 2.13.0 and above, it may be needed to force VMware to use the shipped libfontconfig file instead of the newer system file. In such case, it is also necessary to provide a shared object library file libexpat.so.0 for the shipped fontconfig. This applies for at least VMware version 12.5.9. As root do:

To download the tools manually, visit the VMware repository[dead link 2025-04-06—domain name not resolved].

Navigate to: "application name / version / build ID / linux / packages/" and download the appropriate Tools.

And install using the VMware installer:

If the above does not work, try installing ncurses5-compat-libsAUR.

This is likely due to the vmnet module not being loaded [4]. Enable the services (see #Installation) for automatic loading.

If your mouse's thumb buttons or other additional buttons do not work, set guest to use advanced mouse.

This is related to the current Xorg keyboard layout on Host system. Keep primary layout (e.g., English) selected on Host while working on Guest.

This issue is related to promiscuous mode which, following standard Linux practice, can only be enabled by the root user. To work around these limitations, the permissions for the networking device in question have to be changed.

Give permissions to one group:

Give permissions to all users:

**Examples:**

Example 1 (unknown):
```unknown
vmware-networks-configuration.service
```

Example 2 (unknown):
```unknown
/etc/vmware/networking
```

Example 3 (unknown):
```unknown
vmware-networks.service
```

Example 4 (unknown):
```unknown
could no connect 'ethernet 0' to virtual network
```

---

## cwc

**URL:** https://wiki.archlinux.org/title/Cwc

**Contents:**
- Installation
- Starting
  - LXQT
- Configuration
  - Creating the configuration file
  - Autostart
    - Wallpaper
- Tips and tricks
  - Screenshot
  - Removing window gaps

Install the cwcAUR package.

Select cwc from the menu in a display manager of choice.

System-wide cwc configuration files are in /usr/share/cwc/defconfig/ while user configuration files are in ~/.config/cwc:

First, run the following to create the directory needed in the next step:

Whenever started, cwc will attempt to use whatever custom settings are contained in ~/.config/cwc/rc.lua. Then fall back to /usr/share/cwc/defconfig/ This file is not created by default, so we must copy the template file first:

autostarting is done by

you can use a wallpaper setter such as feh or swww

See Keyboard input to ensure the PrtSc button is assigned correctly. Then install a screen capturing program such as flameshot

Add to the globalkeys array:

it is possible to remove the small gaps between windows; in the screen/tag config table there is a properties section, add to it

It is possible to control both volume and media playback via a combination of amixer(1) (available via the alsa-utils package) and playerctl. The following can be added to the relevant key binding section of your rc.lua configuration file:

To use cwc with waybar you will need to load the plugin:

Then follow the dwl waybar page

See Java#Gray window, applications not resizing with WM, menus immediately closing and [1].

**Examples:**

Example 1 (unknown):
```unknown
/usr/share/cwc/defconfig/
```

Example 2 (unknown):
```unknown
~/.config/cwc
```

Example 3 (unknown):
```unknown
$ mkdir -p ~/.config/cwc/
```

Example 4 (unknown):
```unknown
/usr/share/cwc/defconfig/
```

---

## Electron

**URL:** https://wiki.archlinux.org/title/Electron

**Contents:**
- Installation
- Tips and tricks
  - Configuration files
  - Determine the version of Electron an application uses
  - Secret Service API
  - Turn any website to application
  - Enable Wayland

Electron is an application developed by GitHub to build cross platform desktop apps using web technologies. They are rendered using the Chromium browser engine and back end is using the Node.js runtime environment.

Install the electron package for the latest version.

Some applications require older electron versions. You can install previous versions in parallel with latest. The corresponding packages are suffixed with version number, for example electron30AUR.

The electron command reads command-line flags from $XDG_CONFIG_HOME/electronXX-flags.conf files, where XX is the Electron version, or falls back to $XDG_CONFIG_HOME/electron-flags.conf if the former is not present. ($XDG_CONFIG_HOME defaults to ~/.config if not set.)

Lines starting with a hash # are treated as comments and ignored, but other lines are passed as CLI arguments to the actual Electron binary, one per line (lines are not split on whitespace!), before the options passed to the electron command itself.

This can be useful, for example, to #Enable Wayland globally.

If installed through your package manager, you can query the package's dependencies to see if it depends on e.g. electron38, meaning it uses Electron 38. (If it depends on electron: this package is designed to always provide the latest version of Electron; to learn which version this currently is, query that package's dependencies.)

It is also possible to determine the version of Electron from a running application by using its developer tools; see [1].

Electron provides the safestorage API to interact with a keyring compatible with the FreeDesktop.org's Secret Service API. Example of supported keyrings are GNOME/Keyring through GNOME libsecret, KDE Wallet and KeePass.

The backend can be chosen on the command-line with the --password-store flag when running an Electron application. As an example, running electron-desktop (built with Electron) to interact with libsecret or KeePass:

Sometimes you need to use a specific web site, but use it as an application. With nodejs-nativefierAUR you can turn any website to an electron application. For example, there is a website showing you the pressed buttons on the gamepad, and you want to create a separate window for that. Run:

Now in your home directory there will be a binary ~/gamepad-overlay-linux-x64/gamepad-overlay. You can run it and have the gamepad overlay in its own window.

For more options, see the project homepage.

See Wayland#Electron.

**Examples:**

Example 1 (unknown):
```unknown
$XDG_CONFIG_HOME/electronXX-flags.conf
```

Example 2 (unknown):
```unknown
$XDG_CONFIG_HOME/electron-flags.conf
```

Example 3 (unknown):
```unknown
$XDG_CONFIG_HOME
```

Example 4 (unknown):
```unknown
~/.config/electron-flags.conf
```

---

## ThinkFinger

**URL:** https://wiki.archlinux.org/title/ThinkFinger

**Contents:**
- Installation
- Configuration
  - TF-Tool
- PAM
  - /etc/pam.d/login
  - /etc/pam.d/su
  - /etc/pam.d/sudo
  - /etc/pam.d/xscreensaver
  - /etc/pam.d/gdm
  - /etc/pam.d/xdm

ThinkFinger is a driver for the SGS Thomson Microelectronics fingerprint reader found in older IBM/Lenovo ThinkPads.

ThinkWiki has a list of various fingerprint readers found in ThinkPads. Newer models using different readers might not work with ThinkFinger.

Install the thinkfingerAUR package.

The uinput module needs to be loaded.

Use tf-tool to test ThinkFinger. You will have to run this as root because a direct access to the USB devices is needed. Run tf-tool --acquire to generate a file at /etc/pam_thinkfinger/test.bir and tf-tool --verify to see if it identifies you correctly. tf-tool --add-user <username> acquires and stores your fingerprint in /etc/pam_thinkfinger/<username>.bir, which is needed for an authentication with PAM.

Change the file /etc/pam.d/login to look like this if you want to use your fingerprint to authenticate yourself on logon:

Change this file to confirm the su command with a finger-swipe:

Change this file to confirm the sudo command with a finger-swipe:

The factual accuracy of this article or section is disputed.

XScreensaver is a bit tricky. First, configure PAM with a file /etc/pam.d/xscreensaver containing:

This still will not work because Xscreensaver cannot read/write from /dev/misc/uinput and /dev/bus/usb*. A udev rule must be written to authorize a new group read/write access.

First, create a new group, let us say fingerprint:

Add the user you want to be able to unlock Xscreensaver with the fingerprint reader to the group:

Logout and login again for the changes to take effect.

Next, search for uinput and bus/usb in your udev rules directory:

Copy the lines you found with grep in the previous step to a new udev rules file:

The difference between the rules in /etc/udev/rules.d/99fingreprint.rules and those in /etc/udev/rules.d/udev.rules should only be the addition of MODE="0664", GROUP="fingerprint" or MODE="0660", GROUP="fingerprint" at the end of the lines.

After adding the custom udev rules, you should give your user permissions to access their own fingerprint file:

As a last step, you need to remove the root setuid from /usr/bin/xscreensaver, otherwise Xscreensaver will not be able to unlock with the fingerprint reader:

Edit /etc/pam.d/gdm and add the following line to the top:

Then modify auth required pam_unix.so to look like this:

Edit /etc/pam.d/xdm to look like this:

Append the following to /etc/pam.d/slim:

Now restart SLiM and you may use the fingerprinter to login.

Fprint is an alternative fingerprint reader software that works with some of the newer ThinkPad fingerprint readers.

**Examples:**

Example 1 (unknown):
```unknown
tf-tool --acquire
```

Example 2 (unknown):
```unknown
/etc/pam_thinkfinger/test.bir
```

Example 3 (unknown):
```unknown
tf-tool --verify
```

Example 4 (unknown):
```unknown
tf-tool --add-user <username>
```

---

## Ruby

**URL:** https://wiki.archlinux.org/title/Ruby

**Contents:**
- Installation
  - Multiple versions
  - Documentation
  - JRuby
  - Standard Library
- RubyGems
  - Configuration
  - Usage
  - Installing gems system-wide
  - Bundler

Ruby is a dynamic, interpreted, open source programming language with a focus on simplicity and productivity.

To use Ruby, install the ruby package.

To install IRB, install the ruby-irb package.

If you want to run multiple versions on the same system (e.g. 2.0.0-p0 and 1.9.3-p392), the easiest way is to use one of RVM, chrubyAUR, rbenv, asdf-vmAUR.

To make documentation available through the ri command-line tool, install ruby-rdoc and ruby-docs for the documentation itself. You can then query the docs with: ri Array, ri Array.pop etc. (much like man-pages)

The Java implementation of Ruby, JRuby can be installed with the jruby package.

Part of Ruby's standard library consists of Ruby modules (see RubyGems for more information about modules.) The ruby package does not include all of the standard modules that a Ruby user can assume to be installed on any Ruby system, so some Ruby code may not work out-of-the-box. More information about the set of standard library modules can be found at https://stdgems.org/.

The RubyGems section discusses several methods for installing modules. To install the standard modules system-wide using pacman, one can install the ruby-stdlib package. Note that this is not needed for JRuby, as the jruby package includes the standard modules.

RubyGems is a package manager for Ruby modules (called gems), somewhat comparable to what pacman is to Arch Linux. It can be installed with the rubygems package, which is a dependency of ruby.

By default in Arch Linux, when running gem, gems are installed per-user (into ~/.local/share/gem/ruby/), instead of system-wide (into /usr/lib/ruby/gems/). This is considered the best way to manage gems on Arch, because otherwise they might interfere with gems installed by Pacman.

The recommended way to setup that is by manually specifying your $GEM_HOME, which then can be appended to your $PATH environment variable in order to allow RubyGems binaries to be executed:

This is required for executable gems to work without typing out the full location, although libraries will work without having to modify your path.

Use gem env to view the current RubyGems environment:

To see what gems are installed:

To get information about a gem:

By default, gem list and gem spec use the --local option, which forces gem to search only the local system. This can be overridden with the --remote flag. Thus, to search for the mysql2 gem:

The process can be sped up somewhat if you do not need local documentation:

To update all installed gems:

Gems can be installed system wide by running the gem command as root, appended with the --no-user-install flag. This flag can be set as default by replacing --user-install by --no-user-install in /etc/gemrc (system-wide) or ~/.gemrc (per-user, overrides system-wide).

Bundler can be used to avoid system-wide gem installations by packaging gems into your application. See the section below on using bundler.

Bundler allows you to specify which gems your application depends upon, and optionally which version those gems should be. Once this specification is in place, Bundler installs all required gems (including the full gem dependency tree) and logs the results for later inspection. By default, Bundler installs gems into a shared location, but they can also be installed directly into your application. When your application is run, Bundler provides the correct version of each gem, even if multiple versions of each gem have been installed. This requires a little bit of work: applications should be called with bundle exec, and two lines of boilerplate code must be placed in your application's main executable.

To start a new bundle:

Then edit Gemfile in the current directory (created by bundle init) and list your required gems:

Run the following to install gems into GEM_HOME:

Alternatively, run the following to install gems to .bundle in the working directory:

Do not forget to edit your main executable:

Finally, run your program:

Instead of managing gems with gem, you can use pacman, or an AUR helper. Ruby packages follow the naming convention ruby-gemname.

This option provides the following advantages:

Quarry is a tool that allows to maintain a rubygems binary repository for Arch Linux, as an easier alternative to building packages manually from the AUR. The source is hosted at Github.

The repository is maintained by the Arch developer anatolik at https://pkgbuild.com/~anatolik/quarry/. It contains many popular gems and new gems can be added upon request.

See Unofficial user repositories#quarry to enable it.

Then install the required gem. The name of the package is ruby-gem name.

General questions can be asked at https://bbs.archlinux.org/viewtopic.php?id=182729.

Pry is a powerful alternative to the standard IRB shell for Ruby. It features syntax highlighting, a flexible plugin architecture, runtime invocation and source and documentation browsing.

**Examples:**

Example 1 (unknown):
```unknown
ri Array.pop
```

Example 2 (unknown):
```unknown
~/.local/share/gem/ruby/
```

Example 3 (unknown):
```unknown
/usr/lib/ruby/gems/
```

Example 4 (unknown):
```unknown
export GEM_HOME="$(gem env user_gemhome)"
export PATH="$PATH:$GEM_HOME/bin"
```

---
